{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5f081cf4e20d49beb5e47f66b79f8626": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_c34d06845f7d4977b245bbd13c836a99"
          }
        },
        "e2a43e7b81364e61b9fc8c28a7d1f188": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33081c405bdb4deab6a54ec8af97c871",
            "placeholder": "​",
            "style": "IPY_MODEL_a121e7fe6a0446619fec3194d8e3d798",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "1328fe537bf940219d1810bfa4d5cd95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_d76acfe8d5684455b575221758e4666b",
            "placeholder": "​",
            "style": "IPY_MODEL_aba8b406d27a4794940f8afafda463e7",
            "value": ""
          }
        },
        "8eb8f9cd2f8e46a8b997e44c95aa7396": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_47594bbcf79c4b76baf85448953e6c1a",
            "style": "IPY_MODEL_d8f5fa9fef1d42658873c3888e1da4e5",
            "value": true
          }
        },
        "6bd19859a55a474e9503e2bed766fb9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_8173029662b549a5862cce13aa65c920",
            "style": "IPY_MODEL_3713e9fafa844177a759441a9f974ddc",
            "tooltip": ""
          }
        },
        "4f8652944bd84e7cbcdaa503112166b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfe13da7f7314783804b54bf95f1572f",
            "placeholder": "​",
            "style": "IPY_MODEL_4839d56c110c4473b6a01521c3da96a7",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "c34d06845f7d4977b245bbd13c836a99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "33081c405bdb4deab6a54ec8af97c871": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a121e7fe6a0446619fec3194d8e3d798": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d76acfe8d5684455b575221758e4666b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aba8b406d27a4794940f8afafda463e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47594bbcf79c4b76baf85448953e6c1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8f5fa9fef1d42658873c3888e1da4e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8173029662b549a5862cce13aa65c920": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3713e9fafa844177a759441a9f974ddc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "bfe13da7f7314783804b54bf95f1572f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4839d56c110c4473b6a01521c3da96a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78b807e7e7ad4f16af91a2ef6acf2ac6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57c775949d484702adb4aecef6074c38",
            "placeholder": "​",
            "style": "IPY_MODEL_01a47ba6f1f34f129128a793ecd64c40",
            "value": "Connecting..."
          }
        },
        "57c775949d484702adb4aecef6074c38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01a47ba6f1f34f129128a793ecd64c40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "N1vXw1HpnudY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2861821-8f60-4e5e-ac93-3068c4b3a30d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MedVLMBench'...\n",
            "remote: Enumerating objects: 2979, done.\u001b[K\n",
            "remote: Counting objects: 100% (563/563), done.\u001b[K\n",
            "remote: Compressing objects: 100% (440/440), done.\u001b[K\n",
            "remote: Total 2979 (delta 286), reused 333 (delta 113), pack-reused 2416 (from 1)\u001b[K\n",
            "Receiving objects: 100% (2979/2979), 11.99 MiB | 17.69 MiB/s, done.\n",
            "Resolving deltas: 100% (1717/1717), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Nanboy-Ronan/MedVLMBench.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd MedVLMBench"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oOTRFga5Is4",
        "outputId": "b7d6d94e-6583-4dfe-d706-dfaab0940a09"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MedVLMBench\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U pip setuptools wheel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5705T-ZaN8Os",
        "outputId": "4dcd9525-de2f-4f60-c477-512c09b49ba5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (25.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (80.9.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.12/dist-packages (0.45.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Note that the notebook rely on the other part of the colab environemtn (e.g., torch), which may be updated frequently. You can refer to the next cell to observe the specific package.\n",
        "!pip install torchmetrics\n",
        "!pip install bert-score==0.3.13\n",
        "!pip install qwen-vl-utils==0.0.10\n",
        "!pip install flash-attn --no-build-isolation"
      ],
      "metadata": {
        "id": "gIf7atLp5N_W",
        "outputId": "80fb2900-85ff-41d3-f03d-cfdf4ffb596d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.12/dist-packages (1.8.2)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.0.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (25.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.8.0+cu126)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (0.15.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (80.9.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.19.1)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n",
            "Requirement already satisfied: bert-score==0.3.13 in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from bert-score==0.3.13) (2.8.0+cu126)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from bert-score==0.3.13) (2.2.2)\n",
            "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from bert-score==0.3.13) (4.56.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from bert-score==0.3.13) (2.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from bert-score==0.3.13) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.12/dist-packages (from bert-score==0.3.13) (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from bert-score==0.3.13) (3.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from bert-score==0.3.13) (25.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.1->bert-score==0.3.13) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.1->bert-score==0.3.13) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.1->bert-score==0.3.13) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score==0.3.13) (1.17.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score==0.3.13) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score==0.3.13) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score==0.3.13) (80.9.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score==0.3.13) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score==0.3.13) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score==0.3.13) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score==0.3.13) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score==0.3.13) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score==0.3.13) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score==0.3.13) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score==0.3.13) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score==0.3.13) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score==0.3.13) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score==0.3.13) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score==0.3.13) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score==0.3.13) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score==0.3.13) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score==0.3.13) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score==0.3.13) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score==0.3.13) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score==0.3.13) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score==0.3.13) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.0.0->bert-score==0.3.13) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert-score==0.3.13) (0.34.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert-score==0.3.13) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert-score==0.3.13) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert-score==0.3.13) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert-score==0.3.13) (0.6.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=3.0.0->bert-score==0.3.13) (1.1.9)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.0.0->bert-score==0.3.13) (3.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score==0.3.13) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score==0.3.13) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score==0.3.13) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score==0.3.13) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score==0.3.13) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score==0.3.13) (3.2.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->bert-score==0.3.13) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->bert-score==0.3.13) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->bert-score==0.3.13) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->bert-score==0.3.13) (2025.8.3)\n",
            "Requirement already satisfied: qwen-vl-utils==0.0.10 in /usr/local/lib/python3.12/dist-packages (0.0.10)\n",
            "Requirement already satisfied: av in /usr/local/lib/python3.12/dist-packages (from qwen-vl-utils==0.0.10) (15.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from qwen-vl-utils==0.0.10) (25.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from qwen-vl-utils==0.0.10) (11.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from qwen-vl-utils==0.0.10) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->qwen-vl-utils==0.0.10) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->qwen-vl-utils==0.0.10) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->qwen-vl-utils==0.0.10) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->qwen-vl-utils==0.0.10) (2025.8.3)\n",
            "Collecting flash-attn\n",
            "  Downloading flash_attn-2.8.3.tar.gz (8.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m121.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from flash-attn) (2.8.0+cu126)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from flash-attn) (0.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (80.9.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->flash-attn) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->flash-attn) (3.0.2)\n",
            "Building wheels for collected packages: flash-attn\n",
            "\u001b[33m  DEPRECATION: Building 'flash-attn' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'flash-attn'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
            "\u001b[0m  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flash-attn: filename=flash_attn-2.8.3-cp312-cp312-linux_x86_64.whl size=256040057 sha256=f25da18657a87fc83dc1bfb8b7751b82246e9db355510226b674fd437c34b5fb\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/59/46/f282c12c73dd4bb3c2e3fe199f1a0d0f8cec06df0cccfeee27\n",
            "Successfully built flash-attn\n",
            "Installing collected packages: flash-attn\n",
            "Successfully installed flash-attn-2.8.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1L_GouZaPLdC",
        "outputId": "b2cf23c4-438c-400d-c92a-c4af0ad455da"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "absl-py==1.4.0\n",
            "absolufy-imports==0.3.1\n",
            "accelerate==1.10.1\n",
            "aiofiles==24.1.0\n",
            "aiohappyeyeballs==2.6.1\n",
            "aiohttp==3.12.15\n",
            "aiosignal==1.4.0\n",
            "alabaster==1.0.0\n",
            "albucore==0.0.24\n",
            "albumentations==2.0.8\n",
            "ale-py==0.11.2\n",
            "alembic==1.16.5\n",
            "altair==5.5.0\n",
            "annotated-types==0.7.0\n",
            "antlr4-python3-runtime==4.9.3\n",
            "anyio==4.10.0\n",
            "anywidget==0.9.18\n",
            "argon2-cffi==25.1.0\n",
            "argon2-cffi-bindings==25.1.0\n",
            "array_record==0.8.1\n",
            "arrow==1.3.0\n",
            "arviz==0.22.0\n",
            "astropy==7.1.0\n",
            "astropy-iers-data==0.2025.9.1.0.42.11\n",
            "astunparse==1.6.3\n",
            "atpublic==5.1\n",
            "attrs==25.3.0\n",
            "audioread==3.0.1\n",
            "Authlib==1.6.3\n",
            "autograd==1.8.0\n",
            "av==15.1.0\n",
            "babel==2.17.0\n",
            "backcall==0.2.0\n",
            "beartype==0.21.0\n",
            "beautifulsoup4==4.13.5\n",
            "bert-score==0.3.13\n",
            "betterproto==2.0.0b6\n",
            "bigframes==2.17.0\n",
            "bigquery-magics==0.10.3\n",
            "bleach==6.2.0\n",
            "blinker==1.9.0\n",
            "blis==1.3.0\n",
            "blobfile==3.0.0\n",
            "blosc2==3.7.2\n",
            "bokeh==3.7.3\n",
            "Bottleneck==1.4.2\n",
            "bqplot==0.12.45\n",
            "branca==0.8.1\n",
            "Brotli==1.1.0\n",
            "build==1.3.0\n",
            "CacheControl==0.14.3\n",
            "cachetools==5.5.2\n",
            "catalogue==2.0.10\n",
            "certifi==2025.8.3\n",
            "cffi==1.17.1\n",
            "chardet==5.2.0\n",
            "charset-normalizer==3.4.3\n",
            "chex==0.1.90\n",
            "clarabel==0.11.1\n",
            "click==8.2.1\n",
            "cloudpathlib==0.22.0\n",
            "cloudpickle==3.1.1\n",
            "cmake==3.31.6\n",
            "cmdstanpy==1.2.5\n",
            "colorcet==3.1.0\n",
            "colorlover==0.3.0\n",
            "colour==0.1.5\n",
            "community==1.0.0b1\n",
            "confection==0.1.5\n",
            "cons==0.4.7\n",
            "contourpy==1.3.3\n",
            "cramjam==2.11.0\n",
            "cryptography==43.0.3\n",
            "cuda-python==12.6.2.post1\n",
            "cudf-cu12 @ https://pypi.nvidia.com/cudf-cu12/cudf_cu12-25.6.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl\n",
            "cudf-polars-cu12==25.6.0\n",
            "cufflinks==0.17.3\n",
            "cuml-cu12==25.6.0\n",
            "cupy-cuda12x==13.3.0\n",
            "curl_cffi==0.13.0\n",
            "cuvs-cu12==25.6.1\n",
            "cvxopt==1.3.2\n",
            "cvxpy==1.6.7\n",
            "cycler==0.12.1\n",
            "cyipopt==1.5.0\n",
            "cymem==2.0.11\n",
            "Cython==3.0.12\n",
            "dask==2025.5.0\n",
            "dask-cuda==25.6.0\n",
            "dask-cudf-cu12==25.6.0\n",
            "dataproc-spark-connect==0.8.3\n",
            "datasets==4.0.0\n",
            "db-dtypes==1.4.3\n",
            "dbus-python==1.2.18\n",
            "debugpy==1.8.15\n",
            "decorator==4.4.2\n",
            "defusedxml==0.7.1\n",
            "diffusers==0.35.1\n",
            "dill==0.3.8\n",
            "distributed==2025.5.0\n",
            "distributed-ucxx-cu12==0.44.0\n",
            "distro==1.9.0\n",
            "dlib==19.24.6\n",
            "dm-tree==0.1.9\n",
            "docstring_parser==0.17.0\n",
            "docutils==0.21.2\n",
            "dopamine_rl==4.1.2\n",
            "duckdb==1.3.2\n",
            "earthengine-api==1.5.24\n",
            "easydict==1.13\n",
            "editdistance==0.8.1\n",
            "eerepr==0.1.2\n",
            "einops==0.8.1\n",
            "en_core_web_sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl#sha256=1932429db727d4bff3deed6b34cfc05df17794f4a52eeb26cf8928f7c1a0fb85\n",
            "entrypoints==0.4\n",
            "et_xmlfile==2.0.0\n",
            "etils==1.13.0\n",
            "etuples==0.3.10\n",
            "Farama-Notifications==0.0.4\n",
            "fastai==2.8.4\n",
            "fastapi==0.116.1\n",
            "fastcore==1.8.8\n",
            "fastdownload==0.0.7\n",
            "fastjsonschema==2.21.2\n",
            "fastprogress==1.0.3\n",
            "fastrlock==0.8.3\n",
            "fasttransform==0.0.2\n",
            "ffmpy==0.6.1\n",
            "filelock==3.19.1\n",
            "firebase-admin==6.9.0\n",
            "flash_attn==2.8.3\n",
            "Flask==3.1.2\n",
            "flatbuffers==25.2.10\n",
            "flax==0.10.6\n",
            "folium==0.20.0\n",
            "fonttools==4.59.2\n",
            "fqdn==1.5.1\n",
            "frozendict==2.4.6\n",
            "frozenlist==1.7.0\n",
            "fsspec==2025.3.0\n",
            "future==1.0.0\n",
            "gast==0.6.0\n",
            "gcsfs==2025.3.0\n",
            "GDAL==3.8.4\n",
            "gdown==5.2.0\n",
            "geemap==0.35.3\n",
            "geocoder==1.38.1\n",
            "geographiclib==2.1\n",
            "geopandas==1.1.1\n",
            "geopy==2.4.1\n",
            "gin-config==0.5.0\n",
            "gitdb==4.0.12\n",
            "GitPython==3.1.45\n",
            "glob2==0.7\n",
            "google==2.0.3\n",
            "google-adk==1.13.0\n",
            "google-ai-generativelanguage==0.6.15\n",
            "google-api-core==2.25.1\n",
            "google-api-python-client==2.181.0\n",
            "google-auth==2.38.0\n",
            "google-auth-httplib2==0.2.0\n",
            "google-auth-oauthlib==1.2.2\n",
            "google-cloud-aiplatform==1.111.0\n",
            "google-cloud-appengine-logging==1.6.2\n",
            "google-cloud-audit-log==0.3.2\n",
            "google-cloud-bigquery==3.36.0\n",
            "google-cloud-bigquery-connection==1.18.3\n",
            "google-cloud-bigquery-storage==2.32.0\n",
            "google-cloud-bigtable==2.32.0\n",
            "google-cloud-core==2.4.3\n",
            "google-cloud-dataproc==5.21.0\n",
            "google-cloud-datastore==2.21.0\n",
            "google-cloud-firestore==2.21.0\n",
            "google-cloud-functions==1.20.4\n",
            "google-cloud-language==2.17.2\n",
            "google-cloud-logging==3.12.1\n",
            "google-cloud-resource-manager==1.14.2\n",
            "google-cloud-secret-manager==2.24.0\n",
            "google-cloud-spanner==3.57.0\n",
            "google-cloud-speech==2.33.0\n",
            "google-cloud-storage==2.19.0\n",
            "google-cloud-trace==1.16.2\n",
            "google-cloud-translate==3.21.1\n",
            "google-colab @ file:///colabtools/dist/google_colab-1.0.0.tar.gz\n",
            "google-crc32c==1.7.1\n",
            "google-genai==1.32.0\n",
            "google-generativeai==0.8.5\n",
            "google-pasta==0.2.0\n",
            "google-resumable-media==2.7.2\n",
            "googleapis-common-protos==1.70.0\n",
            "googledrivedownloader==1.1.0\n",
            "gradio==5.44.1\n",
            "gradio_client==1.12.1\n",
            "graphviz==0.21\n",
            "greenlet==3.2.4\n",
            "groovy==0.1.2\n",
            "grpc-google-iam-v1==0.14.2\n",
            "grpc-interceptor==0.15.4\n",
            "grpcio==1.74.0\n",
            "grpcio-status==1.71.2\n",
            "grpclib==0.4.8\n",
            "gspread==6.2.1\n",
            "gspread-dataframe==4.0.0\n",
            "gym==0.25.2\n",
            "gym-notices==0.1.0\n",
            "gymnasium==1.2.0\n",
            "h11==0.16.0\n",
            "h2==4.3.0\n",
            "h5netcdf==1.6.4\n",
            "h5py==3.14.0\n",
            "hdbscan==0.8.40\n",
            "hf-xet==1.1.9\n",
            "hf_transfer==0.1.9\n",
            "highspy==1.11.0\n",
            "holidays==0.80\n",
            "holoviews==1.21.0\n",
            "hpack==4.1.0\n",
            "html5lib==1.1\n",
            "httpcore==1.0.9\n",
            "httpimport==1.4.1\n",
            "httplib2==0.30.0\n",
            "httpx==0.28.1\n",
            "httpx-sse==0.4.1\n",
            "huggingface-hub==0.34.4\n",
            "humanize==4.13.0\n",
            "hyperframe==6.1.0\n",
            "hyperopt==0.2.7\n",
            "ibis-framework==9.5.0\n",
            "idna==3.10\n",
            "imageio==2.37.0\n",
            "imageio-ffmpeg==0.6.0\n",
            "imagesize==1.4.1\n",
            "imbalanced-learn==0.14.0\n",
            "immutabledict==4.2.1\n",
            "importlib_metadata==8.7.0\n",
            "importlib_resources==6.5.2\n",
            "imutils==0.5.4\n",
            "inflect==7.5.0\n",
            "iniconfig==2.1.0\n",
            "intel-cmplr-lib-ur==2025.2.1\n",
            "intel-openmp==2025.2.1\n",
            "ipyevents==2.0.2\n",
            "ipyfilechooser==0.6.0\n",
            "ipykernel==6.17.1\n",
            "ipyleaflet==0.20.0\n",
            "ipyparallel==8.8.0\n",
            "ipython==7.34.0\n",
            "ipython-genutils==0.2.0\n",
            "ipython-sql==0.5.0\n",
            "ipytree==0.2.2\n",
            "ipywidgets==7.7.1\n",
            "isoduration==20.11.0\n",
            "itsdangerous==2.2.0\n",
            "jaraco.classes==3.4.0\n",
            "jaraco.context==6.0.1\n",
            "jaraco.functools==4.3.0\n",
            "jax==0.5.3\n",
            "jax-cuda12-pjrt==0.5.3\n",
            "jax-cuda12-plugin==0.5.3\n",
            "jaxlib==0.5.3\n",
            "jeepney==0.9.0\n",
            "jieba==0.42.1\n",
            "Jinja2==3.1.6\n",
            "jiter==0.10.0\n",
            "joblib==1.5.2\n",
            "jsonpatch==1.33\n",
            "jsonpickle==4.1.1\n",
            "jsonpointer==3.0.0\n",
            "jsonschema==4.25.1\n",
            "jsonschema-specifications==2025.4.1\n",
            "jupyter-console==6.6.3\n",
            "jupyter-events==0.12.0\n",
            "jupyter-leaflet==0.20.0\n",
            "jupyter_client==7.4.9\n",
            "jupyter_core==5.8.1\n",
            "jupyter_kernel_gateway @ git+https://github.com/googlecolab/kernel_gateway@b134e9945df25c2dcb98ade9129399be10788671\n",
            "jupyter_server==2.14.0\n",
            "jupyter_server_terminals==0.5.3\n",
            "jupyterlab_pygments==0.3.0\n",
            "jupyterlab_widgets==3.0.15\n",
            "jupytext==1.17.3\n",
            "kaggle==1.7.4.5\n",
            "kagglehub==0.3.13\n",
            "keras==3.10.0\n",
            "keras-hub==0.21.1\n",
            "keras-nlp==0.21.1\n",
            "keyring==25.6.0\n",
            "keyrings.google-artifactregistry-auth==1.1.2\n",
            "kiwisolver==1.4.9\n",
            "langchain==0.3.27\n",
            "langchain-core==0.3.75\n",
            "langchain-text-splitters==0.3.11\n",
            "langcodes==3.5.0\n",
            "langsmith==0.4.23\n",
            "language_data==1.3.0\n",
            "lark==1.2.2\n",
            "launchpadlib==1.10.16\n",
            "lazr.restfulclient==0.14.4\n",
            "lazr.uri==1.0.6\n",
            "lazy_loader==0.4\n",
            "libclang==18.1.1\n",
            "libcudf-cu12 @ https://pypi.nvidia.com/libcudf-cu12/libcudf_cu12-25.6.0-py3-none-manylinux_2_28_x86_64.whl\n",
            "libcugraph-cu12==25.6.0\n",
            "libcuml-cu12==25.6.0\n",
            "libcuvs-cu12==25.6.1\n",
            "libkvikio-cu12==25.6.0\n",
            "libpysal==4.13.0\n",
            "libraft-cu12==25.6.0\n",
            "librmm-cu12==25.6.0\n",
            "librosa==0.11.0\n",
            "libucx-cu12==1.18.1\n",
            "libucxx-cu12==0.44.0\n",
            "lightgbm @ file:///tmp/lightgbm/LightGBM/dist/lightgbm-4.6.0-py3-none-linux_x86_64.whl\n",
            "lightning-utilities==0.15.2\n",
            "linkify-it-py==2.0.3\n",
            "llvmlite==0.43.0\n",
            "locket==1.0.0\n",
            "logical-unification==0.4.6\n",
            "lxml==5.4.0\n",
            "Mako==1.3.10\n",
            "marisa-trie==1.3.1\n",
            "Markdown==3.8.2\n",
            "markdown-it-py==4.0.0\n",
            "MarkupSafe==3.0.2\n",
            "matplotlib==3.10.0\n",
            "matplotlib-inline==0.1.7\n",
            "matplotlib-venn==1.1.2\n",
            "mcp==1.13.1\n",
            "mdit-py-plugins==0.5.0\n",
            "mdurl==0.1.2\n",
            "miniKanren==1.0.5\n",
            "missingno==0.5.2\n",
            "mistune==3.1.4\n",
            "mizani==0.13.5\n",
            "mkl==2025.2.0\n",
            "ml_dtypes==0.5.3\n",
            "mlxtend==0.23.4\n",
            "more-itertools==10.8.0\n",
            "moviepy==1.0.3\n",
            "mpmath==1.3.0\n",
            "msgpack==1.1.1\n",
            "multidict==6.6.4\n",
            "multipledispatch==1.0.0\n",
            "multiprocess==0.70.16\n",
            "multitasking==0.0.12\n",
            "murmurhash==1.0.13\n",
            "music21==9.3.0\n",
            "namex==0.1.0\n",
            "narwhals==2.3.0\n",
            "natsort==8.4.0\n",
            "nbclassic==1.3.1\n",
            "nbclient==0.10.2\n",
            "nbconvert==7.16.6\n",
            "nbformat==5.10.4\n",
            "ndindex==1.10.0\n",
            "nest-asyncio==1.6.0\n",
            "networkx==3.5\n",
            "nibabel==5.3.2\n",
            "nltk==3.9.1\n",
            "notebook==6.5.7\n",
            "notebook_shim==0.2.4\n",
            "numba==0.60.0\n",
            "numba-cuda==0.11.0\n",
            "numexpr==2.11.0\n",
            "numpy==2.0.2\n",
            "nvidia-cublas-cu12==12.6.4.1\n",
            "nvidia-cuda-cupti-cu12==12.6.80\n",
            "nvidia-cuda-nvcc-cu12==12.5.82\n",
            "nvidia-cuda-nvrtc-cu12==12.6.77\n",
            "nvidia-cuda-runtime-cu12==12.6.77\n",
            "nvidia-cudnn-cu12==9.10.2.21\n",
            "nvidia-cufft-cu12==11.3.0.4\n",
            "nvidia-cufile-cu12==1.11.1.6\n",
            "nvidia-curand-cu12==10.3.7.77\n",
            "nvidia-cusolver-cu12==11.7.1.2\n",
            "nvidia-cusparse-cu12==12.5.4.2\n",
            "nvidia-cusparselt-cu12==0.7.1\n",
            "nvidia-ml-py==12.575.51\n",
            "nvidia-nccl-cu12==2.27.3\n",
            "nvidia-nvjitlink-cu12==12.6.85\n",
            "nvidia-nvtx-cu12==12.6.77\n",
            "nvtx==0.2.13\n",
            "nx-cugraph-cu12 @ https://pypi.nvidia.com/nx-cugraph-cu12/nx_cugraph_cu12-25.6.0-py3-none-any.whl\n",
            "oauth2client==4.1.3\n",
            "oauthlib==3.3.1\n",
            "omegaconf==2.3.0\n",
            "openai==1.104.2\n",
            "opencv-contrib-python==4.12.0.88\n",
            "opencv-python==4.12.0.88\n",
            "opencv-python-headless==4.12.0.88\n",
            "openpyxl==3.1.5\n",
            "opentelemetry-api==1.36.0\n",
            "opentelemetry-exporter-gcp-trace==1.9.0\n",
            "opentelemetry-resourcedetector-gcp==1.9.0a0\n",
            "opentelemetry-sdk==1.36.0\n",
            "opentelemetry-semantic-conventions==0.57b0\n",
            "opt_einsum==3.4.0\n",
            "optax==0.2.5\n",
            "optree==0.17.0\n",
            "orbax-checkpoint==0.11.24\n",
            "orjson==3.11.3\n",
            "osqp==1.0.4\n",
            "overrides==7.7.0\n",
            "packaging==25.0\n",
            "pandas==2.2.2\n",
            "pandas-datareader==0.10.0\n",
            "pandas-gbq==0.29.2\n",
            "pandas-stubs==2.2.2.240909\n",
            "pandocfilters==1.5.1\n",
            "panel==1.7.5\n",
            "param==2.2.1\n",
            "parso==0.8.5\n",
            "parsy==2.1\n",
            "partd==1.4.2\n",
            "patsy==1.0.1\n",
            "peewee==3.18.2\n",
            "peft==0.17.1\n",
            "pexpect==4.9.0\n",
            "pickleshare==0.7.5\n",
            "pillow==11.3.0\n",
            "platformdirs==4.4.0\n",
            "plotly==5.24.1\n",
            "plotnine==0.14.5\n",
            "pluggy==1.6.0\n",
            "plum-dispatch==2.5.7\n",
            "ply==3.11\n",
            "polars==1.25.2\n",
            "pooch==1.8.2\n",
            "portpicker==1.5.2\n",
            "preshed==3.0.10\n",
            "prettytable==3.16.0\n",
            "proglog==0.1.12\n",
            "progressbar2==4.5.0\n",
            "prometheus_client==0.22.1\n",
            "promise==2.3\n",
            "prompt_toolkit==3.0.52\n",
            "propcache==0.3.2\n",
            "prophet==1.1.7\n",
            "proto-plus==1.26.1\n",
            "protobuf==5.29.5\n",
            "psutil==5.9.5\n",
            "psycopg2==2.9.10\n",
            "psygnal==0.14.1\n",
            "ptyprocess==0.7.0\n",
            "py-cpuinfo==9.0.0\n",
            "py4j==0.10.9.7\n",
            "pyarrow==18.1.0\n",
            "pyasn1==0.6.1\n",
            "pyasn1_modules==0.4.2\n",
            "pycairo==1.28.0\n",
            "pycocotools==2.0.10\n",
            "pycparser==2.22\n",
            "pycryptodomex==3.23.0\n",
            "pydantic==2.11.7\n",
            "pydantic-settings==2.10.1\n",
            "pydantic_core==2.33.2\n",
            "pydata-google-auth==1.9.1\n",
            "pydot==3.0.4\n",
            "pydotplus==2.0.2\n",
            "PyDrive2==1.21.3\n",
            "pydub==0.25.1\n",
            "pyerfa==2.0.1.5\n",
            "pygame==2.6.1\n",
            "pygit2==1.18.2\n",
            "Pygments==2.19.2\n",
            "PyGObject==3.42.0\n",
            "PyJWT==2.10.1\n",
            "pylibcudf-cu12 @ https://pypi.nvidia.com/pylibcudf-cu12/pylibcudf_cu12-25.6.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl\n",
            "pylibcugraph-cu12==25.6.0\n",
            "pylibraft-cu12==25.6.0\n",
            "pymc==5.25.1\n",
            "pynndescent==0.5.13\n",
            "pynvjitlink-cu12==0.7.0\n",
            "pynvml==12.0.0\n",
            "pyogrio==0.11.1\n",
            "pyomo==6.9.4\n",
            "PyOpenGL==3.1.10\n",
            "pyOpenSSL==24.2.1\n",
            "pyparsing==3.2.3\n",
            "pyperclip==1.9.0\n",
            "pyproj==3.7.2\n",
            "pyproject_hooks==1.2.0\n",
            "pyshp==2.3.1\n",
            "PySocks==1.7.1\n",
            "pyspark==3.5.1\n",
            "pytensor==2.31.7\n",
            "pytest==8.4.1\n",
            "python-apt==0.0.0\n",
            "python-box==7.3.2\n",
            "python-dateutil==2.9.0.post0\n",
            "python-dotenv==1.1.1\n",
            "python-json-logger==3.3.0\n",
            "python-louvain==0.16\n",
            "python-multipart==0.0.20\n",
            "python-slugify==8.0.4\n",
            "python-snappy==0.7.3\n",
            "python-utils==3.9.1\n",
            "pytz==2025.2\n",
            "pyviz_comms==3.0.6\n",
            "PyWavelets==1.9.0\n",
            "PyYAML==6.0.2\n",
            "pyzmq==26.2.1\n",
            "qwen-vl-utils==0.0.10\n",
            "raft-dask-cu12==25.6.0\n",
            "rapids-dask-dependency==25.6.0\n",
            "rapids-logger==0.1.1\n",
            "ratelim==0.1.6\n",
            "referencing==0.36.2\n",
            "regex==2024.11.6\n",
            "requests==2.32.4\n",
            "requests-oauthlib==2.0.0\n",
            "requests-toolbelt==1.0.0\n",
            "requirements-parser==0.9.0\n",
            "rfc3339-validator==0.1.4\n",
            "rfc3986-validator==0.1.1\n",
            "rfc3987-syntax==1.1.0\n",
            "rich==13.9.4\n",
            "rmm-cu12==25.6.0\n",
            "roman-numerals-py==3.1.0\n",
            "rpds-py==0.27.1\n",
            "rpy2==3.5.17\n",
            "rsa==4.9.1\n",
            "ruff==0.12.11\n",
            "safehttpx==0.1.6\n",
            "safetensors==0.6.2\n",
            "scikit-image==0.25.2\n",
            "scikit-learn==1.6.1\n",
            "scipy==1.16.1\n",
            "scooby==0.10.1\n",
            "scs==3.2.8\n",
            "seaborn==0.13.2\n",
            "SecretStorage==3.3.3\n",
            "semantic-version==2.10.0\n",
            "Send2Trash==1.8.3\n",
            "sentence-transformers==5.1.0\n",
            "sentencepiece==0.2.1\n",
            "sentry-sdk==2.35.2\n",
            "setuptools==80.9.0\n",
            "shap==0.48.0\n",
            "shapely==2.1.1\n",
            "shellingham==1.5.4\n",
            "simple-parsing==0.1.7\n",
            "simplejson==3.20.1\n",
            "simsimd==6.5.1\n",
            "six==1.17.0\n",
            "sklearn-pandas==2.2.0\n",
            "slicer==0.0.8\n",
            "smart_open==7.3.0.post1\n",
            "smmap==5.0.2\n",
            "sniffio==1.3.1\n",
            "snowballstemmer==3.0.1\n",
            "sortedcontainers==2.4.0\n",
            "soundfile==0.13.1\n",
            "soupsieve==2.8\n",
            "soxr==0.5.0.post1\n",
            "spacy==3.8.7\n",
            "spacy-legacy==3.0.12\n",
            "spacy-loggers==1.0.5\n",
            "spanner-graph-notebook==1.1.8\n",
            "Sphinx==8.2.3\n",
            "sphinxcontrib-applehelp==2.0.0\n",
            "sphinxcontrib-devhelp==2.0.0\n",
            "sphinxcontrib-htmlhelp==2.1.0\n",
            "sphinxcontrib-jsmath==1.0.1\n",
            "sphinxcontrib-qthelp==2.0.0\n",
            "sphinxcontrib-serializinghtml==2.0.0\n",
            "SQLAlchemy==2.0.43\n",
            "sqlalchemy-spanner==1.16.0\n",
            "sqlglot==25.20.2\n",
            "sqlparse==0.5.3\n",
            "srsly==2.5.1\n",
            "sse-starlette==3.0.2\n",
            "stanio==0.5.1\n",
            "starlette==0.47.3\n",
            "statsmodels==0.14.5\n",
            "stringzilla==3.12.6\n",
            "stumpy==1.13.0\n",
            "sympy==1.13.3\n",
            "tables==3.10.2\n",
            "tabulate==0.9.0\n",
            "tbb==2022.2.0\n",
            "tblib==3.1.0\n",
            "tcmlib==1.4.0\n",
            "tenacity==8.5.0\n",
            "tensorboard==2.19.0\n",
            "tensorboard-data-server==0.7.2\n",
            "tensorflow==2.19.0\n",
            "tensorflow-datasets==4.9.9\n",
            "tensorflow-hub==0.16.1\n",
            "tensorflow-metadata==1.17.2\n",
            "tensorflow-probability==0.25.0\n",
            "tensorflow-text==2.19.0\n",
            "tensorflow_decision_forests==1.12.0\n",
            "tensorstore==0.1.76\n",
            "termcolor==3.1.0\n",
            "terminado==0.18.1\n",
            "text-unidecode==1.3\n",
            "textblob==0.19.0\n",
            "tf-slim==1.1.0\n",
            "tf_keras==2.19.0\n",
            "thinc==8.3.6\n",
            "threadpoolctl==3.6.0\n",
            "tifffile==2025.8.28\n",
            "tiktoken==0.11.0\n",
            "timm==1.0.19\n",
            "tinycss2==1.4.0\n",
            "tokenizers==0.22.0\n",
            "toml==0.10.2\n",
            "tomlkit==0.13.3\n",
            "toolz==0.12.1\n",
            "torch==2.8.0+cu126\n",
            "torchao==0.10.0\n",
            "torchaudio==2.8.0+cu126\n",
            "torchdata==0.11.0\n",
            "torchmetrics==1.8.2\n",
            "torchsummary==1.5.1\n",
            "torchtune==0.6.1\n",
            "torchvision==0.23.0+cu126\n",
            "tornado==6.4.2\n",
            "tqdm==4.67.1\n",
            "traitlets==5.7.1\n",
            "traittypes==0.2.1\n",
            "transformers==4.56.0\n",
            "treelite==4.4.1\n",
            "treescope==0.1.10\n",
            "triton==3.4.0\n",
            "tsfresh==0.21.1\n",
            "tweepy==4.16.0\n",
            "typeguard==4.4.4\n",
            "typer==0.17.3\n",
            "types-python-dateutil==2.9.0.20250822\n",
            "types-pytz==2025.2.0.20250809\n",
            "types-setuptools==80.9.0.20250822\n",
            "typing-inspection==0.4.1\n",
            "typing_extensions==4.15.0\n",
            "tzdata==2025.2\n",
            "tzlocal==5.3.1\n",
            "uc-micro-py==1.0.3\n",
            "ucx-py-cu12==0.44.0\n",
            "ucxx-cu12==0.44.0\n",
            "umap-learn==0.5.9.post2\n",
            "umf==0.11.0\n",
            "uri-template==1.3.0\n",
            "uritemplate==4.2.0\n",
            "urllib3==2.5.0\n",
            "uvicorn==0.35.0\n",
            "vega-datasets==0.9.0\n",
            "wadllib==1.3.6\n",
            "wandb==0.21.3\n",
            "wasabi==1.1.3\n",
            "watchdog==6.0.0\n",
            "wcwidth==0.2.13\n",
            "weasel==0.4.1\n",
            "webcolors==24.11.1\n",
            "webencodings==0.5.1\n",
            "websocket-client==1.8.0\n",
            "websockets==15.0.1\n",
            "Werkzeug==3.1.3\n",
            "wheel==0.45.1\n",
            "widgetsnbextension==3.6.10\n",
            "wordcloud==1.9.4\n",
            "wrapt==1.17.3\n",
            "wurlitzer==3.1.1\n",
            "xarray==2025.8.0\n",
            "xarray-einstats==0.9.1\n",
            "xgboost==3.0.4\n",
            "xlrd==2.0.2\n",
            "xxhash==3.5.0\n",
            "xyzservices==2025.4.0\n",
            "yarl==1.20.1\n",
            "ydf==0.13.0\n",
            "yellowbrick==1.5\n",
            "yfinance==0.2.65\n",
            "zict==3.0.0\n",
            "zipp==3.23.0\n",
            "zstandard==0.24.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "5f081cf4e20d49beb5e47f66b79f8626",
            "e2a43e7b81364e61b9fc8c28a7d1f188",
            "1328fe537bf940219d1810bfa4d5cd95",
            "8eb8f9cd2f8e46a8b997e44c95aa7396",
            "6bd19859a55a474e9503e2bed766fb9d",
            "4f8652944bd84e7cbcdaa503112166b9",
            "c34d06845f7d4977b245bbd13c836a99",
            "33081c405bdb4deab6a54ec8af97c871",
            "a121e7fe6a0446619fec3194d8e3d798",
            "d76acfe8d5684455b575221758e4666b",
            "aba8b406d27a4794940f8afafda463e7",
            "47594bbcf79c4b76baf85448953e6c1a",
            "d8f5fa9fef1d42658873c3888e1da4e5",
            "8173029662b549a5862cce13aa65c920",
            "3713e9fafa844177a759441a9f974ddc",
            "bfe13da7f7314783804b54bf95f1572f",
            "4839d56c110c4473b6a01521c3da96a7",
            "78b807e7e7ad4f16af91a2ef6acf2ac6",
            "57c775949d484702adb4aecef6074c38",
            "01a47ba6f1f34f129128a793ecd64c40"
          ]
        },
        "id": "w6sqeABIY-hw",
        "outputId": "be197d46-06d7-409b-bab5-81700cfb2229"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5f081cf4e20d49beb5e47f66b79f8626"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_train.py \\\n",
        "    --peft lora --lora_r 32 --lora_alpha 8 --mm_projector_lr 2e-5 \\\n",
        "    --task vqa --dataset PathVQA \\\n",
        "    --model Lingshu \\\n",
        "    --image_path ./notnedded \\\n",
        "    --model_path lingshu-medical-mllm/Lingshu-7B \\\n",
        "    --mm_projector_type mlp2x_gelu \\\n",
        "    --mm_vision_select_layer -2 \\\n",
        "    --mm_use_im_start_end False \\\n",
        "    --mm_use_im_patch_token False \\\n",
        "    --image_aspect_ratio pad \\\n",
        "    --group_by_modality_length True \\\n",
        "    --bf16 True \\\n",
        "    --output_dir ./log \\\n",
        "    --cache_dir ./cache \\\n",
        "    --num_train_epochs 1 \\\n",
        "    --per_device_train_batch_size 16 \\\n",
        "    --per_device_eval_batch_size 4 \\\n",
        "    --gradient_accumulation_steps 1 \\\n",
        "    --save_strategy \"steps\" \\\n",
        "    --save_steps 50000 \\\n",
        "    --save_total_limit 1 \\\n",
        "    --learning_rate 2e-4 \\\n",
        "    --weight_decay 0. \\\n",
        "    --warmup_ratio 0.03 \\\n",
        "    --lr_scheduler_type \"cosine\" \\\n",
        "    --logging_steps 1 \\\n",
        "    --tf32 True \\\n",
        "    --model_max_length 2048 \\\n",
        "    --gradient_checkpointing False \\\n",
        "    --dataloader_num_workers 4 \\\n",
        "    --tune_modules ML"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlqIkdWWhN00",
        "outputId": "56d5822b-a219-4bbc-e667-ce43aa34d1d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-09-04 16:56:29.817104: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-09-04 16:56:29.834283: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1757004989.856594    3146 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1757004989.863199    3146 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1757004989.880135    3146 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757004989.880174    3146 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757004989.880178    3146 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757004989.880180    3146 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-09-04 16:56:29.885063: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/content/MedVLMBench/eval/utils.py:145: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  period_strip = re.compile(\"(?!<=\\d)(\\.)(?!\\d)\")\n",
            "/content/MedVLMBench/eval/utils.py:146: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  comma_strip = re.compile(\"(\\d)(\\,)(\\d)\")\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "25-09-04 16:56:40.633 - INFO: Using following arguments for training.\n",
            "INFO:train:Using following arguments for training.\n",
            "25-09-04 16:56:40.633 - INFO: Arguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "average_tokens_across_devices=False,\n",
            "batch_eval_metrics=False,\n",
            "bf16=True,\n",
            "bf16_full_eval=False,\n",
            "bits=16,\n",
            "cache_dir=./cache,\n",
            "context_length=77,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=4,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "dataset=PathVQA,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "debug_e2e=False,\n",
            "deepspeed=None,\n",
            "deepspeed_plugin=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=False,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "double_quant=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_on_start=False,\n",
            "eval_print_freq=100,\n",
            "eval_steps=None,\n",
            "eval_strategy=IntervalStrategy.NO,\n",
            "eval_use_gather_object=False,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "freeze_backbone=False,\n",
            "freeze_mm_mlp_adapter=False,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "group_by_modality_length=True,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=None,\n",
            "hub_revision=None,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "if_wandb=False,\n",
            "ignore_data_skip=False,\n",
            "image_aspect_ratio=pad,\n",
            "image_path=./notnedded,\n",
            "include_for_metrics=[],\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.0002,\n",
            "length_column_name=length,\n",
            "liger_kernel_config=None,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=./log/runs/Sep04_16-56-38_02eb21efbd1d,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=1.0,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "longvila_sampler=False,\n",
            "lora_alpha=8,\n",
            "lora_bias=none,\n",
            "lora_dropout=0.05,\n",
            "lora_enable=True,\n",
            "lora_r=32,\n",
            "lora_weight_path=,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=SchedulerType.COSINE,\n",
            "max_grad_norm=1.0,\n",
            "max_num_images=6,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mm_patch_merge_type=flat,\n",
            "mm_projector_lr=2e-05,\n",
            "mm_projector_type=mlp2x_gelu,\n",
            "mm_use_im_patch_token=<MM_USE_IM_PATCH_TOKEN>,\n",
            "mm_use_im_start_end=False,\n",
            "mm_vision_select_feature=patch,\n",
            "mm_vision_select_layer=-2,\n",
            "model=Lingshu,\n",
            "model_base=None,\n",
            "model_max_length=2048,\n",
            "model_path=lingshu-medical-mllm/Lingshu-7B,\n",
            "mp_parameters=,\n",
            "mpt_attn_impl=triton,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_time_tokens=0,\n",
            "num_train_epochs=1,\n",
            "optim=OptimizerNames.ADAMW_TORCH,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=./log/vqa/PathVQA/Lingshu/train_lora_ML_seed42_lingshu,\n",
            "overwrite_output_dir=False,\n",
            "parallelism_config=None,\n",
            "past_index=-1,\n",
            "peft=lora,\n",
            "per_device_eval_batch_size=4,\n",
            "per_device_train_batch_size=16,\n",
            "prediction_loss_only=False,\n",
            "pretrain_mm_mlp_adapter=None,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "quant_type=nf4,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=False,\n",
            "report_to=['tensorboard', 'wandb'],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "run_name=None,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_pred=False,\n",
            "save_safetensors=True,\n",
            "save_steps=50000,\n",
            "save_strategy=SaveStrategy.STEPS,\n",
            "save_total_limit=1,\n",
            "seed=42,\n",
            "seq_parallel_size=-1,\n",
            "skip_memory_metrics=True,\n",
            "soft_ce_std=1.0,\n",
            "split=train,\n",
            "task=vqa,\n",
            "tf32=True,\n",
            "time_token_format=<t{t}>,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_empty_cache_steps=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "tune_mm_mlp_adapter=True,\n",
            "tune_modules=ML,\n",
            "usage=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_liger_kernel=False,\n",
            "use_mps_device=False,\n",
            "version=v1,\n",
            "vision_tower_lr=None,\n",
            "wandb_name=None,\n",
            "warmup_ratio=0.03,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "INFO:train:Arguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "average_tokens_across_devices=False,\n",
            "batch_eval_metrics=False,\n",
            "bf16=True,\n",
            "bf16_full_eval=False,\n",
            "bits=16,\n",
            "cache_dir=./cache,\n",
            "context_length=77,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=4,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "dataset=PathVQA,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "debug_e2e=False,\n",
            "deepspeed=None,\n",
            "deepspeed_plugin=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=False,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "double_quant=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_on_start=False,\n",
            "eval_print_freq=100,\n",
            "eval_steps=None,\n",
            "eval_strategy=IntervalStrategy.NO,\n",
            "eval_use_gather_object=False,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "freeze_backbone=False,\n",
            "freeze_mm_mlp_adapter=False,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "group_by_modality_length=True,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=None,\n",
            "hub_revision=None,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "if_wandb=False,\n",
            "ignore_data_skip=False,\n",
            "image_aspect_ratio=pad,\n",
            "image_path=./notnedded,\n",
            "include_for_metrics=[],\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.0002,\n",
            "length_column_name=length,\n",
            "liger_kernel_config=None,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=./log/runs/Sep04_16-56-38_02eb21efbd1d,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=1.0,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "longvila_sampler=False,\n",
            "lora_alpha=8,\n",
            "lora_bias=none,\n",
            "lora_dropout=0.05,\n",
            "lora_enable=True,\n",
            "lora_r=32,\n",
            "lora_weight_path=,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=SchedulerType.COSINE,\n",
            "max_grad_norm=1.0,\n",
            "max_num_images=6,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mm_patch_merge_type=flat,\n",
            "mm_projector_lr=2e-05,\n",
            "mm_projector_type=mlp2x_gelu,\n",
            "mm_use_im_patch_token=<MM_USE_IM_PATCH_TOKEN>,\n",
            "mm_use_im_start_end=False,\n",
            "mm_vision_select_feature=patch,\n",
            "mm_vision_select_layer=-2,\n",
            "model=Lingshu,\n",
            "model_base=None,\n",
            "model_max_length=2048,\n",
            "model_path=lingshu-medical-mllm/Lingshu-7B,\n",
            "mp_parameters=,\n",
            "mpt_attn_impl=triton,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_time_tokens=0,\n",
            "num_train_epochs=1,\n",
            "optim=OptimizerNames.ADAMW_TORCH,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=./log/vqa/PathVQA/Lingshu/train_lora_ML_seed42_lingshu,\n",
            "overwrite_output_dir=False,\n",
            "parallelism_config=None,\n",
            "past_index=-1,\n",
            "peft=lora,\n",
            "per_device_eval_batch_size=4,\n",
            "per_device_train_batch_size=16,\n",
            "prediction_loss_only=False,\n",
            "pretrain_mm_mlp_adapter=None,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "quant_type=nf4,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=False,\n",
            "report_to=['tensorboard', 'wandb'],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "run_name=None,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_pred=False,\n",
            "save_safetensors=True,\n",
            "save_steps=50000,\n",
            "save_strategy=SaveStrategy.STEPS,\n",
            "save_total_limit=1,\n",
            "seed=42,\n",
            "seq_parallel_size=-1,\n",
            "skip_memory_metrics=True,\n",
            "soft_ce_std=1.0,\n",
            "split=train,\n",
            "task=vqa,\n",
            "tf32=True,\n",
            "time_token_format=<t{t}>,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_empty_cache_steps=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "tune_mm_mlp_adapter=True,\n",
            "tune_modules=ML,\n",
            "usage=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_liger_kernel=False,\n",
            "use_mps_device=False,\n",
            "version=v1,\n",
            "vision_tower_lr=None,\n",
            "wandb_name=None,\n",
            "warmup_ratio=0.03,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "config.json: 1.49kB [00:00, 3.25MB/s]\n",
            "model.safetensors.index.json: 57.6kB [00:00, 71.1MB/s]\n",
            "Fetching 4 files:   0% 0/4 [00:00<?, ?it/s]\n",
            "model-00001-of-00004.safetensors:   0% 0.00/4.97G [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:   0% 0.00/4.93G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:   0% 0.00/1.69G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:   0% 0.00/4.99G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:   0% 545k/1.69G [00:02<2:12:06, 213kB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:   0% 554k/4.93G [00:02<6:26:53, 212kB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:   0% 683k/4.99G [00:02<5:30:04, 252kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:   4% 67.6M/1.69G [00:02<00:48, 33.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:   8% 135M/1.69G [00:02<00:20, 74.4MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  16% 269M/1.69G [00:03<00:10, 137MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:   1% 67.7M/4.99G [00:03<03:23, 24.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  20% 336M/1.69G [00:03<00:10, 134MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:   8% 403M/4.99G [00:04<00:30, 151MB/s]  \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:   1% 67.6M/4.93G [00:07<07:49, 10.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  24% 403M/1.69G [00:07<00:27, 47.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:   9% 470M/4.99G [00:07<01:07, 67.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:   3% 135M/4.93G [00:07<03:24, 23.5MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  32% 537M/1.69G [00:07<00:14, 78.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:   5% 269M/4.93G [00:08<01:23, 55.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  37% 619M/1.69G [00:08<00:13, 80.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  12% 604M/4.99G [00:09<01:02, 70.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:   7% 336M/4.93G [00:09<01:23, 55.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  41% 686M/1.69G [00:11<00:20, 49.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:   8% 403M/4.93G [00:11<01:49, 41.4MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:   0% 536k/4.97G [00:11<30:32:07, 45.2kB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  48% 820M/1.69G [00:11<00:11, 79.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:  10% 470M/4.93G [00:13<01:40, 44.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  60% 1.02G/1.69G [00:15<00:09, 70.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  15% 738M/4.99G [00:15<01:49, 39.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  64% 1.09G/1.69G [00:16<00:08, 67.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:  11% 537M/4.93G [00:16<02:13, 32.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:  14% 671M/4.93G [00:17<01:29, 47.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  16% 805M/4.99G [00:17<01:56, 36.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:   1% 67.6M/4.97G [00:19<18:43, 4.36MB/s]  \u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:  18% 873M/4.93G [00:19<00:57, 71.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  19% 940M/4.99G [00:19<01:30, 45.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:  20% 1.01G/4.93G [00:19<00:43, 89.5MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:   3% 135M/4.97G [00:21<09:04, 8.88MB/s] \u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:  22% 1.07G/4.93G [00:24<01:20, 48.1MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:   5% 269M/4.97G [00:24<04:23, 17.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  22% 1.07G/4.99G [00:24<01:47, 36.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  68% 1.16G/1.69G [00:25<00:20, 25.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  72% 1.22G/1.69G [00:25<00:15, 31.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:  23% 1.14G/4.93G [00:25<01:23, 45.4MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:   7% 336M/4.97G [00:28<04:24, 17.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  23% 1.14G/4.99G [00:28<02:02, 31.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:  24% 1.21G/4.93G [00:28<01:31, 40.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  76% 1.29G/1.69G [00:28<00:13, 30.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:  26% 1.27G/4.93G [00:28<01:09, 52.8MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:   8% 403M/4.97G [00:28<03:03, 24.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  80% 1.36G/1.69G [00:28<00:08, 39.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  24% 1.21G/4.99G [00:28<01:37, 38.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:   9% 470M/4.97G [00:29<02:38, 28.4MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:  27% 1.34G/4.93G [00:29<01:15, 47.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  84% 1.42G/1.69G [00:32<00:08, 29.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  26% 1.28G/4.99G [00:32<02:02, 30.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  88% 1.49G/1.69G [00:32<00:04, 40.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  11% 537M/4.97G [00:32<02:37, 28.1MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:  29% 1.41G/4.93G [00:32<01:31, 38.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  92% 1.56G/1.69G [00:32<00:02, 49.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  28% 1.41G/4.99G [00:33<01:21, 43.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  96% 1.62G/1.69G [00:33<00:01, 54.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  12% 604M/4.97G [00:33<02:18, 31.6MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:  31% 1.54G/4.93G [00:34<01:06, 51.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  30% 1.48G/4.99G [00:36<01:39, 35.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:  33% 1.61G/4.93G [00:36<01:18, 42.4MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  14% 671M/4.97G [00:36<02:31, 28.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  31% 1.54G/4.99G [00:36<01:19, 43.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors: 100% 1.69G/1.69G [00:36<00:00, 38.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00004-of-00004.safetensors: 100% 1.69G/1.69G [00:36<00:00, 46.0MB/s]\n",
            "\n",
            "model-00001-of-00004.safetensors:  15% 738M/4.97G [00:37<01:51, 38.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  32% 1.61G/4.99G [00:37<01:13, 45.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  16% 805M/4.97G [00:40<02:23, 29.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  34% 1.68G/4.99G [00:41<01:39, 33.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:  37% 1.81G/4.93G [00:42<01:30, 34.3MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  18% 872M/4.97G [00:42<02:12, 30.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  35% 1.75G/4.99G [00:44<01:49, 29.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:  38% 1.88G/4.93G [00:44<01:33, 32.5MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  19% 940M/4.97G [00:44<02:09, 31.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  36% 1.81G/4.99G [00:44<01:20, 39.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:  39% 1.95G/4.93G [00:44<01:12, 41.1MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  20% 1.01G/4.97G [00:45<01:41, 39.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  38% 1.88G/4.99G [00:45<01:03, 49.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:  41% 2.01G/4.93G [00:45<00:57, 51.1MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  22% 1.07G/4.97G [00:45<01:18, 49.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  39% 1.95G/4.99G [00:45<00:51, 58.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:  42% 2.08G/4.93G [00:46<00:48, 58.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:  44% 2.15G/4.93G [00:49<01:13, 38.1MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  23% 1.14G/4.97G [00:49<01:55, 33.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  40% 2.01G/4.99G [00:49<01:26, 34.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:  46% 2.28G/4.93G [00:50<00:45, 58.5MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  24% 1.21G/4.97G [00:50<01:37, 38.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  42% 2.08G/4.99G [00:51<01:26, 33.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:  48% 2.35G/4.93G [00:52<00:59, 43.1MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  26% 1.28G/4.97G [00:53<01:51, 33.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  43% 2.15G/4.99G [00:53<01:18, 36.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:  49% 2.42G/4.93G [00:54<00:54, 45.8MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  27% 1.34G/4.97G [00:55<01:51, 32.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  44% 2.21G/4.99G [00:55<01:23, 33.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:  50% 2.48G/4.93G [00:55<00:56, 43.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:  52% 2.55G/4.93G [00:56<00:45, 52.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  46% 2.28G/4.99G [00:56<01:07, 39.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  47% 2.35G/4.99G [00:57<00:53, 49.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  30% 1.48G/4.97G [00:57<01:21, 43.0MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:  53% 2.62G/4.93G [00:57<00:40, 57.0MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  34% 1.68G/4.97G [00:58<00:49, 66.7MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:  54% 2.68G/4.93G [00:58<00:39, 57.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  48% 2.42G/4.99G [01:00<01:18, 32.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:  56% 2.75G/4.93G [01:00<00:48, 45.2MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  35% 1.75G/4.97G [01:00<01:00, 53.0MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  36% 1.81G/4.97G [01:01<00:50, 62.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  51% 2.55G/4.99G [01:01<00:44, 55.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  55% 2.75G/4.99G [01:03<00:29, 75.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:  57% 2.82G/4.93G [01:03<00:54, 38.5MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  38% 1.88G/4.97G [01:03<01:00, 51.4MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:  58% 2.89G/4.93G [01:04<00:44, 45.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  58% 2.89G/4.99G [01:06<00:38, 54.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:  60% 2.96G/4.93G [01:07<00:57, 34.6MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  41% 2.01G/4.97G [01:07<01:09, 42.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  59% 2.95G/4.99G [01:07<00:35, 56.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:  61% 3.02G/4.93G [01:08<00:51, 37.4MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  42% 2.08G/4.97G [01:10<01:18, 36.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  61% 3.02G/4.99G [01:10<00:41, 47.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:  63% 3.09G/4.93G [01:10<00:48, 38.4MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  43% 2.15G/4.97G [01:11<01:10, 40.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  62% 3.09G/4.99G [01:11<00:37, 50.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:  64% 3.16G/4.93G [01:11<00:41, 42.9MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  45% 2.21G/4.97G [01:11<00:53, 51.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  63% 3.16G/4.99G [01:12<00:33, 54.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:  65% 3.22G/4.93G [01:12<00:35, 47.8MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  46% 2.28G/4.97G [01:12<00:50, 53.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  65% 3.22G/4.99G [01:15<00:45, 39.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  47% 2.35G/4.97G [01:15<01:04, 40.4MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:  67% 3.29G/4.93G [01:15<00:45, 36.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  66% 3.29G/4.99G [01:15<00:33, 51.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  49% 2.42G/4.97G [01:15<00:51, 50.0MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:  69% 3.42G/4.93G [01:16<00:26, 56.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  67% 3.36G/4.99G [01:16<00:29, 56.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  50% 2.48G/4.97G [01:16<00:42, 58.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  69% 3.42G/4.99G [01:19<00:39, 39.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:  72% 3.56G/4.93G [01:19<00:28, 49.0MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  51% 2.56G/4.97G [01:19<00:58, 41.0MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:  74% 3.63G/4.93G [01:19<00:22, 57.7MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  54% 2.69G/4.97G [01:20<00:38, 58.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  70% 3.49G/4.99G [01:20<00:36, 41.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:  75% 3.69G/4.93G [01:21<00:23, 53.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  71% 3.56G/4.99G [01:29<01:17, 18.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  55% 2.76G/4.97G [01:29<01:38, 22.5MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:  76% 3.76G/4.93G [01:29<00:51, 22.7MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  58% 2.89G/4.97G [01:29<00:55, 37.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  78% 3.89G/4.99G [01:29<00:19, 55.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  60% 2.96G/4.97G [01:29<00:43, 45.8MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:  82% 4.03G/4.93G [01:29<00:17, 52.6MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  61% 3.03G/4.97G [01:29<00:33, 58.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  79% 3.96G/4.99G [01:30<00:17, 60.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  62% 3.09G/4.97G [01:30<00:26, 71.4MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:  82% 4.06G/4.93G [01:30<00:16, 54.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:  84% 4.13G/4.93G [01:31<00:13, 58.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:  85% 4.20G/4.93G [01:31<00:10, 66.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:  86% 4.27G/4.93G [01:32<00:09, 71.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  81% 4.03G/4.99G [01:34<00:26, 37.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  82% 4.09G/4.99G [01:35<00:19, 45.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  83% 4.16G/4.99G [01:36<00:17, 46.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  85% 4.23G/4.99G [01:38<00:17, 44.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  86% 4.30G/4.99G [01:38<00:13, 51.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:  88% 4.33G/4.93G [01:41<00:27, 22.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  87% 4.36G/4.99G [01:41<00:14, 42.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:  89% 4.40G/4.93G [01:41<00:17, 30.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:  91% 4.47G/4.93G [01:41<00:11, 40.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  89% 4.43G/4.99G [01:41<00:10, 55.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  64% 3.16G/4.97G [01:41<01:40, 17.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  90% 4.50G/4.99G [01:41<00:06, 71.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  91% 4.56G/4.99G [01:42<00:04, 88.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  66% 3.29G/4.97G [01:42<00:57, 29.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  93% 4.63G/4.99G [01:42<00:03, 97.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  68% 3.36G/4.97G [01:42<00:44, 36.1MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  69% 3.43G/4.97G [01:43<00:33, 46.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  94% 4.70G/4.99G [01:43<00:03, 97.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  70% 3.49G/4.97G [01:43<00:26, 55.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  95% 4.76G/4.99G [01:43<00:02, 100MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:  92% 4.53G/4.93G [01:44<00:11, 34.0MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  72% 3.56G/4.97G [01:44<00:23, 59.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  96% 4.79G/4.99G [01:44<00:02, 82.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  97% 4.86G/4.99G [01:44<00:01, 106MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  74% 3.70G/4.97G [01:45<00:14, 86.1MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:  93% 4.60G/4.93G [01:45<00:08, 39.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:  95% 4.67G/4.93G [01:45<00:04, 54.0MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  77% 3.83G/4.97G [01:45<00:09, 118MB/s] \u001b[A\n",
            "model-00001-of-00004.safetensors:  78% 3.90G/4.97G [01:45<00:07, 138MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  80% 3.96G/4.97G [01:46<00:07, 141MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  81% 4.03G/4.97G [01:46<00:05, 164MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  82% 4.10G/4.97G [01:46<00:04, 190MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors:  99% 4.93G/4.99G [01:46<00:01, 62.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  84% 4.16G/4.97G [01:47<00:04, 178MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:  96% 4.73G/4.93G [01:47<00:04, 46.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00004.safetensors: 100% 4.99G/4.99G [01:47<00:00, 46.4MB/s]\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  97% 4.80G/4.93G [01:47<00:02, 59.0MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  85% 4.23G/4.97G [01:47<00:05, 131MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors:  99% 4.87G/4.93G [01:48<00:00, 67.6MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  87% 4.30G/4.97G [01:48<00:05, 113MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00004.safetensors: 100% 4.93G/4.93G [01:51<00:00, 44.3MB/s]\n",
            "\n",
            "model-00001-of-00004.safetensors:  88% 4.36G/4.97G [01:51<00:11, 54.7MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  89% 4.43G/4.97G [01:51<00:07, 68.8MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  91% 4.50G/4.97G [01:52<00:05, 89.4MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  93% 4.63G/4.97G [01:52<00:02, 143MB/s] \u001b[A\n",
            "model-00001-of-00004.safetensors:  95% 4.70G/4.97G [01:52<00:01, 156MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  96% 4.77G/4.97G [01:53<00:01, 166MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  97% 4.83G/4.97G [01:53<00:00, 173MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  99% 4.90G/4.97G [01:53<00:00, 158MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors: 100% 4.97G/4.97G [01:54<00:00, 43.4MB/s]\n",
            "Fetching 4 files: 100% 4/4 [01:55<00:00, 28.76s/it] \n",
            "Loading checkpoint shards: 100% 4/4 [00:04<00:00,  1.25s/it]\n",
            "generation_config.json: 100% 244/244 [00:00<00:00, 1.97MB/s]\n",
            "preprocessor_config.json: 100% 575/575 [00:00<00:00, 4.45MB/s]\n",
            "Fetching 1 files: 100% 1/1 [00:01<00:00,  1.10s/it]\n",
            "Fetching 1 files: 100% 1/1 [00:00<00:00, 3449.26it/s]\n",
            "The image processor of type `Qwen2VLImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. Note that this behavior will be extended to all models in a future release.\n",
            "tokenizer_config.json: 5.80kB [00:00, 17.0MB/s]\n",
            "vocab.json: 2.78MB [00:00, 8.52MB/s]\n",
            "merges.txt: 1.67MB [00:00, 9.84MB/s]\n",
            "tokenizer.json: 100% 11.4M/11.4M [00:00<00:00, 17.0MB/s]\n",
            "added_tokens.json: 100% 605/605 [00:00<00:00, 5.48MB/s]\n",
            "special_tokens_map.json: 100% 613/613 [00:00<00:00, 5.65MB/s]\n",
            "Fetching 1 files: 100% 1/1 [00:00<00:00, 3287.07it/s]\n",
            "chat_template.json: 1.05kB [00:00, 5.96MB/s]\n",
            "README.md: 4.29kB [00:00, 13.2MB/s]\n",
            "data/train-00000-of-00007-f2d0e9ef9f022d(…): 100% 42.8M/42.8M [00:01<00:00, 36.4MB/s]\n",
            "data/train-00001-of-00007-47d8e0220bf6c9(…): 100% 81.0M/81.0M [00:00<00:00, 89.8MB/s]\n",
            "data/train-00002-of-00007-7fb5037c4c5da7(…): 100% 104M/104M [00:01<00:00, 83.2MB/s]\n",
            "data/train-00003-of-00007-74b9b7b81cc55f(…): 100% 90.0M/90.0M [00:00<00:00, 105MB/s]   \n",
            "data/train-00004-of-00007-77eea90af4a55d(…): 100% 46.1M/46.1M [00:00<00:00, 50.8MB/s]\n",
            "data/train-00005-of-00007-5332ec423be520(…): 100% 55.8M/55.8M [00:00<00:00, 65.1MB/s]\n",
            "data/train-00006-of-00007-637a58c700b604(…): 100% 57.3M/57.3M [00:00<00:00, 65.0MB/s]\n",
            "data/validation-00000-of-00003-90a5518d2(…): 100% 41.3M/41.3M [00:00<00:00, 52.7MB/s]\n",
            "data/validation-00001-of-00003-cbfe947a3(…): 100% 45.7M/45.7M [00:00<00:00, 51.3MB/s]  \n",
            "data/validation-00002-of-00003-9ec816895(…): 100% 64.7M/64.7M [00:00<00:00, 99.8MB/s]\n",
            "data/test-00000-of-00003-e9adadb4799f44d(…): 100% 41.2M/41.2M [00:00<00:00, 62.5MB/s]\n",
            "data/test-00001-of-00003-7ea98873fc91981(…): 100% 45.3M/45.3M [00:00<00:00, 47.1MB/s]\n",
            "data/test-00002-of-00003-162830843501982(…): 100% 69.8M/69.8M [00:00<00:00, 86.9MB/s]\n",
            "Generating train split: 100% 19654/19654 [00:09<00:00, 2146.47 examples/s]\n",
            "Generating validation split: 100% 6259/6259 [00:05<00:00, 1222.03 examples/s]\n",
            "Generating test split: 100% 6719/6719 [00:02<00:00, 2338.01 examples/s]\n",
            "25-09-04 16:59:38.446 - INFO: Loaded dataset: PathVQA\n",
            "INFO:train:Loaded dataset: PathVQA\n",
            "25-09-04 16:59:38.446 - INFO: Dataset size: 19654\n",
            "INFO:train:Dataset size: 19654\n",
            "/content/MedVLMBench/train/__init__.py:154: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "25-09-04 16:59:51.468 - INFO: Total parameter: 8,305,929,216  Trainable paramter: 58,335,744\n",
            "INFO:train:Total parameter: 8,305,929,216  Trainable paramter: 58,335,744\n",
            "25-09-04 16:59:51.468 - INFO: Tune the following parameters: ['base_model.model.model.visual.merger.mlp.0.weight', 'base_model.model.model.visual.merger.mlp.0.bias', 'base_model.model.model.visual.merger.mlp.2.weight', 'base_model.model.model.visual.merger.mlp.2.bias', 'base_model.model.model.language_model.layers.0.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.0.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.0.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.0.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.0.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.0.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.1.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.1.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.1.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.1.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.1.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.1.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.2.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.2.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.2.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.2.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.2.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.2.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.3.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.3.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.3.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.3.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.3.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.3.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.4.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.4.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.4.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.4.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.4.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.4.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.5.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.5.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.5.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.5.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.5.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.5.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.6.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.6.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.6.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.6.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.6.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.6.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.7.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.7.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.7.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.7.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.7.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.7.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.8.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.8.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.8.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.8.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.8.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.8.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.9.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.9.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.9.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.9.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.9.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.9.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.10.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.10.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.10.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.10.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.10.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.10.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.11.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.11.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.11.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.11.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.11.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.11.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.12.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.12.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.12.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.12.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.12.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.12.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.13.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.13.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.13.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.13.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.13.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.13.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.14.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.14.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.14.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.14.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.14.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.14.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.15.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.15.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.15.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.15.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.15.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.15.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.16.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.16.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.16.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.16.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.16.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.16.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.17.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.17.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.17.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.17.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.17.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.17.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.18.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.18.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.18.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.18.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.18.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.18.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.19.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.19.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.19.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.19.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.19.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.19.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.20.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.20.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.20.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.20.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.20.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.20.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.21.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.21.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.21.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.21.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.21.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.21.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.22.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.22.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.22.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.22.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.22.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.22.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.23.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.23.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.23.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.23.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.23.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.23.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.24.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.24.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.24.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.24.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.24.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.24.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.25.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.25.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.25.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.25.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.25.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.25.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.26.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.26.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.26.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.26.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.26.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.26.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.27.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.27.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.27.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.27.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.27.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.27.self_attn.v_proj.lora_B.default.weight']\n",
            "INFO:train:Tune the following parameters: ['base_model.model.model.visual.merger.mlp.0.weight', 'base_model.model.model.visual.merger.mlp.0.bias', 'base_model.model.model.visual.merger.mlp.2.weight', 'base_model.model.model.visual.merger.mlp.2.bias', 'base_model.model.model.language_model.layers.0.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.0.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.0.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.0.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.0.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.0.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.1.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.1.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.1.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.1.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.1.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.1.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.2.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.2.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.2.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.2.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.2.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.2.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.3.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.3.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.3.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.3.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.3.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.3.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.4.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.4.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.4.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.4.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.4.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.4.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.5.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.5.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.5.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.5.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.5.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.5.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.6.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.6.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.6.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.6.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.6.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.6.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.7.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.7.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.7.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.7.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.7.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.7.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.8.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.8.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.8.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.8.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.8.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.8.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.9.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.9.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.9.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.9.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.9.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.9.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.10.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.10.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.10.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.10.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.10.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.10.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.11.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.11.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.11.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.11.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.11.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.11.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.12.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.12.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.12.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.12.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.12.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.12.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.13.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.13.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.13.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.13.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.13.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.13.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.14.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.14.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.14.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.14.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.14.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.14.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.15.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.15.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.15.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.15.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.15.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.15.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.16.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.16.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.16.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.16.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.16.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.16.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.17.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.17.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.17.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.17.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.17.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.17.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.18.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.18.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.18.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.18.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.18.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.18.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.19.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.19.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.19.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.19.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.19.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.19.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.20.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.20.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.20.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.20.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.20.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.20.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.21.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.21.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.21.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.21.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.21.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.21.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.22.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.22.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.22.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.22.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.22.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.22.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.23.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.23.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.23.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.23.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.23.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.23.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.24.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.24.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.24.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.24.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.24.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.24.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.25.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.25.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.25.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.25.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.25.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.25.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.26.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.26.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.26.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.26.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.26.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.26.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.27.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.27.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.27.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.27.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.language_model.layers.27.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.language_model.layers.27.self_attn.v_proj.lora_B.default.weight']\n",
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.21.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory. Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/MedVLMBench/wandb/offline-run-20250904_170651-9aa515tn\u001b[0m\n",
            "{'loss': 17.5597, 'grad_norm': 24.472705841064453, 'learning_rate': 0.0, 'epoch': 0.0}\n",
            "{'loss': 18.5924, 'grad_norm': 26.062835693359375, 'learning_rate': 5.405405405405406e-06, 'epoch': 0.0}\n",
            "{'loss': 20.9199, 'grad_norm': 52.95681381225586, 'learning_rate': 1.0810810810810812e-05, 'epoch': 0.0}\n",
            "{'loss': 19.0205, 'grad_norm': 40.88325119018555, 'learning_rate': 1.6216216216216218e-05, 'epoch': 0.0}\n",
            "{'loss': 18.377, 'grad_norm': 23.775571823120117, 'learning_rate': 2.1621621621621624e-05, 'epoch': 0.0}\n",
            "{'loss': 19.3201, 'grad_norm': 41.68891143798828, 'learning_rate': 2.702702702702703e-05, 'epoch': 0.0}\n",
            "{'loss': 18.3661, 'grad_norm': 23.301755905151367, 'learning_rate': 3.2432432432432436e-05, 'epoch': 0.01}\n",
            "{'loss': 17.0468, 'grad_norm': 18.378801345825195, 'learning_rate': 3.783783783783784e-05, 'epoch': 0.01}\n",
            "{'loss': 16.5363, 'grad_norm': 23.558324813842773, 'learning_rate': 4.324324324324325e-05, 'epoch': 0.01}\n",
            "{'loss': 16.139, 'grad_norm': 30.95098114013672, 'learning_rate': 4.8648648648648654e-05, 'epoch': 0.01}\n",
            "{'loss': 14.4066, 'grad_norm': 29.651491165161133, 'learning_rate': 5.405405405405406e-05, 'epoch': 0.01}\n",
            "{'loss': 14.1991, 'grad_norm': 23.04998207092285, 'learning_rate': 5.9459459459459466e-05, 'epoch': 0.01}\n",
            "{'loss': 12.9964, 'grad_norm': 21.100954055786133, 'learning_rate': 6.486486486486487e-05, 'epoch': 0.01}\n",
            "{'loss': 12.8685, 'grad_norm': 16.05510139465332, 'learning_rate': 7.027027027027028e-05, 'epoch': 0.01}\n",
            "{'loss': 11.9173, 'grad_norm': 12.691987991333008, 'learning_rate': 7.567567567567568e-05, 'epoch': 0.01}\n",
            "{'loss': 11.6132, 'grad_norm': 11.456239700317383, 'learning_rate': 8.108108108108109e-05, 'epoch': 0.01}\n",
            "{'loss': 11.011, 'grad_norm': 8.295462608337402, 'learning_rate': 8.64864864864865e-05, 'epoch': 0.01}\n",
            "{'loss': 10.8241, 'grad_norm': 8.12586498260498, 'learning_rate': 9.18918918918919e-05, 'epoch': 0.01}\n",
            "{'loss': 10.1423, 'grad_norm': 7.431629180908203, 'learning_rate': 9.729729729729731e-05, 'epoch': 0.02}\n",
            "{'loss': 9.6614, 'grad_norm': 11.092362403869629, 'learning_rate': 0.0001027027027027027, 'epoch': 0.02}\n",
            "{'loss': 9.194, 'grad_norm': 10.243950843811035, 'learning_rate': 0.00010810810810810812, 'epoch': 0.02}\n",
            "{'loss': 8.296, 'grad_norm': 8.334412574768066, 'learning_rate': 0.00011351351351351351, 'epoch': 0.02}\n",
            "{'loss': 8.4749, 'grad_norm': 7.773307800292969, 'learning_rate': 0.00011891891891891893, 'epoch': 0.02}\n",
            "{'loss': 8.057, 'grad_norm': 6.106668949127197, 'learning_rate': 0.00012432432432432433, 'epoch': 0.02}\n",
            "{'loss': 7.7447, 'grad_norm': 5.381484031677246, 'learning_rate': 0.00012972972972972974, 'epoch': 0.02}\n",
            "{'loss': 7.5151, 'grad_norm': 4.003670692443848, 'learning_rate': 0.00013513513513513514, 'epoch': 0.02}\n",
            "{'loss': 7.1715, 'grad_norm': 3.5711638927459717, 'learning_rate': 0.00014054054054054056, 'epoch': 0.02}\n",
            "{'loss': 6.6071, 'grad_norm': 2.816535472869873, 'learning_rate': 0.00014594594594594595, 'epoch': 0.02}\n",
            "{'loss': 6.7457, 'grad_norm': 2.760636568069458, 'learning_rate': 0.00015135135135135137, 'epoch': 0.02}\n",
            "{'loss': 6.0361, 'grad_norm': 3.399286985397339, 'learning_rate': 0.00015675675675675676, 'epoch': 0.02}\n",
            "{'loss': 6.5965, 'grad_norm': 2.1513166427612305, 'learning_rate': 0.00016216216216216218, 'epoch': 0.03}\n",
            "{'loss': 6.5128, 'grad_norm': 3.5835821628570557, 'learning_rate': 0.00016756756756756757, 'epoch': 0.03}\n",
            "{'loss': 6.3926, 'grad_norm': 2.147061824798584, 'learning_rate': 0.000172972972972973, 'epoch': 0.03}\n",
            "{'loss': 6.3197, 'grad_norm': 1.571547031402588, 'learning_rate': 0.00017837837837837839, 'epoch': 0.03}\n",
            "{'loss': 6.2412, 'grad_norm': 1.6296745538711548, 'learning_rate': 0.0001837837837837838, 'epoch': 0.03}\n",
            "{'loss': 5.7297, 'grad_norm': 1.3962451219558716, 'learning_rate': 0.0001891891891891892, 'epoch': 0.03}\n",
            "{'loss': 5.9959, 'grad_norm': 1.3502964973449707, 'learning_rate': 0.00019459459459459462, 'epoch': 0.03}\n",
            "{'loss': 5.4794, 'grad_norm': 1.534571886062622, 'learning_rate': 0.0002, 'epoch': 0.03}\n",
            "{'loss': 6.1144, 'grad_norm': 1.635298490524292, 'learning_rate': 0.0001999996526902403, 'epoch': 0.03}\n",
            "{'loss': 5.9413, 'grad_norm': 0.9343745112419128, 'learning_rate': 0.0001999986107633737, 'epoch': 0.03}\n",
            "{'loss': 5.8607, 'grad_norm': 1.5203059911727905, 'learning_rate': 0.0001999968742266376, 'epoch': 0.03}\n",
            "{'loss': 5.0963, 'grad_norm': 0.7963446378707886, 'learning_rate': 0.00019999444309209432, 'epoch': 0.03}\n",
            "{'loss': 5.7967, 'grad_norm': 0.9261464476585388, 'learning_rate': 0.00019999131737663103, 'epoch': 0.03}\n",
            "{'loss': 5.7081, 'grad_norm': 0.5948179364204407, 'learning_rate': 0.00019998749710195955, 'epoch': 0.04}\n",
            "{'loss': 5.7194, 'grad_norm': 0.5819010138511658, 'learning_rate': 0.00019998298229461622, 'epoch': 0.04}\n",
            "{'loss': 5.5651, 'grad_norm': 0.4087268114089966, 'learning_rate': 0.0001999777729859618, 'epoch': 0.04}\n",
            "{'loss': 5.1342, 'grad_norm': 0.615106999874115, 'learning_rate': 0.0001999718692121812, 'epoch': 0.04}\n",
            "{'loss': 5.7091, 'grad_norm': 0.7014449834823608, 'learning_rate': 0.00019996527101428312, 'epoch': 0.04}\n",
            "{'loss': 5.7679, 'grad_norm': 0.6766050457954407, 'learning_rate': 0.00019995797843809995, 'epoch': 0.04}\n",
            "{'loss': 5.7059, 'grad_norm': 0.4263323247432709, 'learning_rate': 0.00019994999153428737, 'epoch': 0.04}\n",
            "{'loss': 5.7612, 'grad_norm': 0.4851571321487427, 'learning_rate': 0.00019994131035832395, 'epoch': 0.04}\n",
            "{'loss': 5.6986, 'grad_norm': 0.39352938532829285, 'learning_rate': 0.00019993193497051082, 'epoch': 0.04}\n",
            "{'loss': 5.7871, 'grad_norm': 0.4039774537086487, 'learning_rate': 0.0001999218654359713, 'epoch': 0.04}\n",
            "{'loss': 5.758, 'grad_norm': 0.47719061374664307, 'learning_rate': 0.00019991110182465032, 'epoch': 0.04}\n",
            "{'loss': 5.6901, 'grad_norm': 0.4707726240158081, 'learning_rate': 0.000199899644211314, 'epoch': 0.04}\n",
            "{'loss': 5.6535, 'grad_norm': 0.4528368413448334, 'learning_rate': 0.0001998874926755492, 'epoch': 0.05}\n",
            "{'loss': 5.6938, 'grad_norm': 0.4338509142398834, 'learning_rate': 0.00019987464730176284, 'epoch': 0.05}\n",
            "{'loss': 5.68, 'grad_norm': 0.44537419080734253, 'learning_rate': 0.0001998611081791814, 'epoch': 0.05}\n",
            "{'loss': 5.8294, 'grad_norm': 1.0253230333328247, 'learning_rate': 0.00019984687540185026, 'epoch': 0.05}\n",
            "{'loss': 5.641, 'grad_norm': 0.2847212255001068, 'learning_rate': 0.00019983194906863304, 'epoch': 0.05}\n",
            "{'loss': 5.8824, 'grad_norm': 0.27332237362861633, 'learning_rate': 0.00019981632928321104, 'epoch': 0.05}\n",
            "{'loss': 5.7629, 'grad_norm': 0.3177618980407715, 'learning_rate': 0.00019980001615408228, 'epoch': 0.05}\n",
            "{'loss': 5.7544, 'grad_norm': 0.4184955656528473, 'learning_rate': 0.00019978300979456095, 'epoch': 0.05}\n",
            "{'loss': 5.6169, 'grad_norm': 0.2928010821342468, 'learning_rate': 0.00019976531032277653, 'epoch': 0.05}\n",
            "{'loss': 5.7008, 'grad_norm': 0.4361027777194977, 'learning_rate': 0.00019974691786167303, 'epoch': 0.05}\n",
            "{'loss': 5.7234, 'grad_norm': 0.29084378480911255, 'learning_rate': 0.00019972783253900808, 'epoch': 0.05}\n",
            "{'loss': 5.6921, 'grad_norm': 0.46089988946914673, 'learning_rate': 0.00019970805448735204, 'epoch': 0.05}\n",
            "{'loss': 4.7719, 'grad_norm': 0.45034167170524597, 'learning_rate': 0.00019968758384408713, 'epoch': 0.06}\n",
            "{'loss': 5.7475, 'grad_norm': 0.4326910078525543, 'learning_rate': 0.00019966642075140638, 'epoch': 0.06}\n",
            "{'loss': 4.6554, 'grad_norm': 0.35321223735809326, 'learning_rate': 0.00019964456535631286, 'epoch': 0.06}\n",
            "{'loss': 5.5866, 'grad_norm': 0.4474884271621704, 'learning_rate': 0.00019962201781061834, 'epoch': 0.06}\n",
            "{'loss': 5.6421, 'grad_norm': 0.2767503559589386, 'learning_rate': 0.00019959877827094248, 'epoch': 0.06}\n",
            "{'loss': 5.6571, 'grad_norm': 0.4163239598274231, 'learning_rate': 0.00019957484689871167, 'epoch': 0.06}\n",
            "{'loss': 5.8351, 'grad_norm': 0.634209394454956, 'learning_rate': 0.00019955022386015792, 'epoch': 0.06}\n",
            "{'loss': 5.6571, 'grad_norm': 0.3312555253505707, 'learning_rate': 0.0001995249093263176, 'epoch': 0.06}\n",
            "{'loss': 5.6978, 'grad_norm': 0.4105691611766815, 'learning_rate': 0.00019949890347303046, 'epoch': 0.06}\n",
            "  6% 76/1229 [00:45<10:24,  1.84it/s]/usr/local/lib/python3.12/dist-packages/PIL/TiffImagePlugin.py:950: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n",
            "{'loss': 5.7384, 'grad_norm': 0.20774953067302704, 'learning_rate': 0.0001994722064809382, 'epoch': 0.06}\n",
            "{'loss': 5.607, 'grad_norm': 0.3595033586025238, 'learning_rate': 0.00019944481853548335, 'epoch': 0.06}\n",
            "{'loss': 5.6465, 'grad_norm': 0.1936912089586258, 'learning_rate': 0.00019941673982690794, 'epoch': 0.06}\n",
            "{'loss': 5.7106, 'grad_norm': 0.41248005628585815, 'learning_rate': 0.00019938797055025213, 'epoch': 0.07}\n",
            "{'loss': 5.6135, 'grad_norm': 0.3230983316898346, 'learning_rate': 0.00019935851090535295, 'epoch': 0.07}\n",
            "{'loss': 5.4368, 'grad_norm': 0.16401885449886322, 'learning_rate': 0.00019932836109684286, 'epoch': 0.07}\n",
            "{'loss': 5.4659, 'grad_norm': 0.20552390813827515, 'learning_rate': 0.00019929752133414827, 'epoch': 0.07}\n",
            "{'loss': 5.631, 'grad_norm': 0.23803575336933136, 'learning_rate': 0.0001992659918314882, 'epoch': 0.07}\n",
            "{'loss': 5.6206, 'grad_norm': 0.21835920214653015, 'learning_rate': 0.00019923377280787278, 'epoch': 0.07}\n",
            "{'loss': 4.6795, 'grad_norm': 0.17410127818584442, 'learning_rate': 0.0001992008644871016, 'epoch': 0.07}\n",
            "{'loss': 5.7268, 'grad_norm': 0.2869824171066284, 'learning_rate': 0.00019916726709776227, 'epoch': 0.07}\n",
            "{'loss': 5.6074, 'grad_norm': 0.17989782989025116, 'learning_rate': 0.00019913298087322883, 'epoch': 0.07}\n",
            "{'loss': 5.7012, 'grad_norm': 0.18867477774620056, 'learning_rate': 0.0001990980060516601, 'epoch': 0.07}\n",
            "{'loss': 5.6428, 'grad_norm': 0.2110256403684616, 'learning_rate': 0.00019906234287599798, 'epoch': 0.07}\n",
            "{'loss': 5.1122, 'grad_norm': 0.32712748646736145, 'learning_rate': 0.0001990259915939659, 'epoch': 0.07}\n",
            "{'loss': 5.7849, 'grad_norm': 0.38430461287498474, 'learning_rate': 0.0001989889524580669, 'epoch': 0.07}\n",
            "{'loss': 5.7003, 'grad_norm': 0.2570735812187195, 'learning_rate': 0.0001989512257255821, 'epoch': 0.08}\n",
            "{'loss': 5.7046, 'grad_norm': 0.19843211770057678, 'learning_rate': 0.00019891281165856873, 'epoch': 0.08}\n",
            "{'loss': 5.5917, 'grad_norm': 0.4436096251010895, 'learning_rate': 0.0001988737105238584, 'epoch': 0.08}\n",
            "{'loss': 5.6093, 'grad_norm': 0.2097264528274536, 'learning_rate': 0.0001988339225930552, 'epoch': 0.08}\n",
            "{'loss': 5.1217, 'grad_norm': 0.2327219545841217, 'learning_rate': 0.0001987934481425339, 'epoch': 0.08}\n",
            "{'loss': 5.6566, 'grad_norm': 0.38683050870895386, 'learning_rate': 0.00019875228745343794, 'epoch': 0.08}\n",
            "{'loss': 5.7937, 'grad_norm': 0.46317604184150696, 'learning_rate': 0.00019871044081167742, 'epoch': 0.08}\n",
            "{'loss': 5.6413, 'grad_norm': 0.2750377655029297, 'learning_rate': 0.0001986679085079274, 'epoch': 0.08}\n",
            "{'loss': 5.742, 'grad_norm': 0.21949072182178497, 'learning_rate': 0.00019862469083762547, 'epoch': 0.08}\n",
            "{'loss': 5.7101, 'grad_norm': 0.30594077706336975, 'learning_rate': 0.00019858078810097002, 'epoch': 0.08}\n",
            "{'loss': 5.6136, 'grad_norm': 0.3220682144165039, 'learning_rate': 0.00019853620060291812, 'epoch': 0.08}\n",
            "{'loss': 5.5979, 'grad_norm': 0.21915002167224884, 'learning_rate': 0.00019849092865318308, 'epoch': 0.08}\n",
            "{'loss': 5.6688, 'grad_norm': 0.3045479953289032, 'learning_rate': 0.00019844497256623283, 'epoch': 0.09}\n",
            "{'loss': 5.7153, 'grad_norm': 0.4310527443885803, 'learning_rate': 0.00019839833266128724, 'epoch': 0.09}\n",
            "{'loss': 5.6431, 'grad_norm': 0.9430519938468933, 'learning_rate': 0.00019835100926231624, 'epoch': 0.09}\n",
            "{'loss': 5.5817, 'grad_norm': 0.23441405594348907, 'learning_rate': 0.0001983030026980374, 'epoch': 0.09}\n",
            "{'loss': 5.7042, 'grad_norm': 0.19386227428913116, 'learning_rate': 0.00019825431330191363, 'epoch': 0.09}\n",
            "{'loss': 5.645, 'grad_norm': 0.20289091765880585, 'learning_rate': 0.00019820494141215104, 'epoch': 0.09}\n",
            "{'loss': 5.5743, 'grad_norm': 0.2532758116722107, 'learning_rate': 0.0001981548873716964, 'epoch': 0.09}\n",
            "{'loss': 5.6168, 'grad_norm': 0.20720712840557098, 'learning_rate': 0.00019810415152823478, 'epoch': 0.09}\n",
            "{'loss': 5.4723, 'grad_norm': 0.23947155475616455, 'learning_rate': 0.00019805273423418736, 'epoch': 0.09}\n",
            "{'loss': 5.6815, 'grad_norm': 0.3705061376094818, 'learning_rate': 0.00019800063584670863, 'epoch': 0.09}\n",
            "{'loss': 5.5956, 'grad_norm': 0.24630160629749298, 'learning_rate': 0.00019794785672768418, 'epoch': 0.09}\n",
            "{'loss': 4.0488, 'grad_norm': 0.14015372097492218, 'learning_rate': 0.00019789439724372806, 'epoch': 0.09}\n",
            "{'loss': 5.5728, 'grad_norm': 0.16509003937244415, 'learning_rate': 0.0001978402577661803, 'epoch': 0.1}\n",
            "{'loss': 5.5655, 'grad_norm': 0.2614422142505646, 'learning_rate': 0.00019778543867110426, 'epoch': 0.1}\n",
            "{'loss': 5.5978, 'grad_norm': 0.19366461038589478, 'learning_rate': 0.0001977299403392841, 'epoch': 0.1}\n",
            "{'loss': 5.6946, 'grad_norm': 0.21404185891151428, 'learning_rate': 0.00019767376315622204, 'epoch': 0.1}\n",
            "{'loss': 5.6009, 'grad_norm': 0.1799539029598236, 'learning_rate': 0.00019761690751213577, 'epoch': 0.1}\n",
            "{'loss': 5.0856, 'grad_norm': 0.20170313119888306, 'learning_rate': 0.00019755937380195568, 'epoch': 0.1}\n",
            "{'loss': 5.4387, 'grad_norm': 0.22110320627689362, 'learning_rate': 0.00019750116242532218, 'epoch': 0.1}\n",
            "{'loss': 5.5679, 'grad_norm': 0.1464080661535263, 'learning_rate': 0.00019744227378658283, 'epoch': 0.1}\n",
            "{'loss': 5.7262, 'grad_norm': 0.183103546500206, 'learning_rate': 0.0001973827082947896, 'epoch': 0.1}\n",
            "{'loss': 5.5805, 'grad_norm': 0.2896658778190613, 'learning_rate': 0.00019732246636369605, 'epoch': 0.1}\n",
            "{'loss': 5.6261, 'grad_norm': 0.19840054214000702, 'learning_rate': 0.00019726154841175438, 'epoch': 0.1}\n",
            "{'loss': 5.3956, 'grad_norm': 0.17482715845108032, 'learning_rate': 0.0001971999548621126, 'epoch': 0.1}\n",
            "{'loss': 5.6988, 'grad_norm': 0.3649531602859497, 'learning_rate': 0.00019713768614261143, 'epoch': 0.1}\n",
            "{'loss': 5.633, 'grad_norm': 0.2258874624967575, 'learning_rate': 0.0001970747426857817, 'epoch': 0.11}\n",
            "{'loss': 5.696, 'grad_norm': 0.17494437098503113, 'learning_rate': 0.00019701112492884085, 'epoch': 0.11}\n",
            "{'loss': 5.6254, 'grad_norm': 0.20818841457366943, 'learning_rate': 0.00019694683331369022, 'epoch': 0.11}\n",
            "{'loss': 5.5552, 'grad_norm': 0.3894214928150177, 'learning_rate': 0.000196881868286912, 'epoch': 0.11}\n",
            "{'loss': 5.6024, 'grad_norm': 0.15873460471630096, 'learning_rate': 0.00019681623029976588, 'epoch': 0.11}\n",
            "{'loss': 5.5382, 'grad_norm': 0.11958424001932144, 'learning_rate': 0.00019674991980818618, 'epoch': 0.11}\n",
            "{'loss': 5.6215, 'grad_norm': 0.2584933638572693, 'learning_rate': 0.00019668293727277846, 'epoch': 0.11}\n",
            "{'loss': 5.6724, 'grad_norm': 0.3276452124118805, 'learning_rate': 0.00019661528315881654, 'epoch': 0.11}\n",
            "{'loss': 5.4662, 'grad_norm': 0.10599692165851593, 'learning_rate': 0.00019654695793623907, 'epoch': 0.11}\n",
            "{'loss': 5.6135, 'grad_norm': 0.2222614735364914, 'learning_rate': 0.00019647796207964641, 'epoch': 0.11}\n",
            "{'loss': 5.5641, 'grad_norm': 0.17488521337509155, 'learning_rate': 0.00019640829606829723, 'epoch': 0.11}\n",
            "{'loss': 5.5757, 'grad_norm': 0.16911815106868744, 'learning_rate': 0.0001963379603861052, 'epoch': 0.11}\n",
            "{'loss': 5.4941, 'grad_norm': 0.13997240364551544, 'learning_rate': 0.00019626695552163578, 'epoch': 0.12}\n",
            "{'loss': 5.6141, 'grad_norm': 0.20236779749393463, 'learning_rate': 0.00019619528196810254, 'epoch': 0.12}\n",
            "{'loss': 5.0676, 'grad_norm': 0.1705796718597412, 'learning_rate': 0.00019612294022336405, 'epoch': 0.12}\n",
            "{'loss': 5.1856, 'grad_norm': 0.18532389402389526, 'learning_rate': 0.00019604993078992016, 'epoch': 0.12}\n",
            "{'loss': 5.4167, 'grad_norm': 0.1334388554096222, 'learning_rate': 0.0001959762541749086, 'epoch': 0.12}\n",
            "{'loss': 5.5265, 'grad_norm': 0.16272448003292084, 'learning_rate': 0.00019590191089010158, 'epoch': 0.12}\n",
            "{'loss': 5.4421, 'grad_norm': 0.13868139684200287, 'learning_rate': 0.00019582690145190202, 'epoch': 0.12}\n",
            "{'loss': 5.6216, 'grad_norm': 0.14887972176074982, 'learning_rate': 0.0001957512263813402, 'epoch': 0.12}\n",
            "{'loss': 5.5905, 'grad_norm': 0.15501737594604492, 'learning_rate': 0.00019567488620406983, 'epoch': 0.12}\n",
            "{'loss': 5.6057, 'grad_norm': 0.15818272531032562, 'learning_rate': 0.0001955978814503647, 'epoch': 0.12}\n",
            "{'loss': 5.5683, 'grad_norm': 0.13336874544620514, 'learning_rate': 0.0001955202126551149, 'epoch': 0.12}\n",
            "{'loss': 5.736, 'grad_norm': 0.21292641758918762, 'learning_rate': 0.00019544188035782307, 'epoch': 0.12}\n",
            "{'loss': 5.3103, 'grad_norm': 0.2697506844997406, 'learning_rate': 0.00019536288510260056, 'epoch': 0.13}\n",
            "{'loss': 5.5879, 'grad_norm': 0.1397726684808731, 'learning_rate': 0.0001952832274381639, 'epoch': 0.13}\n",
            "{'loss': 4.4103, 'grad_norm': 0.1410389244556427, 'learning_rate': 0.0001952029079178307, 'epoch': 0.13}\n",
            "{'loss': 5.5289, 'grad_norm': 0.13868190348148346, 'learning_rate': 0.0001951219270995161, 'epoch': 0.13}\n",
            "{'loss': 5.7646, 'grad_norm': 0.35601893067359924, 'learning_rate': 0.00019504028554572864, 'epoch': 0.13}\n",
            "{'loss': 5.7505, 'grad_norm': 0.32441967725753784, 'learning_rate': 0.0001949579838235665, 'epoch': 0.13}\n",
            "{'loss': 5.6206, 'grad_norm': 0.2781989872455597, 'learning_rate': 0.00019487502250471349, 'epoch': 0.13}\n",
            "{'loss': 5.5576, 'grad_norm': 0.43599602580070496, 'learning_rate': 0.0001947914021654351, 'epoch': 0.13}\n",
            "{'loss': 5.6486, 'grad_norm': 0.18806865811347961, 'learning_rate': 0.00019470712338657458, 'epoch': 0.13}\n",
            "{'loss': 5.6372, 'grad_norm': 0.19718453288078308, 'learning_rate': 0.00019462218675354875, 'epoch': 0.13}\n",
            "{'loss': 4.8027, 'grad_norm': 0.1733129769563675, 'learning_rate': 0.00019453659285634408, 'epoch': 0.13}\n",
            "{'loss': 5.6457, 'grad_norm': 0.2712439298629761, 'learning_rate': 0.00019445034228951245, 'epoch': 0.13}\n",
            "{'loss': 5.4944, 'grad_norm': 0.22785431146621704, 'learning_rate': 0.00019436343565216711, 'epoch': 0.14}\n",
            "{'loss': 5.6243, 'grad_norm': 0.19786140322685242, 'learning_rate': 0.00019427587354797855, 'epoch': 0.14}\n",
            "{'loss': 4.9969, 'grad_norm': 0.13313625752925873, 'learning_rate': 0.0001941876565851703, 'epoch': 0.14}\n",
            "{'loss': 5.5962, 'grad_norm': 0.20516453683376312, 'learning_rate': 0.00019409878537651453, 'epoch': 0.14}\n",
            "{'loss': 5.508, 'grad_norm': 0.18816909193992615, 'learning_rate': 0.000194009260539328, 'epoch': 0.14}\n",
            "{'loss': 5.1794, 'grad_norm': 0.21106968820095062, 'learning_rate': 0.0001939190826954677, 'epoch': 0.14}\n",
            "{'loss': 5.6232, 'grad_norm': 0.1757524162530899, 'learning_rate': 0.00019382825247132664, 'epoch': 0.14}\n",
            "{'loss': 5.6626, 'grad_norm': 0.1665801703929901, 'learning_rate': 0.00019373677049782916, 'epoch': 0.14}\n",
            "{'loss': 5.6228, 'grad_norm': 0.14771491289138794, 'learning_rate': 0.00019364463741042694, 'epoch': 0.14}\n",
            "{'loss': 5.6527, 'grad_norm': 0.5839395523071289, 'learning_rate': 0.0001935518538490944, 'epoch': 0.14}\n",
            "{'loss': 4.6307, 'grad_norm': 0.11365093290805817, 'learning_rate': 0.00019345842045832428, 'epoch': 0.14}\n",
            "{'loss': 5.7342, 'grad_norm': 0.22580087184906006, 'learning_rate': 0.00019336433788712313, 'epoch': 0.14}\n",
            "{'loss': 5.6203, 'grad_norm': 0.16532112658023834, 'learning_rate': 0.00019326960678900688, 'epoch': 0.14}\n",
            "{'loss': 5.7746, 'grad_norm': 0.17865242063999176, 'learning_rate': 0.00019317422782199616, 'epoch': 0.15}\n",
            "{'loss': 5.2995, 'grad_norm': 0.18401747941970825, 'learning_rate': 0.000193078201648612, 'epoch': 0.15}\n",
            "{'loss': 4.9808, 'grad_norm': 0.14727851748466492, 'learning_rate': 0.00019298152893587085, 'epoch': 0.15}\n",
            "{'loss': 5.6312, 'grad_norm': 0.22253459692001343, 'learning_rate': 0.00019288421035528028, 'epoch': 0.15}\n",
            "{'loss': 5.5612, 'grad_norm': 0.20086011290550232, 'learning_rate': 0.00019278624658283417, 'epoch': 0.15}\n",
            "{'loss': 5.2174, 'grad_norm': 0.19212783873081207, 'learning_rate': 0.00019268763829900798, 'epoch': 0.15}\n",
            "{'loss': 5.5752, 'grad_norm': 0.17325805127620697, 'learning_rate': 0.00019258838618875406, 'epoch': 0.15}\n",
            "{'loss': 5.5709, 'grad_norm': 0.1909487396478653, 'learning_rate': 0.000192488490941497, 'epoch': 0.15}\n",
            "{'loss': 5.2483, 'grad_norm': 0.2001839280128479, 'learning_rate': 0.0001923879532511287, 'epoch': 0.15}\n",
            "{'loss': 5.6027, 'grad_norm': 0.1578589826822281, 'learning_rate': 0.0001922867738160035, 'epoch': 0.15}\n",
            "{'loss': 5.5572, 'grad_norm': 0.20008181035518646, 'learning_rate': 0.0001921849533389336, 'epoch': 0.15}\n",
            "{'loss': 5.6922, 'grad_norm': 0.8894120454788208, 'learning_rate': 0.0001920824925271838, 'epoch': 0.15}\n",
            "{'loss': 5.638, 'grad_norm': 0.1724453568458557, 'learning_rate': 0.00019197939209246697, 'epoch': 0.16}\n",
            "{'loss': 5.5293, 'grad_norm': 0.19225743412971497, 'learning_rate': 0.00019187565275093887, 'epoch': 0.16}\n",
            "{'loss': 5.5501, 'grad_norm': 0.14626210927963257, 'learning_rate': 0.0001917712752231932, 'epoch': 0.16}\n",
            "{'loss': 5.5822, 'grad_norm': 0.16754695773124695, 'learning_rate': 0.00019166626023425662, 'epoch': 0.16}\n",
            "{'loss': 5.4917, 'grad_norm': 0.10971532762050629, 'learning_rate': 0.00019156060851358375, 'epoch': 0.16}\n",
            "{'loss': 5.6192, 'grad_norm': 0.21388192474842072, 'learning_rate': 0.00019145432079505206, 'epoch': 0.16}\n",
            "{'loss': 5.7297, 'grad_norm': 1.0453096628189087, 'learning_rate': 0.0001913473978169568, 'epoch': 0.16}\n",
            "{'loss': 5.7139, 'grad_norm': 0.20174171030521393, 'learning_rate': 0.00019123984032200586, 'epoch': 0.16}\n",
            "{'loss': 5.2632, 'grad_norm': 0.29256314039230347, 'learning_rate': 0.00019113164905731455, 'epoch': 0.16}\n",
            "{'loss': 5.1527, 'grad_norm': 0.41067948937416077, 'learning_rate': 0.00019102282477440055, 'epoch': 0.16}\n",
            "{'loss': 5.547, 'grad_norm': 0.25863292813301086, 'learning_rate': 0.00019091336822917856, 'epoch': 0.16}\n",
            "{'loss': 5.2668, 'grad_norm': 0.3090297281742096, 'learning_rate': 0.00019080328018195513, 'epoch': 0.16}\n",
            "{'loss': 5.4938, 'grad_norm': 0.13847720623016357, 'learning_rate': 0.0001906925613974233, 'epoch': 0.17}\n",
            "{'loss': 5.1337, 'grad_norm': 0.3382842242717743, 'learning_rate': 0.00019058121264465733, 'epoch': 0.17}\n",
            "{'loss': 5.416, 'grad_norm': 0.14038684964179993, 'learning_rate': 0.00019046923469710745, 'epoch': 0.17}\n",
            "{'loss': 5.5139, 'grad_norm': 0.2307513803243637, 'learning_rate': 0.00019035662833259432, 'epoch': 0.17}\n",
            "{'loss': 5.5598, 'grad_norm': 0.16229456663131714, 'learning_rate': 0.0001902433943333037, 'epoch': 0.17}\n",
            "{'loss': 5.701, 'grad_norm': 0.18399132788181305, 'learning_rate': 0.0001901295334857811, 'epoch': 0.17}\n",
            "{'loss': 5.6611, 'grad_norm': 0.2562008500099182, 'learning_rate': 0.00019001504658092616, 'epoch': 0.17}\n",
            "{'loss': 5.5904, 'grad_norm': 0.22134393453598022, 'learning_rate': 0.00018989993441398726, 'epoch': 0.17}\n",
            "{'loss': 4.9079, 'grad_norm': 0.17674623429775238, 'learning_rate': 0.00018978419778455604, 'epoch': 0.17}\n",
            "{'loss': 5.6429, 'grad_norm': 0.1708010882139206, 'learning_rate': 0.00018966783749656163, 'epoch': 0.17}\n",
            "{'loss': 5.6146, 'grad_norm': 0.14867204427719116, 'learning_rate': 0.00018955085435826537, 'epoch': 0.17}\n",
            "{'loss': 4.7468, 'grad_norm': 0.22460412979125977, 'learning_rate': 0.00018943324918225494, 'epoch': 0.17}\n",
            "{'loss': 5.5558, 'grad_norm': 0.1542593091726303, 'learning_rate': 0.00018931502278543886, 'epoch': 0.17}\n",
            "{'loss': 5.7194, 'grad_norm': 0.30485808849334717, 'learning_rate': 0.0001891961759890408, 'epoch': 0.18}\n",
            "{'loss': 4.9675, 'grad_norm': 0.16808900237083435, 'learning_rate': 0.0001890767096185937, 'epoch': 0.18}\n",
            "{'loss': 5.6349, 'grad_norm': 0.1340656280517578, 'learning_rate': 0.00018895662450393438, 'epoch': 0.18}\n",
            "{'loss': 4.9922, 'grad_norm': 0.17560666799545288, 'learning_rate': 0.0001888359214791975, 'epoch': 0.18}\n",
            "{'loss': 5.5968, 'grad_norm': 0.24407123029232025, 'learning_rate': 0.00018871460138280972, 'epoch': 0.18}\n",
            "{'loss': 5.4515, 'grad_norm': 0.31601253151893616, 'learning_rate': 0.0001885926650574842, 'epoch': 0.18}\n",
            "{'loss': 5.6715, 'grad_norm': 0.139661967754364, 'learning_rate': 0.00018847011335021449, 'epoch': 0.18}\n",
            "{'loss': 5.5303, 'grad_norm': 0.1757218837738037, 'learning_rate': 0.00018834694711226857, 'epoch': 0.18}\n",
            "{'loss': 5.4032, 'grad_norm': 0.10525058954954147, 'learning_rate': 0.0001882231671991832, 'epoch': 0.18}\n",
            "{'loss': 5.2662, 'grad_norm': 0.25592416524887085, 'learning_rate': 0.00018809877447075788, 'epoch': 0.18}\n",
            "{'loss': 5.5904, 'grad_norm': 0.237284854054451, 'learning_rate': 0.00018797376979104872, 'epoch': 0.18}\n",
            "{'loss': 5.4008, 'grad_norm': 0.27109968662261963, 'learning_rate': 0.00018784815402836264, 'epoch': 0.18}\n",
            "{'loss': 5.5739, 'grad_norm': 0.17521436512470245, 'learning_rate': 0.00018772192805525126, 'epoch': 0.19}\n",
            "{'loss': 5.5216, 'grad_norm': 0.25154584646224976, 'learning_rate': 0.0001875950927485048, 'epoch': 0.19}\n",
            "{'loss': 5.4312, 'grad_norm': 0.17726297676563263, 'learning_rate': 0.0001874676489891461, 'epoch': 0.19}\n",
            "{'loss': 5.5331, 'grad_norm': 0.31425637006759644, 'learning_rate': 0.00018733959766242431, 'epoch': 0.19}\n",
            "{'loss': 5.3702, 'grad_norm': 0.23063670098781586, 'learning_rate': 0.00018721093965780907, 'epoch': 0.19}\n",
            "{'loss': 5.3186, 'grad_norm': 0.1456817388534546, 'learning_rate': 0.00018708167586898387, 'epoch': 0.19}\n",
            "{'loss': 5.4073, 'grad_norm': 0.1506948173046112, 'learning_rate': 0.00018695180719384029, 'epoch': 0.19}\n",
            "{'loss': 5.5342, 'grad_norm': 0.1234881728887558, 'learning_rate': 0.00018682133453447146, 'epoch': 0.19}\n",
            "{'loss': 5.6753, 'grad_norm': 0.1750371754169464, 'learning_rate': 0.00018669025879716595, 'epoch': 0.19}\n",
            "{'loss': 5.5737, 'grad_norm': 0.17898082733154297, 'learning_rate': 0.00018655858089240143, 'epoch': 0.19}\n",
            "{'loss': 5.4374, 'grad_norm': 0.19198128581047058, 'learning_rate': 0.00018642630173483832, 'epoch': 0.19}\n",
            "{'loss': 5.7495, 'grad_norm': 0.18528595566749573, 'learning_rate': 0.00018629342224331347, 'epoch': 0.19}\n",
            "{'loss': 5.5267, 'grad_norm': 0.21450164914131165, 'learning_rate': 0.00018615994334083378, 'epoch': 0.2}\n",
            "{'loss': 5.6256, 'grad_norm': 0.13891597092151642, 'learning_rate': 0.00018602586595456972, 'epoch': 0.2}\n",
            "{'loss': 5.5203, 'grad_norm': 0.2289591282606125, 'learning_rate': 0.00018589119101584898, 'epoch': 0.2}\n",
            "{'loss': 5.4461, 'grad_norm': 0.23577973246574402, 'learning_rate': 0.00018575591946015004, 'epoch': 0.2}\n",
            "{'loss': 5.668, 'grad_norm': 0.16076351702213287, 'learning_rate': 0.00018562005222709548, 'epoch': 0.2}\n",
            "{'loss': 5.5046, 'grad_norm': 0.09316297620534897, 'learning_rate': 0.00018548359026044565, 'epoch': 0.2}\n",
            "{'loss': 5.6151, 'grad_norm': 0.21874739229679108, 'learning_rate': 0.00018534653450809197, 'epoch': 0.2}\n",
            "{'loss': 5.546, 'grad_norm': 0.22663846611976624, 'learning_rate': 0.0001852088859220505, 'epoch': 0.2}\n",
            "{'loss': 5.4351, 'grad_norm': 0.23962295055389404, 'learning_rate': 0.00018507064545845515, 'epoch': 0.2}\n",
            "{'loss': 4.8683, 'grad_norm': 0.14924190938472748, 'learning_rate': 0.00018493181407755116, 'epoch': 0.2}\n",
            "{'loss': 5.6043, 'grad_norm': 0.10622184723615646, 'learning_rate': 0.0001847923927436884, 'epoch': 0.2}\n",
            "{'loss': 5.6062, 'grad_norm': 0.16549378633499146, 'learning_rate': 0.00018465238242531466, 'epoch': 0.2}\n",
            "{'loss': 5.4676, 'grad_norm': 0.20738907158374786, 'learning_rate': 0.00018451178409496902, 'epoch': 0.21}\n",
            "{'loss': 5.5656, 'grad_norm': 0.16711843013763428, 'learning_rate': 0.0001843705987292748, 'epoch': 0.21}\n",
            "{'loss': 5.4566, 'grad_norm': 0.2533760666847229, 'learning_rate': 0.0001842288273089332, 'epoch': 0.21}\n",
            "{'loss': 5.5559, 'grad_norm': 0.15389707684516907, 'learning_rate': 0.00018408647081871618, 'epoch': 0.21}\n",
            "{'loss': 5.5503, 'grad_norm': 0.13789162039756775, 'learning_rate': 0.00018394353024745965, 'epoch': 0.21}\n",
            "{'loss': 3.8711, 'grad_norm': 0.11784239858388901, 'learning_rate': 0.00018380000658805678, 'epoch': 0.21}\n",
            "{'loss': 5.4696, 'grad_norm': 0.11514238268136978, 'learning_rate': 0.00018365590083745085, 'epoch': 0.21}\n",
            "{'loss': 5.6361, 'grad_norm': 0.25542551279067993, 'learning_rate': 0.00018351121399662863, 'epoch': 0.21}\n",
            "{'loss': 5.7363, 'grad_norm': 0.3014337122440338, 'learning_rate': 0.00018336594707061307, 'epoch': 0.21}\n",
            "{'loss': 5.6057, 'grad_norm': 0.1380842626094818, 'learning_rate': 0.00018322010106845663, 'epoch': 0.21}\n",
            "{'loss': 5.4492, 'grad_norm': 0.19729645550251007, 'learning_rate': 0.0001830736770032341, 'epoch': 0.21}\n",
            "{'loss': 5.4972, 'grad_norm': 0.18335071206092834, 'learning_rate': 0.00018292667589203565, 'epoch': 0.21}\n",
            "{'loss': 5.5643, 'grad_norm': 0.1520020216703415, 'learning_rate': 0.00018277909875595967, 'epoch': 0.21}\n",
            "{'loss': 5.5476, 'grad_norm': 0.13834935426712036, 'learning_rate': 0.00018263094662010574, 'epoch': 0.22}\n",
            "{'loss': 5.7245, 'grad_norm': 0.1552107036113739, 'learning_rate': 0.00018248222051356754, 'epoch': 0.22}\n",
            "{'loss': 5.076, 'grad_norm': 0.1534809023141861, 'learning_rate': 0.00018233292146942559, 'epoch': 0.22}\n",
            "{'loss': 5.5749, 'grad_norm': 0.11923040449619293, 'learning_rate': 0.00018218305052474025, 'epoch': 0.22}\n",
            "{'loss': 5.545, 'grad_norm': 0.09932737052440643, 'learning_rate': 0.00018203260872054432, 'epoch': 0.22}\n",
            "{'loss': 5.5395, 'grad_norm': 0.144911989569664, 'learning_rate': 0.00018188159710183594, 'epoch': 0.22}\n",
            "{'loss': 5.3114, 'grad_norm': 0.17989115417003632, 'learning_rate': 0.0001817300167175713, 'epoch': 0.22}\n",
            "{'loss': 5.6497, 'grad_norm': 0.19227156043052673, 'learning_rate': 0.00018157786862065732, 'epoch': 0.22}\n",
            "{'loss': 5.5742, 'grad_norm': 0.14750546216964722, 'learning_rate': 0.00018142515386794443, 'epoch': 0.22}\n",
            "{'loss': 5.462, 'grad_norm': 0.16563186049461365, 'learning_rate': 0.00018127187352021907, 'epoch': 0.22}\n",
            "{'loss': 5.6609, 'grad_norm': 0.11718206107616425, 'learning_rate': 0.0001811180286421964, 'epoch': 0.22}\n",
            "{'loss': 5.6459, 'grad_norm': 0.15764525532722473, 'learning_rate': 0.00018096362030251313, 'epoch': 0.22}\n",
            "{'loss': 5.6543, 'grad_norm': 0.11973915994167328, 'learning_rate': 0.00018080864957371957, 'epoch': 0.23}\n",
            "{'loss': 5.4315, 'grad_norm': 0.27085962891578674, 'learning_rate': 0.00018065311753227273, 'epoch': 0.23}\n",
            "{'loss': 4.4607, 'grad_norm': 0.1412597894668579, 'learning_rate': 0.00018049702525852848, 'epoch': 0.23}\n",
            "{'loss': 5.4929, 'grad_norm': 0.13520044088363647, 'learning_rate': 0.00018034037383673427, 'epoch': 0.23}\n",
            "{'loss': 5.5645, 'grad_norm': 0.14992080628871918, 'learning_rate': 0.00018018316435502142, 'epoch': 0.23}\n",
            "{'loss': 5.5853, 'grad_norm': 0.17931261658668518, 'learning_rate': 0.00018002539790539773, 'epoch': 0.23}\n",
            "{'loss': 4.3993, 'grad_norm': 0.184067040681839, 'learning_rate': 0.00017986707558373968, 'epoch': 0.23}\n",
            "{'loss': 5.5028, 'grad_norm': 0.1568947583436966, 'learning_rate': 0.00017970819848978504, 'epoch': 0.23}\n",
            "{'loss': 5.5802, 'grad_norm': 0.1776595264673233, 'learning_rate': 0.00017954876772712517, 'epoch': 0.23}\n",
            "{'loss': 5.646, 'grad_norm': 0.1918664574623108, 'learning_rate': 0.0001793887844031972, 'epoch': 0.23}\n",
            "{'loss': 5.7938, 'grad_norm': 0.23649518191814423, 'learning_rate': 0.00017922824962927659, 'epoch': 0.23}\n",
            "{'loss': 5.0975, 'grad_norm': 0.13781781494617462, 'learning_rate': 0.00017906716452046915, 'epoch': 0.23}\n",
            "{'loss': 4.7174, 'grad_norm': 0.17901068925857544, 'learning_rate': 0.00017890553019570354, 'epoch': 0.24}\n",
            "{'loss': 5.536, 'grad_norm': 0.23689407110214233, 'learning_rate': 0.00017874334777772327, 'epoch': 0.24}\n",
            "{'loss': 5.1562, 'grad_norm': 0.14737693965435028, 'learning_rate': 0.0001785806183930791, 'epoch': 0.24}\n",
            "{'loss': 5.58, 'grad_norm': 0.234691321849823, 'learning_rate': 0.00017841734317212117, 'epoch': 0.24}\n",
            "{'loss': 5.5382, 'grad_norm': 0.2531448304653168, 'learning_rate': 0.00017825352324899095, 'epoch': 0.24}\n",
            "{'loss': 5.2216, 'grad_norm': 0.16300396621227264, 'learning_rate': 0.00017808915976161362, 'epoch': 0.24}\n",
            "{'loss': 5.5556, 'grad_norm': 0.13439622521400452, 'learning_rate': 0.00017792425385169006, 'epoch': 0.24}\n",
            "{'loss': 5.5221, 'grad_norm': 0.12063223868608475, 'learning_rate': 0.0001777588066646889, 'epoch': 0.24}\n",
            "{'loss': 5.5946, 'grad_norm': 0.49358436465263367, 'learning_rate': 0.0001775928193498386, 'epoch': 0.24}\n",
            "{'loss': 5.3308, 'grad_norm': 0.1964796930551529, 'learning_rate': 0.00017742629306011944, 'epoch': 0.24}\n",
            "{'loss': 5.4696, 'grad_norm': 0.1121722161769867, 'learning_rate': 0.00017725922895225554, 'epoch': 0.24}\n",
            "{'loss': 5.5885, 'grad_norm': 0.19910487532615662, 'learning_rate': 0.00017709162818670682, 'epoch': 0.24}\n",
            "{'loss': 5.6389, 'grad_norm': 0.17597979307174683, 'learning_rate': 0.00017692349192766088, 'epoch': 0.24}\n",
            "{'loss': 5.6571, 'grad_norm': 0.20586109161376953, 'learning_rate': 0.000176754821343025, 'epoch': 0.25}\n",
            "{'loss': 5.551, 'grad_norm': 0.1278647929430008, 'learning_rate': 0.000176585617604418, 'epoch': 0.25}\n",
            "{'loss': 5.7407, 'grad_norm': 0.16677355766296387, 'learning_rate': 0.0001764158818871621, 'epoch': 0.25}\n",
            "{'loss': 5.5159, 'grad_norm': 0.2275792956352234, 'learning_rate': 0.00017624561537027465, 'epoch': 0.25}\n",
            "{'loss': 5.5115, 'grad_norm': 0.221608966588974, 'learning_rate': 0.00017607481923646016, 'epoch': 0.25}\n",
            "{'loss': 5.6767, 'grad_norm': 0.12649071216583252, 'learning_rate': 0.00017590349467210193, 'epoch': 0.25}\n",
            "{'loss': 5.6336, 'grad_norm': 0.16143488883972168, 'learning_rate': 0.00017573164286725378, 'epoch': 0.25}\n",
            "{'loss': 5.7103, 'grad_norm': 0.21169230341911316, 'learning_rate': 0.00017555926501563196, 'epoch': 0.25}\n",
            "{'loss': 5.6699, 'grad_norm': 0.1487158238887787, 'learning_rate': 0.0001753863623146066, 'epoch': 0.25}\n",
            "{'loss': 5.6201, 'grad_norm': 0.11246936023235321, 'learning_rate': 0.00017521293596519364, 'epoch': 0.25}\n",
            "{'loss': 5.6173, 'grad_norm': 0.123260498046875, 'learning_rate': 0.0001750389871720463, 'epoch': 0.25}\n",
            "{'loss': 5.3561, 'grad_norm': 0.13178712129592896, 'learning_rate': 0.00017486451714344701, 'epoch': 0.25}\n",
            "{'loss': 5.7231, 'grad_norm': 0.20985198020935059, 'learning_rate': 0.00017468952709129846, 'epoch': 0.26}\n",
            "{'loss': 4.9289, 'grad_norm': 0.14563682675361633, 'learning_rate': 0.00017451401823111583, 'epoch': 0.26}\n",
            "{'loss': 5.0004, 'grad_norm': 0.11889741569757462, 'learning_rate': 0.00017433799178201786, 'epoch': 0.26}\n",
            "{'loss': 5.6822, 'grad_norm': 0.21279028058052063, 'learning_rate': 0.00017416144896671866, 'epoch': 0.26}\n",
            "{'loss': 5.5171, 'grad_norm': 0.212720587849617, 'learning_rate': 0.00017398439101151905, 'epoch': 0.26}\n",
            "{'loss': 5.4371, 'grad_norm': 0.17543648183345795, 'learning_rate': 0.0001738068191462982, 'epoch': 0.26}\n",
            "{'loss': 5.2729, 'grad_norm': 0.1386990249156952, 'learning_rate': 0.0001736287346045049, 'epoch': 0.26}\n",
            "{'loss': 5.6369, 'grad_norm': 0.17536568641662598, 'learning_rate': 0.00017345013862314913, 'epoch': 0.26}\n",
            "{'loss': 5.034, 'grad_norm': 0.11622073501348495, 'learning_rate': 0.00017327103244279348, 'epoch': 0.26}\n",
            "{'loss': 5.6097, 'grad_norm': 0.1450619101524353, 'learning_rate': 0.00017309141730754442, 'epoch': 0.26}\n",
            "{'loss': 5.5585, 'grad_norm': 0.15206223726272583, 'learning_rate': 0.00017291129446504375, 'epoch': 0.26}\n",
            "{'loss': 5.4396, 'grad_norm': 0.11144054681062698, 'learning_rate': 0.00017273066516645987, 'epoch': 0.26}\n",
            "{'loss': 5.5544, 'grad_norm': 0.1376873254776001, 'learning_rate': 0.00017254953066647913, 'epoch': 0.27}\n",
            "{'loss': 5.5579, 'grad_norm': 0.11600520461797714, 'learning_rate': 0.00017236789222329718, 'epoch': 0.27}\n",
            "{'loss': 5.6452, 'grad_norm': 0.17960844933986664, 'learning_rate': 0.00017218575109861008, 'epoch': 0.27}\n",
            "{'loss': 5.6506, 'grad_norm': 0.16403906047344208, 'learning_rate': 0.0001720031085576056, 'epoch': 0.27}\n",
            "{'loss': 4.9846, 'grad_norm': 0.14667603373527527, 'learning_rate': 0.00017181996586895454, 'epoch': 0.27}\n",
            "{'loss': 5.6379, 'grad_norm': 0.1711675375699997, 'learning_rate': 0.00017163632430480173, 'epoch': 0.27}\n",
            "{'loss': 5.3214, 'grad_norm': 0.1466732621192932, 'learning_rate': 0.0001714521851407573, 'epoch': 0.27}\n",
            "{'loss': 5.5459, 'grad_norm': 0.1865895688533783, 'learning_rate': 0.00017126754965588785, 'epoch': 0.27}\n",
            "{'loss': 5.6158, 'grad_norm': 0.18902406096458435, 'learning_rate': 0.0001710824191327075, 'epoch': 0.27}\n",
            "{'loss': 5.5597, 'grad_norm': 0.14627279341220856, 'learning_rate': 0.00017089679485716896, 'epoch': 0.27}\n",
            "{'loss': 5.7139, 'grad_norm': 0.157759428024292, 'learning_rate': 0.00017071067811865476, 'epoch': 0.27}\n",
            "{'loss': 5.1393, 'grad_norm': 0.13499143719673157, 'learning_rate': 0.00017052407020996804, 'epoch': 0.27}\n",
            "{'loss': 5.6016, 'grad_norm': 0.13596008718013763, 'learning_rate': 0.00017033697242732377, 'epoch': 0.28}\n",
            "{'loss': 5.6007, 'grad_norm': 0.1447802633047104, 'learning_rate': 0.00017014938607033968, 'epoch': 0.28}\n",
            "{'loss': 5.6004, 'grad_norm': 0.14436209201812744, 'learning_rate': 0.0001699613124420272, 'epoch': 0.28}\n",
            "{'loss': 5.5167, 'grad_norm': 0.14779336750507355, 'learning_rate': 0.00016977275284878242, 'epoch': 0.28}\n",
            "{'loss': 5.6203, 'grad_norm': 0.16021303832530975, 'learning_rate': 0.00016958370860037717, 'epoch': 0.28}\n",
            " 28% 342/1229 [03:10<08:01,  1.84it/s]/usr/local/lib/python3.12/dist-packages/PIL/TiffImagePlugin.py:950: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n",
            "{'loss': 5.5388, 'grad_norm': 0.15208177268505096, 'learning_rate': 0.00016939418100994972, 'epoch': 0.28}\n",
            "{'loss': 5.5816, 'grad_norm': 0.15161865949630737, 'learning_rate': 0.00016920417139399557, 'epoch': 0.28}\n",
            "{'loss': 5.6472, 'grad_norm': 0.15474188327789307, 'learning_rate': 0.0001690136810723587, 'epoch': 0.28}\n",
            "{'loss': 5.6607, 'grad_norm': 0.16770261526107788, 'learning_rate': 0.00016882271136822206, 'epoch': 0.28}\n",
            "{'loss': 5.5646, 'grad_norm': 0.12626874446868896, 'learning_rate': 0.0001686312636080985, 'epoch': 0.28}\n",
            "{'loss': 5.6058, 'grad_norm': 0.15054093301296234, 'learning_rate': 0.0001684393391218215, 'epoch': 0.28}\n",
            "{'loss': 5.5134, 'grad_norm': 0.1700124889612198, 'learning_rate': 0.00016824693924253595, 'epoch': 0.28}\n",
            "{'loss': 5.5851, 'grad_norm': 0.11705639213323593, 'learning_rate': 0.0001680540653066891, 'epoch': 0.28}\n",
            "{'loss': 5.5463, 'grad_norm': 0.18136386573314667, 'learning_rate': 0.00016786071865402088, 'epoch': 0.29}\n",
            "{'loss': 5.7, 'grad_norm': 0.2834891080856323, 'learning_rate': 0.0001676669006275549, 'epoch': 0.29}\n",
            "{'loss': 5.6396, 'grad_norm': 0.1448485255241394, 'learning_rate': 0.00016747261257358894, 'epoch': 0.29}\n",
            "{'loss': 5.5674, 'grad_norm': 0.12934209406375885, 'learning_rate': 0.00016727785584168581, 'epoch': 0.29}\n",
            "{'loss': 5.6695, 'grad_norm': 0.17642247676849365, 'learning_rate': 0.0001670826317846638, 'epoch': 0.29}\n",
            "{'loss': 5.676, 'grad_norm': 0.14720530807971954, 'learning_rate': 0.0001668869417585873, 'epoch': 0.29}\n",
            "{'loss': 5.604, 'grad_norm': 0.1329520344734192, 'learning_rate': 0.00016669078712275737, 'epoch': 0.29}\n",
            "{'loss': 5.5378, 'grad_norm': 0.17360974848270416, 'learning_rate': 0.0001664941692397025, 'epoch': 0.29}\n",
            "{'loss': 5.4691, 'grad_norm': 0.17285387217998505, 'learning_rate': 0.00016629708947516877, 'epoch': 0.29}\n",
            "{'loss': 5.1278, 'grad_norm': 0.12480762600898743, 'learning_rate': 0.00016609954919811077, 'epoch': 0.29}\n",
            "{'loss': 5.7159, 'grad_norm': 0.22919988632202148, 'learning_rate': 0.00016590154978068185, 'epoch': 0.29}\n",
            "{'loss': 5.5812, 'grad_norm': 0.12382206320762634, 'learning_rate': 0.00016570309259822453, 'epoch': 0.29}\n",
            "{'loss': 5.5359, 'grad_norm': 0.11513824015855789, 'learning_rate': 0.0001655041790292612, 'epoch': 0.3}\n",
            " 30% 363/1229 [03:22<07:48,  1.85it/s]/usr/local/lib/python3.12/dist-packages/PIL/TiffImagePlugin.py:950: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n",
            "{'loss': 5.5593, 'grad_norm': 0.11357497423887253, 'learning_rate': 0.00016530481045548426, 'epoch': 0.3}\n",
            "{'loss': 5.563, 'grad_norm': 0.10554051399230957, 'learning_rate': 0.00016510498826174686, 'epoch': 0.3}\n",
            "{'loss': 5.408, 'grad_norm': 0.17473921179771423, 'learning_rate': 0.00016490471383605288, 'epoch': 0.3}\n",
            "{'loss': 5.4703, 'grad_norm': 0.15378287434577942, 'learning_rate': 0.00016470398856954755, 'epoch': 0.3}\n",
            "{'loss': 5.5413, 'grad_norm': 0.1921520084142685, 'learning_rate': 0.0001645028138565078, 'epoch': 0.3}\n",
            "{'loss': 5.5533, 'grad_norm': 0.12518787384033203, 'learning_rate': 0.0001643011910943325, 'epoch': 0.3}\n",
            "{'loss': 5.6562, 'grad_norm': 0.22327172756195068, 'learning_rate': 0.0001640991216835326, 'epoch': 0.3}\n",
            "{'loss': 5.7365, 'grad_norm': 0.19781166315078735, 'learning_rate': 0.00016389660702772173, 'epoch': 0.3}\n",
            "{'loss': 5.3978, 'grad_norm': 0.13450941443443298, 'learning_rate': 0.0001636936485336062, 'epoch': 0.3}\n",
            "{'loss': 5.7235, 'grad_norm': 0.19387508928775787, 'learning_rate': 0.00016349024761097534, 'epoch': 0.3}\n",
            "{'loss': 5.5581, 'grad_norm': 0.20097704231739044, 'learning_rate': 0.0001632864056726917, 'epoch': 0.3}\n",
            "{'loss': 5.5089, 'grad_norm': 0.25422337651252747, 'learning_rate': 0.00016308212413468113, 'epoch': 0.31}\n",
            "{'loss': 5.5526, 'grad_norm': 0.18199792504310608, 'learning_rate': 0.000162877404415923, 'epoch': 0.31}\n",
            "{'loss': 5.4648, 'grad_norm': 0.18970905244350433, 'learning_rate': 0.00016267224793844057, 'epoch': 0.31}\n",
            "{'loss': 5.6507, 'grad_norm': 0.16133195161819458, 'learning_rate': 0.00016246665612729074, 'epoch': 0.31}\n",
            "{'loss': 5.6731, 'grad_norm': 0.213705375790596, 'learning_rate': 0.00016226063041055428, 'epoch': 0.31}\n",
            "{'loss': 5.5846, 'grad_norm': 0.19529522955417633, 'learning_rate': 0.0001620541722193261, 'epoch': 0.31}\n",
            "{'loss': 5.6425, 'grad_norm': 0.20836658775806427, 'learning_rate': 0.00016184728298770508, 'epoch': 0.31}\n",
            "{'loss': 5.6638, 'grad_norm': 0.1954594850540161, 'learning_rate': 0.00016163996415278424, 'epoch': 0.31}\n",
            "{'loss': 5.6274, 'grad_norm': 0.15649983286857605, 'learning_rate': 0.00016143221715464066, 'epoch': 0.31}\n",
            "{'loss': 5.4902, 'grad_norm': 0.13928522169589996, 'learning_rate': 0.00016122404343632546, 'epoch': 0.31}\n",
            "{'loss': 5.6111, 'grad_norm': 0.21341800689697266, 'learning_rate': 0.00016101544444385404, 'epoch': 0.31}\n",
            "{'loss': 5.6157, 'grad_norm': 0.21715804934501648, 'learning_rate': 0.00016080642162619565, 'epoch': 0.31}\n",
            "{'loss': 5.5856, 'grad_norm': 0.18313336372375488, 'learning_rate': 0.0001605969764352636, 'epoch': 0.31}\n",
            "{'loss': 5.4721, 'grad_norm': 0.1811215877532959, 'learning_rate': 0.00016038711032590508, 'epoch': 0.32}\n",
            "{'loss': 5.6346, 'grad_norm': 0.1863955855369568, 'learning_rate': 0.00016017682475589102, 'epoch': 0.32}\n",
            "{'loss': 5.5596, 'grad_norm': 0.13063400983810425, 'learning_rate': 0.00015996612118590603, 'epoch': 0.32}\n",
            "{'loss': 5.5772, 'grad_norm': 0.198960080742836, 'learning_rate': 0.00015975500107953832, 'epoch': 0.32}\n",
            "{'loss': 5.6697, 'grad_norm': 0.2504955530166626, 'learning_rate': 0.00015954346590326925, 'epoch': 0.32}\n",
            "{'loss': 5.6355, 'grad_norm': 0.17655996978282928, 'learning_rate': 0.0001593315171264635, 'epoch': 0.32}\n",
            "{'loss': 5.1268, 'grad_norm': 0.16891340911388397, 'learning_rate': 0.00015911915622135862, 'epoch': 0.32}\n",
            "{'loss': 4.9482, 'grad_norm': 0.1695115566253662, 'learning_rate': 0.00015890638466305496, 'epoch': 0.32}\n",
            "{'loss': 5.236, 'grad_norm': 0.16296684741973877, 'learning_rate': 0.00015869320392950526, 'epoch': 0.32}\n",
            "{'loss': 5.5658, 'grad_norm': 0.1935933232307434, 'learning_rate': 0.00015847961550150447, 'epoch': 0.32}\n",
            "{'loss': 5.5775, 'grad_norm': 0.14955276250839233, 'learning_rate': 0.00015826562086267956, 'epoch': 0.32}\n",
            "{'loss': 5.5381, 'grad_norm': 0.15204453468322754, 'learning_rate': 0.00015805122149947903, 'epoch': 0.32}\n",
            "{'loss': 5.6461, 'grad_norm': 0.1248549222946167, 'learning_rate': 0.00015783641890116274, 'epoch': 0.33}\n",
            "{'loss': 5.5183, 'grad_norm': 0.1375003159046173, 'learning_rate': 0.00015762121455979142, 'epoch': 0.33}\n",
            "{'loss': 5.4757, 'grad_norm': 0.12090767174959183, 'learning_rate': 0.00015740560997021648, 'epoch': 0.33}\n",
            "{'loss': 5.4433, 'grad_norm': 0.13177676498889923, 'learning_rate': 0.0001571896066300694, 'epoch': 0.33}\n",
            "{'loss': 4.9519, 'grad_norm': 0.13077791035175323, 'learning_rate': 0.0001569732060397517, 'epoch': 0.33}\n",
            "{'loss': 5.4863, 'grad_norm': 0.10141532868146896, 'learning_rate': 0.00015675640970242393, 'epoch': 0.33}\n",
            "{'loss': 5.2419, 'grad_norm': 0.138255313038826, 'learning_rate': 0.00015653921912399589, 'epoch': 0.33}\n",
            "{'loss': 5.6143, 'grad_norm': 0.1988605409860611, 'learning_rate': 0.0001563216358131157, 'epoch': 0.33}\n",
            "{'loss': 5.5948, 'grad_norm': 0.12124762684106827, 'learning_rate': 0.00015610366128115954, 'epoch': 0.33}\n",
            "{'loss': 4.8481, 'grad_norm': 0.14500677585601807, 'learning_rate': 0.00015588529704222098, 'epoch': 0.33}\n",
            "{'loss': 5.7153, 'grad_norm': 0.15288567543029785, 'learning_rate': 0.0001556665446131007, 'epoch': 0.33}\n",
            "{'loss': 5.5842, 'grad_norm': 0.10554302483797073, 'learning_rate': 0.00015544740551329578, 'epoch': 0.33}\n",
            "{'loss': 5.6547, 'grad_norm': 0.19235268235206604, 'learning_rate': 0.00015522788126498917, 'epoch': 0.34}\n",
            "{'loss': 5.5064, 'grad_norm': 0.21327091753482819, 'learning_rate': 0.00015500797339303913, 'epoch': 0.34}\n",
            "{'loss': 5.5443, 'grad_norm': 0.17614637315273285, 'learning_rate': 0.0001547876834249687, 'epoch': 0.34}\n",
            "{'loss': 5.5451, 'grad_norm': 0.18888694047927856, 'learning_rate': 0.00015456701289095497, 'epoch': 0.34}\n",
            "{'loss': 5.5779, 'grad_norm': 0.1373145580291748, 'learning_rate': 0.00015434596332381852, 'epoch': 0.34}\n",
            "{'loss': 5.6715, 'grad_norm': 0.18823273479938507, 'learning_rate': 0.0001541245362590128, 'epoch': 0.34}\n",
            "{'loss': 5.5572, 'grad_norm': 0.1529136449098587, 'learning_rate': 0.00015390273323461352, 'epoch': 0.34}\n",
            "{'loss': 5.6055, 'grad_norm': 0.14741401374340057, 'learning_rate': 0.00015368055579130768, 'epoch': 0.34}\n",
            "{'loss': 5.5157, 'grad_norm': 0.12506632506847382, 'learning_rate': 0.00015345800547238316, 'epoch': 0.34}\n",
            "{'loss': 5.4663, 'grad_norm': 0.1024351716041565, 'learning_rate': 0.00015323508382371795, 'epoch': 0.34}\n",
            "{'loss': 5.6518, 'grad_norm': 0.189619779586792, 'learning_rate': 0.00015301179239376938, 'epoch': 0.34}\n",
            "{'loss': 5.5128, 'grad_norm': 0.14116470515727997, 'learning_rate': 0.00015278813273356324, 'epoch': 0.34}\n",
            "{'loss': 5.0804, 'grad_norm': 0.1443474292755127, 'learning_rate': 0.00015256410639668318, 'epoch': 0.34}\n",
            "{'loss': 5.3925, 'grad_norm': 0.22234869003295898, 'learning_rate': 0.0001523397149392599, 'epoch': 0.35}\n",
            "{'loss': 5.7128, 'grad_norm': 0.1593235582113266, 'learning_rate': 0.00015211495991996027, 'epoch': 0.35}\n",
            "{'loss': 5.2247, 'grad_norm': 0.11997351050376892, 'learning_rate': 0.0001518898428999765, 'epoch': 0.35}\n",
            "{'loss': 5.4795, 'grad_norm': 0.1568034440279007, 'learning_rate': 0.00015166436544301537, 'epoch': 0.35}\n",
            "{'loss': 5.4964, 'grad_norm': 0.2003520429134369, 'learning_rate': 0.00015143852911528728, 'epoch': 0.35}\n",
            "{'loss': 5.595, 'grad_norm': 0.12901867926120758, 'learning_rate': 0.0001512123354854955, 'epoch': 0.35}\n",
            "{'loss': 5.5603, 'grad_norm': 0.17725922167301178, 'learning_rate': 0.0001509857861248251, 'epoch': 0.35}\n",
            "{'loss': 5.698, 'grad_norm': 0.163543701171875, 'learning_rate': 0.00015075888260693214, 'epoch': 0.35}\n",
            "{'loss': 5.6831, 'grad_norm': 0.14264114201068878, 'learning_rate': 0.00015053162650793274, 'epoch': 0.35}\n",
            "{'loss': 5.536, 'grad_norm': 0.19428785145282745, 'learning_rate': 0.0001503040194063922, 'epoch': 0.35}\n",
            "{'loss': 5.5909, 'grad_norm': 0.1440851390361786, 'learning_rate': 0.0001500760628833138, 'epoch': 0.35}\n",
            "{'loss': 5.0783, 'grad_norm': 0.11654169112443924, 'learning_rate': 0.00014984775852212807, 'epoch': 0.35}\n",
            "{'loss': 5.5859, 'grad_norm': 0.0926026776432991, 'learning_rate': 0.00014961910790868164, 'epoch': 0.36}\n",
            "{'loss': 5.5353, 'grad_norm': 0.1649128496646881, 'learning_rate': 0.00014939011263122634, 'epoch': 0.36}\n",
            "{'loss': 3.9821, 'grad_norm': 0.12426063418388367, 'learning_rate': 0.00014916077428040811, 'epoch': 0.36}\n",
            "{'loss': 5.6173, 'grad_norm': 0.17251692712306976, 'learning_rate': 0.00014893109444925578, 'epoch': 0.36}\n",
            "{'loss': 5.6154, 'grad_norm': 0.18124105036258698, 'learning_rate': 0.00014870107473317033, 'epoch': 0.36}\n",
            "{'loss': 5.3126, 'grad_norm': 0.14139848947525024, 'learning_rate': 0.00014847071672991367, 'epoch': 0.36}\n",
            "{'loss': 5.5465, 'grad_norm': 0.1640486717224121, 'learning_rate': 0.0001482400220395974, 'epoch': 0.36}\n",
            "{'loss': 5.6494, 'grad_norm': 0.13808032870292664, 'learning_rate': 0.00014800899226467191, 'epoch': 0.36}\n",
            "{'loss': 5.0607, 'grad_norm': 0.13127465546131134, 'learning_rate': 0.00014777762900991504, 'epoch': 0.36}\n",
            "{'loss': 4.6557, 'grad_norm': 0.1877567321062088, 'learning_rate': 0.00014754593388242117, 'epoch': 0.36}\n",
            "{'loss': 5.5859, 'grad_norm': 0.15518806874752045, 'learning_rate': 0.0001473139084915899, 'epoch': 0.36}\n",
            "{'loss': 5.6871, 'grad_norm': 0.15975908935070038, 'learning_rate': 0.00014708155444911484, 'epoch': 0.36}\n",
            "{'loss': 5.2494, 'grad_norm': 0.17442873120307922, 'learning_rate': 0.00014684887336897256, 'epoch': 0.37}\n",
            "{'loss': 5.5719, 'grad_norm': 0.14900535345077515, 'learning_rate': 0.0001466158668674112, 'epoch': 0.37}\n",
            "{'loss': 5.5072, 'grad_norm': 0.22666122019290924, 'learning_rate': 0.00014638253656293947, 'epoch': 0.37}\n",
            "{'loss': 5.5882, 'grad_norm': 0.2087218016386032, 'learning_rate': 0.0001461488840763152, 'epoch': 0.37}\n",
            "{'loss': 5.6003, 'grad_norm': 0.16745269298553467, 'learning_rate': 0.00014591491103053413, 'epoch': 0.37}\n",
            "{'loss': 5.6645, 'grad_norm': 0.23951081931591034, 'learning_rate': 0.00014568061905081875, 'epoch': 0.37}\n",
            "{'loss': 4.8768, 'grad_norm': 0.15453438460826874, 'learning_rate': 0.00014544600976460682, 'epoch': 0.37}\n",
            "{'loss': 5.3344, 'grad_norm': 0.23167085647583008, 'learning_rate': 0.00014521108480154032, 'epoch': 0.37}\n",
            "{'loss': 4.7248, 'grad_norm': 0.17399074137210846, 'learning_rate': 0.00014497584579345384, 'epoch': 0.37}\n",
            "{'loss': 5.7242, 'grad_norm': 0.2312643676996231, 'learning_rate': 0.00014474029437436348, 'epoch': 0.37}\n",
            "{'loss': 5.4961, 'grad_norm': 0.16288720071315765, 'learning_rate': 0.00014450443218045532, 'epoch': 0.37}\n",
            "{'loss': 5.4555, 'grad_norm': 0.17546911537647247, 'learning_rate': 0.00014426826085007428, 'epoch': 0.37}\n",
            "{'loss': 5.5814, 'grad_norm': 0.11074256896972656, 'learning_rate': 0.00014403178202371245, 'epoch': 0.38}\n",
            "{'loss': 5.5508, 'grad_norm': 0.13268595933914185, 'learning_rate': 0.00014379499734399798, 'epoch': 0.38}\n",
            "{'loss': 5.5795, 'grad_norm': 0.11415475606918335, 'learning_rate': 0.0001435579084556834, 'epoch': 0.38}\n",
            "{'loss': 5.6635, 'grad_norm': 0.18691037595272064, 'learning_rate': 0.00014332051700563446, 'epoch': 0.38}\n",
            "{'loss': 5.5717, 'grad_norm': 0.11789728701114655, 'learning_rate': 0.0001430828246428185, 'epoch': 0.38}\n",
            "{'loss': 5.3831, 'grad_norm': 0.12985678017139435, 'learning_rate': 0.0001428448330182931, 'epoch': 0.38}\n",
            "{'loss': 5.6035, 'grad_norm': 0.1537146419286728, 'learning_rate': 0.00014260654378519445, 'epoch': 0.38}\n",
            "{'loss': 4.8394, 'grad_norm': 0.12723314762115479, 'learning_rate': 0.00014236795859872613, 'epoch': 0.38}\n",
            "{'loss': 5.5994, 'grad_norm': 0.141082301735878, 'learning_rate': 0.00014212907911614742, 'epoch': 0.38}\n",
            "{'loss': 5.696, 'grad_norm': 0.13781046867370605, 'learning_rate': 0.00014188990699676184, 'epoch': 0.38}\n",
            "{'loss': 5.2254, 'grad_norm': 0.13232216238975525, 'learning_rate': 0.00014165044390190563, 'epoch': 0.38}\n",
            "{'loss': 5.7119, 'grad_norm': 0.20539456605911255, 'learning_rate': 0.00014141069149493612, 'epoch': 0.38}\n",
            "{'loss': 4.7725, 'grad_norm': 0.13668476045131683, 'learning_rate': 0.00014117065144122036, 'epoch': 0.38}\n",
            "{'loss': 5.7084, 'grad_norm': 0.1608646810054779, 'learning_rate': 0.00014093032540812348, 'epoch': 0.39}\n",
            "{'loss': 5.4902, 'grad_norm': 0.21477089822292328, 'learning_rate': 0.00014068971506499693, 'epoch': 0.39}\n",
            "{'loss': 5.5782, 'grad_norm': 0.15146644413471222, 'learning_rate': 0.00014044882208316713, 'epoch': 0.39}\n",
            "{'loss': 5.6847, 'grad_norm': 0.1781262457370758, 'learning_rate': 0.0001402076481359238, 'epoch': 0.39}\n",
            "{'loss': 5.7043, 'grad_norm': 0.2137419879436493, 'learning_rate': 0.00013996619489850822, 'epoch': 0.39}\n",
            "{'loss': 5.5132, 'grad_norm': 0.17502939701080322, 'learning_rate': 0.00013972446404810176, 'epoch': 0.39}\n",
            "{'loss': 5.556, 'grad_norm': 0.11328653991222382, 'learning_rate': 0.000139482457263814, 'epoch': 0.39}\n",
            "{'loss': 5.6079, 'grad_norm': 0.1690046340227127, 'learning_rate': 0.00013924017622667133, 'epoch': 0.39}\n",
            "{'loss': 5.5191, 'grad_norm': 0.16340462863445282, 'learning_rate': 0.00013899762261960518, 'epoch': 0.39}\n",
            "{'loss': 5.553, 'grad_norm': 0.12288564443588257, 'learning_rate': 0.00013875479812744022, 'epoch': 0.39}\n",
            "{'loss': 5.1994, 'grad_norm': 0.20323684811592102, 'learning_rate': 0.00013851170443688273, 'epoch': 0.39}\n",
            "{'loss': 5.5856, 'grad_norm': 0.13047592341899872, 'learning_rate': 0.000138268343236509, 'epoch': 0.39}\n",
            "{'loss': 5.4912, 'grad_norm': 0.195042684674263, 'learning_rate': 0.00013802471621675338, 'epoch': 0.4}\n",
            "{'loss': 4.8213, 'grad_norm': 0.14137881994247437, 'learning_rate': 0.00013778082506989673, 'epoch': 0.4}\n",
            "{'loss': 5.6214, 'grad_norm': 0.1718583106994629, 'learning_rate': 0.00013753667149005457, 'epoch': 0.4}\n",
            "{'loss': 5.609, 'grad_norm': 0.1296253204345703, 'learning_rate': 0.00013729225717316526, 'epoch': 0.4}\n",
            "{'loss': 5.6351, 'grad_norm': 0.17644847929477692, 'learning_rate': 0.00013704758381697844, 'epoch': 0.4}\n",
            "{'loss': 5.5395, 'grad_norm': 0.1542007178068161, 'learning_rate': 0.00013680265312104298, 'epoch': 0.4}\n",
            "{'loss': 5.5527, 'grad_norm': 0.14402297139167786, 'learning_rate': 0.00013655746678669525, 'epoch': 0.4}\n",
            "{'loss': 5.5971, 'grad_norm': 0.12048260122537613, 'learning_rate': 0.00013631202651704743, 'epoch': 0.4}\n",
            "{'loss': 5.4251, 'grad_norm': 0.1562628149986267, 'learning_rate': 0.00013606633401697557, 'epoch': 0.4}\n",
            "{'loss': 5.5326, 'grad_norm': 0.1591678112745285, 'learning_rate': 0.00013582039099310767, 'epoch': 0.4}\n",
            "{'loss': 5.7617, 'grad_norm': 0.27753305435180664, 'learning_rate': 0.000135574199153812, 'epoch': 0.4}\n",
            "{'loss': 4.5461, 'grad_norm': 0.14576609432697296, 'learning_rate': 0.00013532776020918513, 'epoch': 0.4}\n",
            "{'loss': 5.4147, 'grad_norm': 0.14517319202423096, 'learning_rate': 0.0001350810758710401, 'epoch': 0.41}\n",
            "{'loss': 5.6873, 'grad_norm': 0.212152898311615, 'learning_rate': 0.00013483414785289444, 'epoch': 0.41}\n",
            "{'loss': 5.5983, 'grad_norm': 0.1489342302083969, 'learning_rate': 0.0001345869778699584, 'epoch': 0.41}\n",
            "{'loss': 5.5484, 'grad_norm': 0.19875121116638184, 'learning_rate': 0.0001343395676391229, 'epoch': 0.41}\n",
            "{'loss': 5.4974, 'grad_norm': 0.22500361502170563, 'learning_rate': 0.0001340919188789477, 'epoch': 0.41}\n",
            "{'loss': 5.6774, 'grad_norm': 0.16925013065338135, 'learning_rate': 0.00013384403330964943, 'epoch': 0.41}\n",
            "{'loss': 5.4826, 'grad_norm': 0.11426475644111633, 'learning_rate': 0.00013359591265308963, 'epoch': 0.41}\n",
            "{'loss': 5.6126, 'grad_norm': 0.18537907302379608, 'learning_rate': 0.00013334755863276287, 'epoch': 0.41}\n",
            "{'loss': 5.6492, 'grad_norm': 0.21126903593540192, 'learning_rate': 0.00013309897297378455, 'epoch': 0.41}\n",
            "{'loss': 5.5675, 'grad_norm': 0.16360564529895782, 'learning_rate': 0.00013285015740287925, 'epoch': 0.41}\n",
            "{'loss': 5.4276, 'grad_norm': 0.09748240560293198, 'learning_rate': 0.00013260111364836848, 'epoch': 0.41}\n",
            "{'loss': 5.3049, 'grad_norm': 0.15763279795646667, 'learning_rate': 0.00013235184344015876, 'epoch': 0.41}\n",
            "{'loss': 5.5098, 'grad_norm': 0.12599529325962067, 'learning_rate': 0.00013210234850972964, 'epoch': 0.41}\n",
            "{'loss': 5.5269, 'grad_norm': 0.14126846194267273, 'learning_rate': 0.00013185263059012158, 'epoch': 0.42}\n",
            "{'loss': 5.5566, 'grad_norm': 0.09517334401607513, 'learning_rate': 0.00013160269141592398, 'epoch': 0.42}\n",
            "{'loss': 5.6564, 'grad_norm': 0.1748078614473343, 'learning_rate': 0.00013135253272326315, 'epoch': 0.42}\n",
            "{'loss': 5.6294, 'grad_norm': 0.14136181771755219, 'learning_rate': 0.00013110215624979025, 'epoch': 0.42}\n",
            "{'loss': 5.4042, 'grad_norm': 0.21605195105075836, 'learning_rate': 0.00013085156373466905, 'epoch': 0.42}\n",
            "{'loss': 5.5389, 'grad_norm': 0.18462581932544708, 'learning_rate': 0.00013060075691856407, 'epoch': 0.42}\n",
            "{'loss': 5.6704, 'grad_norm': 0.18174628913402557, 'learning_rate': 0.0001303497375436285, 'epoch': 0.42}\n",
            "{'loss': 5.7158, 'grad_norm': 0.18282632529735565, 'learning_rate': 0.0001300985073534919, 'epoch': 0.42}\n",
            "{'loss': 5.5721, 'grad_norm': 0.11784236133098602, 'learning_rate': 0.00012984706809324813, 'epoch': 0.42}\n",
            "{'loss': 5.49, 'grad_norm': 0.168272003531456, 'learning_rate': 0.0001295954215094434, 'epoch': 0.42}\n",
            "{'loss': 5.6372, 'grad_norm': 0.11514443904161453, 'learning_rate': 0.00012934356935006405, 'epoch': 0.42}\n",
            "{'loss': 5.4745, 'grad_norm': 0.1380162239074707, 'learning_rate': 0.0001290915133645243, 'epoch': 0.42}\n",
            "{'loss': 5.7161, 'grad_norm': 0.2654491364955902, 'learning_rate': 0.00012883925530365423, 'epoch': 0.43}\n",
            "{'loss': 5.6355, 'grad_norm': 0.15160463750362396, 'learning_rate': 0.00012858679691968753, 'epoch': 0.43}\n",
            "{'loss': 5.6151, 'grad_norm': 0.15766434371471405, 'learning_rate': 0.00012833413996624952, 'epoch': 0.43}\n",
            "{'loss': 5.4142, 'grad_norm': 0.14001533389091492, 'learning_rate': 0.00012808128619834461, 'epoch': 0.43}\n",
            "{'loss': 5.3634, 'grad_norm': 0.1641319990158081, 'learning_rate': 0.00012782823737234451, 'epoch': 0.43}\n",
            "{'loss': 4.7199, 'grad_norm': 0.1647971123456955, 'learning_rate': 0.0001275749952459757, 'epoch': 0.43}\n",
            "{'loss': 5.5841, 'grad_norm': 0.15884943306446075, 'learning_rate': 0.00012732156157830744, 'epoch': 0.43}\n",
            "{'loss': 5.5628, 'grad_norm': 0.14834293723106384, 'learning_rate': 0.00012706793812973941, 'epoch': 0.43}\n",
            "{'loss': 5.5667, 'grad_norm': 0.12404350936412811, 'learning_rate': 0.00012681412666198968, 'epoch': 0.43}\n",
            "{'loss': 5.6239, 'grad_norm': 0.15959611535072327, 'learning_rate': 0.0001265601289380822, 'epoch': 0.43}\n",
            "{'loss': 5.5805, 'grad_norm': 0.1429937779903412, 'learning_rate': 0.00012630594672233473, 'epoch': 0.43}\n",
            "{'loss': 4.9689, 'grad_norm': 0.10792265087366104, 'learning_rate': 0.00012605158178034654, 'epoch': 0.43}\n",
            "{'loss': 5.5426, 'grad_norm': 0.18536482751369476, 'learning_rate': 0.00012579703587898623, 'epoch': 0.44}\n",
            "{'loss': 5.6247, 'grad_norm': 0.140710711479187, 'learning_rate': 0.00012554231078637927, 'epoch': 0.44}\n",
            "{'loss': 5.6321, 'grad_norm': 0.14086738228797913, 'learning_rate': 0.00012528740827189586, 'epoch': 0.44}\n",
            "{'loss': 5.564, 'grad_norm': 0.12728847563266754, 'learning_rate': 0.00012503233010613865, 'epoch': 0.44}\n",
            "{'loss': 4.9402, 'grad_norm': 0.1298564225435257, 'learning_rate': 0.0001247770780609304, 'epoch': 0.44}\n",
            "{'loss': 5.3854, 'grad_norm': 0.20562893152236938, 'learning_rate': 0.0001245216539093016, 'epoch': 0.44}\n",
            "{'loss': 5.5994, 'grad_norm': 0.15109771490097046, 'learning_rate': 0.00012426605942547823, 'epoch': 0.44}\n",
            "{'loss': 5.6091, 'grad_norm': 0.19160833954811096, 'learning_rate': 0.00012401029638486953, 'epoch': 0.44}\n",
            "{'loss': 5.029, 'grad_norm': 0.13897840678691864, 'learning_rate': 0.00012375436656405543, 'epoch': 0.44}\n",
            "{'loss': 5.5065, 'grad_norm': 0.13706499338150024, 'learning_rate': 0.00012349827174077448, 'epoch': 0.44}\n",
            "{'loss': 5.5777, 'grad_norm': 0.12317914515733719, 'learning_rate': 0.00012324201369391134, 'epoch': 0.44}\n",
            "{'loss': 5.5912, 'grad_norm': 0.16532374918460846, 'learning_rate': 0.00012298559420348437, 'epoch': 0.44}\n",
            "{'loss': 5.2381, 'grad_norm': 0.13440608978271484, 'learning_rate': 0.0001227290150506334, 'epoch': 0.45}\n",
            "{'loss': 5.5493, 'grad_norm': 0.14863520860671997, 'learning_rate': 0.00012247227801760732, 'epoch': 0.45}\n",
            "{'loss': 5.7394, 'grad_norm': 0.2749028503894806, 'learning_rate': 0.00012221538488775167, 'epoch': 0.45}\n",
            "{'loss': 5.6454, 'grad_norm': 0.1485397219657898, 'learning_rate': 0.0001219583374454963, 'epoch': 0.45}\n",
            "{'loss': 5.5814, 'grad_norm': 0.15648482739925385, 'learning_rate': 0.00012170113747634288, 'epoch': 0.45}\n",
            "{'loss': 5.5669, 'grad_norm': 0.2058187574148178, 'learning_rate': 0.00012144378676685265, 'epoch': 0.45}\n",
            "{'loss': 5.5619, 'grad_norm': 0.1946265548467636, 'learning_rate': 0.00012118628710463382, 'epoch': 0.45}\n",
            "{'loss': 5.3293, 'grad_norm': 0.15897582471370697, 'learning_rate': 0.00012092864027832933, 'epoch': 0.45}\n",
            "{'loss': 5.5881, 'grad_norm': 0.16732054948806763, 'learning_rate': 0.00012067084807760431, 'epoch': 0.45}\n",
            "{'loss': 4.4385, 'grad_norm': 0.1904650628566742, 'learning_rate': 0.00012041291229313372, 'epoch': 0.45}\n",
            "{'loss': 5.57, 'grad_norm': 0.07723312079906464, 'learning_rate': 0.00012015483471658986, 'epoch': 0.45}\n",
            "{'loss': 4.9748, 'grad_norm': 0.19527417421340942, 'learning_rate': 0.00011989661714062999, 'epoch': 0.45}\n",
            "{'loss': 4.9563, 'grad_norm': 0.1647091507911682, 'learning_rate': 0.00011963826135888374, 'epoch': 0.45}\n",
            "{'loss': 5.656, 'grad_norm': 0.2257409244775772, 'learning_rate': 0.0001193797691659408, 'epoch': 0.46}\n",
            "{'loss': 5.4947, 'grad_norm': 0.09487578272819519, 'learning_rate': 0.00011912114235733844, 'epoch': 0.46}\n",
            "{'loss': 5.4817, 'grad_norm': 0.10590234398841858, 'learning_rate': 0.00011886238272954897, 'epoch': 0.46}\n",
            "{'loss': 5.6116, 'grad_norm': 0.1671861857175827, 'learning_rate': 0.00011860349207996718, 'epoch': 0.46}\n",
            "{'loss': 5.5089, 'grad_norm': 0.17089571058750153, 'learning_rate': 0.00011834447220689813, 'epoch': 0.46}\n",
            "{'loss': 5.6504, 'grad_norm': 0.16464675962924957, 'learning_rate': 0.00011808532490954438, 'epoch': 0.46}\n",
            "{'loss': 5.6052, 'grad_norm': 0.13177721202373505, 'learning_rate': 0.0001178260519879937, 'epoch': 0.46}\n",
            "{'loss': 5.6871, 'grad_norm': 0.1725168228149414, 'learning_rate': 0.00011756665524320638, 'epoch': 0.46}\n",
            "{'loss': 5.5955, 'grad_norm': 0.190491184592247, 'learning_rate': 0.00011730713647700282, 'epoch': 0.46}\n",
            "{'loss': 5.5362, 'grad_norm': 0.2600094974040985, 'learning_rate': 0.00011704749749205103, 'epoch': 0.46}\n",
            "{'loss': 5.6056, 'grad_norm': 0.10058508813381195, 'learning_rate': 0.0001167877400918541, 'epoch': 0.46}\n",
            "{'loss': 5.5219, 'grad_norm': 0.14916086196899414, 'learning_rate': 0.00011652786608073762, 'epoch': 0.46}\n",
            "{'loss': 4.8598, 'grad_norm': 0.17034997045993805, 'learning_rate': 0.0001162678772638372, 'epoch': 0.47}\n",
            "{'loss': 5.615, 'grad_norm': 0.16591277718544006, 'learning_rate': 0.00011600777544708594, 'epoch': 0.47}\n",
            "{'loss': 5.6036, 'grad_norm': 0.1580149531364441, 'learning_rate': 0.0001157475624372018, 'epoch': 0.47}\n",
            "{'loss': 4.8654, 'grad_norm': 0.10090214014053345, 'learning_rate': 0.00011548724004167512, 'epoch': 0.47}\n",
            "{'loss': 5.519, 'grad_norm': 0.14663080871105194, 'learning_rate': 0.00011522681006875613, 'epoch': 0.47}\n",
            "{'loss': 5.5576, 'grad_norm': 0.20044146478176117, 'learning_rate': 0.00011496627432744216, 'epoch': 0.47}\n",
            "{'loss': 5.7556, 'grad_norm': 0.23198741674423218, 'learning_rate': 0.00011470563462746541, 'epoch': 0.47}\n",
            "{'loss': 5.3304, 'grad_norm': 0.15906362235546112, 'learning_rate': 0.0001144448927792801, 'epoch': 0.47}\n",
            "{'loss': 5.6778, 'grad_norm': 0.1489657312631607, 'learning_rate': 0.00011418405059405002, 'epoch': 0.47}\n",
            "{'loss': 5.6653, 'grad_norm': 0.19927671551704407, 'learning_rate': 0.00011392310988363584, 'epoch': 0.47}\n",
            "{'loss': 5.5329, 'grad_norm': 0.15635253489017487, 'learning_rate': 0.0001136620724605827, 'epoch': 0.47}\n",
            "{'loss': 5.5183, 'grad_norm': 0.20883308351039886, 'learning_rate': 0.00011340094013810749, 'epoch': 0.47}\n",
            "{'loss': 5.6969, 'grad_norm': 0.16127640008926392, 'learning_rate': 0.00011313971473008629, 'epoch': 0.48}\n",
            "{'loss': 5.6101, 'grad_norm': 0.2077094167470932, 'learning_rate': 0.0001128783980510418, 'epoch': 0.48}\n",
            "{'loss': 5.6825, 'grad_norm': 0.15538549423217773, 'learning_rate': 0.00011261699191613066, 'epoch': 0.48}\n",
            "{'loss': 5.5358, 'grad_norm': 0.13889682292938232, 'learning_rate': 0.00011235549814113092, 'epoch': 0.48}\n",
            "{'loss': 5.2488, 'grad_norm': 0.12752728164196014, 'learning_rate': 0.00011209391854242936, 'epoch': 0.48}\n",
            "{'loss': 5.3427, 'grad_norm': 0.13861897587776184, 'learning_rate': 0.00011183225493700894, 'epoch': 0.48}\n",
            "{'loss': 5.0127, 'grad_norm': 0.17787513136863708, 'learning_rate': 0.00011157050914243614, 'epoch': 0.48}\n",
            "{'loss': 4.9298, 'grad_norm': 0.17274247109889984, 'learning_rate': 0.00011130868297684833, 'epoch': 0.48}\n",
            "{'loss': 5.5662, 'grad_norm': 0.11624965816736221, 'learning_rate': 0.00011104677825894121, 'epoch': 0.48}\n",
            "{'loss': 5.6258, 'grad_norm': 0.19010178744792938, 'learning_rate': 0.00011078479680795604, 'epoch': 0.48}\n",
            "{'loss': 5.485, 'grad_norm': 0.14571774005889893, 'learning_rate': 0.00011052274044366711, 'epoch': 0.48}\n",
            "{'loss': 5.2811, 'grad_norm': 0.18709062039852142, 'learning_rate': 0.00011026061098636906, 'epoch': 0.48}\n",
            "{'loss': 5.5812, 'grad_norm': 0.19290466606616974, 'learning_rate': 0.0001099984102568643, 'epoch': 0.48}\n",
            "{'loss': 5.5998, 'grad_norm': 0.14793981611728668, 'learning_rate': 0.00010973614007645028, 'epoch': 0.49}\n",
            "{'loss': 5.6863, 'grad_norm': 0.17185774445533752, 'learning_rate': 0.00010947380226690684, 'epoch': 0.49}\n",
            "{'loss': 5.1624, 'grad_norm': 0.18066146969795227, 'learning_rate': 0.00010921139865048362, 'epoch': 0.49}\n",
            "{'loss': 5.0404, 'grad_norm': 0.1751386821269989, 'learning_rate': 0.00010894893104988738, 'epoch': 0.49}\n",
            "{'loss': 5.5762, 'grad_norm': 0.13165000081062317, 'learning_rate': 0.00010868640128826928, 'epoch': 0.49}\n",
            "{'loss': 4.7968, 'grad_norm': 0.19049270451068878, 'learning_rate': 0.00010842381118921232, 'epoch': 0.49}\n",
            "{'loss': 5.6015, 'grad_norm': 0.13836495578289032, 'learning_rate': 0.00010816116257671855, 'epoch': 0.49}\n",
            "{'loss': 5.5599, 'grad_norm': 0.11849671602249146, 'learning_rate': 0.00010789845727519647, 'epoch': 0.49}\n",
            "{'loss': 5.5608, 'grad_norm': 0.15710942447185516, 'learning_rate': 0.00010763569710944848, 'epoch': 0.49}\n",
            "{'loss': 5.5719, 'grad_norm': 0.13976842164993286, 'learning_rate': 0.00010737288390465792, 'epoch': 0.49}\n",
            "{'loss': 5.5828, 'grad_norm': 0.15140663087368011, 'learning_rate': 0.0001071100194863766, 'epoch': 0.49}\n",
            "{'loss': 5.6496, 'grad_norm': 0.17709451913833618, 'learning_rate': 0.0001068471056805121, 'epoch': 0.49}\n",
            "{'loss': 5.6704, 'grad_norm': 0.18636903166770935, 'learning_rate': 0.00010658414431331502, 'epoch': 0.5}\n",
            "{'loss': 5.4324, 'grad_norm': 0.12432214617729187, 'learning_rate': 0.00010632113721136636, 'epoch': 0.5}\n",
            "{'loss': 5.5492, 'grad_norm': 0.14906378090381622, 'learning_rate': 0.00010605808620156479, 'epoch': 0.5}\n",
            "{'loss': 5.6071, 'grad_norm': 0.1512058526277542, 'learning_rate': 0.00010579499311111396, 'epoch': 0.5}\n",
            "{'loss': 5.526, 'grad_norm': 0.1448023021221161, 'learning_rate': 0.00010553185976750981, 'epoch': 0.5}\n",
            "{'loss': 5.6469, 'grad_norm': 0.13748671114444733, 'learning_rate': 0.00010526868799852796, 'epoch': 0.5}\n",
            "{'loss': 5.7479, 'grad_norm': 0.22817888855934143, 'learning_rate': 0.00010500547963221086, 'epoch': 0.5}\n",
            "{'loss': 5.6157, 'grad_norm': 0.13362343609333038, 'learning_rate': 0.00010474223649685517, 'epoch': 0.5}\n",
            "{'loss': 5.5745, 'grad_norm': 0.16475704312324524, 'learning_rate': 0.00010447896042099914, 'epoch': 0.5}\n",
            "{'loss': 5.4427, 'grad_norm': 0.23131366074085236, 'learning_rate': 0.00010421565323340971, 'epoch': 0.5}\n",
            "{'loss': 5.4193, 'grad_norm': 0.19188067317008972, 'learning_rate': 0.00010395231676307012, 'epoch': 0.5}\n",
            "{'loss': 5.4633, 'grad_norm': 0.16354800760746002, 'learning_rate': 0.00010368895283916678, 'epoch': 0.5}\n",
            "{'loss': 5.6176, 'grad_norm': 0.18837937712669373, 'learning_rate': 0.00010342556329107697, 'epoch': 0.51}\n",
            "{'loss': 5.7045, 'grad_norm': 0.293234258890152, 'learning_rate': 0.0001031621499483559, 'epoch': 0.51}\n",
            "{'loss': 5.305, 'grad_norm': 0.23471781611442566, 'learning_rate': 0.00010289871464072404, 'epoch': 0.51}\n",
            "{'loss': 5.5636, 'grad_norm': 0.15670901536941528, 'learning_rate': 0.00010263525919805448, 'epoch': 0.51}\n",
            "{'loss': 5.5167, 'grad_norm': 0.16171620786190033, 'learning_rate': 0.00010237178545036015, 'epoch': 0.51}\n",
            "{'loss': 5.7004, 'grad_norm': 0.20383109152317047, 'learning_rate': 0.00010210829522778111, 'epoch': 0.51}\n",
            "{'loss': 5.6822, 'grad_norm': 0.17279675602912903, 'learning_rate': 0.00010184479036057191, 'epoch': 0.51}\n",
            "{'loss': 5.4901, 'grad_norm': 0.17817403376102448, 'learning_rate': 0.00010158127267908877, 'epoch': 0.51}\n",
            "{'loss': 5.3739, 'grad_norm': 0.15820840001106262, 'learning_rate': 0.00010131774401377694, 'epoch': 0.51}\n",
            "{'loss': 5.5925, 'grad_norm': 0.20012840628623962, 'learning_rate': 0.00010105420619515798, 'epoch': 0.51}\n",
            "{'loss': 5.6699, 'grad_norm': 0.17728184163570404, 'learning_rate': 0.00010079066105381701, 'epoch': 0.51}\n",
            "{'loss': 5.3961, 'grad_norm': 0.1487932652235031, 'learning_rate': 0.00010052711042039, 'epoch': 0.51}\n",
            "{'loss': 5.5551, 'grad_norm': 0.10212042927742004, 'learning_rate': 0.00010026355612555117, 'epoch': 0.52}\n",
            "{'loss': 5.5139, 'grad_norm': 0.1542205959558487, 'learning_rate': 0.0001, 'epoch': 0.52}\n",
            "{'loss': 5.6739, 'grad_norm': 0.18904803693294525, 'learning_rate': 9.973644387444886e-05, 'epoch': 0.52}\n",
            "{'loss': 5.5179, 'grad_norm': 0.20125196874141693, 'learning_rate': 9.947288957961e-05, 'epoch': 0.52}\n",
            "{'loss': 5.4986, 'grad_norm': 0.11626751720905304, 'learning_rate': 9.920933894618303e-05, 'epoch': 0.52}\n",
            "{'loss': 5.6275, 'grad_norm': 0.17241820693016052, 'learning_rate': 9.894579380484204e-05, 'epoch': 0.52}\n",
            "{'loss': 5.5303, 'grad_norm': 0.11996129900217056, 'learning_rate': 9.86822559862231e-05, 'epoch': 0.52}\n",
            "{'loss': 5.6012, 'grad_norm': 0.16621865332126617, 'learning_rate': 9.841872732091128e-05, 'epoch': 0.52}\n",
            "{'loss': 4.1421, 'grad_norm': 0.10069641470909119, 'learning_rate': 9.815520963942813e-05, 'epoch': 0.52}\n",
            " 52% 641/1229 [05:53<05:28,  1.79it/s]/usr/local/lib/python3.12/dist-packages/PIL/TiffImagePlugin.py:950: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n",
            "{'loss': 5.5825, 'grad_norm': 0.23148806393146515, 'learning_rate': 9.789170477221891e-05, 'epoch': 0.52}\n",
            "{'loss': 5.5975, 'grad_norm': 0.20401212573051453, 'learning_rate': 9.762821454963989e-05, 'epoch': 0.52}\n",
            "{'loss': 5.5753, 'grad_norm': 0.134556382894516, 'learning_rate': 9.736474080194554e-05, 'epoch': 0.52}\n",
            "{'loss': 5.5325, 'grad_norm': 0.15245112776756287, 'learning_rate': 9.710128535927597e-05, 'epoch': 0.52}\n",
            "{'loss': 5.7342, 'grad_norm': 0.20873244106769562, 'learning_rate': 9.683785005164411e-05, 'epoch': 0.53}\n",
            "{'loss': 5.6048, 'grad_norm': 0.1546975076198578, 'learning_rate': 9.657443670892303e-05, 'epoch': 0.53}\n",
            "{'loss': 5.7385, 'grad_norm': 0.18315622210502625, 'learning_rate': 9.631104716083326e-05, 'epoch': 0.53}\n",
            "{'loss': 5.6248, 'grad_norm': 0.19733430445194244, 'learning_rate': 9.604768323692993e-05, 'epoch': 0.53}\n",
            "{'loss': 5.4023, 'grad_norm': 0.3142433762550354, 'learning_rate': 9.57843467665903e-05, 'epoch': 0.53}\n",
            "{'loss': 5.4623, 'grad_norm': 0.17044609785079956, 'learning_rate': 9.552103957900089e-05, 'epoch': 0.53}\n",
            "{'loss': 5.5761, 'grad_norm': 0.11914853006601334, 'learning_rate': 9.525776350314485e-05, 'epoch': 0.53}\n",
            "{'loss': 5.5843, 'grad_norm': 0.1268550455570221, 'learning_rate': 9.499452036778916e-05, 'epoch': 0.53}\n",
            "{'loss': 5.6238, 'grad_norm': 0.13879764080047607, 'learning_rate': 9.473131200147205e-05, 'epoch': 0.53}\n",
            "{'loss': 5.6352, 'grad_norm': 0.16563178598880768, 'learning_rate': 9.446814023249018e-05, 'epoch': 0.53}\n",
            "{'loss': 5.6298, 'grad_norm': 0.15425249934196472, 'learning_rate': 9.420500688888609e-05, 'epoch': 0.53}\n",
            "{'loss': 5.5169, 'grad_norm': 0.1336347758769989, 'learning_rate': 9.394191379843524e-05, 'epoch': 0.53}\n",
            "{'loss': 5.6081, 'grad_norm': 0.16047830879688263, 'learning_rate': 9.367886278863366e-05, 'epoch': 0.54}\n",
            "{'loss': 5.5257, 'grad_norm': 0.12493957579135895, 'learning_rate': 9.3415855686685e-05, 'epoch': 0.54}\n",
            "{'loss': 5.4876, 'grad_norm': 0.11612533032894135, 'learning_rate': 9.315289431948792e-05, 'epoch': 0.54}\n",
            "{'loss': 5.4966, 'grad_norm': 0.12408309429883957, 'learning_rate': 9.288998051362342e-05, 'epoch': 0.54}\n",
            "{'loss': 5.475, 'grad_norm': 0.1077166348695755, 'learning_rate': 9.26271160953421e-05, 'epoch': 0.54}\n",
            "{'loss': 5.6306, 'grad_norm': 0.19449838995933533, 'learning_rate': 9.236430289055153e-05, 'epoch': 0.54}\n",
            "{'loss': 5.7131, 'grad_norm': 0.2203354835510254, 'learning_rate': 9.210154272480353e-05, 'epoch': 0.54}\n",
            "{'loss': 5.5499, 'grad_norm': 0.1612929254770279, 'learning_rate': 9.18388374232815e-05, 'epoch': 0.54}\n",
            "{'loss': 5.5354, 'grad_norm': 0.20328602194786072, 'learning_rate': 9.157618881078772e-05, 'epoch': 0.54}\n",
            "{'loss': 5.6197, 'grad_norm': 0.1354285478591919, 'learning_rate': 9.131359871173074e-05, 'epoch': 0.54}\n",
            "{'loss': 5.6342, 'grad_norm': 0.18077506124973297, 'learning_rate': 9.105106895011263e-05, 'epoch': 0.54}\n",
            "{'loss': 5.5309, 'grad_norm': 0.14865317940711975, 'learning_rate': 9.078860134951639e-05, 'epoch': 0.54}\n",
            "{'loss': 5.2176, 'grad_norm': 0.14583948254585266, 'learning_rate': 9.052619773309317e-05, 'epoch': 0.55}\n",
            "{'loss': 5.7291, 'grad_norm': 0.2421630173921585, 'learning_rate': 9.026385992354974e-05, 'epoch': 0.55}\n",
            "{'loss': 5.6139, 'grad_norm': 0.14585214853286743, 'learning_rate': 9.000158974313571e-05, 'epoch': 0.55}\n",
            "{'loss': 5.4052, 'grad_norm': 0.2525542080402374, 'learning_rate': 8.973938901363092e-05, 'epoch': 0.55}\n",
            "{'loss': 5.4887, 'grad_norm': 0.15608647465705872, 'learning_rate': 8.947725955633294e-05, 'epoch': 0.55}\n",
            "{'loss': 5.5732, 'grad_norm': 0.15616106986999512, 'learning_rate': 8.921520319204399e-05, 'epoch': 0.55}\n",
            "{'loss': 5.5225, 'grad_norm': 0.12841589748859406, 'learning_rate': 8.895322174105881e-05, 'epoch': 0.55}\n",
            "{'loss': 5.6533, 'grad_norm': 0.21565517783164978, 'learning_rate': 8.869131702315168e-05, 'epoch': 0.55}\n",
            "{'loss': 5.5787, 'grad_norm': 0.12650565803050995, 'learning_rate': 8.84294908575639e-05, 'epoch': 0.55}\n",
            "{'loss': 5.6237, 'grad_norm': 0.1940380185842514, 'learning_rate': 8.816774506299106e-05, 'epoch': 0.55}\n",
            "{'loss': 5.1625, 'grad_norm': 0.11892998218536377, 'learning_rate': 8.790608145757065e-05, 'epoch': 0.55}\n",
            "{'loss': 5.5893, 'grad_norm': 0.12462363392114639, 'learning_rate': 8.76445018588691e-05, 'epoch': 0.55}\n",
            "{'loss': 5.6018, 'grad_norm': 0.14696969091892242, 'learning_rate': 8.738300808386935e-05, 'epoch': 0.55}\n",
            "{'loss': 5.5241, 'grad_norm': 0.13515886664390564, 'learning_rate': 8.712160194895824e-05, 'epoch': 0.56}\n",
            "{'loss': 5.5917, 'grad_norm': 0.12384481728076935, 'learning_rate': 8.686028526991372e-05, 'epoch': 0.56}\n",
            "{'loss': 5.57, 'grad_norm': 0.12641498446464539, 'learning_rate': 8.659905986189254e-05, 'epoch': 0.56}\n",
            "{'loss': 5.4166, 'grad_norm': 0.14501863718032837, 'learning_rate': 8.633792753941733e-05, 'epoch': 0.56}\n",
            "{'loss': 5.5375, 'grad_norm': 0.15555380284786224, 'learning_rate': 8.60768901163642e-05, 'epoch': 0.56}\n",
            "{'loss': 5.5158, 'grad_norm': 0.17088690400123596, 'learning_rate': 8.581594940595002e-05, 'epoch': 0.56}\n",
            "{'loss': 5.6015, 'grad_norm': 0.11077291518449783, 'learning_rate': 8.555510722071988e-05, 'epoch': 0.56}\n",
            "{'loss': 5.1042, 'grad_norm': 0.138569176197052, 'learning_rate': 8.529436537253458e-05, 'epoch': 0.56}\n",
            "{'loss': 5.6293, 'grad_norm': 0.15720565617084503, 'learning_rate': 8.503372567255786e-05, 'epoch': 0.56}\n",
            "{'loss': 5.4801, 'grad_norm': 0.12109750509262085, 'learning_rate': 8.477318993124392e-05, 'epoch': 0.56}\n",
            "{'loss': 5.5435, 'grad_norm': 0.15161225199699402, 'learning_rate': 8.45127599583249e-05, 'epoch': 0.56}\n",
            "{'loss': 5.6138, 'grad_norm': 0.18605375289916992, 'learning_rate': 8.425243756279824e-05, 'epoch': 0.56}\n",
            "{'loss': 5.5738, 'grad_norm': 0.1675126552581787, 'learning_rate': 8.399222455291408e-05, 'epoch': 0.57}\n",
            "{'loss': 5.4585, 'grad_norm': 0.11123709380626678, 'learning_rate': 8.373212273616282e-05, 'epoch': 0.57}\n",
            "{'loss': 5.2296, 'grad_norm': 0.2326570451259613, 'learning_rate': 8.34721339192624e-05, 'epoch': 0.57}\n",
            "{'loss': 5.5247, 'grad_norm': 0.13943161070346832, 'learning_rate': 8.321225990814591e-05, 'epoch': 0.57}\n",
            "{'loss': 5.4966, 'grad_norm': 0.11541938781738281, 'learning_rate': 8.295250250794899e-05, 'epoch': 0.57}\n",
            "{'loss': 5.4703, 'grad_norm': 0.15970835089683533, 'learning_rate': 8.269286352299724e-05, 'epoch': 0.57}\n",
            "{'loss': 5.6511, 'grad_norm': 0.15689586102962494, 'learning_rate': 8.243334475679366e-05, 'epoch': 0.57}\n",
            "{'loss': 5.5642, 'grad_norm': 0.17508777976036072, 'learning_rate': 8.217394801200631e-05, 'epoch': 0.57}\n",
            "{'loss': 5.5318, 'grad_norm': 0.1538148671388626, 'learning_rate': 8.191467509045563e-05, 'epoch': 0.57}\n",
            "{'loss': 5.5665, 'grad_norm': 0.16255146265029907, 'learning_rate': 8.165552779310191e-05, 'epoch': 0.57}\n",
            "{'loss': 5.5768, 'grad_norm': 0.16818265616893768, 'learning_rate': 8.139650792003286e-05, 'epoch': 0.57}\n",
            "{'loss': 5.451, 'grad_norm': 0.14055135846138, 'learning_rate': 8.113761727045105e-05, 'epoch': 0.57}\n",
            "{'loss': 5.4932, 'grad_norm': 0.13809508085250854, 'learning_rate': 8.087885764266155e-05, 'epoch': 0.58}\n",
            "{'loss': 5.5676, 'grad_norm': 0.1675659716129303, 'learning_rate': 8.062023083405918e-05, 'epoch': 0.58}\n",
            "{'loss': 5.5468, 'grad_norm': 0.10509945452213287, 'learning_rate': 8.036173864111631e-05, 'epoch': 0.58}\n",
            "{'loss': 5.5257, 'grad_norm': 0.12597110867500305, 'learning_rate': 8.010338285937006e-05, 'epoch': 0.58}\n",
            "{'loss': 5.6056, 'grad_norm': 0.18283340334892273, 'learning_rate': 7.984516528341016e-05, 'epoch': 0.58}\n",
            "{'loss': 5.5625, 'grad_norm': 0.10614091157913208, 'learning_rate': 7.958708770686629e-05, 'epoch': 0.58}\n",
            "{'loss': 5.6048, 'grad_norm': 0.11519774794578552, 'learning_rate': 7.932915192239571e-05, 'epoch': 0.58}\n",
            "{'loss': 5.5868, 'grad_norm': 0.1419525146484375, 'learning_rate': 7.907135972167069e-05, 'epoch': 0.58}\n",
            "{'loss': 5.5021, 'grad_norm': 0.14560706913471222, 'learning_rate': 7.88137128953662e-05, 'epoch': 0.58}\n",
            "{'loss': 5.6267, 'grad_norm': 0.1884280890226364, 'learning_rate': 7.855621323314736e-05, 'epoch': 0.58}\n",
            "{'loss': 4.8217, 'grad_norm': 0.13023248314857483, 'learning_rate': 7.829886252365711e-05, 'epoch': 0.58}\n",
            "{'loss': 5.6318, 'grad_norm': 0.14936520159244537, 'learning_rate': 7.804166255450373e-05, 'epoch': 0.58}\n",
            "{'loss': 5.6372, 'grad_norm': 0.13988713920116425, 'learning_rate': 7.778461511224834e-05, 'epoch': 0.59}\n",
            "{'loss': 5.455, 'grad_norm': 0.14069761335849762, 'learning_rate': 7.75277219823927e-05, 'epoch': 0.59}\n",
            "{'loss': 4.9014, 'grad_norm': 0.15739798545837402, 'learning_rate': 7.727098494936663e-05, 'epoch': 0.59}\n",
            "{'loss': 5.6359, 'grad_norm': 0.13320359587669373, 'learning_rate': 7.701440579651566e-05, 'epoch': 0.59}\n",
            "{'loss': 5.5382, 'grad_norm': 0.16457435488700867, 'learning_rate': 7.675798630608867e-05, 'epoch': 0.59}\n",
            "{'loss': 5.6369, 'grad_norm': 0.14219407737255096, 'learning_rate': 7.65017282592255e-05, 'epoch': 0.59}\n",
            "{'loss': 5.6626, 'grad_norm': 0.17500421404838562, 'learning_rate': 7.624563343594458e-05, 'epoch': 0.59}\n",
            "{'loss': 5.3035, 'grad_norm': 0.15860921144485474, 'learning_rate': 7.598970361513051e-05, 'epoch': 0.59}\n",
            "{'loss': 5.5248, 'grad_norm': 0.13869202136993408, 'learning_rate': 7.573394057452181e-05, 'epoch': 0.59}\n",
            "{'loss': 5.3269, 'grad_norm': 0.15212972462177277, 'learning_rate': 7.547834609069846e-05, 'epoch': 0.59}\n",
            "{'loss': 5.2405, 'grad_norm': 0.12633271515369415, 'learning_rate': 7.522292193906963e-05, 'epoch': 0.59}\n",
            "{'loss': 4.7415, 'grad_norm': 0.16210375726222992, 'learning_rate': 7.496766989386136e-05, 'epoch': 0.59}\n",
            "{'loss': 5.6422, 'grad_norm': 0.13956519961357117, 'learning_rate': 7.471259172810416e-05, 'epoch': 0.59}\n",
            "{'loss': 5.1639, 'grad_norm': 0.13336944580078125, 'learning_rate': 7.445768921362077e-05, 'epoch': 0.6}\n",
            "{'loss': 5.6247, 'grad_norm': 0.16196365654468536, 'learning_rate': 7.42029641210138e-05, 'epoch': 0.6}\n",
            "{'loss': 5.653, 'grad_norm': 0.11681584268808365, 'learning_rate': 7.394841821965345e-05, 'epoch': 0.6}\n",
            "{'loss': 5.6192, 'grad_norm': 0.16895706951618195, 'learning_rate': 7.369405327766532e-05, 'epoch': 0.6}\n",
            "{'loss': 5.5433, 'grad_norm': 0.14029937982559204, 'learning_rate': 7.343987106191785e-05, 'epoch': 0.6}\n",
            "{'loss': 5.5176, 'grad_norm': 0.13509051501750946, 'learning_rate': 7.318587333801036e-05, 'epoch': 0.6}\n",
            "{'loss': 5.6316, 'grad_norm': 0.14927458763122559, 'learning_rate': 7.293206187026061e-05, 'epoch': 0.6}\n",
            "{'loss': 5.4962, 'grad_norm': 0.12991806864738464, 'learning_rate': 7.26784384216926e-05, 'epoch': 0.6}\n",
            "{'loss': 5.5174, 'grad_norm': 0.13861043751239777, 'learning_rate': 7.242500475402433e-05, 'epoch': 0.6}\n",
            "{'loss': 5.5515, 'grad_norm': 0.12164124846458435, 'learning_rate': 7.217176262765551e-05, 'epoch': 0.6}\n",
            "{'loss': 5.4576, 'grad_norm': 0.132606640458107, 'learning_rate': 7.191871380165538e-05, 'epoch': 0.6}\n",
            "{'loss': 5.6107, 'grad_norm': 0.1471240073442459, 'learning_rate': 7.166586003375049e-05, 'epoch': 0.6}\n",
            "{'loss': 5.4994, 'grad_norm': 0.10269780457019806, 'learning_rate': 7.14132030803125e-05, 'epoch': 0.61}\n",
            "{'loss': 5.5459, 'grad_norm': 0.21672025322914124, 'learning_rate': 7.116074469634581e-05, 'epoch': 0.61}\n",
            "{'loss': 5.5401, 'grad_norm': 0.19181720912456512, 'learning_rate': 7.090848663547574e-05, 'epoch': 0.61}\n",
            "{'loss': 5.5874, 'grad_norm': 0.19478823244571686, 'learning_rate': 7.065643064993598e-05, 'epoch': 0.61}\n",
            "{'loss': 5.554, 'grad_norm': 0.16958387196063995, 'learning_rate': 7.040457849055662e-05, 'epoch': 0.61}\n",
            "{'loss': 5.5905, 'grad_norm': 0.18680550158023834, 'learning_rate': 7.015293190675191e-05, 'epoch': 0.61}\n",
            "{'loss': 5.5506, 'grad_norm': 0.17443962395191193, 'learning_rate': 6.990149264650814e-05, 'epoch': 0.61}\n",
            "{'loss': 5.6342, 'grad_norm': 0.1452665627002716, 'learning_rate': 6.96502624563715e-05, 'epoch': 0.61}\n",
            "{'loss': 5.4229, 'grad_norm': 0.1386520117521286, 'learning_rate': 6.939924308143591e-05, 'epoch': 0.61}\n",
            "{'loss': 5.438, 'grad_norm': 0.20568417012691498, 'learning_rate': 6.914843626533099e-05, 'epoch': 0.61}\n",
            "{'loss': 5.5964, 'grad_norm': 0.1625654697418213, 'learning_rate': 6.889784375020978e-05, 'epoch': 0.61}\n",
            "{'loss': 5.5292, 'grad_norm': 0.22278396785259247, 'learning_rate': 6.864746727673686e-05, 'epoch': 0.61}\n",
            "{'loss': 5.6543, 'grad_norm': 0.12459525465965271, 'learning_rate': 6.839730858407603e-05, 'epoch': 0.62}\n",
            "{'loss': 5.3612, 'grad_norm': 0.1883918195962906, 'learning_rate': 6.814736940987844e-05, 'epoch': 0.62}\n",
            "{'loss': 5.4996, 'grad_norm': 0.19271519780158997, 'learning_rate': 6.789765149027039e-05, 'epoch': 0.62}\n",
            "{'loss': 5.5136, 'grad_norm': 0.12035418301820755, 'learning_rate': 6.764815655984125e-05, 'epoch': 0.62}\n",
            "{'loss': 5.4252, 'grad_norm': 0.12353190034627914, 'learning_rate': 6.739888635163154e-05, 'epoch': 0.62}\n",
            "{'loss': 5.5915, 'grad_norm': 0.19415050745010376, 'learning_rate': 6.714984259712074e-05, 'epoch': 0.62}\n",
            "{'loss': 5.5354, 'grad_norm': 0.17688784003257751, 'learning_rate': 6.690102702621548e-05, 'epoch': 0.62}\n",
            "{'loss': 5.6435, 'grad_norm': 0.2251364141702652, 'learning_rate': 6.665244136723719e-05, 'epoch': 0.62}\n",
            "{'loss': 5.5217, 'grad_norm': 0.18002775311470032, 'learning_rate': 6.640408734691038e-05, 'epoch': 0.62}\n",
            "{'loss': 5.7215, 'grad_norm': 0.23743966221809387, 'learning_rate': 6.615596669035059e-05, 'epoch': 0.62}\n",
            "{'loss': 5.2923, 'grad_norm': 0.2231147587299347, 'learning_rate': 6.590808112105232e-05, 'epoch': 0.62}\n",
            "{'loss': 5.0209, 'grad_norm': 0.16176222264766693, 'learning_rate': 6.56604323608771e-05, 'epoch': 0.62}\n",
            "{'loss': 5.4524, 'grad_norm': 0.18152828514575958, 'learning_rate': 6.541302213004159e-05, 'epoch': 0.62}\n",
            "{'loss': 5.6058, 'grad_norm': 0.16785858571529388, 'learning_rate': 6.516585214710554e-05, 'epoch': 0.63}\n",
            "{'loss': 5.2285, 'grad_norm': 0.13203610479831696, 'learning_rate': 6.491892412895995e-05, 'epoch': 0.63}\n",
            "{'loss': 5.3517, 'grad_norm': 0.1434914916753769, 'learning_rate': 6.46722397908149e-05, 'epoch': 0.63}\n",
            "{'loss': 5.5156, 'grad_norm': 0.17868606746196747, 'learning_rate': 6.442580084618805e-05, 'epoch': 0.63}\n",
            "{'loss': 5.6088, 'grad_norm': 0.1767498254776001, 'learning_rate': 6.417960900689237e-05, 'epoch': 0.63}\n",
            "{'loss': 5.645, 'grad_norm': 0.1797674149274826, 'learning_rate': 6.393366598302446e-05, 'epoch': 0.63}\n",
            "{'loss': 5.6147, 'grad_norm': 0.15041302144527435, 'learning_rate': 6.368797348295256e-05, 'epoch': 0.63}\n",
            "{'loss': 5.616, 'grad_norm': 0.15149180591106415, 'learning_rate': 6.344253321330476e-05, 'epoch': 0.63}\n",
            "{'loss': 5.6573, 'grad_norm': 0.28107643127441406, 'learning_rate': 6.319734687895705e-05, 'epoch': 0.63}\n",
            "{'loss': 5.4201, 'grad_norm': 0.2136300504207611, 'learning_rate': 6.295241618302156e-05, 'epoch': 0.63}\n",
            "{'loss': 5.6513, 'grad_norm': 0.1767793744802475, 'learning_rate': 6.270774282683476e-05, 'epoch': 0.63}\n",
            "{'loss': 5.515, 'grad_norm': 0.11922851204872131, 'learning_rate': 6.246332850994547e-05, 'epoch': 0.63}\n",
            "{'loss': 5.7069, 'grad_norm': 0.2734915614128113, 'learning_rate': 6.22191749301033e-05, 'epoch': 0.64}\n",
            "{'loss': 4.6654, 'grad_norm': 0.14999552071094513, 'learning_rate': 6.197528378324665e-05, 'epoch': 0.64}\n",
            "{'loss': 5.5348, 'grad_norm': 0.15237563848495483, 'learning_rate': 6.173165676349103e-05, 'epoch': 0.64}\n",
            "{'loss': 5.5053, 'grad_norm': 0.15410195291042328, 'learning_rate': 6.148829556311728e-05, 'epoch': 0.64}\n",
            "{'loss': 5.4905, 'grad_norm': 0.121251180768013, 'learning_rate': 6.124520187255982e-05, 'epoch': 0.64}\n",
            "{'loss': 5.5903, 'grad_norm': 0.200633242726326, 'learning_rate': 6.100237738039484e-05, 'epoch': 0.64}\n",
            "{'loss': 5.5276, 'grad_norm': 0.14234600961208344, 'learning_rate': 6.075982377332867e-05, 'epoch': 0.64}\n",
            "{'loss': 5.5201, 'grad_norm': 0.14241139590740204, 'learning_rate': 6.051754273618605e-05, 'epoch': 0.64}\n",
            "{'loss': 5.5543, 'grad_norm': 0.10547278076410294, 'learning_rate': 6.02755359518983e-05, 'epoch': 0.64}\n",
            "{'loss': 5.109, 'grad_norm': 0.11046794056892395, 'learning_rate': 6.0033805101491794e-05, 'epoch': 0.64}\n",
            "{'loss': 5.6263, 'grad_norm': 0.1934964954853058, 'learning_rate': 5.979235186407621e-05, 'epoch': 0.64}\n",
            "{'loss': 5.1427, 'grad_norm': 0.16484585404396057, 'learning_rate': 5.955117791683289e-05, 'epoch': 0.64}\n",
            "{'loss': 5.6599, 'grad_norm': 0.21063925325870514, 'learning_rate': 5.93102849350031e-05, 'epoch': 0.65}\n",
            "{'loss': 5.4295, 'grad_norm': 0.21317420899868011, 'learning_rate': 5.9069674591876534e-05, 'epoch': 0.65}\n",
            "{'loss': 5.5752, 'grad_norm': 0.12744539976119995, 'learning_rate': 5.882934855877962e-05, 'epoch': 0.65}\n",
            "{'loss': 5.6491, 'grad_norm': 0.16676485538482666, 'learning_rate': 5.858930850506388e-05, 'epoch': 0.65}\n",
            "{'loss': 5.2846, 'grad_norm': 0.12081246823072433, 'learning_rate': 5.8349556098094426e-05, 'epoch': 0.65}\n",
            "{'loss': 5.6702, 'grad_norm': 0.1316545307636261, 'learning_rate': 5.811009300323818e-05, 'epoch': 0.65}\n",
            "{'loss': 5.4753, 'grad_norm': 0.2286357581615448, 'learning_rate': 5.78709208838526e-05, 'epoch': 0.65}\n",
            "{'loss': 4.8743, 'grad_norm': 0.17488496005535126, 'learning_rate': 5.7632041401273895e-05, 'epoch': 0.65}\n",
            "{'loss': 5.6259, 'grad_norm': 0.11201310157775879, 'learning_rate': 5.739345621480559e-05, 'epoch': 0.65}\n",
            "{'loss': 4.9424, 'grad_norm': 0.1717386543750763, 'learning_rate': 5.7155166981706956e-05, 'epoch': 0.65}\n",
            "{'loss': 5.5039, 'grad_norm': 0.1944931000471115, 'learning_rate': 5.6917175357181505e-05, 'epoch': 0.65}\n",
            "{'loss': 5.5632, 'grad_norm': 0.1504768431186676, 'learning_rate': 5.667948299436555e-05, 'epoch': 0.65}\n",
            "{'loss': 5.6315, 'grad_norm': 0.16942772269248962, 'learning_rate': 5.644209154431661e-05, 'epoch': 0.66}\n",
            "{'loss': 5.4898, 'grad_norm': 0.2006853222846985, 'learning_rate': 5.620500265600206e-05, 'epoch': 0.66}\n",
            "{'loss': 5.5344, 'grad_norm': 0.13252203166484833, 'learning_rate': 5.596821797628756e-05, 'epoch': 0.66}\n",
            "{'loss': 5.5506, 'grad_norm': 0.14054563641548157, 'learning_rate': 5.573173914992575e-05, 'epoch': 0.66}\n",
            "{'loss': 5.4939, 'grad_norm': 0.1266629993915558, 'learning_rate': 5.549556781954468e-05, 'epoch': 0.66}\n",
            "{'loss': 5.567, 'grad_norm': 0.17009517550468445, 'learning_rate': 5.525970562563656e-05, 'epoch': 0.66}\n",
            "{'loss': 5.3443, 'grad_norm': 0.14668886363506317, 'learning_rate': 5.502415420654619e-05, 'epoch': 0.66}\n",
            "{'loss': 5.6909, 'grad_norm': 0.220082089304924, 'learning_rate': 5.47889151984597e-05, 'epoch': 0.66}\n",
            "{'loss': 4.7269, 'grad_norm': 0.13537824153900146, 'learning_rate': 5.455399023539318e-05, 'epoch': 0.66}\n",
            "{'loss': 5.5957, 'grad_norm': 0.17543746531009674, 'learning_rate': 5.431938094918132e-05, 'epoch': 0.66}\n",
            "{'loss': 5.4957, 'grad_norm': 0.12193159759044647, 'learning_rate': 5.408508896946591e-05, 'epoch': 0.66}\n",
            "{'loss': 5.5903, 'grad_norm': 0.16238148510456085, 'learning_rate': 5.385111592368486e-05, 'epoch': 0.66}\n",
            "{'loss': 4.9165, 'grad_norm': 0.17265503108501434, 'learning_rate': 5.361746343706052e-05, 'epoch': 0.66}\n",
            "{'loss': 5.5102, 'grad_norm': 0.15606781840324402, 'learning_rate': 5.3384133132588784e-05, 'epoch': 0.67}\n",
            "{'loss': 5.5193, 'grad_norm': 0.12400104105472565, 'learning_rate': 5.315112663102746e-05, 'epoch': 0.67}\n",
            "{'loss': 5.6789, 'grad_norm': 0.17976726591587067, 'learning_rate': 5.2918445550885165e-05, 'epoch': 0.67}\n",
            "{'loss': 5.5923, 'grad_norm': 0.13010765612125397, 'learning_rate': 5.2686091508410106e-05, 'epoch': 0.67}\n",
            "{'loss': 5.4116, 'grad_norm': 0.20305466651916504, 'learning_rate': 5.2454066117578815e-05, 'epoch': 0.67}\n",
            "{'loss': 5.5765, 'grad_norm': 0.14913199841976166, 'learning_rate': 5.2222370990085e-05, 'epoch': 0.67}\n",
            "{'loss': 5.5298, 'grad_norm': 0.19430255889892578, 'learning_rate': 5.199100773532814e-05, 'epoch': 0.67}\n",
            "{'loss': 5.5623, 'grad_norm': 0.21828652918338776, 'learning_rate': 5.175997796040262e-05, 'epoch': 0.67}\n",
            "{'loss': 5.3619, 'grad_norm': 0.19894219934940338, 'learning_rate': 5.152928327008635e-05, 'epoch': 0.67}\n",
            "{'loss': 5.5418, 'grad_norm': 0.20162852108478546, 'learning_rate': 5.129892526682969e-05, 'epoch': 0.67}\n",
            "{'loss': 5.6668, 'grad_norm': 0.1738843470811844, 'learning_rate': 5.106890555074426e-05, 'epoch': 0.67}\n",
            "{'loss': 5.5693, 'grad_norm': 0.16819962859153748, 'learning_rate': 5.083922571959194e-05, 'epoch': 0.67}\n",
            "{'loss': 5.5961, 'grad_norm': 0.14787256717681885, 'learning_rate': 5.060988736877366e-05, 'epoch': 0.68}\n",
            "{'loss': 5.5772, 'grad_norm': 0.1528928279876709, 'learning_rate': 5.038089209131837e-05, 'epoch': 0.68}\n",
            "{'loss': 5.5265, 'grad_norm': 0.15084069967269897, 'learning_rate': 5.015224147787195e-05, 'epoch': 0.68}\n",
            "{'loss': 5.2304, 'grad_norm': 0.1467863917350769, 'learning_rate': 4.9923937116686215e-05, 'epoch': 0.68}\n",
            "{'loss': 5.3248, 'grad_norm': 0.19150801002979279, 'learning_rate': 4.9695980593607817e-05, 'epoch': 0.68}\n",
            "{'loss': 5.4816, 'grad_norm': 0.15233144164085388, 'learning_rate': 4.946837349206725e-05, 'epoch': 0.68}\n",
            "{'loss': 5.5882, 'grad_norm': 0.14381788671016693, 'learning_rate': 4.924111739306788e-05, 'epoch': 0.68}\n",
            "{'loss': 5.3682, 'grad_norm': 0.12834316492080688, 'learning_rate': 4.901421387517492e-05, 'epoch': 0.68}\n",
            "{'loss': 5.6231, 'grad_norm': 0.1687590330839157, 'learning_rate': 4.8787664514504504e-05, 'epoch': 0.68}\n",
            "{'loss': 5.6524, 'grad_norm': 0.11975634843111038, 'learning_rate': 4.856147088471271e-05, 'epoch': 0.68}\n",
            "{'loss': 5.5487, 'grad_norm': 0.1998366266489029, 'learning_rate': 4.833563455698468e-05, 'epoch': 0.68}\n",
            "{'loss': 5.5876, 'grad_norm': 0.16477584838867188, 'learning_rate': 4.811015710002355e-05, 'epoch': 0.68}\n",
            "{'loss': 5.5806, 'grad_norm': 0.16309501230716705, 'learning_rate': 4.788504008003978e-05, 'epoch': 0.69}\n",
            "{'loss': 5.4593, 'grad_norm': 0.1621963381767273, 'learning_rate': 4.766028506074014e-05, 'epoch': 0.69}\n",
            "{'loss': 4.6338, 'grad_norm': 0.17286282777786255, 'learning_rate': 4.743589360331683e-05, 'epoch': 0.69}\n",
            "{'loss': 5.4899, 'grad_norm': 0.1539619117975235, 'learning_rate': 4.721186726643679e-05, 'epoch': 0.69}\n",
            "{'loss': 5.3888, 'grad_norm': 0.18890991806983948, 'learning_rate': 4.698820760623064e-05, 'epoch': 0.69}\n",
            "{'loss': 5.6167, 'grad_norm': 0.16046211123466492, 'learning_rate': 4.676491617628204e-05, 'epoch': 0.69}\n",
            "{'loss': 5.489, 'grad_norm': 0.1467711478471756, 'learning_rate': 4.6541994527616836e-05, 'epoch': 0.69}\n",
            "{'loss': 5.4652, 'grad_norm': 0.14127622544765472, 'learning_rate': 4.631944420869237e-05, 'epoch': 0.69}\n",
            "{'loss': 5.4388, 'grad_norm': 0.14683209359645844, 'learning_rate': 4.609726676538652e-05, 'epoch': 0.69}\n",
            "{'loss': 5.6867, 'grad_norm': 0.2944665253162384, 'learning_rate': 4.587546374098719e-05, 'epoch': 0.69}\n",
            "{'loss': 5.5076, 'grad_norm': 0.11312374472618103, 'learning_rate': 4.56540366761815e-05, 'epoch': 0.69}\n",
            "{'loss': 5.6292, 'grad_norm': 0.2200511395931244, 'learning_rate': 4.5432987109045065e-05, 'epoch': 0.69}\n",
            "{'loss': 5.4746, 'grad_norm': 0.0893738865852356, 'learning_rate': 4.521231657503132e-05, 'epoch': 0.69}\n",
            "{'loss': 5.0437, 'grad_norm': 0.15682411193847656, 'learning_rate': 4.499202660696088e-05, 'epoch': 0.7}\n",
            "{'loss': 5.5794, 'grad_norm': 0.165058434009552, 'learning_rate': 4.477211873501085e-05, 'epoch': 0.7}\n",
            "{'loss': 5.6321, 'grad_norm': 0.18187156319618225, 'learning_rate': 4.4552594486704225e-05, 'epoch': 0.7}\n",
            "{'loss': 5.2023, 'grad_norm': 0.16712230443954468, 'learning_rate': 4.433345538689929e-05, 'epoch': 0.7}\n",
            "{'loss': 5.6034, 'grad_norm': 0.1499100774526596, 'learning_rate': 4.411470295777903e-05, 'epoch': 0.7}\n",
            "{'loss': 5.23, 'grad_norm': 0.11420490592718124, 'learning_rate': 4.389633871884048e-05, 'epoch': 0.7}\n",
            "{'loss': 5.6352, 'grad_norm': 0.17174780368804932, 'learning_rate': 4.36783641868843e-05, 'epoch': 0.7}\n",
            "{'loss': 5.4936, 'grad_norm': 0.16515745222568512, 'learning_rate': 4.346078087600412e-05, 'epoch': 0.7}\n",
            "{'loss': 5.6404, 'grad_norm': 0.141493558883667, 'learning_rate': 4.324359029757608e-05, 'epoch': 0.7}\n",
            "{'loss': 5.6553, 'grad_norm': 0.214674711227417, 'learning_rate': 4.3026793960248334e-05, 'epoch': 0.7}\n",
            "{'loss': 5.5131, 'grad_norm': 0.1789114624261856, 'learning_rate': 4.281039336993058e-05, 'epoch': 0.7}\n",
            "{'loss': 5.5427, 'grad_norm': 0.2604357898235321, 'learning_rate': 4.2594390029783534e-05, 'epoch': 0.7}\n",
            "{'loss': 5.4829, 'grad_norm': 0.16300052404403687, 'learning_rate': 4.2378785440208614e-05, 'epoch': 0.71}\n",
            "{'loss': 5.5309, 'grad_norm': 0.20773860812187195, 'learning_rate': 4.21635810988373e-05, 'epoch': 0.71}\n",
            "{'loss': 5.6746, 'grad_norm': 0.14727967977523804, 'learning_rate': 4.1948778500521005e-05, 'epoch': 0.71}\n",
            "{'loss': 5.5837, 'grad_norm': 0.15092365443706512, 'learning_rate': 4.173437913732048e-05, 'epoch': 0.71}\n",
            "{'loss': 5.6731, 'grad_norm': 0.13585688173770905, 'learning_rate': 4.152038449849556e-05, 'epoch': 0.71}\n",
            "{'loss': 4.9975, 'grad_norm': 0.1652669906616211, 'learning_rate': 4.1306796070494755e-05, 'epoch': 0.71}\n",
            "{'loss': 5.652, 'grad_norm': 0.14275972545146942, 'learning_rate': 4.1093615336945034e-05, 'epoch': 0.71}\n",
            "{'loss': 5.0422, 'grad_norm': 0.167924702167511, 'learning_rate': 4.088084377864135e-05, 'epoch': 0.71}\n",
            "{'loss': 5.6287, 'grad_norm': 0.18223920464515686, 'learning_rate': 4.0668482873536496e-05, 'epoch': 0.71}\n",
            "{'loss': 5.4473, 'grad_norm': 0.16047824919223785, 'learning_rate': 4.045653409673078e-05, 'epoch': 0.71}\n",
            "{'loss': 5.4141, 'grad_norm': 0.11962674558162689, 'learning_rate': 4.024499892046172e-05, 'epoch': 0.71}\n",
            "{'loss': 5.6915, 'grad_norm': 0.1904800832271576, 'learning_rate': 4.003387881409397e-05, 'epoch': 0.71}\n",
            "{'loss': 5.5515, 'grad_norm': 0.17703622579574585, 'learning_rate': 3.9823175244109014e-05, 'epoch': 0.72}\n",
            "{'loss': 5.6601, 'grad_norm': 0.16481848061084747, 'learning_rate': 3.9612889674094954e-05, 'epoch': 0.72}\n",
            "{'loss': 5.6012, 'grad_norm': 0.18057827651500702, 'learning_rate': 3.940302356473642e-05, 'epoch': 0.72}\n",
            "{'loss': 5.1424, 'grad_norm': 0.2115568220615387, 'learning_rate': 3.9193578373804364e-05, 'epoch': 0.72}\n",
            "{'loss': 5.5942, 'grad_norm': 0.15402546525001526, 'learning_rate': 3.898455555614597e-05, 'epoch': 0.72}\n",
            "{'loss': 5.5191, 'grad_norm': 0.16285885870456696, 'learning_rate': 3.8775956563674543e-05, 'epoch': 0.72}\n",
            "{'loss': 5.5445, 'grad_norm': 0.17311018705368042, 'learning_rate': 3.856778284535938e-05, 'epoch': 0.72}\n",
            "{'loss': 5.6442, 'grad_norm': 0.17288991808891296, 'learning_rate': 3.836003584721577e-05, 'epoch': 0.72}\n",
            "{'loss': 5.4483, 'grad_norm': 0.18112844228744507, 'learning_rate': 3.815271701229491e-05, 'epoch': 0.72}\n",
            "{'loss': 5.6381, 'grad_norm': 0.12825630605220795, 'learning_rate': 3.7945827780673905e-05, 'epoch': 0.72}\n",
            "{'loss': 5.5223, 'grad_norm': 0.16574904322624207, 'learning_rate': 3.773936958944574e-05, 'epoch': 0.72}\n",
            "{'loss': 5.1868, 'grad_norm': 0.13534368574619293, 'learning_rate': 3.7533343872709294e-05, 'epoch': 0.72}\n",
            "{'loss': 5.6589, 'grad_norm': 0.21353840827941895, 'learning_rate': 3.732775206155943e-05, 'epoch': 0.72}\n",
            "{'loss': 5.6371, 'grad_norm': 0.16170692443847656, 'learning_rate': 3.712259558407698e-05, 'epoch': 0.73}\n",
            "{'loss': 5.419, 'grad_norm': 0.1573343425989151, 'learning_rate': 3.691787586531894e-05, 'epoch': 0.73}\n",
            "{'loss': 5.4674, 'grad_norm': 0.16561932861804962, 'learning_rate': 3.671359432730834e-05, 'epoch': 0.73}\n",
            "{'loss': 5.5093, 'grad_norm': 0.15898549556732178, 'learning_rate': 3.6509752389024685e-05, 'epoch': 0.73}\n",
            "{'loss': 5.4931, 'grad_norm': 0.1453668177127838, 'learning_rate': 3.630635146639384e-05, 'epoch': 0.73}\n",
            "{'loss': 5.6191, 'grad_norm': 0.12218733876943588, 'learning_rate': 3.6103392972278324e-05, 'epoch': 0.73}\n",
            "{'loss': 5.5169, 'grad_norm': 0.13260555267333984, 'learning_rate': 3.5900878316467454e-05, 'epoch': 0.73}\n",
            "{'loss': 4.9555, 'grad_norm': 0.1821388602256775, 'learning_rate': 3.569880890566752e-05, 'epoch': 0.73}\n",
            "{'loss': 5.588, 'grad_norm': 0.1528870016336441, 'learning_rate': 3.549718614349218e-05, 'epoch': 0.73}\n",
            "{'loss': 5.6626, 'grad_norm': 0.19472596049308777, 'learning_rate': 3.529601143045244e-05, 'epoch': 0.73}\n",
            "{'loss': 5.41, 'grad_norm': 0.1674908697605133, 'learning_rate': 3.509528616394716e-05, 'epoch': 0.73}\n",
            "{'loss': 5.6754, 'grad_norm': 0.1793905347585678, 'learning_rate': 3.4895011738253155e-05, 'epoch': 0.73}\n",
            "{'loss': 5.6988, 'grad_norm': 0.20245403051376343, 'learning_rate': 3.469518954451573e-05, 'epoch': 0.74}\n",
            "{'loss': 5.5189, 'grad_norm': 0.1665535271167755, 'learning_rate': 3.4495820970738834e-05, 'epoch': 0.74}\n",
            "{'loss': 5.4643, 'grad_norm': 0.1611214578151703, 'learning_rate': 3.429690740177549e-05, 'epoch': 0.74}\n",
            "{'loss': 5.6277, 'grad_norm': 0.16723667085170746, 'learning_rate': 3.409845021931818e-05, 'epoch': 0.74}\n",
            "{'loss': 5.6603, 'grad_norm': 0.1576080173254013, 'learning_rate': 3.390045080188923e-05, 'epoch': 0.74}\n",
            "{'loss': 5.6194, 'grad_norm': 0.13135682046413422, 'learning_rate': 3.370291052483124e-05, 'epoch': 0.74}\n",
            "{'loss': 5.6959, 'grad_norm': 0.172031432390213, 'learning_rate': 3.350583076029754e-05, 'epoch': 0.74}\n",
            "{'loss': 5.5624, 'grad_norm': 0.18904919922351837, 'learning_rate': 3.330921287724264e-05, 'epoch': 0.74}\n",
            "{'loss': 5.5666, 'grad_norm': 0.1563614159822464, 'learning_rate': 3.311305824141273e-05, 'epoch': 0.74}\n",
            "{'loss': 5.5245, 'grad_norm': 0.2588801681995392, 'learning_rate': 3.291736821533621e-05, 'epoch': 0.74}\n",
            "{'loss': 5.5122, 'grad_norm': 0.20871828496456146, 'learning_rate': 3.272214415831418e-05, 'epoch': 0.74}\n",
            "{'loss': 5.628, 'grad_norm': 0.17946787178516388, 'learning_rate': 3.252738742641106e-05, 'epoch': 0.74}\n",
            "{'loss': 5.4579, 'grad_norm': 0.1817796379327774, 'learning_rate': 3.233309937244513e-05, 'epoch': 0.75}\n",
            "{'loss': 5.5994, 'grad_norm': 0.11459282040596008, 'learning_rate': 3.213928134597912e-05, 'epoch': 0.75}\n",
            "{'loss': 5.7034, 'grad_norm': 0.203850656747818, 'learning_rate': 3.1945934693310896e-05, 'epoch': 0.75}\n",
            "{'loss': 5.6429, 'grad_norm': 0.1433536261320114, 'learning_rate': 3.175306075746406e-05, 'epoch': 0.75}\n",
            "{'loss': 5.1545, 'grad_norm': 0.1727246195077896, 'learning_rate': 3.156066087817856e-05, 'epoch': 0.75}\n",
            "{'loss': 5.295, 'grad_norm': 0.1443212330341339, 'learning_rate': 3.136873639190154e-05, 'epoch': 0.75}\n",
            "{'loss': 5.6233, 'grad_norm': 0.15953686833381653, 'learning_rate': 3.117728863177796e-05, 'epoch': 0.75}\n",
            "{'loss': 5.5959, 'grad_norm': 0.13812842965126038, 'learning_rate': 3.098631892764131e-05, 'epoch': 0.75}\n",
            "{'loss': 5.1833, 'grad_norm': 0.1673324704170227, 'learning_rate': 3.0795828606004454e-05, 'epoch': 0.75}\n",
            "{'loss': 5.6317, 'grad_norm': 0.1225062757730484, 'learning_rate': 3.060581899005033e-05, 'epoch': 0.75}\n",
            "{'loss': 5.6605, 'grad_norm': 0.17878755927085876, 'learning_rate': 3.041629139962283e-05, 'epoch': 0.75}\n",
            "{'loss': 5.3592, 'grad_norm': 0.18405310809612274, 'learning_rate': 3.0227247151217552e-05, 'epoch': 0.75}\n",
            "{'loss': 5.5714, 'grad_norm': 0.11017431318759918, 'learning_rate': 3.0038687557972856e-05, 'epoch': 0.76}\n",
            "{'loss': 5.7173, 'grad_norm': 0.1743965893983841, 'learning_rate': 2.9850613929660365e-05, 'epoch': 0.76}\n",
            "{'loss': 4.829, 'grad_norm': 0.1968287080526352, 'learning_rate': 2.966302757267625e-05, 'epoch': 0.76}\n",
            "{'loss': 5.4609, 'grad_norm': 0.18707670271396637, 'learning_rate': 2.9475929790031976e-05, 'epoch': 0.76}\n",
            "{'loss': 5.4725, 'grad_norm': 0.21343466639518738, 'learning_rate': 2.9289321881345254e-05, 'epoch': 0.76}\n",
            "{'loss': 5.4902, 'grad_norm': 0.18185120820999146, 'learning_rate': 2.9103205142831036e-05, 'epoch': 0.76}\n",
            "{'loss': 5.5212, 'grad_norm': 0.11364887654781342, 'learning_rate': 2.8917580867292526e-05, 'epoch': 0.76}\n",
            "{'loss': 5.6836, 'grad_norm': 0.1753225326538086, 'learning_rate': 2.8732450344112173e-05, 'epoch': 0.76}\n",
            "{'loss': 5.6892, 'grad_norm': 0.1771102100610733, 'learning_rate': 2.8547814859242727e-05, 'epoch': 0.76}\n",
            "{'loss': 5.2699, 'grad_norm': 0.1640474796295166, 'learning_rate': 2.8363675695198323e-05, 'epoch': 0.76}\n",
            "{'loss': 5.4562, 'grad_norm': 0.14349153637886047, 'learning_rate': 2.8180034131045464e-05, 'epoch': 0.76}\n",
            "{'loss': 5.4618, 'grad_norm': 0.1745445877313614, 'learning_rate': 2.799689144239439e-05, 'epoch': 0.76}\n",
            "{'loss': 5.5607, 'grad_norm': 0.17034178972244263, 'learning_rate': 2.7814248901389918e-05, 'epoch': 0.76}\n",
            "{'loss': 5.6241, 'grad_norm': 0.16657809913158417, 'learning_rate': 2.763210777670281e-05, 'epoch': 0.77}\n",
            "{'loss': 5.6272, 'grad_norm': 0.15884442627429962, 'learning_rate': 2.7450469333520855e-05, 'epoch': 0.77}\n",
            "{'loss': 5.7004, 'grad_norm': 0.22369703650474548, 'learning_rate': 2.726933483354014e-05, 'epoch': 0.77}\n",
            "{'loss': 5.6044, 'grad_norm': 0.1580372154712677, 'learning_rate': 2.708870553495626e-05, 'epoch': 0.77}\n",
            "{'loss': 5.6266, 'grad_norm': 0.1599486917257309, 'learning_rate': 2.6908582692455576e-05, 'epoch': 0.77}\n",
            "{'loss': 5.4974, 'grad_norm': 0.1737636774778366, 'learning_rate': 2.672896755720654e-05, 'epoch': 0.77}\n",
            "{'loss': 5.6015, 'grad_norm': 0.12261708080768585, 'learning_rate': 2.6549861376850882e-05, 'epoch': 0.77}\n",
            "{'loss': 5.6298, 'grad_norm': 0.14596253633499146, 'learning_rate': 2.6371265395495137e-05, 'epoch': 0.77}\n",
            "{'loss': 5.6258, 'grad_norm': 0.13304349780082703, 'learning_rate': 2.6193180853701828e-05, 'epoch': 0.77}\n",
            "{'loss': 5.5713, 'grad_norm': 0.14534354209899902, 'learning_rate': 2.6015608988480955e-05, 'epoch': 0.77}\n",
            "{'loss': 4.8644, 'grad_norm': 0.13254766166210175, 'learning_rate': 2.5838551033281367e-05, 'epoch': 0.77}\n",
            "{'loss': 5.5594, 'grad_norm': 0.1209983304142952, 'learning_rate': 2.5662008217982158e-05, 'epoch': 0.77}\n",
            "{'loss': 5.599, 'grad_norm': 0.16326704621315002, 'learning_rate': 2.5485981768884194e-05, 'epoch': 0.78}\n",
            "{'loss': 5.3539, 'grad_norm': 0.1475338190793991, 'learning_rate': 2.5310472908701555e-05, 'epoch': 0.78}\n",
            "{'loss': 5.8367, 'grad_norm': 0.23955662548542023, 'learning_rate': 2.5135482856553026e-05, 'epoch': 0.78}\n",
            "{'loss': 5.4716, 'grad_norm': 0.225503072142601, 'learning_rate': 2.496101282795369e-05, 'epoch': 0.78}\n",
            "{'loss': 5.566, 'grad_norm': 0.13809703290462494, 'learning_rate': 2.4787064034806397e-05, 'epoch': 0.78}\n",
            "{'loss': 5.5424, 'grad_norm': 0.2022671401500702, 'learning_rate': 2.4613637685393432e-05, 'epoch': 0.78}\n",
            "{'loss': 5.4414, 'grad_norm': 0.20317108929157257, 'learning_rate': 2.4440734984368075e-05, 'epoch': 0.78}\n",
            "{'loss': 5.5792, 'grad_norm': 0.18709397315979004, 'learning_rate': 2.4268357132746223e-05, 'epoch': 0.78}\n",
            "{'loss': 5.6676, 'grad_norm': 0.19755016267299652, 'learning_rate': 2.4096505327898078e-05, 'epoch': 0.78}\n",
            "{'loss': 5.4595, 'grad_norm': 0.14663417637348175, 'learning_rate': 2.3925180763539844e-05, 'epoch': 0.78}\n",
            "{'loss': 5.3269, 'grad_norm': 0.14412961900234222, 'learning_rate': 2.375438462972539e-05, 'epoch': 0.78}\n",
            "{'loss': 5.5959, 'grad_norm': 0.15489186346530914, 'learning_rate': 2.358411811283796e-05, 'epoch': 0.78}\n",
            "{'loss': 5.5852, 'grad_norm': 0.13864271342754364, 'learning_rate': 2.3414382395582023e-05, 'epoch': 0.79}\n",
            "{'loss': 5.7364, 'grad_norm': 0.21832527220249176, 'learning_rate': 2.324517865697501e-05, 'epoch': 0.79}\n",
            "{'loss': 5.6409, 'grad_norm': 0.1686057150363922, 'learning_rate': 2.307650807233913e-05, 'epoch': 0.79}\n",
            "{'loss': 5.6235, 'grad_norm': 0.1734847128391266, 'learning_rate': 2.2908371813293195e-05, 'epoch': 0.79}\n",
            "{'loss': 5.2083, 'grad_norm': 0.1314534842967987, 'learning_rate': 2.2740771047744457e-05, 'epoch': 0.79}\n",
            "{'loss': 5.5758, 'grad_norm': 0.12314379960298538, 'learning_rate': 2.2573706939880555e-05, 'epoch': 0.79}\n",
            "{'loss': 5.612, 'grad_norm': 0.1454777866601944, 'learning_rate': 2.240718065016141e-05, 'epoch': 0.79}\n",
            "{'loss': 5.4931, 'grad_norm': 0.1762993037700653, 'learning_rate': 2.224119333531113e-05, 'epoch': 0.79}\n",
            "{'loss': 5.6432, 'grad_norm': 0.22970984876155853, 'learning_rate': 2.2075746148309962e-05, 'epoch': 0.79}\n",
            "{'loss': 5.1761, 'grad_norm': 0.1246606707572937, 'learning_rate': 2.1910840238386398e-05, 'epoch': 0.79}\n",
            "{'loss': 5.5597, 'grad_norm': 0.16175948083400726, 'learning_rate': 2.174647675100907e-05, 'epoch': 0.79}\n",
            "{'loss': 5.6327, 'grad_norm': 0.17585337162017822, 'learning_rate': 2.1582656827878844e-05, 'epoch': 0.79}\n",
            "{'loss': 5.4886, 'grad_norm': 0.17499852180480957, 'learning_rate': 2.1419381606920884e-05, 'epoch': 0.79}\n",
            "{'loss': 5.7071, 'grad_norm': 0.15669165551662445, 'learning_rate': 2.125665222227675e-05, 'epoch': 0.8}\n",
            "{'loss': 5.6102, 'grad_norm': 0.15818534791469574, 'learning_rate': 2.10944698042965e-05, 'epoch': 0.8}\n",
            "{'loss': 5.5316, 'grad_norm': 0.15537616610527039, 'learning_rate': 2.0932835479530877e-05, 'epoch': 0.8}\n",
            "{'loss': 5.5866, 'grad_norm': 0.13977986574172974, 'learning_rate': 2.077175037072344e-05, 'epoch': 0.8}\n",
            "{'loss': 5.5957, 'grad_norm': 0.10873086750507355, 'learning_rate': 2.06112155968028e-05, 'epoch': 0.8}\n",
            "{'loss': 5.5001, 'grad_norm': 0.16745902597904205, 'learning_rate': 2.0451232272874845e-05, 'epoch': 0.8}\n",
            "{'loss': 5.6029, 'grad_norm': 0.1363292634487152, 'learning_rate': 2.029180151021496e-05, 'epoch': 0.8}\n",
            "{'loss': 5.3055, 'grad_norm': 0.19864659011363983, 'learning_rate': 2.0132924416260346e-05, 'epoch': 0.8}\n",
            "{'loss': 5.7278, 'grad_norm': 0.23845955729484558, 'learning_rate': 1.99746020946023e-05, 'epoch': 0.8}\n",
            "{'loss': 5.6197, 'grad_norm': 0.1419205367565155, 'learning_rate': 1.9816835644978583e-05, 'epoch': 0.8}\n",
            "{'loss': 5.6657, 'grad_norm': 0.20363430678844452, 'learning_rate': 1.9659626163265745e-05, 'epoch': 0.8}\n",
            "{'loss': 5.5368, 'grad_norm': 0.17131105065345764, 'learning_rate': 1.950297474147156e-05, 'epoch': 0.8}\n",
            "{'loss': 5.6116, 'grad_norm': 0.1220608800649643, 'learning_rate': 1.9346882467727325e-05, 'epoch': 0.81}\n",
            "{'loss': 4.0871, 'grad_norm': 0.14260469377040863, 'learning_rate': 1.9191350426280475e-05, 'epoch': 0.81}\n",
            "{'loss': 5.5096, 'grad_norm': 0.1538984179496765, 'learning_rate': 1.9036379697486928e-05, 'epoch': 0.81}\n",
            "{'loss': 5.5405, 'grad_norm': 0.16767314076423645, 'learning_rate': 1.8881971357803573e-05, 'epoch': 0.81}\n",
            "{'loss': 5.3171, 'grad_norm': 0.16128243505954742, 'learning_rate': 1.872812647978095e-05, 'epoch': 0.81}\n",
            "{'loss': 5.5732, 'grad_norm': 0.18730710446834564, 'learning_rate': 1.857484613205558e-05, 'epoch': 0.81}\n",
            "{'loss': 5.6651, 'grad_norm': 0.19905336201190948, 'learning_rate': 1.8422131379342668e-05, 'epoch': 0.81}\n",
            "{'loss': 5.2451, 'grad_norm': 0.1597277671098709, 'learning_rate': 1.8269983282428706e-05, 'epoch': 0.81}\n",
            "{'loss': 5.5135, 'grad_norm': 0.19260546565055847, 'learning_rate': 1.811840289816409e-05, 'epoch': 0.81}\n",
            "{'loss': 5.4785, 'grad_norm': 0.17344628274440765, 'learning_rate': 1.7967391279455714e-05, 'epoch': 0.81}\n",
            "{'loss': 5.6309, 'grad_norm': 0.18455713987350464, 'learning_rate': 1.781694947525979e-05, 'epoch': 0.81}\n",
            "{'loss': 5.5098, 'grad_norm': 0.13145986199378967, 'learning_rate': 1.7667078530574434e-05, 'epoch': 0.81}\n",
            "{'loss': 5.5329, 'grad_norm': 0.1437135934829712, 'learning_rate': 1.7517779486432495e-05, 'epoch': 0.82}\n",
            "{'loss': 5.6669, 'grad_norm': 0.15721622109413147, 'learning_rate': 1.7369053379894285e-05, 'epoch': 0.82}\n",
            "{'loss': 5.5524, 'grad_norm': 0.10127070546150208, 'learning_rate': 1.7220901244040356e-05, 'epoch': 0.82}\n",
            "{'loss': 5.597, 'grad_norm': 0.15816417336463928, 'learning_rate': 1.707332410796436e-05, 'epoch': 0.82}\n",
            "{'loss': 5.6248, 'grad_norm': 0.15818215906620026, 'learning_rate': 1.6926322996765897e-05, 'epoch': 0.82}\n",
            "{'loss': 5.519, 'grad_norm': 0.16624678671360016, 'learning_rate': 1.6779898931543382e-05, 'epoch': 0.82}\n",
            "{'loss': 5.5134, 'grad_norm': 0.18530985713005066, 'learning_rate': 1.6634052929386944e-05, 'epoch': 0.82}\n",
            "{'loss': 5.6766, 'grad_norm': 0.1500740647315979, 'learning_rate': 1.6488786003371393e-05, 'epoch': 0.82}\n",
            "{'loss': 4.2251, 'grad_norm': 0.1401655673980713, 'learning_rate': 1.634409916254914e-05, 'epoch': 0.82}\n",
            "{'loss': 5.5055, 'grad_norm': 0.1880500316619873, 'learning_rate': 1.6199993411943237e-05, 'epoch': 0.82}\n",
            "{'loss': 4.9012, 'grad_norm': 0.16324463486671448, 'learning_rate': 1.605646975254035e-05, 'epoch': 0.82}\n",
            "{'loss': 5.6756, 'grad_norm': 0.21729448437690735, 'learning_rate': 1.5913529181283837e-05, 'epoch': 0.82}\n",
            "{'loss': 5.652, 'grad_norm': 0.23275886476039886, 'learning_rate': 1.5771172691066794e-05, 'epoch': 0.83}\n",
            "{'loss': 5.7125, 'grad_norm': 0.20556578040122986, 'learning_rate': 1.5629401270725197e-05, 'epoch': 0.83}\n",
            "{'loss': 5.65, 'grad_norm': 0.1936051845550537, 'learning_rate': 1.5488215905031034e-05, 'epoch': 0.83}\n",
            "{'loss': 5.5834, 'grad_norm': 0.13746057450771332, 'learning_rate': 1.5347617574685358e-05, 'epoch': 0.83}\n",
            "{'loss': 5.3217, 'grad_norm': 0.168461874127388, 'learning_rate': 1.520760725631164e-05, 'epoch': 0.83}\n",
            "{'loss': 5.5603, 'grad_norm': 0.11924746632575989, 'learning_rate': 1.5068185922448885e-05, 'epoch': 0.83}\n",
            "{'loss': 5.5466, 'grad_norm': 0.16097024083137512, 'learning_rate': 1.4929354541544883e-05, 'epoch': 0.83}\n",
            "{'loss': 5.4759, 'grad_norm': 0.21337957680225372, 'learning_rate': 1.4791114077949498e-05, 'epoch': 0.83}\n",
            "{'loss': 5.4973, 'grad_norm': 0.1964314877986908, 'learning_rate': 1.4653465491908003e-05, 'epoch': 0.83}\n",
            "{'loss': 5.5242, 'grad_norm': 0.21257854998111725, 'learning_rate': 1.4516409739554338e-05, 'epoch': 0.83}\n",
            "{'loss': 5.5972, 'grad_norm': 0.11810934543609619, 'learning_rate': 1.4379947772904501e-05, 'epoch': 0.83}\n",
            "{'loss': 5.5245, 'grad_norm': 0.1387651264667511, 'learning_rate': 1.4244080539849969e-05, 'epoch': 0.83}\n",
            "{'loss': 5.6099, 'grad_norm': 0.11611826717853546, 'learning_rate': 1.4108808984151023e-05, 'epoch': 0.83}\n",
            "{'loss': 5.6272, 'grad_norm': 0.14338941872119904, 'learning_rate': 1.397413404543031e-05, 'epoch': 0.84}\n",
            "{'loss': 5.0921, 'grad_norm': 0.14493201673030853, 'learning_rate': 1.3840056659166257e-05, 'epoch': 0.84}\n",
            "{'loss': 5.5837, 'grad_norm': 0.14175643026828766, 'learning_rate': 1.3706577756686545e-05, 'epoch': 0.84}\n",
            "{'loss': 5.2918, 'grad_norm': 0.1229882687330246, 'learning_rate': 1.3573698265161683e-05, 'epoch': 0.84}\n",
            "{'loss': 5.5931, 'grad_norm': 0.1143840029835701, 'learning_rate': 1.3441419107598573e-05, 'epoch': 0.84}\n",
            "{'loss': 5.5526, 'grad_norm': 0.14433282613754272, 'learning_rate': 1.3309741202834048e-05, 'epoch': 0.84}\n",
            "{'loss': 4.6123, 'grad_norm': 0.13599789142608643, 'learning_rate': 1.317866546552855e-05, 'epoch': 0.84}\n",
            "{'loss': 5.6246, 'grad_norm': 0.135651633143425, 'learning_rate': 1.3048192806159721e-05, 'epoch': 0.84}\n",
            "{'loss': 5.6648, 'grad_norm': 0.1934581696987152, 'learning_rate': 1.2918324131016134e-05, 'epoch': 0.84}\n",
            "{'loss': 5.5351, 'grad_norm': 0.15460558235645294, 'learning_rate': 1.278906034219094e-05, 'epoch': 0.84}\n",
            "{'loss': 5.5518, 'grad_norm': 0.14429406821727753, 'learning_rate': 1.2660402337575673e-05, 'epoch': 0.84}\n",
            "{'loss': 5.557, 'grad_norm': 0.14691613614559174, 'learning_rate': 1.2532351010853916e-05, 'epoch': 0.84}\n",
            "{'loss': 5.5203, 'grad_norm': 0.17575787007808685, 'learning_rate': 1.2404907251495201e-05, 'epoch': 0.85}\n",
            "{'loss': 5.5888, 'grad_norm': 0.1667320281267166, 'learning_rate': 1.2278071944748748e-05, 'epoch': 0.85}\n",
            "{'loss': 5.5619, 'grad_norm': 0.1566404402256012, 'learning_rate': 1.2151845971637366e-05, 'epoch': 0.85}\n",
            "{'loss': 5.6022, 'grad_norm': 0.16816984117031097, 'learning_rate': 1.2026230208951306e-05, 'epoch': 0.85}\n",
            "{'loss': 5.6206, 'grad_norm': 0.1250947117805481, 'learning_rate': 1.1901225529242144e-05, 'epoch': 0.85}\n",
            "{'loss': 5.4587, 'grad_norm': 0.12599392235279083, 'learning_rate': 1.1776832800816807e-05, 'epoch': 0.85}\n",
            "{'loss': 5.5683, 'grad_norm': 0.14411716163158417, 'learning_rate': 1.1653052887731463e-05, 'epoch': 0.85}\n",
            "{'loss': 5.5868, 'grad_norm': 0.1716700792312622, 'learning_rate': 1.152988664978556e-05, 'epoch': 0.85}\n",
            "{'loss': 5.5923, 'grad_norm': 0.15956613421440125, 'learning_rate': 1.1407334942515802e-05, 'epoch': 0.85}\n",
            "{'loss': 5.0809, 'grad_norm': 0.13871219754219055, 'learning_rate': 1.1285398617190279e-05, 'epoch': 0.85}\n",
            "{'loss': 5.4936, 'grad_norm': 0.16295813024044037, 'learning_rate': 1.1164078520802534e-05, 'epoch': 0.85}\n",
            "{'loss': 5.4414, 'grad_norm': 0.19694453477859497, 'learning_rate': 1.1043375496065611e-05, 'epoch': 0.85}\n",
            "{'loss': 5.6697, 'grad_norm': 0.16655759513378143, 'learning_rate': 1.0923290381406316e-05, 'epoch': 0.86}\n",
            "{'loss': 5.6109, 'grad_norm': 0.16587090492248535, 'learning_rate': 1.0803824010959252e-05, 'epoch': 0.86}\n",
            "{'loss': 5.5931, 'grad_norm': 0.1615234911441803, 'learning_rate': 1.0684977214561154e-05, 'epoch': 0.86}\n",
            "{'loss': 5.539, 'grad_norm': 0.1399448812007904, 'learning_rate': 1.0566750817745074e-05, 'epoch': 0.86}\n",
            "{'loss': 5.5245, 'grad_norm': 0.16513334214687347, 'learning_rate': 1.0449145641734647e-05, 'epoch': 0.86}\n",
            "{'loss': 5.6392, 'grad_norm': 0.1832868754863739, 'learning_rate': 1.0332162503438381e-05, 'epoch': 0.86}\n",
            "{'loss': 5.6967, 'grad_norm': 0.16055302321910858, 'learning_rate': 1.0215802215443992e-05, 'epoch': 0.86}\n",
            "{'loss': 5.5294, 'grad_norm': 0.14722812175750732, 'learning_rate': 1.010006558601274e-05, 'epoch': 0.86}\n",
            "{'loss': 5.5046, 'grad_norm': 0.16725145280361176, 'learning_rate': 9.98495341907385e-06, 'epoch': 0.86}\n",
            "{'loss': 5.588, 'grad_norm': 0.12569229304790497, 'learning_rate': 9.870466514218911e-06, 'epoch': 0.86}\n",
            "{'loss': 5.5758, 'grad_norm': 0.13224917650222778, 'learning_rate': 9.756605666696305e-06, 'epoch': 0.86}\n",
            "{'loss': 5.5268, 'grad_norm': 0.14861749112606049, 'learning_rate': 9.643371667405698e-06, 'epoch': 0.86}\n",
            "{'loss': 5.3199, 'grad_norm': 0.1270272582769394, 'learning_rate': 9.530765302892552e-06, 'epoch': 0.86}\n",
            "{'loss': 5.127, 'grad_norm': 0.15062399208545685, 'learning_rate': 9.418787355342673e-06, 'epoch': 0.87}\n",
            "{'loss': 5.7548, 'grad_norm': 0.24258719384670258, 'learning_rate': 9.307438602576724e-06, 'epoch': 0.87}\n",
            "{'loss': 5.4944, 'grad_norm': 0.17852230370044708, 'learning_rate': 9.196719818044886e-06, 'epoch': 0.87}\n",
            "{'loss': 5.5251, 'grad_norm': 0.18415915966033936, 'learning_rate': 9.08663177082143e-06, 'epoch': 0.87}\n",
            "{'loss': 5.5005, 'grad_norm': 0.1619696468114853, 'learning_rate': 8.977175225599466e-06, 'epoch': 0.87}\n",
            "{'loss': 5.6384, 'grad_norm': 0.1713123768568039, 'learning_rate': 8.868350942685465e-06, 'epoch': 0.87}\n",
            "{'loss': 5.6995, 'grad_norm': 0.20660936832427979, 'learning_rate': 8.760159677994172e-06, 'epoch': 0.87}\n",
            "{'loss': 5.4904, 'grad_norm': 0.15810959041118622, 'learning_rate': 8.652602183043213e-06, 'epoch': 0.87}\n",
            "{'loss': 5.5401, 'grad_norm': 0.10581046342849731, 'learning_rate': 8.545679204947954e-06, 'epoch': 0.87}\n",
            "{'loss': 5.615, 'grad_norm': 0.14136838912963867, 'learning_rate': 8.43939148641627e-06, 'epoch': 0.87}\n",
            "{'loss': 5.7377, 'grad_norm': 0.2103596329689026, 'learning_rate': 8.333739765743398e-06, 'epoch': 0.87}\n",
            "{'loss': 5.5593, 'grad_norm': 0.10988417267799377, 'learning_rate': 8.228724776806818e-06, 'epoch': 0.87}\n",
            "{'loss': 5.1539, 'grad_norm': 0.16291670501232147, 'learning_rate': 8.124347249061115e-06, 'epoch': 0.88}\n",
            "{'loss': 5.5492, 'grad_norm': 0.17077791690826416, 'learning_rate': 8.020607907533017e-06, 'epoch': 0.88}\n",
            "{'loss': 5.532, 'grad_norm': 0.17538943886756897, 'learning_rate': 7.91750747281621e-06, 'epoch': 0.88}\n",
            "{'loss': 5.6395, 'grad_norm': 0.17937703430652618, 'learning_rate': 7.815046661066438e-06, 'epoch': 0.88}\n",
            "{'loss': 5.5438, 'grad_norm': 0.1457529217004776, 'learning_rate': 7.713226183996514e-06, 'epoch': 0.88}\n",
            "{'loss': 4.9198, 'grad_norm': 0.16199064254760742, 'learning_rate': 7.612046748871327e-06, 'epoch': 0.88}\n",
            "{'loss': 5.6739, 'grad_norm': 0.22172994911670685, 'learning_rate': 7.5115090585029966e-06, 'epoch': 0.88}\n",
            "{'loss': 5.1722, 'grad_norm': 0.18154200911521912, 'learning_rate': 7.411613811245943e-06, 'epoch': 0.88}\n",
            "{'loss': 5.5385, 'grad_norm': 0.18816694617271423, 'learning_rate': 7.312361700992043e-06, 'epoch': 0.88}\n",
            "{'loss': 5.4692, 'grad_norm': 0.14515866339206696, 'learning_rate': 7.213753417165836e-06, 'epoch': 0.88}\n",
            "{'loss': 5.6166, 'grad_norm': 0.15375378727912903, 'learning_rate': 7.115789644719728e-06, 'epoch': 0.88}\n",
            "{'loss': 5.6694, 'grad_norm': 0.23344063758850098, 'learning_rate': 7.018471064129161e-06, 'epoch': 0.88}\n",
            "{'loss': 5.2716, 'grad_norm': 0.17942841351032257, 'learning_rate': 6.92179835138802e-06, 'epoch': 0.89}\n",
            "{'loss': 5.5403, 'grad_norm': 0.1428471952676773, 'learning_rate': 6.825772178003831e-06, 'epoch': 0.89}\n",
            "{'loss': 5.6236, 'grad_norm': 0.15551725029945374, 'learning_rate': 6.730393210993147e-06, 'epoch': 0.89}\n",
            "{'loss': 5.628, 'grad_norm': 0.14110691845417023, 'learning_rate': 6.635662112876884e-06, 'epoch': 0.89}\n",
            "{'loss': 5.5233, 'grad_norm': 0.14075234532356262, 'learning_rate': 6.541579541675735e-06, 'epoch': 0.89}\n",
            "{'loss': 5.6043, 'grad_norm': 0.13479754328727722, 'learning_rate': 6.4481461509056096e-06, 'epoch': 0.89}\n",
            "{'loss': 5.1769, 'grad_norm': 0.19819475710391998, 'learning_rate': 6.355362589573077e-06, 'epoch': 0.89}\n",
            "{'loss': 5.622, 'grad_norm': 0.14060159027576447, 'learning_rate': 6.2632295021708865e-06, 'epoch': 0.89}\n",
            "{'loss': 5.5686, 'grad_norm': 0.11967665702104568, 'learning_rate': 6.1717475286734e-06, 'epoch': 0.89}\n",
            "{'loss': 5.6203, 'grad_norm': 0.14929206669330597, 'learning_rate': 6.0809173045322964e-06, 'epoch': 0.89}\n",
            "{'loss': 5.5485, 'grad_norm': 0.1604829579591751, 'learning_rate': 5.990739460672024e-06, 'epoch': 0.89}\n",
            "{'loss': 5.4394, 'grad_norm': 0.1978464424610138, 'learning_rate': 5.901214623485507e-06, 'epoch': 0.89}\n",
            "{'loss': 5.646, 'grad_norm': 0.2115676999092102, 'learning_rate': 5.812343414829724e-06, 'epoch': 0.9}\n",
            "{'loss': 5.0037, 'grad_norm': 0.1657063215970993, 'learning_rate': 5.724126452021439e-06, 'epoch': 0.9}\n",
            "{'loss': 5.5566, 'grad_norm': 0.18646429479122162, 'learning_rate': 5.636564347832907e-06, 'epoch': 0.9}\n",
            "{'loss': 5.1195, 'grad_norm': 0.17901751399040222, 'learning_rate': 5.549657710487588e-06, 'epoch': 0.9}\n",
            "{'loss': 5.6208, 'grad_norm': 0.12948325276374817, 'learning_rate': 5.463407143655941e-06, 'epoch': 0.9}\n",
            "{'loss': 5.7593, 'grad_norm': 0.24004846811294556, 'learning_rate': 5.377813246451257e-06, 'epoch': 0.9}\n",
            "{'loss': 5.5745, 'grad_norm': 0.12038024514913559, 'learning_rate': 5.2928766134254345e-06, 'epoch': 0.9}\n",
            "{'loss': 5.4138, 'grad_norm': 0.3149433434009552, 'learning_rate': 5.20859783456491e-06, 'epoch': 0.9}\n",
            "{'loss': 5.5934, 'grad_norm': 0.14036938548088074, 'learning_rate': 5.124977495286542e-06, 'epoch': 0.9}\n",
            "{'loss': 5.4799, 'grad_norm': 0.18270593881607056, 'learning_rate': 5.042016176433528e-06, 'epoch': 0.9}\n",
            "{'loss': 5.669, 'grad_norm': 0.1402054727077484, 'learning_rate': 4.959714454271369e-06, 'epoch': 0.9}\n",
            "{'loss': 5.5706, 'grad_norm': 0.10291871428489685, 'learning_rate': 4.878072900483898e-06, 'epoch': 0.9}\n",
            "{'loss': 4.7638, 'grad_norm': 0.1688474416732788, 'learning_rate': 4.7970920821693076e-06, 'epoch': 0.9}\n",
            "{'loss': 5.602, 'grad_norm': 0.14257220923900604, 'learning_rate': 4.716772561836136e-06, 'epoch': 0.91}\n",
            "{'loss': 5.5071, 'grad_norm': 0.19546252489089966, 'learning_rate': 4.6371148973994525e-06, 'epoch': 0.91}\n",
            "{'loss': 5.297, 'grad_norm': 0.14550885558128357, 'learning_rate': 4.558119642176939e-06, 'epoch': 0.91}\n",
            "{'loss': 5.5394, 'grad_norm': 0.15506649017333984, 'learning_rate': 4.479787344885078e-06, 'epoch': 0.91}\n",
            "{'loss': 5.6724, 'grad_norm': 0.15181705355644226, 'learning_rate': 4.4021185496353035e-06, 'epoch': 0.91}\n",
            "{'loss': 5.558, 'grad_norm': 0.10585471987724304, 'learning_rate': 4.325113795930203e-06, 'epoch': 0.91}\n",
            "{'loss': 5.5306, 'grad_norm': 0.1989848017692566, 'learning_rate': 4.248773618659829e-06, 'epoch': 0.91}\n",
            "{'loss': 5.6885, 'grad_norm': 0.2149631828069687, 'learning_rate': 4.173098548097965e-06, 'epoch': 0.91}\n",
            "{'loss': 5.565, 'grad_norm': 0.1845548003911972, 'learning_rate': 4.098089109898439e-06, 'epoch': 0.91}\n",
            "{'loss': 5.5758, 'grad_norm': 0.15112511813640594, 'learning_rate': 4.023745825091407e-06, 'epoch': 0.91}\n",
            "{'loss': 5.5826, 'grad_norm': 0.14989636838436127, 'learning_rate': 3.9500692100798655e-06, 'epoch': 0.91}\n",
            "{'loss': 5.5255, 'grad_norm': 0.16987179219722748, 'learning_rate': 3.877059776635949e-06, 'epoch': 0.91}\n",
            "{'loss': 5.5892, 'grad_norm': 0.15644818544387817, 'learning_rate': 3.8047180318974476e-06, 'epoch': 0.92}\n",
            "{'loss': 5.5191, 'grad_norm': 0.1284271478652954, 'learning_rate': 3.7330444783642338e-06, 'epoch': 0.92}\n",
            "{'loss': 5.6078, 'grad_norm': 0.16054052114486694, 'learning_rate': 3.6620396138948076e-06, 'epoch': 0.92}\n",
            "{'loss': 5.6071, 'grad_norm': 0.15070170164108276, 'learning_rate': 3.5917039317028055e-06, 'epoch': 0.92}\n",
            "{'loss': 5.6167, 'grad_norm': 0.13273851573467255, 'learning_rate': 3.5220379203536047e-06, 'epoch': 0.92}\n",
            "{'loss': 5.6738, 'grad_norm': 0.16698402166366577, 'learning_rate': 3.4530420637609363e-06, 'epoch': 0.92}\n",
            "{'loss': 5.609, 'grad_norm': 0.15161506831645966, 'learning_rate': 3.384716841183466e-06, 'epoch': 0.92}\n",
            "{'loss': 5.5409, 'grad_norm': 0.12434884160757065, 'learning_rate': 3.3170627272215427e-06, 'epoch': 0.92}\n",
            "{'loss': 5.5114, 'grad_norm': 0.11855926364660263, 'learning_rate': 3.2500801918138422e-06, 'epoch': 0.92}\n",
            "{'loss': 5.5375, 'grad_norm': 0.191177099943161, 'learning_rate': 3.1837697002341293e-06, 'epoch': 0.92}\n",
            "{'loss': 5.6194, 'grad_norm': 0.14698679745197296, 'learning_rate': 3.1181317130880127e-06, 'epoch': 0.92}\n",
            "{'loss': 5.538, 'grad_norm': 0.1464920938014984, 'learning_rate': 3.053166686309783e-06, 'epoch': 0.92}\n",
            "{'loss': 5.5866, 'grad_norm': 0.1315179467201233, 'learning_rate': 2.9888750711591805e-06, 'epoch': 0.93}\n",
            "{'loss': 5.4917, 'grad_norm': 0.16879262030124664, 'learning_rate': 2.9252573142183326e-06, 'epoch': 0.93}\n",
            "{'loss': 5.3158, 'grad_norm': 0.21104760468006134, 'learning_rate': 2.8623138573885767e-06, 'epoch': 0.93}\n",
            "{'loss': 5.4903, 'grad_norm': 0.14883925020694733, 'learning_rate': 2.8000451378874525e-06, 'epoch': 0.93}\n",
            "{'loss': 5.57, 'grad_norm': 0.12387407571077347, 'learning_rate': 2.7384515882456386e-06, 'epoch': 0.93}\n",
            "{'loss': 5.5615, 'grad_norm': 0.1091945618391037, 'learning_rate': 2.677533636303964e-06, 'epoch': 0.93}\n",
            "{'loss': 5.1878, 'grad_norm': 0.16766291856765747, 'learning_rate': 2.6172917052104117e-06, 'epoch': 0.93}\n",
            "{'loss': 5.5513, 'grad_norm': 0.17092961072921753, 'learning_rate': 2.5577262134171885e-06, 'epoch': 0.93}\n",
            "{'loss': 5.4453, 'grad_norm': 0.1460561454296112, 'learning_rate': 2.498837574677837e-06, 'epoch': 0.93}\n",
            "{'loss': 5.6816, 'grad_norm': 0.16143253445625305, 'learning_rate': 2.440626198044327e-06, 'epoch': 0.93}\n",
            "{'loss': 5.5615, 'grad_norm': 0.11966709792613983, 'learning_rate': 2.383092487864247e-06, 'epoch': 0.93}\n",
            "{'loss': 5.5868, 'grad_norm': 0.12779182195663452, 'learning_rate': 2.3262368437779737e-06, 'epoch': 0.93}\n",
            "{'loss': 5.6163, 'grad_norm': 0.15824992954730988, 'learning_rate': 2.2700596607159176e-06, 'epoch': 0.93}\n",
            "{'loss': 5.6162, 'grad_norm': 0.15389519929885864, 'learning_rate': 2.2145613288957478e-06, 'epoch': 0.94}\n",
            "{'loss': 5.5819, 'grad_norm': 0.1442597657442093, 'learning_rate': 2.159742233819717e-06, 'epoch': 0.94}\n",
            "{'loss': 5.5172, 'grad_norm': 0.13268476724624634, 'learning_rate': 2.1056027562719514e-06, 'epoch': 0.94}\n",
            "{'loss': 5.3794, 'grad_norm': 0.15087002515792847, 'learning_rate': 2.052143272315843e-06, 'epoch': 0.94}\n",
            "{'loss': 5.5676, 'grad_norm': 0.16924941539764404, 'learning_rate': 1.9993641532913833e-06, 'epoch': 0.94}\n",
            "{'loss': 5.4452, 'grad_norm': 0.14877520501613617, 'learning_rate': 1.947265765812656e-06, 'epoch': 0.94}\n",
            "{'loss': 5.6478, 'grad_norm': 0.1664217710494995, 'learning_rate': 1.895848471765227e-06, 'epoch': 0.94}\n",
            "{'loss': 5.6747, 'grad_norm': 0.20699314773082733, 'learning_rate': 1.8451126283036357e-06, 'epoch': 0.94}\n",
            "{'loss': 5.537, 'grad_norm': 0.13260075449943542, 'learning_rate': 1.7950585878489856e-06, 'epoch': 0.94}\n",
            "{'loss': 5.494, 'grad_norm': 0.18473505973815918, 'learning_rate': 1.7456866980863795e-06, 'epoch': 0.94}\n",
            "{'loss': 5.1884, 'grad_norm': 0.18174248933792114, 'learning_rate': 1.696997301962633e-06, 'epoch': 0.94}\n",
            "{'loss': 5.3024, 'grad_norm': 0.13668778538703918, 'learning_rate': 1.6489907376837644e-06, 'epoch': 0.94}\n",
            "{'loss': 5.6414, 'grad_norm': 0.2079564481973648, 'learning_rate': 1.6016673387127646e-06, 'epoch': 0.95}\n",
            "{'loss': 5.6099, 'grad_norm': 0.15091368556022644, 'learning_rate': 1.5550274337671866e-06, 'epoch': 0.95}\n",
            "{'loss': 5.5948, 'grad_norm': 0.12798409163951874, 'learning_rate': 1.509071346816926e-06, 'epoch': 0.95}\n",
            "{'loss': 5.4472, 'grad_norm': 0.13624656200408936, 'learning_rate': 1.463799397081922e-06, 'epoch': 0.95}\n",
            "{'loss': 5.6949, 'grad_norm': 0.20827727019786835, 'learning_rate': 1.4192118990299707e-06, 'epoch': 0.95}\n",
            "{'loss': 5.508, 'grad_norm': 0.17321954667568207, 'learning_rate': 1.3753091623745495e-06, 'epoch': 0.95}\n",
            "{'loss': 4.9252, 'grad_norm': 0.11362645030021667, 'learning_rate': 1.332091492072629e-06, 'epoch': 0.95}\n",
            "{'loss': 5.4213, 'grad_norm': 0.1698710322380066, 'learning_rate': 1.2895591883225754e-06, 'epoch': 0.95}\n",
            "{'loss': 5.0736, 'grad_norm': 0.12342594563961029, 'learning_rate': 1.2477125465620853e-06, 'epoch': 0.95}\n",
            "{'loss': 5.581, 'grad_norm': 0.11384651809930801, 'learning_rate': 1.2065518574660983e-06, 'epoch': 0.95}\n",
            "{'loss': 5.2937, 'grad_norm': 0.15886196494102478, 'learning_rate': 1.1660774069447877e-06, 'epoch': 0.95}\n",
            "{'loss': 5.2773, 'grad_norm': 0.18671824038028717, 'learning_rate': 1.1262894761416066e-06, 'epoch': 0.95}\n",
            "{'loss': 5.4428, 'grad_norm': 0.21292456984519958, 'learning_rate': 1.0871883414312777e-06, 'epoch': 0.96}\n",
            "{'loss': 5.5299, 'grad_norm': 0.13929785788059235, 'learning_rate': 1.0487742744178963e-06, 'epoch': 0.96}\n",
            "{'loss': 5.5712, 'grad_norm': 0.17121393978595734, 'learning_rate': 1.0110475419330967e-06, 'epoch': 0.96}\n",
            "{'loss': 5.5694, 'grad_norm': 0.19561058282852173, 'learning_rate': 9.740084060341103e-07, 'epoch': 0.96}\n",
            "{'loss': 5.5595, 'grad_norm': 0.16014619171619415, 'learning_rate': 9.376571240020227e-07, 'epoch': 0.96}\n",
            "{'loss': 4.718, 'grad_norm': 0.1463528424501419, 'learning_rate': 9.019939483399076e-07, 'epoch': 0.96}\n",
            "{'loss': 5.6575, 'grad_norm': 0.15351982414722443, 'learning_rate': 8.670191267711736e-07, 'epoch': 0.96}\n",
            "{'loss': 5.5139, 'grad_norm': 0.174228698015213, 'learning_rate': 8.327329022377317e-07, 'epoch': 0.96}\n",
            "{'loss': 5.7106, 'grad_norm': 0.19938011467456818, 'learning_rate': 7.991355128984079e-07, 'epoch': 0.96}\n",
            "{'loss': 5.5408, 'grad_norm': 0.10454442352056503, 'learning_rate': 7.662271921272224e-07, 'epoch': 0.96}\n",
            "{'loss': 5.6808, 'grad_norm': 0.22377358376979828, 'learning_rate': 7.340081685117905e-07, 'epoch': 0.96}\n",
            "{'loss': 5.4405, 'grad_norm': 0.13483592867851257, 'learning_rate': 7.024786658517468e-07, 'epoch': 0.96}\n",
            "{'loss': 5.5844, 'grad_norm': 0.12239380180835724, 'learning_rate': 6.716389031571568e-07, 'epoch': 0.97}\n",
            "{'loss': 5.4668, 'grad_norm': 0.16116243600845337, 'learning_rate': 6.41489094647052e-07, 'epoch': 0.97}\n",
            "{'loss': 5.6863, 'grad_norm': 0.20853188633918762, 'learning_rate': 6.120294497478752e-07, 'epoch': 0.97}\n",
            "{'loss': 5.6403, 'grad_norm': 0.18176743388175964, 'learning_rate': 5.832601730920706e-07, 'epoch': 0.97}\n",
            "{'loss': 5.2125, 'grad_norm': 0.14714369177818298, 'learning_rate': 5.55181464516652e-07, 'epoch': 0.97}\n",
            "{'loss': 5.6199, 'grad_norm': 0.14287790656089783, 'learning_rate': 5.277935190618144e-07, 'epoch': 0.97}\n",
            "{'loss': 5.674, 'grad_norm': 0.16507326066493988, 'learning_rate': 5.010965269695578e-07, 'epoch': 0.97}\n",
            "{'loss': 5.4886, 'grad_norm': 0.16928239166736603, 'learning_rate': 4.750906736824101e-07, 'epoch': 0.97}\n",
            "{'loss': 5.7096, 'grad_norm': 0.22865194082260132, 'learning_rate': 4.497761398421063e-07, 'epoch': 0.97}\n",
            "{'loss': 5.5255, 'grad_norm': 0.1326184719800949, 'learning_rate': 4.2515310128833366e-07, 'epoch': 0.97}\n",
            "{'loss': 5.5593, 'grad_norm': 0.14126110076904297, 'learning_rate': 4.0122172905753266e-07, 'epoch': 0.97}\n",
            "{'loss': 4.2597, 'grad_norm': 0.14307166635990143, 'learning_rate': 3.7798218938167596e-07, 'epoch': 0.97}\n",
            "{'loss': 5.5853, 'grad_norm': 0.1693945676088333, 'learning_rate': 3.554346436871581e-07, 'epoch': 0.97}\n",
            "{'loss': 5.4028, 'grad_norm': 0.18664616346359253, 'learning_rate': 3.3357924859361845e-07, 'epoch': 0.98}\n",
            "{'loss': 4.7399, 'grad_norm': 0.18576154112815857, 'learning_rate': 3.12416155912898e-07, 'epoch': 0.98}\n",
            "{'loss': 5.5536, 'grad_norm': 0.10476520657539368, 'learning_rate': 2.919455126479731e-07, 'epoch': 0.98}\n",
            "{'loss': 5.5906, 'grad_norm': 0.1293201893568039, 'learning_rate': 2.721674609919345e-07, 'epoch': 0.98}\n",
            "{'loss': 5.6989, 'grad_norm': 0.213518425822258, 'learning_rate': 2.530821383269766e-07, 'epoch': 0.98}\n",
            "{'loss': 5.4917, 'grad_norm': 0.16933903098106384, 'learning_rate': 2.3468967722347634e-07, 'epoch': 0.98}\n",
            "{'loss': 5.6058, 'grad_norm': 0.17248690128326416, 'learning_rate': 2.1699020543907156e-07, 'epoch': 0.98}\n",
            "{'loss': 5.5046, 'grad_norm': 0.17132321000099182, 'learning_rate': 1.9998384591773944e-07, 'epoch': 0.98}\n",
            "{'loss': 5.3374, 'grad_norm': 0.1923067271709442, 'learning_rate': 1.8367071678897507e-07, 'epoch': 0.98}\n",
            "{'loss': 4.8518, 'grad_norm': 0.15650002658367157, 'learning_rate': 1.680509313669587e-07, 'epoch': 0.98}\n",
            "{'loss': 5.5521, 'grad_norm': 0.14488667249679565, 'learning_rate': 1.5312459814975644e-07, 'epoch': 0.98}\n",
            "{'loss': 5.6809, 'grad_norm': 0.23145198822021484, 'learning_rate': 1.3889182081860962e-07, 'epoch': 0.98}\n",
            "{'loss': 5.2089, 'grad_norm': 0.1344054639339447, 'learning_rate': 1.253526982371689e-07, 'epoch': 0.99}\n",
            "{'loss': 5.4525, 'grad_norm': 0.1556062400341034, 'learning_rate': 1.1250732445080569e-07, 'epoch': 0.99}\n",
            "{'loss': 5.4489, 'grad_norm': 0.1466575413942337, 'learning_rate': 1.0035578868600182e-07, 'epoch': 0.99}\n",
            "{'loss': 5.5821, 'grad_norm': 0.11181218922138214, 'learning_rate': 8.889817534969425e-08, 'epoch': 0.99}\n",
            "{'loss': 5.5646, 'grad_norm': 0.11916955560445786, 'learning_rate': 7.8134564028709e-08, 'epoch': 0.99}\n",
            "{'loss': 5.5773, 'grad_norm': 0.1706455796957016, 'learning_rate': 6.806502948918381e-08, 'epoch': 0.99}\n",
            "{'loss': 5.386, 'grad_norm': 0.17877118289470673, 'learning_rate': 5.86896416760685e-08, 'epoch': 0.99}\n",
            "{'loss': 5.5413, 'grad_norm': 0.1841815561056137, 'learning_rate': 5.000846571264761e-08, 'epoch': 0.99}\n",
            "{'loss': 5.5845, 'grad_norm': 0.16606079041957855, 'learning_rate': 4.202156190006301e-08, 'epoch': 0.99}\n",
            "{'loss': 5.4836, 'grad_norm': 0.147564098238945, 'learning_rate': 3.472898571690308e-08, 'epoch': 0.99}\n",
            "{'loss': 5.398, 'grad_norm': 0.1413285881280899, 'learning_rate': 2.8130787818814174e-08, 'epoch': 0.99}\n",
            "{'loss': 5.4412, 'grad_norm': 0.17336200177669525, 'learning_rate': 2.222701403818972e-08, 'epoch': 0.99}\n",
            "{'loss': 5.7323, 'grad_norm': 0.18711350858211517, 'learning_rate': 1.7017705383781668e-08, 'epoch': 1.0}\n",
            "{'loss': 5.6104, 'grad_norm': 0.16376961767673492, 'learning_rate': 1.2502898040456234e-08, 'epoch': 1.0}\n",
            "{'loss': 5.5092, 'grad_norm': 0.14780572056770325, 'learning_rate': 8.682623368971854e-09, 'epoch': 1.0}\n",
            "{'loss': 5.6313, 'grad_norm': 0.15801802277565002, 'learning_rate': 5.5569079056794206e-09, 'epoch': 1.0}\n",
            "{'loss': 5.5525, 'grad_norm': 0.1373720020055771, 'learning_rate': 3.1257733624112664e-09, 'epoch': 1.0}\n",
            "{'loss': 5.5786, 'grad_norm': 0.1121148094534874, 'learning_rate': 1.3892366263146272e-09, 'epoch': 1.0}\n",
            "{'loss': 5.4681, 'grad_norm': 0.2403053641319275, 'learning_rate': 3.4730975969621273e-10, 'epoch': 1.0}\n",
            "{'train_runtime': 1094.1106, 'train_samples_per_second': 17.963, 'train_steps_per_second': 1.123, 'train_loss': 5.677044213739617, 'epoch': 1.0}\n",
            "100% 1229/1229 [11:13<00:00,  1.83it/s]\n",
            "25-09-04 17:18:07.547 - INFO: End of the training\n",
            "INFO:train:End of the training\n",
            "\u001b[1;34mwandb\u001b[0m: \n",
            "\u001b[1;34mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[1;34mwandb\u001b[0m: \u001b[1mwandb sync /content/MedVLMBench/wandb/offline-run-20250904_170651-9aa515tn\u001b[0m\n",
            "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/offline-run-20250904_170651-9aa515tn/logs\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}