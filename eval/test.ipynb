{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yesindeed/anaconda3/envs/vlmbenchmark/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torchmetrics.functional.text import bleu_score, rouge_score\n",
    "\n",
    "from utils import normalize_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26812800765037537"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Hello word, where are you\"\n",
    "reference = \"May I know the place you are staying?\"\n",
    "\n",
    "bleu1 = bleu_score([normalize_word(text)], [\n",
    "                   [normalize_word(reference)]], n_gram=1).item()\n",
    "\n",
    "bleu1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26812801841425576"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "weight = (1, 0, 0, 0)\n",
    "bleu2 = sentence_bleu(\n",
    "    [normalize_word(reference).split()],\n",
    "    normalize_word(text).split(),\n",
    "    weights=weight,\n",
    "    smoothing_function=SmoothingFunction().method1,\n",
    ")\n",
    "\n",
    "bleu2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yesindeed/anaconda3/envs/vlmbenchmark/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: The argument `model_name_or_path` was not specified while it is required when default `transformers` model are used.It is, therefore, used the default recommended model - roberta-large.\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    }
   ],
   "source": [
    "from torchmetrics.functional.text import bert_score\n",
    "\n",
    "s_ = bert_score([normalize_word(text)], [normalize_word(reference)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': tensor(0.9703), 'recall': tensor(0.9677), 'f1': tensor(0.9690)}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/yesindeed/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.14705882352941174"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.translate.meteor_score import meteor_score\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "methor = meteor_score(\n",
    "    [normalize_word(reference).split()],\n",
    "    normalize_word(text).split(),\n",
    ")\n",
    "\n",
    "methor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['may', 'i', 'know', 'place', 'you', 'are', 'staying']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize_word(reference).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from safetensors import safe_open\n",
    "\n",
    "tensors = {}\n",
    "with safe_open(\n",
    "    \"/media/yesindeed/DATADRIVE1/mount/remote_cse/experiments/med_vlm_benchmark/vqa/SLAKE/LLaVA-1.5/train_lora_L_seed42_llava/adapter_model.safetensors\",\n",
    "    framework=\"pt\",\n",
    "    device=0,\n",
    ") as f:\n",
    "    for k in f.keys():\n",
    "        tensors[k] = f.get_tensor(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_model.model.model.layers.0.mlp.down_proj.lora_A.weight': tensor([[ 1.0925e-02,  3.4332e-03, -1.4420e-03,  ..., -1.0986e-02,\n",
       "          -1.0834e-03, -6.5613e-03],\n",
       "         [-5.4016e-03,  3.2043e-03,  5.4626e-03,  ...,  1.6785e-03,\n",
       "          -8.0109e-04,  7.8735e-03],\n",
       "         [-2.4567e-03, -7.3853e-03,  5.7678e-03,  ...,  8.4400e-05,\n",
       "           3.4790e-03, -1.9150e-03],\n",
       "         ...,\n",
       "         [-2.1973e-03, -3.8300e-03,  6.5308e-03,  ...,  3.6011e-03,\n",
       "          -3.1738e-03, -2.2583e-03],\n",
       "         [ 3.2959e-03,  6.5002e-03,  2.6855e-03,  ..., -1.8005e-03,\n",
       "           1.0010e-02, -1.8311e-03],\n",
       "         [-5.3711e-03, -4.0894e-03,  2.3193e-03,  ..., -5.6763e-03,\n",
       "          -6.5002e-03, -2.8229e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.0.mlp.down_proj.lora_B.weight': tensor([[-2.0905e-03, -1.3649e-05, -5.1498e-04,  ...,  1.7853e-03,\n",
       "           8.4877e-05,  7.7438e-04],\n",
       "         [-1.4572e-03,  1.4343e-03, -6.9046e-04,  ...,  1.5106e-03,\n",
       "           1.6174e-03,  1.1063e-04],\n",
       "         [-5.9891e-04,  2.0447e-03,  7.8964e-04,  ..., -3.2997e-04,\n",
       "          -1.8005e-03,  2.1515e-03],\n",
       "         ...,\n",
       "         [-1.6022e-03, -2.9564e-04, -9.2316e-04,  ..., -2.1515e-03,\n",
       "          -1.0071e-03,  1.3046e-03],\n",
       "         [ 3.0365e-03, -2.7618e-03,  1.5793e-03,  ...,  1.1826e-04,\n",
       "           1.7395e-03, -2.6398e-03],\n",
       "         [-5.5695e-04,  1.7242e-03,  1.6327e-03,  ...,  2.1973e-03,\n",
       "           2.2888e-03, -1.8616e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.0.mlp.gate_proj.lora_A.weight': tensor([[ 0.0095, -0.0034, -0.0015,  ..., -0.0032,  0.0036,  0.0100],\n",
       "         [-0.0064, -0.0015,  0.0134,  ...,  0.0055, -0.0129, -0.0098],\n",
       "         [-0.0062, -0.0060, -0.0011,  ...,  0.0048,  0.0036,  0.0170],\n",
       "         ...,\n",
       "         [ 0.0032,  0.0092,  0.0065,  ..., -0.0081,  0.0129,  0.0044],\n",
       "         [-0.0020, -0.0058,  0.0001,  ...,  0.0021,  0.0033,  0.0007],\n",
       "         [ 0.0122,  0.0060,  0.0111,  ..., -0.0156,  0.0055, -0.0115]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.0.mlp.gate_proj.lora_B.weight': tensor([[ 1.7471e-03, -4.1504e-03, -4.9973e-04,  ...,  9.8419e-04,\n",
       "          -1.0681e-03,  2.1515e-03],\n",
       "         [ 9.1553e-04,  1.1826e-03,  8.2016e-05,  ...,  2.0123e-04,\n",
       "           1.1063e-03,  4.5967e-04],\n",
       "         [-1.0223e-03,  1.4114e-03, -3.0136e-04,  ..., -9.0790e-04,\n",
       "           1.1368e-03,  4.1008e-04],\n",
       "         ...,\n",
       "         [ 6.3324e-04, -1.0300e-03,  2.5749e-04,  ..., -1.4038e-03,\n",
       "           5.7602e-04, -2.0599e-03],\n",
       "         [ 1.4572e-03, -1.0529e-03,  1.6937e-03,  ..., -1.6479e-03,\n",
       "           2.4557e-05,  2.5024e-03],\n",
       "         [ 1.5545e-04,  1.7395e-03,  7.4387e-04,  ..., -1.3580e-03,\n",
       "          -6.3324e-04, -2.3193e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.0.mlp.up_proj.lora_A.weight': tensor([[ 4.1199e-03, -1.1353e-02, -3.2806e-03,  ..., -2.8076e-03,\n",
       "          -1.0925e-02, -3.9673e-03],\n",
       "         [-1.0681e-02, -6.6223e-03,  1.0681e-02,  ..., -6.9580e-03,\n",
       "           2.2799e-06,  6.8970e-03],\n",
       "         [-3.1281e-04, -6.5994e-04, -1.4099e-02,  ..., -1.3855e-02,\n",
       "          -1.1047e-02, -3.2654e-03],\n",
       "         ...,\n",
       "         [-8.7891e-03, -1.0147e-03,  4.9591e-04,  ...,  1.0681e-02,\n",
       "          -1.3123e-02,  4.4250e-03],\n",
       "         [-8.4839e-03,  2.2697e-04, -8.9722e-03,  ...,  2.2583e-03,\n",
       "           4.8523e-03,  1.2695e-02],\n",
       "         [-4.9133e-03,  3.1281e-04, -6.5002e-03,  ..., -1.1353e-02,\n",
       "           1.4954e-02, -8.9111e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.0.mlp.up_proj.lora_B.weight': tensor([[-2.6464e-05,  7.8678e-05, -3.0518e-03,  ..., -3.8300e-03,\n",
       "          -2.8534e-03,  3.4180e-03],\n",
       "         [ 1.8997e-03,  1.6098e-03, -4.6349e-04,  ...,  5.8365e-04,\n",
       "          -1.3123e-03,  1.2665e-03],\n",
       "         [-2.1210e-03, -3.6049e-04, -1.0223e-03,  ..., -2.9297e-03,\n",
       "           1.8120e-04, -3.0136e-04],\n",
       "         ...,\n",
       "         [ 2.4796e-04,  5.2261e-04,  4.9210e-04,  ...,  1.4782e-04,\n",
       "           1.0529e-03,  7.7438e-04],\n",
       "         [-4.6730e-04, -1.8215e-04, -5.9128e-04,  ...,  3.2806e-04,\n",
       "          -4.0436e-04, -2.2125e-03],\n",
       "         [ 9.5367e-04, -6.4850e-04, -1.7929e-03,  ...,  1.0986e-03,\n",
       "           6.6757e-04, -7.5531e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.0.self_attn.k_proj.lora_A.weight': tensor([[-0.0095,  0.0016,  0.0147,  ...,  0.0046, -0.0129,  0.0162],\n",
       "         [ 0.0043,  0.0090,  0.0026,  ..., -0.0068, -0.0125,  0.0089],\n",
       "         [-0.0112,  0.0042,  0.0065,  ..., -0.0058, -0.0028,  0.0006],\n",
       "         ...,\n",
       "         [ 0.0059,  0.0102,  0.0045,  ...,  0.0067,  0.0109,  0.0042],\n",
       "         [-0.0109,  0.0117,  0.0096,  ...,  0.0068,  0.0067, -0.0092],\n",
       "         [ 0.0069,  0.0181, -0.0006,  ...,  0.0092, -0.0081, -0.0010]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.0.self_attn.k_proj.lora_B.weight': tensor([[ 9.9182e-05, -9.2030e-05,  1.5030e-03,  ..., -9.5367e-04,\n",
       "          -2.6703e-03, -1.1063e-03],\n",
       "         [ 2.0790e-04,  1.1368e-03, -1.1826e-03,  ..., -4.2343e-04,\n",
       "           1.0300e-03,  9.9182e-04],\n",
       "         [ 1.6785e-03, -3.2043e-03,  1.2283e-03,  ..., -1.0681e-03,\n",
       "          -1.3275e-03, -1.4801e-03],\n",
       "         ...,\n",
       "         [-3.0756e-05, -1.4038e-03, -1.8024e-04,  ..., -4.2343e-04,\n",
       "           4.4441e-04, -2.8133e-05],\n",
       "         [ 1.7834e-04,  1.2741e-03,  5.3787e-04,  ..., -1.7929e-04,\n",
       "           4.7684e-04,  8.7261e-05],\n",
       "         [ 1.0223e-03,  6.5613e-04, -2.3270e-04,  ..., -1.7929e-04,\n",
       "           2.9602e-03, -1.6880e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.0.self_attn.o_proj.lora_A.weight': tensor([[-0.0090,  0.0086, -0.0082,  ..., -0.0053,  0.0046,  0.0063],\n",
       "         [ 0.0096, -0.0026, -0.0090,  ...,  0.0022,  0.0143, -0.0036],\n",
       "         [ 0.0112, -0.0096,  0.0157,  ...,  0.0095, -0.0129,  0.0118],\n",
       "         ...,\n",
       "         [-0.0056, -0.0014,  0.0015,  ..., -0.0147,  0.0023,  0.0125],\n",
       "         [ 0.0128, -0.0094, -0.0052,  ...,  0.0143, -0.0089, -0.0064],\n",
       "         [-0.0065, -0.0106, -0.0071,  ..., -0.0046,  0.0126, -0.0028]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.0.self_attn.o_proj.lora_B.weight': tensor([[ 1.5564e-03,  3.1281e-03,  2.5330e-03,  ..., -2.4261e-03,\n",
       "          -5.2261e-04, -5.1498e-04],\n",
       "         [ 2.0599e-03, -1.3657e-03,  1.8024e-04,  ...,  6.4850e-04,\n",
       "           1.7166e-03,  2.6855e-03],\n",
       "         [-1.2741e-03,  5.4321e-03,  5.5313e-04,  ...,  1.7090e-03,\n",
       "          -6.3419e-05,  4.1809e-03],\n",
       "         ...,\n",
       "         [ 3.7193e-05,  5.6839e-04,  1.5411e-03,  ...,  6.5804e-05,\n",
       "          -2.8014e-05, -9.5749e-04],\n",
       "         [-6.7139e-04,  1.4648e-03,  4.3106e-04,  ...,  6.6376e-04,\n",
       "           1.9150e-03, -3.3188e-04],\n",
       "         [-3.0060e-03,  2.1973e-03, -2.2736e-03,  ...,  1.4038e-03,\n",
       "          -2.7008e-03, -1.9989e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.0.self_attn.q_proj.lora_A.weight': tensor([[-0.0041,  0.0075,  0.0146,  ...,  0.0165,  0.0002, -0.0017],\n",
       "         [ 0.0090,  0.0090,  0.0095,  ..., -0.0049, -0.0020, -0.0004],\n",
       "         [ 0.0109,  0.0094,  0.0145,  ..., -0.0110,  0.0125,  0.0142],\n",
       "         ...,\n",
       "         [ 0.0023,  0.0120, -0.0067,  ..., -0.0128, -0.0098, -0.0161],\n",
       "         [-0.0063,  0.0101, -0.0142,  ...,  0.0168, -0.0087, -0.0049],\n",
       "         [ 0.0165,  0.0033,  0.0050,  ...,  0.0087, -0.0067,  0.0014]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.weight': tensor([[ 5.9843e-05, -1.5411e-03, -5.7220e-04,  ..., -1.8692e-03,\n",
       "          -1.6327e-03, -1.6479e-03],\n",
       "         [ 1.1978e-03,  5.1880e-04, -1.3580e-03,  ...,  1.2589e-03,\n",
       "           5.5313e-04,  7.3624e-04],\n",
       "         [ 4.0054e-04,  1.0376e-03, -3.5667e-04,  ...,  9.3937e-05,\n",
       "          -7.4005e-04, -4.2343e-04],\n",
       "         ...,\n",
       "         [-1.5259e-03, -8.8120e-04,  8.2779e-04,  ..., -3.9291e-04,\n",
       "          -1.4267e-03, -1.1215e-03],\n",
       "         [ 1.4191e-03,  5.7602e-04, -4.9973e-04,  ..., -2.8849e-05,\n",
       "           1.0529e-03,  7.0190e-04],\n",
       "         [-1.5869e-03, -6.2561e-04,  9.3079e-04,  ..., -3.4523e-04,\n",
       "          -1.6403e-03, -5.4169e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.weight': tensor([[-0.0062, -0.0023,  0.0172,  ..., -0.0006, -0.0103, -0.0135],\n",
       "         [ 0.0160, -0.0135, -0.0027,  ..., -0.0053,  0.0157, -0.0139],\n",
       "         [-0.0150, -0.0024,  0.0150,  ..., -0.0067, -0.0023, -0.0015],\n",
       "         ...,\n",
       "         [ 0.0095,  0.0024,  0.0091,  ..., -0.0060,  0.0172,  0.0069],\n",
       "         [-0.0142, -0.0018,  0.0074,  ...,  0.0114,  0.0065, -0.0112],\n",
       "         [ 0.0156, -0.0025, -0.0118,  ...,  0.0054, -0.0033, -0.0069]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.weight': tensor([[-8.1658e-06, -1.9169e-04,  5.9128e-04,  ...,  2.8372e-05,\n",
       "           8.3542e-04, -8.5831e-04],\n",
       "         [-1.2207e-03,  7.3624e-04, -8.3160e-04,  ...,  1.3428e-03,\n",
       "          -7.1716e-04,  4.8828e-04],\n",
       "         [-2.5177e-04,  9.7656e-04, -9.7275e-04,  ...,  3.6001e-05,\n",
       "          -1.7166e-03,  1.1292e-03],\n",
       "         ...,\n",
       "         [-1.0147e-03,  5.1260e-05,  3.0327e-04,  ...,  9.6893e-04,\n",
       "           7.4768e-04, -5.2261e-04],\n",
       "         [-3.0994e-05, -9.8228e-05, -8.1062e-05,  ...,  1.0803e-06,\n",
       "           2.5368e-04,  3.0518e-04],\n",
       "         [ 8.3447e-05, -1.0834e-03,  6.6757e-04,  ..., -3.9101e-05,\n",
       "           1.3809e-03, -5.0735e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.1.mlp.down_proj.lora_A.weight': tensor([[ 0.0041, -0.0079, -0.0073,  ..., -0.0146, -0.0037,  0.0014],\n",
       "         [-0.0082, -0.0012,  0.0062,  ..., -0.0082, -0.0095, -0.0018],\n",
       "         [-0.0003, -0.0072, -0.0018,  ..., -0.0006, -0.0029,  0.0040],\n",
       "         ...,\n",
       "         [ 0.0010,  0.0020,  0.0029,  ...,  0.0128,  0.0044,  0.0007],\n",
       "         [ 0.0084, -0.0093, -0.0065,  ..., -0.0025,  0.0104, -0.0058],\n",
       "         [-0.0056, -0.0033, -0.0070,  ...,  0.0039, -0.0002,  0.0082]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.1.mlp.down_proj.lora_B.weight': tensor([[ 3.3760e-04, -7.4863e-05, -1.8616e-03,  ..., -6.5994e-04,\n",
       "          -4.1771e-04,  4.6539e-04],\n",
       "         [-1.1292e-03, -1.4191e-03, -2.1362e-03,  ...,  1.1444e-03,\n",
       "           1.2054e-03, -1.2436e-03],\n",
       "         [-1.3161e-04, -1.3638e-04, -1.2817e-03,  ...,  6.9618e-05,\n",
       "          -1.2589e-04, -3.4904e-04],\n",
       "         ...,\n",
       "         [-2.3937e-04, -2.6894e-04, -7.7820e-04,  ...,  4.1962e-04,\n",
       "           3.8338e-04, -4.9591e-04],\n",
       "         [-1.1978e-03, -1.3275e-03, -1.8005e-03,  ...,  1.1978e-03,\n",
       "           1.2589e-03, -1.2054e-03],\n",
       "         [-1.4038e-03, -1.4877e-03, -1.6251e-03,  ...,  1.4648e-03,\n",
       "           1.4114e-03, -1.4877e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.1.mlp.gate_proj.lora_A.weight': tensor([[ 0.0143,  0.0037,  0.0020,  ...,  0.0038,  0.0134, -0.0155],\n",
       "         [-0.0055,  0.0062,  0.0117,  ..., -0.0124, -0.0057, -0.0109],\n",
       "         [-0.0089,  0.0107, -0.0025,  ...,  0.0074, -0.0121,  0.0007],\n",
       "         ...,\n",
       "         [-0.0051, -0.0125,  0.0121,  ..., -0.0061, -0.0116,  0.0096],\n",
       "         [-0.0127,  0.0145, -0.0087,  ..., -0.0024, -0.0029,  0.0008],\n",
       "         [-0.0123, -0.0025, -0.0116,  ...,  0.0100,  0.0143, -0.0067]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.1.mlp.gate_proj.lora_B.weight': tensor([[ 5.0735e-04, -1.7319e-03,  1.6212e-04,  ...,  2.4109e-03,\n",
       "           4.2152e-04, -9.9182e-04],\n",
       "         [-9.1553e-04, -1.4305e-04,  2.3651e-03,  ..., -3.8147e-03,\n",
       "           1.4725e-03,  3.9673e-03],\n",
       "         [-2.7466e-03, -1.0071e-03,  4.1199e-03,  ..., -2.9755e-03,\n",
       "           7.0095e-05,  2.3193e-03],\n",
       "         ...,\n",
       "         [ 1.6861e-03,  3.0327e-04, -8.8120e-04,  ...,  1.0967e-05,\n",
       "          -3.5286e-04, -3.7384e-04],\n",
       "         [-8.6212e-04,  8.4686e-04, -1.9150e-03,  ...,  4.9973e-04,\n",
       "          -1.6251e-03, -2.7466e-03],\n",
       "         [ 1.7700e-03,  9.1934e-04,  1.0757e-03,  ..., -1.0452e-03,\n",
       "           1.4725e-03,  7.8201e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.1.mlp.up_proj.lora_A.weight': tensor([[ 0.0049,  0.0102, -0.0166,  ..., -0.0061, -0.0013, -0.0162],\n",
       "         [ 0.0104, -0.0128,  0.0034,  ..., -0.0055, -0.0050, -0.0083],\n",
       "         [-0.0006, -0.0085, -0.0107,  ...,  0.0009,  0.0028, -0.0144],\n",
       "         ...,\n",
       "         [ 0.0041,  0.0008,  0.0028,  ..., -0.0057,  0.0041, -0.0112],\n",
       "         [ 0.0071,  0.0077, -0.0013,  ..., -0.0149,  0.0058,  0.0047],\n",
       "         [-0.0040,  0.0137,  0.0118,  ..., -0.0083, -0.0029, -0.0154]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.1.mlp.up_proj.lora_B.weight': tensor([[-1.0376e-03,  2.5177e-03,  2.1667e-03,  ...,  1.6251e-03,\n",
       "          -3.2501e-03,  3.0060e-03],\n",
       "         [-3.9816e-05,  2.4223e-04,  4.8065e-04,  ...,  2.2125e-03,\n",
       "          -5.2261e-04, -2.0905e-03],\n",
       "         [-2.8610e-04, -1.4400e-04, -8.3160e-04,  ...,  2.5787e-03,\n",
       "          -2.0752e-03,  1.5106e-03],\n",
       "         ...,\n",
       "         [ 3.7766e-04,  5.0735e-04,  1.6632e-03,  ..., -4.2419e-03,\n",
       "          -7.4387e-04,  6.2180e-04],\n",
       "         [-4.4556e-03, -1.8005e-03, -4.6730e-05,  ..., -8.6212e-04,\n",
       "           1.4725e-03, -5.5552e-05],\n",
       "         [-2.9445e-05, -1.7242e-03, -2.0599e-03,  ..., -1.5640e-03,\n",
       "           1.0834e-03, -2.8491e-05]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.1.self_attn.k_proj.lora_A.weight': tensor([[ 0.0026, -0.0082,  0.0097,  ...,  0.0132, -0.0134, -0.0034],\n",
       "         [ 0.0073,  0.0148,  0.0043,  ...,  0.0106,  0.0034, -0.0060],\n",
       "         [ 0.0053, -0.0070, -0.0100,  ..., -0.0016,  0.0129,  0.0070],\n",
       "         ...,\n",
       "         [-0.0116, -0.0077,  0.0033,  ..., -0.0006, -0.0157, -0.0016],\n",
       "         [ 0.0109,  0.0134,  0.0106,  ..., -0.0033, -0.0072,  0.0200],\n",
       "         [ 0.0083,  0.0067, -0.0003,  ...,  0.0042,  0.0043, -0.0080]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.1.self_attn.k_proj.lora_B.weight': tensor([[-0.0016,  0.0005,  0.0011,  ..., -0.0013,  0.0014, -0.0009],\n",
       "         [-0.0020,  0.0011, -0.0001,  ..., -0.0009,  0.0009, -0.0014],\n",
       "         [-0.0029,  0.0007,  0.0009,  ..., -0.0008,  0.0009, -0.0012],\n",
       "         ...,\n",
       "         [-0.0012,  0.0010,  0.0005,  ..., -0.0004, -0.0004, -0.0021],\n",
       "         [ 0.0012, -0.0011, -0.0004,  ...,  0.0006,  0.0004,  0.0020],\n",
       "         [-0.0012,  0.0010,  0.0005,  ..., -0.0005, -0.0005, -0.0020]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.1.self_attn.o_proj.lora_A.weight': tensor([[ 0.0090,  0.0106,  0.0089,  ..., -0.0133, -0.0159, -0.0143],\n",
       "         [ 0.0142, -0.0092, -0.0118,  ..., -0.0037,  0.0055, -0.0128],\n",
       "         [ 0.0031,  0.0010, -0.0040,  ...,  0.0095,  0.0108, -0.0050],\n",
       "         ...,\n",
       "         [ 0.0006, -0.0166, -0.0086,  ...,  0.0128,  0.0006,  0.0052],\n",
       "         [ 0.0049, -0.0128, -0.0050,  ..., -0.0033,  0.0077, -0.0069],\n",
       "         [-0.0135,  0.0116,  0.0014,  ..., -0.0111, -0.0004, -0.0064]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.1.self_attn.o_proj.lora_B.weight': tensor([[-7.3624e-04,  1.5640e-03, -1.7471e-03,  ...,  8.0872e-04,\n",
       "          -8.1635e-04,  9.1553e-05],\n",
       "         [-1.2283e-03,  3.7384e-04, -4.1199e-03,  ..., -3.9673e-03,\n",
       "          -2.1515e-03, -4.2725e-04],\n",
       "         [-2.1057e-03, -2.2583e-03, -3.7956e-04,  ..., -1.9531e-03,\n",
       "           8.6212e-04, -2.0294e-03],\n",
       "         ...,\n",
       "         [-8.3160e-04, -1.2741e-03, -2.2125e-03,  ..., -4.0283e-03,\n",
       "          -2.2125e-03, -2.7161e-03],\n",
       "         [-1.6708e-03,  1.4267e-03, -1.6022e-03,  ..., -2.6550e-03,\n",
       "          -1.4267e-03, -4.1504e-03],\n",
       "         [-2.4605e-04,  1.7929e-04, -9.5749e-04,  ..., -2.1973e-03,\n",
       "           9.6893e-04, -1.1139e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.weight': tensor([[-6.0425e-03, -1.0986e-02,  5.7678e-03,  ...,  7.8125e-03,\n",
       "          -1.0681e-02, -5.7983e-03],\n",
       "         [ 3.7537e-03, -1.2329e-02,  1.6602e-02,  ...,  1.1536e-02,\n",
       "          -1.0681e-02,  5.0049e-03],\n",
       "         [ 5.8899e-03,  7.5073e-03, -7.4158e-03,  ..., -1.3550e-02,\n",
       "          -3.3112e-03,  9.5749e-04],\n",
       "         ...,\n",
       "         [-7.8735e-03, -1.2756e-02,  1.1414e-02,  ..., -1.0376e-02,\n",
       "           7.3547e-03, -2.9755e-03],\n",
       "         [-7.4768e-03, -6.3419e-05, -9.4604e-03,  ...,  5.2185e-03,\n",
       "           2.2430e-03,  1.9989e-03],\n",
       "         [-1.8716e-05,  9.7656e-03, -1.0620e-02,  ..., -6.9427e-04,\n",
       "           2.0599e-03,  1.1597e-02]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.weight': tensor([[ 1.2894e-03,  1.2665e-03,  1.2512e-03,  ...,  1.3504e-03,\n",
       "          -1.3809e-03, -1.2589e-03],\n",
       "         [ 1.9379e-03,  1.3657e-03,  1.5564e-03,  ...,  1.2360e-03,\n",
       "          -1.0605e-03, -1.6556e-03],\n",
       "         [ 5.0735e-04,  8.6212e-04,  3.9482e-04,  ...,  5.1498e-04,\n",
       "           8.3542e-04, -8.7357e-04],\n",
       "         ...,\n",
       "         [-5.1880e-04,  1.2779e-04,  1.3351e-04,  ...,  7.1335e-04,\n",
       "          -1.2894e-03, -3.0136e-04],\n",
       "         [ 6.5994e-04, -7.2479e-05, -7.7248e-05,  ..., -6.1798e-04,\n",
       "           1.2436e-03,  2.4796e-04],\n",
       "         [-2.6131e-04,  2.2793e-04,  1.9741e-04,  ...,  9.5749e-04,\n",
       "          -1.3885e-03, -3.8910e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.weight': tensor([[ 0.0044,  0.0143,  0.0130,  ...,  0.0141, -0.0006,  0.0079],\n",
       "         [ 0.0130,  0.0132, -0.0012,  ..., -0.0089, -0.0101, -0.0002],\n",
       "         [ 0.0110, -0.0024, -0.0023,  ...,  0.0160,  0.0025,  0.0045],\n",
       "         ...,\n",
       "         [-0.0034, -0.0045, -0.0152,  ...,  0.0068,  0.0146, -0.0142],\n",
       "         [-0.0116,  0.0146, -0.0028,  ..., -0.0036, -0.0161, -0.0108],\n",
       "         [-0.0149, -0.0151,  0.0110,  ..., -0.0142, -0.0054, -0.0116]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.weight': tensor([[-1.6479e-03, -1.4191e-03, -1.6022e-03,  ..., -2.8839e-03,\n",
       "          -1.3046e-03,  1.4114e-03],\n",
       "         [ 3.3112e-03, -2.2125e-03,  3.0212e-03,  ...,  2.5024e-03,\n",
       "           1.9836e-03, -2.2888e-03],\n",
       "         [ 2.1973e-03, -6.5994e-04,  2.2583e-03,  ..., -1.5640e-03,\n",
       "           2.1515e-03, -2.3651e-03],\n",
       "         ...,\n",
       "         [ 3.4523e-04, -1.5030e-03,  3.1281e-04,  ..., -4.9973e-04,\n",
       "          -2.1648e-04, -2.5482e-03],\n",
       "         [ 9.6798e-05, -1.3351e-03,  4.4250e-04,  ...,  1.3638e-04,\n",
       "           2.7275e-04, -8.2016e-04],\n",
       "         [ 4.2534e-04,  5.5313e-04,  1.1063e-03,  ...,  6.6757e-04,\n",
       "           1.1597e-03, -9.2506e-05]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.10.mlp.down_proj.lora_A.weight': tensor([[-9.7656e-04,  1.2779e-04,  1.3809e-03,  ...,  3.7537e-03,\n",
       "          -8.7738e-04,  2.2583e-03],\n",
       "         [-1.2436e-03,  1.1292e-03, -8.0566e-03,  ..., -6.1035e-03,\n",
       "          -9.6130e-04, -6.0730e-03],\n",
       "         [-8.0566e-03, -5.2185e-03,  2.1057e-03,  ..., -4.4441e-04,\n",
       "           4.8218e-03, -2.2888e-03],\n",
       "         ...,\n",
       "         [-6.6833e-03,  5.2490e-03,  3.5706e-03,  ...,  8.9722e-03,\n",
       "           9.7656e-03,  9.0122e-05],\n",
       "         [-9.5825e-03,  6.8054e-03, -7.4463e-03,  ...,  2.9297e-03,\n",
       "           8.6060e-03, -9.0790e-04],\n",
       "         [-7.9346e-03, -3.7842e-03,  1.7242e-03,  ...,  6.6833e-03,\n",
       "           5.6763e-03, -3.2043e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.10.mlp.down_proj.lora_B.weight': tensor([[-0.0015, -0.0004, -0.0002,  ...,  0.0017, -0.0018, -0.0029],\n",
       "         [-0.0034,  0.0003, -0.0005,  ..., -0.0017, -0.0005, -0.0008],\n",
       "         [ 0.0019,  0.0018,  0.0024,  ..., -0.0003,  0.0012, -0.0003],\n",
       "         ...,\n",
       "         [-0.0008, -0.0002, -0.0009,  ...,  0.0003,  0.0007,  0.0011],\n",
       "         [-0.0015, -0.0022, -0.0004,  ..., -0.0003, -0.0017,  0.0015],\n",
       "         [-0.0005, -0.0027, -0.0012,  ...,  0.0006, -0.0024, -0.0015]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.10.mlp.gate_proj.lora_A.weight': tensor([[ 4.7913e-03,  1.0559e-02, -1.1169e-02,  ..., -8.4839e-03,\n",
       "          -4.6997e-03,  1.5503e-02],\n",
       "         [-5.9509e-03, -1.2817e-02, -1.0437e-02,  ...,  1.2634e-02,\n",
       "           1.4648e-02,  5.2185e-03],\n",
       "         [-1.9684e-03,  6.9885e-03,  6.1035e-03,  ..., -5.3101e-03,\n",
       "           6.1951e-03, -1.2573e-02],\n",
       "         ...,\n",
       "         [-1.6968e-02, -9.2773e-03,  1.4801e-03,  ...,  1.3504e-03,\n",
       "          -7.0801e-03, -2.1515e-03],\n",
       "         [ 6.8359e-03, -1.1353e-02,  1.0742e-02,  ..., -8.1177e-03,\n",
       "          -1.0498e-02, -1.2573e-02],\n",
       "         [-5.8594e-03, -1.2512e-02,  8.2397e-03,  ..., -1.0010e-02,\n",
       "          -5.4016e-03, -7.2479e-05]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.10.mlp.gate_proj.lora_B.weight': tensor([[ 1.3962e-03, -1.5335e-03, -7.5531e-04,  ...,  2.0313e-04,\n",
       "          -6.8665e-04, -8.9645e-04],\n",
       "         [ 4.4107e-05, -3.1281e-04, -1.0910e-03,  ..., -2.1744e-04,\n",
       "           2.9373e-04, -1.1292e-03],\n",
       "         [ 2.5024e-03,  1.4591e-04, -1.9989e-03,  ...,  6.3419e-05,\n",
       "           1.1139e-03,  2.6703e-03],\n",
       "         ...,\n",
       "         [-2.3651e-03,  2.4414e-03,  5.3406e-04,  ..., -1.8997e-03,\n",
       "          -1.3351e-03,  6.3705e-04],\n",
       "         [ 1.9836e-03, -1.1063e-03, -1.9150e-03,  ..., -4.5013e-04,\n",
       "          -7.2479e-04,  9.0408e-04],\n",
       "         [ 2.4033e-04, -8.2779e-04,  2.7657e-04,  ..., -4.1389e-04,\n",
       "          -9.7275e-04, -4.4060e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.10.mlp.up_proj.lora_A.weight': tensor([[-7.1411e-03, -4.8523e-03,  1.2756e-02,  ..., -3.7842e-03,\n",
       "           3.9482e-04, -7.2632e-03],\n",
       "         [-3.3569e-03, -2.3041e-03, -4.0588e-03,  ...,  1.6724e-02,\n",
       "          -1.6602e-02, -3.4485e-03],\n",
       "         [-6.4087e-04, -1.7944e-02, -1.1047e-02,  ..., -7.9346e-03,\n",
       "           1.6602e-02, -6.1035e-03],\n",
       "         ...,\n",
       "         [-9.5215e-03, -5.7068e-03,  9.5825e-03,  ...,  4.0283e-03,\n",
       "           2.2793e-04,  1.2146e-02],\n",
       "         [ 1.0254e-02,  8.9264e-04, -1.2512e-02,  ...,  3.8300e-03,\n",
       "           5.3406e-03, -8.4229e-03],\n",
       "         [ 5.1737e-05, -6.1951e-03, -3.8338e-04,  ..., -1.4099e-02,\n",
       "           5.0354e-03,  1.4526e-02]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.10.mlp.up_proj.lora_B.weight': tensor([[ 3.4943e-03, -2.4986e-04, -5.8746e-04,  ...,  2.4567e-03,\n",
       "           9.4223e-04,  1.3199e-03],\n",
       "         [ 1.7929e-03, -3.8910e-04, -1.0452e-03,  ...,  1.5945e-03,\n",
       "           5.0354e-04,  9.7275e-04],\n",
       "         [ 2.9206e-05,  4.2725e-04,  1.3199e-03,  ...,  1.5717e-03,\n",
       "           1.6861e-03, -2.4567e-03],\n",
       "         ...,\n",
       "         [-5.9605e-05, -9.9945e-04,  1.6689e-04,  ..., -2.5177e-03,\n",
       "           1.4725e-03,  8.3923e-05],\n",
       "         [ 1.1749e-03, -6.2561e-04,  6.7520e-04,  ...,  5.0735e-04,\n",
       "           1.2131e-03, -3.3264e-03],\n",
       "         [-3.0708e-04, -4.8256e-04,  7.3242e-04,  ...,  3.9673e-03,\n",
       "          -7.6675e-04,  3.5858e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.10.self_attn.k_proj.lora_A.weight': tensor([[ 0.0055, -0.0141,  0.0046,  ..., -0.0125,  0.0064,  0.0049],\n",
       "         [-0.0192, -0.0146, -0.0093,  ..., -0.0006, -0.0029, -0.0098],\n",
       "         [-0.0198,  0.0141,  0.0007,  ..., -0.0070,  0.0002, -0.0021],\n",
       "         ...,\n",
       "         [-0.0108, -0.0142,  0.0035,  ...,  0.0086,  0.0028, -0.0010],\n",
       "         [-0.0069, -0.0060,  0.0103,  ..., -0.0071,  0.0126,  0.0134],\n",
       "         [ 0.0017,  0.0128, -0.0004,  ..., -0.0034, -0.0007,  0.0068]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.10.self_attn.k_proj.lora_B.weight': tensor([[ 2.6245e-03, -2.3041e-03,  8.1253e-04,  ..., -5.8746e-04,\n",
       "          -5.3167e-05, -1.6556e-03],\n",
       "         [ 3.1090e-04,  1.0300e-03, -2.4414e-03,  ..., -1.6174e-03,\n",
       "           1.3351e-03,  1.3580e-03],\n",
       "         [ 1.7776e-03, -5.7220e-04,  7.6675e-04,  ..., -1.9989e-03,\n",
       "           2.8419e-04, -5.5695e-04],\n",
       "         ...,\n",
       "         [ 3.0160e-05, -1.1292e-03, -1.2970e-03,  ..., -2.9325e-05,\n",
       "           1.1206e-04,  6.1512e-05],\n",
       "         [ 1.3256e-04,  1.4877e-03, -2.3193e-03,  ..., -1.6022e-03,\n",
       "           7.9727e-04, -1.4648e-03],\n",
       "         [ 1.6174e-03, -4.2152e-04, -2.0752e-03,  ..., -3.0060e-03,\n",
       "           4.1580e-04, -2.0885e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.10.self_attn.o_proj.lora_A.weight': tensor([[-0.0038, -0.0003,  0.0098,  ..., -0.0047,  0.0084, -0.0094],\n",
       "         [ 0.0068,  0.0107,  0.0165,  ..., -0.0029, -0.0092,  0.0033],\n",
       "         [ 0.0143,  0.0105, -0.0043,  ..., -0.0112,  0.0147, -0.0131],\n",
       "         ...,\n",
       "         [-0.0114, -0.0076, -0.0099,  ..., -0.0120,  0.0066,  0.0154],\n",
       "         [ 0.0024,  0.0057,  0.0148,  ...,  0.0081, -0.0005,  0.0078],\n",
       "         [-0.0056,  0.0051,  0.0189,  ...,  0.0033,  0.0025, -0.0154]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.10.self_attn.o_proj.lora_B.weight': tensor([[-5.1880e-04, -4.3869e-04, -2.0905e-03,  ...,  2.5940e-03,\n",
       "           2.9564e-04, -1.5793e-03],\n",
       "         [-9.8419e-04, -2.5635e-03, -7.1335e-04,  ...,  1.2684e-04,\n",
       "           1.5163e-04, -1.7853e-03],\n",
       "         [ 8.2397e-04,  1.1826e-04,  6.9427e-04,  ..., -7.2479e-04,\n",
       "           1.8768e-03, -3.3379e-04],\n",
       "         ...,\n",
       "         [ 7.7248e-05, -3.4714e-04, -2.2430e-03,  ...,  1.7166e-03,\n",
       "           6.9427e-04,  5.4169e-04],\n",
       "         [ 1.4114e-03,  1.2159e-05,  1.1673e-03,  ..., -1.2589e-03,\n",
       "           2.7008e-03,  6.9427e-04],\n",
       "         [ 7.7057e-04,  3.0327e-04,  4.1008e-04,  ...,  4.0627e-04,\n",
       "          -1.7881e-05, -4.1199e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.10.self_attn.q_proj.lora_A.weight': tensor([[ 0.0018, -0.0020, -0.0022,  ..., -0.0106,  0.0146,  0.0066],\n",
       "         [ 0.0034,  0.0074, -0.0017,  ...,  0.0077,  0.0140,  0.0077],\n",
       "         [ 0.0162, -0.0012, -0.0029,  ..., -0.0017, -0.0117,  0.0023],\n",
       "         ...,\n",
       "         [ 0.0116,  0.0106, -0.0149,  ...,  0.0095, -0.0156,  0.0109],\n",
       "         [-0.0137,  0.0120, -0.0027,  ..., -0.0079, -0.0132,  0.0141],\n",
       "         [-0.0061, -0.0140,  0.0026,  ..., -0.0133,  0.0003,  0.0070]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.10.self_attn.q_proj.lora_B.weight': tensor([[ 1.1444e-03,  8.2397e-04,  1.7738e-04,  ...,  4.0894e-03,\n",
       "           8.1253e-04,  1.5020e-05],\n",
       "         [-4.0283e-03,  5.9891e-04, -8.2016e-04,  ...,  5.1737e-05,\n",
       "           1.7071e-04, -5.5313e-04],\n",
       "         [-1.5182e-03, -1.2360e-03, -1.2131e-03,  ..., -1.4801e-03,\n",
       "          -1.1902e-03,  1.2589e-03],\n",
       "         ...,\n",
       "         [ 5.3024e-04, -9.3460e-04, -1.2970e-03,  ..., -1.0300e-03,\n",
       "          -8.6594e-04,  7.2098e-04],\n",
       "         [-1.9989e-03, -1.2283e-03, -2.4719e-03,  ...,  2.5024e-03,\n",
       "          -6.3324e-04, -3.2806e-04],\n",
       "         [-8.7357e-04, -2.3956e-03, -8.5068e-04,  ..., -2.4140e-06,\n",
       "          -1.0757e-03, -8.8215e-05]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.10.self_attn.v_proj.lora_A.weight': tensor([[ 0.0100, -0.0052,  0.0128,  ..., -0.0138, -0.0086, -0.0105],\n",
       "         [ 0.0089,  0.0039, -0.0105,  ...,  0.0024, -0.0118,  0.0032],\n",
       "         [ 0.0116, -0.0090, -0.0087,  ..., -0.0020, -0.0003,  0.0002],\n",
       "         ...,\n",
       "         [ 0.0003, -0.0132, -0.0136,  ...,  0.0047, -0.0095,  0.0025],\n",
       "         [-0.0094,  0.0146,  0.0054,  ..., -0.0076, -0.0003,  0.0007],\n",
       "         [ 0.0079,  0.0058,  0.0149,  ..., -0.0150, -0.0025,  0.0145]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.10.self_attn.v_proj.lora_B.weight': tensor([[-2.7657e-04, -1.9455e-04,  1.8616e-03,  ...,  9.0408e-04,\n",
       "           1.2207e-03,  3.8338e-04],\n",
       "         [ 1.3351e-03, -3.2425e-04, -9.3842e-04,  ..., -6.4087e-04,\n",
       "          -1.3428e-03, -8.6594e-04],\n",
       "         [-1.4191e-03, -4.6158e-04,  3.4809e-05,  ..., -5.3167e-05,\n",
       "           1.1749e-03,  5.3406e-04],\n",
       "         ...,\n",
       "         [ 9.1934e-04, -8.3923e-04, -2.4986e-04,  ...,  1.1597e-03,\n",
       "           8.8501e-04,  3.2997e-04],\n",
       "         [ 4.3335e-03, -6.1417e-04, -1.5640e-03,  ...,  3.3569e-04,\n",
       "          -7.8583e-04,  9.9945e-04],\n",
       "         [ 9.0790e-04,  2.5153e-05, -1.6212e-04,  ...,  1.1292e-03,\n",
       "          -4.1771e-04, -1.9264e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.11.mlp.down_proj.lora_A.weight': tensor([[-0.0017, -0.0077, -0.0040,  ..., -0.0074,  0.0022,  0.0021],\n",
       "         [-0.0049,  0.0036, -0.0114,  ...,  0.0015,  0.0115,  0.0068],\n",
       "         [ 0.0010,  0.0028,  0.0064,  ...,  0.0072,  0.0012, -0.0062],\n",
       "         ...,\n",
       "         [-0.0101, -0.0065,  0.0053,  ...,  0.0038,  0.0027, -0.0014],\n",
       "         [ 0.0008,  0.0003, -0.0045,  ..., -0.0053,  0.0093, -0.0054],\n",
       "         [-0.0060,  0.0039, -0.0040,  ..., -0.0062,  0.0076, -0.0012]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.11.mlp.down_proj.lora_B.weight': tensor([[-2.5635e-03, -3.0327e-04, -2.3193e-03,  ...,  1.6479e-03,\n",
       "          -1.7700e-03,  6.3324e-04],\n",
       "         [-2.9564e-04, -3.5858e-04,  1.8158e-03,  ...,  1.8921e-03,\n",
       "          -1.4496e-03, -1.5030e-03],\n",
       "         [ 1.4572e-03, -1.7395e-03, -1.8768e-03,  ...,  8.2779e-04,\n",
       "           4.0283e-03,  4.5013e-04],\n",
       "         ...,\n",
       "         [-9.6512e-04,  2.6550e-03, -1.7548e-03,  ...,  6.2180e-04,\n",
       "           1.0986e-03, -1.4114e-03],\n",
       "         [ 7.7820e-04,  2.3460e-04, -1.0681e-03,  ...,  1.2283e-03,\n",
       "           2.5940e-03, -2.2125e-03],\n",
       "         [ 2.1935e-05, -5.7697e-05, -2.2736e-03,  ...,  1.2589e-03,\n",
       "           1.5717e-03, -2.6093e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.11.mlp.gate_proj.lora_A.weight': tensor([[-0.0042,  0.0131,  0.0082,  ..., -0.0062, -0.0139, -0.0123],\n",
       "         [ 0.0095, -0.0081, -0.0061,  ..., -0.0104,  0.0042,  0.0125],\n",
       "         [-0.0171, -0.0023, -0.0101,  ..., -0.0044, -0.0106,  0.0035],\n",
       "         ...,\n",
       "         [ 0.0110,  0.0045, -0.0034,  ...,  0.0148, -0.0048, -0.0020],\n",
       "         [-0.0117, -0.0061, -0.0129,  ..., -0.0126, -0.0039, -0.0028],\n",
       "         [-0.0002, -0.0111, -0.0084,  ...,  0.0063,  0.0045,  0.0064]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.11.mlp.gate_proj.lora_B.weight': tensor([[ 0.0004,  0.0008,  0.0011,  ...,  0.0018, -0.0006, -0.0006],\n",
       "         [-0.0014, -0.0016, -0.0019,  ..., -0.0014,  0.0023, -0.0008],\n",
       "         [ 0.0003, -0.0007, -0.0009,  ..., -0.0012,  0.0005, -0.0018],\n",
       "         ...,\n",
       "         [-0.0018,  0.0021, -0.0026,  ...,  0.0038,  0.0030, -0.0015],\n",
       "         [-0.0018, -0.0011, -0.0014,  ...,  0.0010,  0.0026,  0.0008],\n",
       "         [ 0.0008,  0.0015, -0.0002,  ...,  0.0023,  0.0011, -0.0016]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.11.mlp.up_proj.lora_A.weight': tensor([[ 0.0060, -0.0121,  0.0131,  ...,  0.0027,  0.0143,  0.0034],\n",
       "         [-0.0097,  0.0160,  0.0019,  ..., -0.0087,  0.0094,  0.0021],\n",
       "         [-0.0059, -0.0089,  0.0013,  ...,  0.0134, -0.0153, -0.0076],\n",
       "         ...,\n",
       "         [-0.0152, -0.0106,  0.0135,  ..., -0.0010,  0.0131,  0.0062],\n",
       "         [-0.0019, -0.0148,  0.0103,  ..., -0.0013,  0.0113, -0.0067],\n",
       "         [-0.0044,  0.0128, -0.0123,  ...,  0.0117, -0.0048,  0.0134]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.11.mlp.up_proj.lora_B.weight': tensor([[-1.5182e-03, -1.2131e-03, -1.3580e-03,  ..., -7.1526e-05,\n",
       "           2.1667e-03, -1.3809e-03],\n",
       "         [ 2.7466e-04, -1.2665e-03,  4.1809e-03,  ...,  3.2043e-04,\n",
       "           1.0452e-03,  6.6376e-04],\n",
       "         [ 6.3705e-04, -2.0752e-03,  1.9836e-03,  ..., -3.9482e-04,\n",
       "           2.3651e-03, -1.5259e-03],\n",
       "         ...,\n",
       "         [ 7.0190e-04,  2.4261e-03, -1.5717e-03,  ..., -5.6458e-04,\n",
       "          -1.5640e-04,  3.5248e-03],\n",
       "         [ 2.0752e-03,  5.7983e-04, -2.5482e-03,  ...,  4.5586e-04,\n",
       "           2.1515e-03, -2.4719e-03],\n",
       "         [ 5.5313e-04,  1.2436e-03,  1.1520e-03,  ...,  1.5182e-03,\n",
       "           5.7220e-04,  1.9684e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.11.self_attn.k_proj.lora_A.weight': tensor([[-0.0025, -0.0107, -0.0006,  ...,  0.0151, -0.0033,  0.0009],\n",
       "         [ 0.0115, -0.0015, -0.0027,  ...,  0.0063, -0.0054,  0.0131],\n",
       "         [-0.0066, -0.0100,  0.0111,  ..., -0.0003,  0.0052, -0.0092],\n",
       "         ...,\n",
       "         [-0.0059,  0.0051,  0.0083,  ...,  0.0146,  0.0008, -0.0021],\n",
       "         [-0.0067,  0.0062,  0.0052,  ...,  0.0005,  0.0149,  0.0156],\n",
       "         [ 0.0090,  0.0117,  0.0004,  ...,  0.0022,  0.0072,  0.0120]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.11.self_attn.k_proj.lora_B.weight': tensor([[ 0.0011, -0.0002,  0.0029,  ...,  0.0016, -0.0024, -0.0008],\n",
       "         [-0.0021,  0.0004, -0.0020,  ..., -0.0012,  0.0033, -0.0009],\n",
       "         [-0.0019,  0.0010, -0.0026,  ..., -0.0009,  0.0025, -0.0002],\n",
       "         ...,\n",
       "         [-0.0019,  0.0013, -0.0014,  ..., -0.0014, -0.0004, -0.0023],\n",
       "         [-0.0009, -0.0005, -0.0002,  ...,  0.0006,  0.0018, -0.0008],\n",
       "         [ 0.0035, -0.0013,  0.0008,  ..., -0.0003, -0.0001,  0.0026]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.11.self_attn.o_proj.lora_A.weight': tensor([[-1.1902e-02, -5.6458e-03,  3.0212e-03,  ...,  1.1108e-02,\n",
       "           4.4250e-03,  1.0376e-02],\n",
       "         [ 2.8839e-03,  1.3611e-02,  1.0925e-02,  ...,  8.8501e-03,\n",
       "          -4.2114e-03, -4.7445e-05],\n",
       "         [-1.0529e-03, -1.2817e-02,  1.3000e-02,  ...,  8.5068e-04,\n",
       "          -1.2878e-02, -1.4832e-02],\n",
       "         ...,\n",
       "         [-1.5869e-02,  5.6152e-03, -1.3428e-02,  ..., -7.7515e-03,\n",
       "           7.0496e-03, -1.2360e-03],\n",
       "         [ 3.5400e-03, -5.4016e-03,  8.6670e-03,  ...,  7.3624e-04,\n",
       "           9.7656e-03,  2.6131e-04],\n",
       "         [ 3.9673e-03,  5.3101e-03,  1.5198e-02,  ...,  6.9275e-03,\n",
       "          -1.9226e-03, -8.6670e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.11.self_attn.o_proj.lora_B.weight': tensor([[ 3.4332e-05, -3.7003e-04, -1.8921e-03,  ...,  5.7220e-04,\n",
       "           1.7262e-04,  1.6861e-03],\n",
       "         [ 1.0452e-03, -1.7548e-03, -1.3256e-04,  ..., -7.3624e-04,\n",
       "           4.5013e-04,  5.5313e-05],\n",
       "         [ 1.6212e-04, -2.2583e-03, -3.6774e-03,  ..., -3.0823e-03,\n",
       "           2.5635e-03, -1.0147e-03],\n",
       "         ...,\n",
       "         [-9.0790e-04,  7.5531e-04, -7.2861e-04,  ..., -9.1171e-04,\n",
       "           1.0147e-03,  1.6327e-03],\n",
       "         [-1.4687e-04,  2.5177e-04, -1.2436e-03,  ...,  1.0586e-04,\n",
       "           6.1798e-04,  1.0223e-03],\n",
       "         [ 4.0233e-06,  9.0408e-04, -4.8637e-04,  ..., -2.0599e-03,\n",
       "           9.6893e-04, -4.5061e-05]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.11.self_attn.q_proj.lora_A.weight': tensor([[ 0.0148, -0.0021,  0.0030,  ..., -0.0182, -0.0099, -0.0123],\n",
       "         [-0.0037,  0.0018, -0.0006,  ...,  0.0146,  0.0066, -0.0013],\n",
       "         [-0.0080, -0.0142,  0.0082,  ..., -0.0059,  0.0084, -0.0103],\n",
       "         ...,\n",
       "         [-0.0002,  0.0073, -0.0157,  ...,  0.0063, -0.0053,  0.0068],\n",
       "         [ 0.0078, -0.0093, -0.0088,  ..., -0.0149, -0.0148, -0.0044],\n",
       "         [-0.0153,  0.0081, -0.0137,  ...,  0.0022, -0.0105,  0.0050]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.11.self_attn.q_proj.lora_B.weight': tensor([[-8.0872e-04, -2.2173e-05,  8.8501e-04,  ..., -9.9945e-04,\n",
       "          -2.6093e-03,  3.2501e-03],\n",
       "         [ 8.6594e-04,  1.1292e-03,  1.3733e-03,  ..., -2.9182e-04,\n",
       "           4.4060e-04,  1.4648e-03],\n",
       "         [-2.3804e-03, -9.5749e-04,  7.4387e-04,  ...,  2.0504e-04,\n",
       "          -2.5940e-03,  4.3335e-03],\n",
       "         ...,\n",
       "         [-3.2196e-03, -7.4387e-04, -8.4305e-04,  ..., -5.6839e-04,\n",
       "          -2.7161e-03,  1.3123e-03],\n",
       "         [-3.1891e-03, -1.2665e-03, -1.0204e-04,  ..., -1.3351e-04,\n",
       "          -7.4387e-04, -9.7656e-04],\n",
       "         [ 1.1520e-03, -3.9101e-04,  1.3123e-03,  ..., -6.3324e-04,\n",
       "           6.7520e-04,  1.1301e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.11.self_attn.v_proj.lora_A.weight': tensor([[ 0.0034, -0.0073,  0.0004,  ...,  0.0033, -0.0077, -0.0064],\n",
       "         [-0.0008,  0.0166, -0.0044,  ..., -0.0078, -0.0022, -0.0023],\n",
       "         [ 0.0056,  0.0113, -0.0021,  ...,  0.0129,  0.0019, -0.0131],\n",
       "         ...,\n",
       "         [-0.0112,  0.0137, -0.0121,  ...,  0.0042, -0.0048, -0.0064],\n",
       "         [ 0.0031, -0.0147,  0.0066,  ...,  0.0093, -0.0127,  0.0111],\n",
       "         [ 0.0009,  0.0033, -0.0021,  ...,  0.0076,  0.0037,  0.0098]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.11.self_attn.v_proj.lora_B.weight': tensor([[ 0.0025, -0.0021,  0.0009,  ..., -0.0027,  0.0023, -0.0024],\n",
       "         [-0.0018,  0.0019, -0.0014,  ...,  0.0012, -0.0011,  0.0019],\n",
       "         [-0.0005,  0.0010, -0.0014,  ...,  0.0005, -0.0011,  0.0007],\n",
       "         ...,\n",
       "         [ 0.0013, -0.0013,  0.0008,  ..., -0.0013,  0.0014, -0.0018],\n",
       "         [-0.0008,  0.0006, -0.0002,  ...,  0.0013, -0.0013,  0.0008],\n",
       "         [ 0.0012, -0.0012,  0.0015,  ..., -0.0009,  0.0016, -0.0012]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.12.mlp.down_proj.lora_A.weight': tensor([[ 0.0048, -0.0084, -0.0009,  ...,  0.0086,  0.0047,  0.0079],\n",
       "         [ 0.0084, -0.0093, -0.0020,  ..., -0.0040, -0.0045,  0.0033],\n",
       "         [-0.0091,  0.0040, -0.0052,  ..., -0.0029, -0.0049, -0.0084],\n",
       "         ...,\n",
       "         [ 0.0032,  0.0085,  0.0038,  ...,  0.0022,  0.0109, -0.0042],\n",
       "         [-0.0093, -0.0001,  0.0049,  ...,  0.0013,  0.0037, -0.0095],\n",
       "         [-0.0022,  0.0048, -0.0015,  ...,  0.0026,  0.0086,  0.0048]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.12.mlp.down_proj.lora_B.weight': tensor([[-1.3962e-03,  1.7776e-03,  1.6556e-03,  ..., -1.1444e-03,\n",
       "          -8.6594e-04, -5.9128e-04],\n",
       "         [-1.6327e-03, -1.4400e-04,  3.5248e-03,  ...,  4.0436e-04,\n",
       "          -2.4109e-03, -1.3351e-03],\n",
       "         [-9.2316e-04, -2.5635e-03, -1.3924e-04,  ...,  2.0294e-03,\n",
       "          -9.0790e-04,  1.3638e-04],\n",
       "         ...,\n",
       "         [ 2.7771e-03,  7.0095e-05, -2.1362e-03,  ...,  1.4648e-03,\n",
       "           1.1826e-03,  2.2736e-03],\n",
       "         [-1.9379e-03, -1.9073e-03,  1.5106e-03,  ...,  6.6757e-04,\n",
       "          -4.1771e-04,  1.0910e-03],\n",
       "         [-1.1749e-03, -2.3956e-03,  2.2430e-03,  ...,  2.4414e-03,\n",
       "          -1.3580e-03,  8.1635e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.12.mlp.gate_proj.lora_A.weight': tensor([[-0.0137, -0.0120, -0.0062,  ...,  0.0164, -0.0020, -0.0119],\n",
       "         [ 0.0022,  0.0007,  0.0125,  ..., -0.0071,  0.0154,  0.0109],\n",
       "         [ 0.0145,  0.0027, -0.0050,  ...,  0.0125,  0.0027, -0.0030],\n",
       "         ...,\n",
       "         [ 0.0081,  0.0159, -0.0081,  ...,  0.0010, -0.0112,  0.0184],\n",
       "         [-0.0061, -0.0002,  0.0053,  ..., -0.0003,  0.0164,  0.0083],\n",
       "         [ 0.0047, -0.0144,  0.0068,  ..., -0.0103, -0.0030, -0.0102]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.12.mlp.gate_proj.lora_B.weight': tensor([[ 2.7657e-04,  4.9438e-03,  5.2691e-05,  ..., -3.8605e-03,\n",
       "          -2.1820e-03,  2.3651e-03],\n",
       "         [ 3.0823e-03, -3.5286e-04,  9.3460e-04,  ...,  1.4572e-03,\n",
       "           3.4142e-04,  8.3160e-04],\n",
       "         [-4.4823e-04,  1.3657e-03,  1.3275e-03,  ...,  3.1738e-03,\n",
       "           1.5945e-03, -1.5717e-03],\n",
       "         ...,\n",
       "         [ 2.3651e-03,  2.5368e-04,  1.1749e-03,  ..., -3.4637e-03,\n",
       "           1.7700e-03, -1.0300e-03],\n",
       "         [-8.4877e-05,  2.5635e-03,  1.3828e-04,  ..., -2.1057e-03,\n",
       "          -2.3041e-03,  2.4872e-03],\n",
       "         [-1.9073e-03, -1.0223e-03, -4.1962e-05,  ...,  1.9684e-03,\n",
       "           1.8158e-03, -1.4114e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.12.mlp.up_proj.lora_A.weight': tensor([[ 2.4719e-03, -1.7578e-02, -9.0942e-03,  ..., -1.8311e-03,\n",
       "           5.8899e-03, -9.4986e-04],\n",
       "         [ 8.0566e-03, -3.6926e-03,  1.1353e-02,  ...,  1.4343e-02,\n",
       "          -2.2583e-03, -7.3242e-03],\n",
       "         [ 5.4016e-03, -1.2146e-02, -1.4587e-02,  ...,  4.8280e-06,\n",
       "           5.2795e-03, -6.1340e-03],\n",
       "         ...,\n",
       "         [ 3.1281e-03, -3.5858e-04, -4.0283e-03,  ..., -1.1047e-02,\n",
       "           1.4648e-02, -2.0294e-03],\n",
       "         [-9.3994e-03,  9.8267e-03,  1.3855e-02,  ..., -3.2043e-03,\n",
       "          -4.9744e-03, -1.2451e-02],\n",
       "         [-2.5482e-03,  1.5381e-02,  2.1210e-03,  ..., -1.8311e-02,\n",
       "           4.0588e-03, -9.8877e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.12.mlp.up_proj.lora_B.weight': tensor([[-3.3188e-04,  2.7466e-03,  2.3041e-03,  ...,  1.0910e-03,\n",
       "           6.8665e-04,  2.3193e-03],\n",
       "         [-1.2817e-03, -3.3875e-03, -6.7520e-04,  ...,  3.5477e-04,\n",
       "           1.0910e-03, -1.2665e-03],\n",
       "         [ 2.5558e-04, -2.1515e-03, -1.7776e-03,  ...,  4.4632e-04,\n",
       "           2.3651e-03, -7.6294e-04],\n",
       "         ...,\n",
       "         [ 3.3722e-03,  1.1597e-03,  1.9226e-03,  ...,  5.0735e-04,\n",
       "           2.1667e-03,  2.3804e-03],\n",
       "         [ 8.3923e-04,  1.6632e-03,  1.0834e-03,  ...,  4.7112e-04,\n",
       "          -1.4019e-04, -1.5182e-03],\n",
       "         [-3.2425e-05, -1.9226e-03,  2.2888e-03,  ...,  7.0572e-04,\n",
       "          -9.9945e-04, -3.2806e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.12.self_attn.k_proj.lora_A.weight': tensor([[ 0.0042,  0.0098,  0.0081,  ...,  0.0052, -0.0012, -0.0093],\n",
       "         [ 0.0141, -0.0123,  0.0045,  ..., -0.0010, -0.0065, -0.0020],\n",
       "         [ 0.0142,  0.0141,  0.0028,  ...,  0.0092,  0.0120, -0.0112],\n",
       "         ...,\n",
       "         [-0.0022,  0.0102, -0.0086,  ..., -0.0055,  0.0118, -0.0081],\n",
       "         [ 0.0112, -0.0057, -0.0037,  ...,  0.0133, -0.0036, -0.0010],\n",
       "         [ 0.0031, -0.0005,  0.0075,  ..., -0.0080, -0.0132,  0.0009]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.12.self_attn.k_proj.lora_B.weight': tensor([[-0.0006,  0.0014,  0.0021,  ...,  0.0007, -0.0001, -0.0008],\n",
       "         [-0.0017,  0.0005, -0.0007,  ...,  0.0011,  0.0022,  0.0002],\n",
       "         [ 0.0009,  0.0004,  0.0002,  ..., -0.0002, -0.0028, -0.0009],\n",
       "         ...,\n",
       "         [-0.0006, -0.0015, -0.0013,  ...,  0.0005,  0.0016,  0.0007],\n",
       "         [-0.0017, -0.0005,  0.0044,  ...,  0.0005,  0.0034, -0.0010],\n",
       "         [ 0.0011,  0.0016, -0.0010,  ..., -0.0010, -0.0014,  0.0015]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.12.self_attn.o_proj.lora_A.weight': tensor([[-0.0122,  0.0015, -0.0072,  ...,  0.0031, -0.0109,  0.0024],\n",
       "         [ 0.0134,  0.0110,  0.0152,  ...,  0.0118,  0.0119, -0.0084],\n",
       "         [-0.0042,  0.0032,  0.0023,  ..., -0.0134,  0.0043,  0.0094],\n",
       "         ...,\n",
       "         [-0.0096, -0.0064,  0.0087,  ...,  0.0089, -0.0078,  0.0139],\n",
       "         [ 0.0175,  0.0065, -0.0103,  ...,  0.0092, -0.0012,  0.0141],\n",
       "         [ 0.0017, -0.0092, -0.0053,  ..., -0.0090,  0.0085, -0.0053]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.12.self_attn.o_proj.lora_B.weight': tensor([[ 8.8882e-04,  1.8997e-03,  3.1090e-04,  ...,  9.4223e-04,\n",
       "          -2.1515e-03, -1.3828e-04],\n",
       "         [-1.4038e-03,  4.2343e-04, -4.6387e-03,  ...,  1.7700e-03,\n",
       "           5.9509e-04,  6.4087e-04],\n",
       "         [ 9.9945e-04,  3.1281e-04,  3.3379e-04,  ..., -4.6997e-03,\n",
       "           2.0447e-03, -1.4877e-03],\n",
       "         ...,\n",
       "         [ 3.7432e-05, -1.0529e-03, -7.0953e-04,  ...,  1.1520e-03,\n",
       "           1.7395e-03, -2.8687e-03],\n",
       "         [-8.5449e-04, -7.8583e-04, -1.1673e-03,  ..., -1.6689e-04,\n",
       "           3.0327e-04, -1.0729e-04],\n",
       "         [-1.1597e-03,  2.2583e-03, -1.6861e-03,  ..., -1.6251e-03,\n",
       "           1.8387e-03,  7.1716e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.12.self_attn.q_proj.lora_A.weight': tensor([[-0.0043, -0.0141,  0.0056,  ...,  0.0027,  0.0123,  0.0165],\n",
       "         [-0.0026,  0.0026,  0.0061,  ..., -0.0138, -0.0096, -0.0085],\n",
       "         [-0.0018, -0.0132,  0.0020,  ...,  0.0108,  0.0131, -0.0024],\n",
       "         ...,\n",
       "         [ 0.0079,  0.0096,  0.0162,  ...,  0.0012, -0.0005,  0.0160],\n",
       "         [ 0.0070, -0.0025, -0.0009,  ..., -0.0015,  0.0033,  0.0050],\n",
       "         [-0.0142, -0.0020, -0.0082,  ..., -0.0075, -0.0103,  0.0165]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.12.self_attn.q_proj.lora_B.weight': tensor([[ 1.4496e-04, -1.1978e-03, -2.7466e-04,  ...,  3.7766e-04,\n",
       "           1.8024e-04,  8.2397e-04],\n",
       "         [-2.9297e-03, -2.2888e-03, -8.3160e-04,  ...,  3.9673e-03,\n",
       "          -1.1368e-03,  1.7090e-03],\n",
       "         [-1.0834e-03, -6.2943e-04,  2.1820e-03,  ..., -2.2125e-03,\n",
       "          -3.9101e-04,  6.4850e-04],\n",
       "         ...,\n",
       "         [ 1.7624e-03, -3.3826e-06, -2.6131e-04,  ..., -4.7302e-04,\n",
       "           4.4250e-04, -7.0953e-04],\n",
       "         [ 6.9809e-04,  1.8921e-03, -1.3046e-03,  ..., -2.1667e-03,\n",
       "           1.8616e-03, -1.2207e-03],\n",
       "         [ 2.7466e-04,  1.3580e-03,  5.1409e-07,  ..., -2.1667e-03,\n",
       "           1.8692e-03, -3.2349e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.12.self_attn.v_proj.lora_A.weight': tensor([[ 0.0159, -0.0049, -0.0065,  ..., -0.0022,  0.0084,  0.0036],\n",
       "         [-0.0065,  0.0053, -0.0074,  ...,  0.0151, -0.0131, -0.0148],\n",
       "         [ 0.0093, -0.0165,  0.0110,  ..., -0.0042, -0.0026, -0.0008],\n",
       "         ...,\n",
       "         [ 0.0023,  0.0156,  0.0142,  ...,  0.0051, -0.0141, -0.0064],\n",
       "         [-0.0048,  0.0084,  0.0128,  ..., -0.0001, -0.0071,  0.0066],\n",
       "         [ 0.0036,  0.0126, -0.0091,  ..., -0.0076, -0.0066, -0.0081]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.12.self_attn.v_proj.lora_B.weight': tensor([[ 1.5259e-03,  1.2436e-03,  1.4877e-03,  ..., -8.3923e-04,\n",
       "           1.4267e-03,  1.9455e-04],\n",
       "         [-5.1260e-06, -5.4932e-04,  8.5068e-04,  ...,  1.2741e-03,\n",
       "           7.6294e-04, -8.1253e-04],\n",
       "         [-1.4648e-03, -1.1749e-03, -1.6022e-03,  ...,  5.1117e-04,\n",
       "          -1.0681e-03,  1.3580e-03],\n",
       "         ...,\n",
       "         [-1.6174e-03, -9.7275e-04, -6.7139e-04,  ...,  1.6022e-03,\n",
       "          -1.1444e-03,  1.6689e-04],\n",
       "         [ 1.6861e-03, -1.9789e-05,  4.8447e-04,  ..., -1.2207e-03,\n",
       "           1.4114e-03,  3.2187e-05],\n",
       "         [ 1.1444e-03,  1.2970e-03,  8.1635e-04,  ..., -3.5706e-03,\n",
       "           1.8311e-03,  9.1553e-05]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.13.mlp.down_proj.lora_A.weight': tensor([[-0.0043,  0.0034,  0.0039,  ...,  0.0012,  0.0040,  0.0069],\n",
       "         [-0.0091,  0.0041, -0.0099,  ...,  0.0026, -0.0019,  0.0012],\n",
       "         [ 0.0024, -0.0010, -0.0021,  ..., -0.0020,  0.0060, -0.0018],\n",
       "         ...,\n",
       "         [ 0.0008, -0.0016,  0.0087,  ..., -0.0115,  0.0012,  0.0092],\n",
       "         [-0.0064, -0.0020,  0.0098,  ..., -0.0062,  0.0028,  0.0056],\n",
       "         [ 0.0076, -0.0068,  0.0042,  ..., -0.0005, -0.0101, -0.0074]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.13.mlp.down_proj.lora_B.weight': tensor([[-1.3657e-03, -2.3651e-03,  9.0408e-04,  ...,  2.6093e-03,\n",
       "           4.6921e-04, -2.3041e-03],\n",
       "         [ 4.2021e-06,  1.2159e-04, -4.6921e-04,  ..., -1.3885e-03,\n",
       "           2.1815e-05, -9.7275e-04],\n",
       "         [ 1.1902e-03, -2.1820e-03, -2.8992e-03,  ...,  1.3275e-03,\n",
       "          -4.2725e-04, -8.6975e-04],\n",
       "         ...,\n",
       "         [-2.1515e-03,  1.0757e-03, -1.2283e-03,  ..., -9.8419e-04,\n",
       "          -1.2054e-03,  1.6556e-03],\n",
       "         [-2.0695e-04, -5.2643e-04,  2.7275e-04,  ..., -3.6240e-05,\n",
       "           1.3504e-03, -1.1063e-03],\n",
       "         [-1.3885e-03, -4.1504e-03, -1.3351e-03,  ...,  3.9339e-05,\n",
       "          -4.3945e-03,  9.6893e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.13.mlp.gate_proj.lora_A.weight': tensor([[-0.0092,  0.0085,  0.0042,  ...,  0.0070,  0.0145, -0.0132],\n",
       "         [ 0.0091,  0.0071,  0.0022,  ..., -0.0134,  0.0011,  0.0131],\n",
       "         [ 0.0112,  0.0012,  0.0009,  ..., -0.0149,  0.0051,  0.0103],\n",
       "         ...,\n",
       "         [ 0.0073,  0.0081, -0.0029,  ..., -0.0062,  0.0020, -0.0082],\n",
       "         [-0.0028,  0.0098,  0.0007,  ..., -0.0060,  0.0122,  0.0041],\n",
       "         [ 0.0019,  0.0121, -0.0011,  ...,  0.0106,  0.0070, -0.0090]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.13.mlp.gate_proj.lora_B.weight': tensor([[ 2.7657e-04,  9.9945e-04,  3.6049e-04,  ...,  1.7471e-03,\n",
       "           6.1798e-04, -1.2665e-03],\n",
       "         [ 3.9816e-05, -7.3910e-05, -7.2861e-04,  ...,  4.9114e-05,\n",
       "           7.6294e-04,  2.7771e-03],\n",
       "         [-7.1716e-04, -1.2665e-03, -2.1667e-03,  ..., -9.6321e-05,\n",
       "          -6.7139e-04,  1.1597e-03],\n",
       "         ...,\n",
       "         [-2.3651e-03,  3.4943e-03,  8.0872e-04,  ...,  3.1738e-03,\n",
       "          -5.8889e-05,  1.8692e-03],\n",
       "         [-1.6174e-03,  1.2512e-03, -2.9922e-05,  ...,  1.1921e-04,\n",
       "          -1.0910e-03, -4.4556e-03],\n",
       "         [ 1.3962e-03, -1.5736e-04, -1.0757e-03,  ..., -5.4550e-04,\n",
       "          -1.9073e-03,  6.4468e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.13.mlp.up_proj.lora_A.weight': tensor([[-7.8735e-03, -7.8735e-03, -1.5137e-02,  ..., -1.2695e-02,\n",
       "           3.9673e-03, -1.3672e-02],\n",
       "         [-4.0894e-03, -7.0801e-03,  4.1504e-03,  ...,  1.1414e-02,\n",
       "          -1.5991e-02, -1.1749e-03],\n",
       "         [ 6.6223e-03, -6.6528e-03, -4.3030e-03,  ...,  6.0081e-05,\n",
       "           8.7891e-03,  9.5215e-03],\n",
       "         ...,\n",
       "         [-1.5869e-02,  1.1658e-02,  1.5747e-02,  ...,  3.2959e-03,\n",
       "          -8.2397e-03,  1.0803e-02],\n",
       "         [-8.9722e-03,  3.3569e-03, -4.8523e-03,  ..., -4.4250e-03,\n",
       "           1.4420e-03, -8.6060e-03],\n",
       "         [ 8.3618e-03, -1.2589e-03,  4.3640e-03,  ..., -5.4932e-03,\n",
       "           1.0803e-02,  4.4250e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.13.mlp.up_proj.lora_B.weight': tensor([[ 3.1891e-03,  1.9989e-03,  2.0790e-04,  ..., -2.8076e-03,\n",
       "           2.2736e-03, -3.3112e-03],\n",
       "         [-5.1498e-04, -1.2741e-03, -8.8501e-04,  ..., -7.8678e-06,\n",
       "           8.5449e-04,  2.8419e-04],\n",
       "         [ 2.1553e-04,  2.1057e-03, -7.1716e-04,  ..., -8.7738e-04,\n",
       "          -2.0294e-03,  1.3580e-03],\n",
       "         ...,\n",
       "         [-6.3419e-05,  2.3804e-03,  4.4060e-04,  ..., -1.0681e-03,\n",
       "          -2.5177e-03,  1.6327e-03],\n",
       "         [ 1.0300e-03, -8.8120e-04, -6.2943e-04,  ...,  1.0376e-03,\n",
       "           1.8005e-03,  8.2779e-04],\n",
       "         [-1.4420e-03, -5.4550e-04, -2.4605e-04,  ..., -1.5736e-04,\n",
       "           1.3123e-03, -9.4604e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.13.self_attn.k_proj.lora_A.weight': tensor([[-0.0018, -0.0115,  0.0023,  ...,  0.0067, -0.0147,  0.0073],\n",
       "         [-0.0103, -0.0066,  0.0013,  ..., -0.0082, -0.0022,  0.0093],\n",
       "         [ 0.0140, -0.0102,  0.0069,  ..., -0.0113,  0.0019, -0.0084],\n",
       "         ...,\n",
       "         [ 0.0059, -0.0033,  0.0038,  ...,  0.0006, -0.0056, -0.0025],\n",
       "         [ 0.0140, -0.0013,  0.0092,  ...,  0.0028, -0.0006,  0.0135],\n",
       "         [-0.0056, -0.0157, -0.0107,  ..., -0.0142,  0.0087,  0.0089]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.13.self_attn.k_proj.lora_B.weight': tensor([[-3.8528e-04, -4.4584e-05,  9.4223e-04,  ...,  2.8839e-03,\n",
       "          -1.1215e-03, -3.0060e-03],\n",
       "         [-2.5177e-03, -2.2888e-03,  1.4496e-03,  ...,  6.5613e-04,\n",
       "          -1.5335e-03, -1.6861e-03],\n",
       "         [ 1.0109e-04,  9.6512e-04, -1.3580e-03,  ...,  2.6131e-04,\n",
       "          -1.1978e-03,  1.1292e-03],\n",
       "         ...,\n",
       "         [-2.4719e-03,  2.9945e-04, -5.2261e-04,  ...,  2.2769e-05,\n",
       "           1.0757e-03, -1.1368e-03],\n",
       "         [-8.7738e-04,  1.1368e-03,  2.6093e-03,  ...,  8.4686e-04,\n",
       "          -8.1253e-04, -3.2043e-04],\n",
       "         [ 3.0975e-03,  7.5531e-04,  4.2343e-04,  ...,  1.9989e-03,\n",
       "           1.3962e-03, -1.8463e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.13.self_attn.o_proj.lora_A.weight': tensor([[-0.0003, -0.0167, -0.0160,  ...,  0.0033,  0.0033,  0.0049],\n",
       "         [-0.0112, -0.0071,  0.0070,  ..., -0.0090, -0.0042,  0.0025],\n",
       "         [-0.0052,  0.0018,  0.0131,  ..., -0.0002,  0.0042, -0.0077],\n",
       "         ...,\n",
       "         [-0.0151,  0.0104,  0.0075,  ...,  0.0105, -0.0164,  0.0125],\n",
       "         [-0.0107,  0.0146, -0.0081,  ...,  0.0141,  0.0107,  0.0034],\n",
       "         [-0.0008,  0.0057,  0.0018,  ..., -0.0009, -0.0076,  0.0045]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.13.self_attn.o_proj.lora_B.weight': tensor([[-1.3173e-05,  1.5182e-03,  1.0605e-03,  ..., -3.3855e-05,\n",
       "          -2.1210e-03, -7.9632e-05],\n",
       "         [-4.0627e-04, -7.4387e-04, -7.2956e-05,  ...,  1.2207e-03,\n",
       "          -4.3106e-04, -1.8005e-03],\n",
       "         [-1.4725e-03, -9.0027e-04,  2.2430e-03,  ..., -1.7853e-03,\n",
       "           3.2959e-03, -5.3406e-04],\n",
       "         ...,\n",
       "         [ 1.1063e-03, -1.1444e-03, -5.1117e-04,  ...,  3.6621e-04,\n",
       "           7.2098e-04, -3.5477e-04],\n",
       "         [-2.1362e-03,  1.2589e-03,  4.3335e-03,  ...,  3.4485e-03,\n",
       "           1.5793e-03,  2.7924e-03],\n",
       "         [-1.2131e-03,  2.2030e-04,  1.3657e-03,  ...,  1.3275e-03,\n",
       "           1.8768e-03,  8.4686e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.13.self_attn.q_proj.lora_A.weight': tensor([[-0.0092,  0.0123, -0.0093,  ..., -0.0103,  0.0001,  0.0038],\n",
       "         [ 0.0017,  0.0011, -0.0055,  ..., -0.0116,  0.0089, -0.0032],\n",
       "         [-0.0017,  0.0032, -0.0022,  ...,  0.0113, -0.0087, -0.0039],\n",
       "         ...,\n",
       "         [-0.0067,  0.0082,  0.0002,  ..., -0.0111, -0.0050,  0.0098],\n",
       "         [-0.0126,  0.0071, -0.0041,  ...,  0.0018,  0.0041, -0.0088],\n",
       "         [ 0.0099,  0.0088, -0.0090,  ...,  0.0100, -0.0038,  0.0026]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.13.self_attn.q_proj.lora_B.weight': tensor([[-7.0572e-04, -3.4790e-03,  1.6708e-03,  ...,  1.5259e-03,\n",
       "           1.1265e-05, -4.1199e-04],\n",
       "         [ 2.7275e-04,  1.4801e-03, -1.7395e-03,  ..., -9.0027e-04,\n",
       "          -4.5013e-04,  2.2125e-03],\n",
       "         [-2.1515e-03,  1.7014e-03, -9.8419e-04,  ...,  1.6174e-03,\n",
       "           4.7302e-04,  1.8921e-03],\n",
       "         ...,\n",
       "         [ 2.5635e-03,  9.8419e-04, -9.3842e-04,  ...,  6.7902e-04,\n",
       "           8.0109e-04, -1.6785e-03],\n",
       "         [ 3.1233e-05,  6.7139e-04, -1.9360e-04,  ..., -1.2112e-04,\n",
       "          -1.7166e-03, -1.5335e-03],\n",
       "         [-6.5994e-04,  4.0817e-04,  8.9264e-04,  ...,  1.2436e-03,\n",
       "          -7.9632e-05,  2.3804e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.13.self_attn.v_proj.lora_A.weight': tensor([[-0.0004, -0.0112, -0.0103,  ...,  0.0010,  0.0100,  0.0147],\n",
       "         [ 0.0093, -0.0124, -0.0081,  ...,  0.0055,  0.0007, -0.0092],\n",
       "         [-0.0100, -0.0030,  0.0090,  ..., -0.0025, -0.0014,  0.0110],\n",
       "         ...,\n",
       "         [-0.0111, -0.0156,  0.0072,  ..., -0.0114,  0.0047, -0.0069],\n",
       "         [-0.0100,  0.0083, -0.0082,  ..., -0.0071,  0.0142,  0.0074],\n",
       "         [-0.0136, -0.0052, -0.0043,  ...,  0.0125, -0.0010,  0.0049]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.13.self_attn.v_proj.lora_B.weight': tensor([[ 5.2261e-04,  4.4250e-03,  1.4877e-03,  ...,  1.8501e-04,\n",
       "           9.6512e-04, -4.4250e-04],\n",
       "         [ 5.4932e-04,  2.5330e-03,  8.6784e-05,  ..., -8.5449e-04,\n",
       "           9.0408e-04, -3.8528e-04],\n",
       "         [-7.0572e-04,  2.2736e-03,  2.9945e-04,  ..., -1.9836e-03,\n",
       "           3.3760e-04,  5.9509e-04],\n",
       "         ...,\n",
       "         [-1.4801e-03, -1.2589e-03, -1.2741e-03,  ..., -2.0447e-03,\n",
       "          -1.2970e-03,  3.0060e-03],\n",
       "         [ 1.5564e-03,  9.8419e-04,  1.2741e-03,  ...,  1.0757e-03,\n",
       "           2.8381e-03, -1.9684e-03],\n",
       "         [-1.2131e-03,  2.0409e-04, -2.5368e-04,  ..., -2.7084e-04,\n",
       "          -8.8501e-04, -1.1215e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.14.mlp.down_proj.lora_A.weight': tensor([[ 5.2490e-03, -2.0294e-03,  8.1635e-04,  ...,  7.0190e-03,\n",
       "           6.5308e-03, -8.2397e-03],\n",
       "         [ 6.0425e-03,  6.9046e-04,  1.9379e-03,  ..., -2.5787e-03,\n",
       "          -6.2256e-03, -5.7220e-04],\n",
       "         [-8.2493e-05,  8.6060e-03, -1.1719e-02,  ...,  7.4768e-03,\n",
       "           3.3379e-04,  4.9133e-03],\n",
       "         ...,\n",
       "         [-4.1199e-03,  6.5002e-03,  9.9487e-03,  ..., -6.6833e-03,\n",
       "          -3.6774e-03,  2.1820e-03],\n",
       "         [-7.8583e-04, -6.7444e-03, -4.2419e-03,  ..., -4.8523e-03,\n",
       "          -1.9684e-03, -1.7929e-03],\n",
       "         [ 5.6763e-03,  6.7749e-03, -7.6599e-03,  ..., -3.7766e-04,\n",
       "           1.0681e-02,  6.1951e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.14.mlp.down_proj.lora_B.weight': tensor([[ 5.5313e-04, -1.5030e-03, -2.5558e-04,  ..., -5.9509e-04,\n",
       "           1.5488e-03, -4.1199e-04],\n",
       "         [-4.6921e-04,  2.1935e-04, -1.1444e-03,  ..., -6.5994e-04,\n",
       "           4.5204e-04, -2.6550e-03],\n",
       "         [-2.1973e-03, -2.0447e-03, -8.6212e-04,  ...,  1.1292e-03,\n",
       "           8.2779e-04,  3.8338e-04],\n",
       "         ...,\n",
       "         [ 1.8997e-03, -1.4572e-03,  2.9449e-03,  ..., -4.4861e-03,\n",
       "           2.8610e-05,  1.1978e-03],\n",
       "         [-5.1880e-04, -2.4261e-03, -2.0142e-03,  ..., -2.1267e-04,\n",
       "          -2.3937e-04, -2.3346e-03],\n",
       "         [ 1.8692e-03, -1.2064e-04,  1.5831e-04,  ..., -5.3787e-04,\n",
       "          -1.4572e-03,  3.5477e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.14.mlp.gate_proj.lora_A.weight': tensor([[-0.0003, -0.0142, -0.0172,  ...,  0.0046, -0.0053,  0.0040],\n",
       "         [-0.0003,  0.0099, -0.0009,  ..., -0.0144, -0.0079, -0.0030],\n",
       "         [ 0.0101,  0.0031,  0.0082,  ..., -0.0142, -0.0132,  0.0032],\n",
       "         ...,\n",
       "         [-0.0056, -0.0012, -0.0078,  ...,  0.0056, -0.0078, -0.0008],\n",
       "         [ 0.0160,  0.0027,  0.0138,  ..., -0.0071, -0.0047,  0.0047],\n",
       "         [ 0.0065,  0.0044, -0.0160,  ..., -0.0103, -0.0074,  0.0126]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.14.mlp.gate_proj.lora_B.weight': tensor([[-2.1515e-03, -1.6632e-03, -6.3705e-04,  ...,  9.5749e-04,\n",
       "          -1.6403e-03,  5.6076e-04],\n",
       "         [ 3.3760e-04,  1.0223e-03,  3.5706e-03,  ..., -9.1076e-05,\n",
       "           1.7242e-03, -1.7262e-04],\n",
       "         [-2.3746e-04, -1.0605e-03,  2.5635e-03,  ..., -1.5354e-04,\n",
       "           8.0109e-04,  1.0605e-03],\n",
       "         ...,\n",
       "         [-2.5787e-03, -2.5482e-03, -1.8768e-03,  ..., -1.9741e-04,\n",
       "          -2.2583e-03,  2.6512e-04],\n",
       "         [ 1.2970e-03,  2.1667e-03,  2.7847e-04,  ..., -2.1553e-04,\n",
       "           2.3193e-03,  9.7275e-04],\n",
       "         [-2.7466e-03, -8.8882e-04, -6.7520e-04,  ..., -1.2131e-03,\n",
       "           1.1673e-03, -2.2583e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.14.mlp.up_proj.lora_A.weight': tensor([[ 0.0010,  0.0032, -0.0033,  ..., -0.0136,  0.0016, -0.0057],\n",
       "         [ 0.0126,  0.0063,  0.0008,  ...,  0.0115,  0.0088, -0.0081],\n",
       "         [-0.0038,  0.0012,  0.0022,  ..., -0.0065, -0.0032, -0.0036],\n",
       "         ...,\n",
       "         [ 0.0142,  0.0123,  0.0103,  ...,  0.0108, -0.0118, -0.0121],\n",
       "         [ 0.0137,  0.0084,  0.0024,  ...,  0.0157, -0.0039, -0.0011],\n",
       "         [ 0.0012,  0.0142,  0.0002,  ..., -0.0131, -0.0122,  0.0001]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.14.mlp.up_proj.lora_B.weight': tensor([[-5.3024e-04, -3.9291e-04,  5.0735e-04,  ...,  1.0681e-03,\n",
       "          -2.5177e-04,  3.6926e-03],\n",
       "         [-1.8005e-03, -6.0272e-04, -1.5564e-03,  ...,  2.4719e-03,\n",
       "          -6.1035e-04, -2.8381e-03],\n",
       "         [ 1.1520e-03, -1.6861e-03,  2.7008e-03,  ...,  3.1948e-05,\n",
       "          -1.2779e-04,  1.4496e-03],\n",
       "         ...,\n",
       "         [-2.3556e-04,  2.5177e-04, -4.5395e-04,  ...,  2.6131e-04,\n",
       "           3.2959e-03, -7.9727e-04],\n",
       "         [ 2.3651e-03,  3.8338e-04,  9.1171e-04,  ...,  2.6245e-03,\n",
       "           2.2316e-04, -2.5940e-03],\n",
       "         [ 1.0147e-03,  2.4319e-04, -1.7242e-03,  ...,  7.2861e-04,\n",
       "           3.9368e-03,  2.8229e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.14.self_attn.k_proj.lora_A.weight': tensor([[-6.2256e-03, -1.4893e-02, -6.6528e-03,  ..., -1.4526e-02,\n",
       "          -1.4404e-02,  4.7913e-03],\n",
       "         [-5.1270e-03,  1.0986e-02,  1.5198e-02,  ...,  2.9922e-05,\n",
       "          -8.1253e-04, -1.1108e-02],\n",
       "         [ 1.0498e-02,  1.1780e-02, -4.1199e-03,  ..., -2.9755e-03,\n",
       "           1.7242e-03, -5.4932e-03],\n",
       "         ...,\n",
       "         [ 1.2451e-02, -1.7212e-02, -1.7212e-02,  ...,  9.0332e-03,\n",
       "           3.4790e-03,  1.3977e-02],\n",
       "         [-1.1169e-02, -1.2085e-02, -1.1475e-02,  ...,  6.5918e-03,\n",
       "          -1.9646e-04, -3.4332e-03],\n",
       "         [ 4.2725e-03, -1.2451e-02,  1.5076e-02,  ..., -2.4796e-04,\n",
       "          -1.4771e-02,  6.6223e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.14.self_attn.k_proj.lora_B.weight': tensor([[ 1.5182e-03,  4.2200e-05, -2.3174e-04,  ...,  1.4725e-03,\n",
       "           9.0790e-04,  3.7193e-04],\n",
       "         [ 4.7112e-04,  1.2207e-03, -1.9836e-03,  ..., -3.8147e-04,\n",
       "           1.0223e-03, -6.9809e-04],\n",
       "         [-1.2054e-03,  4.6730e-04,  2.3346e-03,  ..., -1.2665e-03,\n",
       "           2.0905e-03,  1.2054e-03],\n",
       "         ...,\n",
       "         [-5.6076e-04,  1.2360e-03, -1.6174e-03,  ..., -1.9150e-03,\n",
       "          -1.0071e-03,  1.4725e-03],\n",
       "         [ 5.4550e-04, -1.2207e-03, -9.5749e-04,  ..., -8.5831e-04,\n",
       "           2.3556e-04, -2.3079e-04],\n",
       "         [-2.5940e-03, -2.1515e-03, -3.3417e-03,  ..., -2.4109e-03,\n",
       "          -2.5635e-03,  2.2278e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.14.self_attn.o_proj.lora_A.weight': tensor([[-1.1414e-02,  9.0332e-03,  6.1340e-03,  ...,  3.0060e-03,\n",
       "          -1.3275e-03, -1.2268e-02],\n",
       "         [ 1.4954e-02,  1.0315e-02,  5.1270e-03,  ...,  1.5869e-03,\n",
       "          -1.0452e-03, -1.1673e-03],\n",
       "         [-4.0770e-05,  7.3547e-03,  2.0294e-03,  ...,  3.0518e-03,\n",
       "          -7.1335e-04, -9.7656e-03],\n",
       "         ...,\n",
       "         [ 1.6724e-02,  5.6763e-03, -9.5825e-03,  ...,  6.6833e-03,\n",
       "           9.5215e-03, -1.4038e-02],\n",
       "         [ 6.9580e-03,  1.1536e-02, -9.2773e-03,  ...,  1.2512e-02,\n",
       "          -4.4861e-03,  1.5198e-02],\n",
       "         [-7.4463e-03, -2.0752e-03,  6.3477e-03,  ..., -1.1963e-02,\n",
       "          -3.0060e-03, -1.1658e-02]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.14.self_attn.o_proj.lora_B.weight': tensor([[-1.1749e-03, -7.1335e-04, -6.2943e-04,  ...,  1.1749e-03,\n",
       "          -1.8692e-03, -1.5182e-03],\n",
       "         [-1.8005e-03,  2.2888e-03,  3.9101e-04,  ...,  5.2261e-04,\n",
       "           2.7313e-03,  2.5635e-03],\n",
       "         [-9.0790e-04,  2.2278e-03, -3.3875e-03,  ...,  5.4169e-04,\n",
       "          -7.0953e-04,  2.3499e-03],\n",
       "         ...,\n",
       "         [ 2.3193e-03,  3.2806e-03,  4.4060e-04,  ..., -1.2207e-04,\n",
       "           6.8665e-04, -1.0452e-03],\n",
       "         [-4.7302e-04,  5.7602e-04,  3.7432e-05,  ..., -4.1580e-04,\n",
       "          -1.2302e-04,  3.8910e-04],\n",
       "         [ 5.4550e-04,  8.6212e-04, -1.9836e-03,  ..., -2.0027e-05,\n",
       "           7.0953e-04, -1.7319e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.14.self_attn.q_proj.lora_A.weight': tensor([[-0.0074, -0.0015,  0.0027,  ..., -0.0120, -0.0127,  0.0016],\n",
       "         [-0.0052,  0.0059,  0.0058,  ...,  0.0170, -0.0023,  0.0047],\n",
       "         [ 0.0016,  0.0109, -0.0076,  ..., -0.0104, -0.0089, -0.0025],\n",
       "         ...,\n",
       "         [-0.0039,  0.0052, -0.0095,  ..., -0.0138,  0.0078, -0.0093],\n",
       "         [ 0.0151,  0.0033,  0.0139,  ..., -0.0073, -0.0134, -0.0033],\n",
       "         [-0.0159, -0.0131, -0.0008,  ..., -0.0092, -0.0049,  0.0028]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.14.self_attn.q_proj.lora_B.weight': tensor([[-7.9346e-04,  8.9264e-04, -1.9150e-03,  ...,  1.1873e-04,\n",
       "           1.6403e-04,  8.1539e-05],\n",
       "         [ 1.5564e-03, -2.6131e-04,  4.0054e-04,  ...,  6.6757e-04,\n",
       "          -5.0545e-05, -4.0054e-04],\n",
       "         [-1.7395e-03, -1.2817e-03, -5.6458e-04,  ..., -6.1417e-04,\n",
       "           5.9307e-06, -8.0109e-04],\n",
       "         ...,\n",
       "         [ 1.2207e-03, -1.8082e-03,  8.1253e-04,  ..., -3.6240e-04,\n",
       "           1.2665e-03,  9.5844e-05],\n",
       "         [-9.2316e-04,  6.5231e-04, -1.8158e-03,  ...,  9.8419e-04,\n",
       "          -1.6708e-03, -1.5259e-03],\n",
       "         [-1.4420e-03,  6.7520e-04, -3.1586e-03,  ...,  2.5482e-03,\n",
       "          -1.4038e-03,  5.3406e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.14.self_attn.v_proj.lora_A.weight': tensor([[-6.8188e-05, -1.1292e-02, -1.2878e-02,  ...,  1.0010e-02,\n",
       "           1.2894e-03,  4.6997e-03],\n",
       "         [-6.4392e-03, -1.2817e-02, -1.5320e-02,  ..., -1.3428e-02,\n",
       "          -1.5747e-02, -5.3711e-03],\n",
       "         [-1.1719e-02,  5.8289e-03, -1.5747e-02,  ..., -1.3062e-02,\n",
       "          -1.7090e-03,  1.2573e-02],\n",
       "         ...,\n",
       "         [-1.3062e-02,  1.4343e-03, -1.0300e-03,  ..., -2.6093e-03,\n",
       "          -5.6458e-04,  8.6670e-03],\n",
       "         [ 1.5335e-03,  1.3306e-02,  3.6011e-03,  ..., -1.2207e-02,\n",
       "           3.5400e-03, -5.6458e-03],\n",
       "         [ 4.6082e-03, -3.1891e-03, -3.5706e-03,  ...,  1.4648e-03,\n",
       "          -1.7624e-03, -9.2773e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.14.self_attn.v_proj.lora_B.weight': tensor([[-1.1597e-03,  1.8387e-03,  8.3447e-05,  ..., -7.8964e-04,\n",
       "          -3.6049e-04,  8.5068e-04],\n",
       "         [ 5.0354e-04,  4.3678e-04,  4.6158e-04,  ..., -4.0436e-04,\n",
       "           1.4572e-03, -4.2915e-05],\n",
       "         [ 9.8419e-04,  1.4801e-03, -5.2643e-04,  ...,  8.8501e-04,\n",
       "           2.1744e-04,  1.8954e-05],\n",
       "         ...,\n",
       "         [-5.1117e-04, -1.1063e-03, -1.6327e-03,  ..., -9.6130e-04,\n",
       "          -6.1417e-04, -5.4169e-04],\n",
       "         [-1.0834e-03, -1.5106e-03, -1.3733e-03,  ..., -5.4550e-04,\n",
       "          -1.0681e-03, -2.8687e-03],\n",
       "         [ 1.2741e-03,  3.5858e-04,  5.9366e-05,  ...,  1.6785e-03,\n",
       "           1.2054e-03, -1.7929e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.15.mlp.down_proj.lora_A.weight': tensor([[ 0.0004, -0.0029, -0.0081,  ..., -0.0028, -0.0014, -0.0045],\n",
       "         [-0.0057, -0.0062,  0.0029,  ..., -0.0040,  0.0093,  0.0078],\n",
       "         [ 0.0006, -0.0069, -0.0078,  ..., -0.0083, -0.0039,  0.0041],\n",
       "         ...,\n",
       "         [ 0.0125,  0.0066,  0.0062,  ...,  0.0020,  0.0019, -0.0086],\n",
       "         [-0.0013, -0.0049, -0.0076,  ...,  0.0006, -0.0035,  0.0040],\n",
       "         [-0.0047, -0.0073, -0.0056,  ..., -0.0005,  0.0033,  0.0089]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.15.mlp.down_proj.lora_B.weight': tensor([[ 9.8419e-04,  9.0790e-04,  1.6022e-03,  ...,  5.0735e-04,\n",
       "          -7.3910e-05,  1.7090e-03],\n",
       "         [-2.4872e-03,  2.9182e-04, -7.6294e-04,  ...,  7.0572e-04,\n",
       "           4.0588e-03,  1.9150e-03],\n",
       "         [-1.4343e-03,  1.8005e-03, -3.1128e-03,  ...,  1.4954e-03,\n",
       "           2.6245e-03, -6.2943e-04],\n",
       "         ...,\n",
       "         [-2.8839e-03,  3.0060e-03, -7.7820e-04,  ..., -3.2501e-03,\n",
       "          -8.9264e-04, -1.8005e-03],\n",
       "         [-4.9438e-03,  1.7776e-03, -9.0408e-04,  ..., -1.7700e-03,\n",
       "           3.5286e-04,  1.7776e-03],\n",
       "         [-2.8534e-03, -6.2943e-04,  5.2261e-04,  ...,  1.0376e-03,\n",
       "           2.9144e-03, -6.1512e-05]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.15.mlp.gate_proj.lora_A.weight': tensor([[ 1.4954e-02, -2.4261e-03,  1.2451e-02,  ...,  8.5449e-04,\n",
       "          -1.4160e-02, -1.2329e-02],\n",
       "         [ 6.6833e-03,  1.8555e-02, -1.2329e-02,  ..., -1.9897e-02,\n",
       "          -1.6235e-02,  1.1292e-02],\n",
       "         [ 1.0193e-02,  1.1047e-02,  1.1597e-02,  ..., -9.3079e-04,\n",
       "          -1.1719e-02,  1.5564e-02],\n",
       "         ...,\n",
       "         [-8.8501e-03, -1.4709e-02, -2.1362e-03,  ..., -1.0010e-02,\n",
       "           8.9111e-03, -7.2937e-03],\n",
       "         [ 1.0681e-02, -4.1199e-03, -1.0437e-02,  ..., -1.1108e-02,\n",
       "           6.1340e-03,  3.7842e-03],\n",
       "         [ 1.0925e-02,  2.2292e-05, -2.2125e-03,  ..., -5.1270e-03,\n",
       "          -1.2024e-02, -1.8433e-02]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.15.mlp.gate_proj.lora_B.weight': tensor([[ 8.8501e-04, -9.1934e-04,  1.1215e-03,  ...,  2.0599e-03,\n",
       "           1.7471e-03, -4.5776e-03],\n",
       "         [ 3.0518e-03,  3.4332e-03,  1.6093e-05,  ..., -2.2030e-04,\n",
       "           1.7319e-03,  1.4648e-03],\n",
       "         [ 1.8463e-03, -3.9062e-03,  1.1597e-03,  ...,  2.5940e-04,\n",
       "          -1.4114e-04,  1.3351e-03],\n",
       "         ...,\n",
       "         [ 1.8692e-03,  7.6294e-04,  1.9302e-03,  ..., -3.5095e-04,\n",
       "          -2.1973e-03,  1.5182e-03],\n",
       "         [-2.7924e-03, -1.5640e-03,  7.2098e-04,  ..., -8.8501e-04,\n",
       "          -8.0490e-04, -1.2741e-03],\n",
       "         [-4.0627e-04, -1.9836e-04, -1.7242e-03,  ..., -2.0447e-03,\n",
       "           8.9645e-04, -1.2817e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.15.mlp.up_proj.lora_A.weight': tensor([[ 0.0056, -0.0033,  0.0161,  ..., -0.0062, -0.0113, -0.0034],\n",
       "         [ 0.0038,  0.0141, -0.0081,  ...,  0.0051, -0.0110, -0.0106],\n",
       "         [ 0.0084, -0.0011,  0.0127,  ...,  0.0109,  0.0053, -0.0089],\n",
       "         ...,\n",
       "         [-0.0080, -0.0069, -0.0115,  ..., -0.0040, -0.0068,  0.0007],\n",
       "         [ 0.0059, -0.0046,  0.0132,  ...,  0.0118,  0.0050,  0.0003],\n",
       "         [ 0.0081, -0.0015,  0.0046,  ...,  0.0027,  0.0098,  0.0103]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.15.mlp.up_proj.lora_B.weight': tensor([[ 1.4725e-03,  2.1935e-04, -2.6550e-03,  ...,  7.0572e-04,\n",
       "          -3.3569e-04,  2.9445e-05],\n",
       "         [ 3.7384e-03, -2.6703e-03, -2.0752e-03,  ..., -2.5787e-03,\n",
       "          -3.2349e-03, -2.0447e-03],\n",
       "         [ 4.2152e-04, -2.0447e-03, -4.2725e-04,  ..., -1.1683e-04,\n",
       "           1.2207e-03, -8.8120e-04],\n",
       "         ...,\n",
       "         [ 2.0752e-03, -9.9182e-05, -2.6093e-03,  ...,  4.0283e-03,\n",
       "           3.8300e-03, -5.8365e-04],\n",
       "         [-1.5030e-03, -2.2125e-03, -6.7902e-04,  ...,  2.0599e-03,\n",
       "          -1.2283e-03, -1.6403e-03],\n",
       "         [ 1.4648e-03,  2.1210e-03, -9.2697e-04,  ..., -1.2665e-03,\n",
       "          -4.9438e-03, -3.8719e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.15.self_attn.k_proj.lora_A.weight': tensor([[-1.5076e-02, -1.5869e-02,  5.1575e-03,  ...,  4.2114e-03,\n",
       "           5.0354e-04,  6.0425e-03],\n",
       "         [ 3.1891e-03, -4.3335e-03,  5.7068e-03,  ..., -1.3672e-02,\n",
       "          -3.3379e-05, -1.2360e-03],\n",
       "         [-1.0681e-02,  6.6528e-03,  9.8877e-03,  ...,  7.4768e-04,\n",
       "          -3.7384e-03,  1.3672e-02],\n",
       "         ...,\n",
       "         [-1.4221e-02,  1.5869e-03, -1.1230e-02,  ..., -1.1414e-02,\n",
       "           8.9111e-03,  9.7046e-03],\n",
       "         [-1.1780e-02,  3.0670e-03, -1.3245e-02,  ...,  7.5378e-03,\n",
       "           1.4282e-02,  7.3547e-03],\n",
       "         [-1.3062e-02, -1.0864e-02, -1.3916e-02,  ..., -3.7842e-03,\n",
       "           2.5177e-03, -3.6774e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.15.self_attn.k_proj.lora_B.weight': tensor([[ 3.0136e-04, -3.1090e-04,  1.3962e-03,  ..., -1.4038e-03,\n",
       "           1.4496e-03, -3.6001e-05],\n",
       "         [ 1.5182e-03, -3.2806e-03,  1.1520e-03,  ..., -2.6398e-03,\n",
       "          -7.7057e-04, -1.9836e-03],\n",
       "         [ 6.1035e-04, -4.1723e-05,  5.1117e-04,  ...,  2.4261e-03,\n",
       "           2.5330e-03,  4.8218e-03],\n",
       "         ...,\n",
       "         [ 1.8768e-03,  1.2016e-04,  2.4986e-04,  ..., -2.5177e-03,\n",
       "          -2.8229e-04,  1.3733e-03],\n",
       "         [ 8.8120e-04, -1.6022e-03,  1.4648e-03,  ..., -1.4420e-03,\n",
       "           1.7548e-03, -1.1368e-03],\n",
       "         [-7.0572e-04, -1.8024e-04,  1.0395e-04,  ...,  2.7313e-03,\n",
       "          -5.0068e-05,  1.1349e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.15.self_attn.o_proj.lora_A.weight': tensor([[ 0.0040,  0.0118, -0.0164,  ...,  0.0086,  0.0040,  0.0034],\n",
       "         [-0.0052,  0.0135, -0.0157,  ..., -0.0034, -0.0018,  0.0135],\n",
       "         [ 0.0049, -0.0089, -0.0028,  ...,  0.0137,  0.0006, -0.0105],\n",
       "         ...,\n",
       "         [-0.0026,  0.0091, -0.0012,  ..., -0.0115,  0.0016,  0.0024],\n",
       "         [ 0.0161, -0.0019,  0.0125,  ...,  0.0133, -0.0063,  0.0147],\n",
       "         [-0.0092,  0.0083,  0.0056,  ...,  0.0004, -0.0176,  0.0008]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.15.self_attn.o_proj.lora_B.weight': tensor([[-1.0605e-03, -8.2397e-04, -5.3406e-04,  ..., -2.6512e-04,\n",
       "          -5.2795e-03,  2.0142e-03],\n",
       "         [ 6.8188e-05,  8.2397e-04,  2.7771e-03,  ..., -1.3809e-03,\n",
       "           6.2180e-04,  5.3406e-04],\n",
       "         [-9.3079e-04,  6.3324e-04,  2.8229e-03,  ..., -1.8921e-03,\n",
       "           2.0123e-04,  5.6152e-03],\n",
       "         ...,\n",
       "         [ 7.5150e-04, -4.0627e-04, -9.6512e-04,  ...,  7.3242e-04,\n",
       "           1.0071e-03, -3.5858e-04],\n",
       "         [-4.7493e-04,  7.8964e-04,  5.9891e-04,  ..., -1.0681e-03,\n",
       "          -4.0588e-03, -1.8215e-04],\n",
       "         [-1.0605e-03,  2.7008e-03,  1.1902e-03,  ..., -2.0599e-03,\n",
       "          -5.2643e-04,  1.0834e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.15.self_attn.q_proj.lora_A.weight': tensor([[-0.0197, -0.0032, -0.0011,  ..., -0.0038,  0.0033,  0.0179],\n",
       "         [ 0.0036,  0.0018, -0.0014,  ..., -0.0077,  0.0057, -0.0027],\n",
       "         [-0.0044,  0.0154, -0.0027,  ...,  0.0026,  0.0084, -0.0037],\n",
       "         ...,\n",
       "         [-0.0116,  0.0078, -0.0044,  ...,  0.0078,  0.0115,  0.0095],\n",
       "         [ 0.0123,  0.0114,  0.0040,  ..., -0.0007, -0.0048,  0.0041],\n",
       "         [-0.0004,  0.0079,  0.0020,  ..., -0.0030, -0.0105, -0.0056]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.15.self_attn.q_proj.lora_B.weight': tensor([[-2.7618e-03, -6.2561e-04, -2.5940e-04,  ...,  5.3406e-04,\n",
       "           1.0669e-05,  1.9836e-04],\n",
       "         [ 5.9891e-04,  3.9673e-04,  9.4223e-04,  ...,  3.0670e-03,\n",
       "          -1.0223e-03,  2.5787e-03],\n",
       "         [ 2.5177e-04,  2.0447e-03, -3.2616e-04,  ...,  9.7656e-04,\n",
       "          -3.9673e-04, -2.1210e-03],\n",
       "         ...,\n",
       "         [-1.4267e-03, -7.1335e-04, -4.7493e-04,  ..., -5.4550e-04,\n",
       "           7.0953e-04, -1.7452e-04],\n",
       "         [-6.2561e-04, -4.2725e-04, -1.4114e-03,  ..., -1.8921e-03,\n",
       "           3.1471e-04, -8.4686e-04],\n",
       "         [ 2.6321e-04, -1.9932e-04, -2.8610e-04,  ...,  1.8692e-04,\n",
       "           1.1292e-03,  1.8845e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.15.self_attn.v_proj.lora_A.weight': tensor([[ 0.0045, -0.0020, -0.0120,  ...,  0.0069, -0.0069,  0.0049],\n",
       "         [-0.0073, -0.0026, -0.0018,  ...,  0.0096, -0.0096,  0.0010],\n",
       "         [ 0.0129, -0.0129,  0.0110,  ...,  0.0043, -0.0057, -0.0005],\n",
       "         ...,\n",
       "         [ 0.0044,  0.0071,  0.0087,  ...,  0.0073, -0.0129,  0.0006],\n",
       "         [-0.0165, -0.0055, -0.0043,  ..., -0.0125,  0.0089, -0.0033],\n",
       "         [-0.0040, -0.0052, -0.0106,  ...,  0.0014, -0.0041,  0.0133]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.15.self_attn.v_proj.lora_B.weight': tensor([[-2.7313e-03,  2.1820e-03,  9.1553e-04,  ...,  4.5776e-03,\n",
       "          -2.4261e-03,  2.6093e-03],\n",
       "         [-1.4877e-04, -1.1063e-03,  2.7161e-03,  ..., -4.9973e-04,\n",
       "          -5.7983e-04, -5.6458e-04],\n",
       "         [-1.0910e-03,  1.8997e-03, -4.2725e-03,  ...,  6.8665e-04,\n",
       "          -1.0757e-03,  1.2207e-03],\n",
       "         ...,\n",
       "         [-2.1515e-03,  2.2888e-03,  3.7193e-04,  ...,  2.1515e-03,\n",
       "           3.5286e-05,  2.7275e-04],\n",
       "         [-1.2665e-03,  5.1880e-04,  1.2283e-03,  ..., -1.2665e-03,\n",
       "           4.1771e-04, -2.0905e-03],\n",
       "         [ 3.4790e-03, -2.3460e-04, -1.5411e-03,  ...,  1.1597e-03,\n",
       "          -4.6492e-05, -1.0605e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.16.mlp.down_proj.lora_A.weight': tensor([[ 0.0131,  0.0140,  0.0049,  ..., -0.0092,  0.0074, -0.0092],\n",
       "         [-0.0039, -0.0089,  0.0031,  ..., -0.0008,  0.0076, -0.0037],\n",
       "         [ 0.0098,  0.0114, -0.0096,  ...,  0.0076,  0.0069, -0.0030],\n",
       "         ...,\n",
       "         [ 0.0080,  0.0029,  0.0079,  ...,  0.0115,  0.0025,  0.0010],\n",
       "         [ 0.0025, -0.0007, -0.0053,  ...,  0.0045,  0.0012, -0.0006],\n",
       "         [-0.0076, -0.0040,  0.0030,  ...,  0.0060, -0.0066,  0.0042]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.16.mlp.down_proj.lora_B.weight': tensor([[-3.3112e-03,  2.6093e-03, -2.0599e-03,  ..., -6.5804e-05,\n",
       "           3.3951e-04,  2.3651e-04],\n",
       "         [ 9.8419e-04,  6.6376e-04, -2.2125e-03,  ..., -3.4142e-04,\n",
       "           4.8828e-04, -3.4142e-04],\n",
       "         [ 2.8229e-03, -3.1662e-04,  4.6730e-04,  ...,  4.9210e-04,\n",
       "          -2.1744e-04, -1.9150e-03],\n",
       "         ...,\n",
       "         [-1.7624e-03, -2.4414e-04, -3.8719e-04,  ..., -2.2583e-03,\n",
       "           9.3079e-04, -2.7924e-03],\n",
       "         [ 1.1749e-03,  3.1433e-03, -1.9073e-03,  ...,  1.8883e-04,\n",
       "          -2.2888e-03,  1.1301e-04],\n",
       "         [-9.2030e-05,  1.3657e-03, -1.1673e-03,  ..., -3.6774e-03,\n",
       "          -6.9046e-04, -2.0447e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.16.mlp.gate_proj.lora_A.weight': tensor([[-0.0069,  0.0146, -0.0119,  ...,  0.0054,  0.0075,  0.0077],\n",
       "         [-0.0048, -0.0011,  0.0079,  ...,  0.0030,  0.0012, -0.0127],\n",
       "         [ 0.0033, -0.0078,  0.0092,  ...,  0.0128,  0.0066, -0.0022],\n",
       "         ...,\n",
       "         [ 0.0031,  0.0085, -0.0139,  ...,  0.0084, -0.0146,  0.0138],\n",
       "         [-0.0054,  0.0034, -0.0047,  ..., -0.0037,  0.0165,  0.0004],\n",
       "         [ 0.0021, -0.0095,  0.0014,  ..., -0.0055,  0.0108,  0.0177]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.16.mlp.gate_proj.lora_B.weight': tensor([[ 3.2959e-03,  3.6240e-04,  3.3569e-04,  ..., -2.6703e-03,\n",
       "          -1.5335e-03, -2.1820e-03],\n",
       "         [-6.5994e-04, -1.3962e-03,  6.5231e-04,  ...,  2.0752e-03,\n",
       "          -1.8005e-03,  1.0586e-04],\n",
       "         [-5.6076e-04, -9.3842e-04,  5.9891e-04,  ..., -5.3024e-04,\n",
       "          -1.5869e-03,  1.7776e-03],\n",
       "         ...,\n",
       "         [-9.6130e-04, -4.4584e-05,  2.5787e-03,  ..., -4.4632e-04,\n",
       "          -1.6327e-03,  1.1673e-03],\n",
       "         [-3.3875e-03,  8.2779e-04,  1.6937e-03,  ...,  3.4180e-03,\n",
       "          -3.1586e-03,  7.1049e-05],\n",
       "         [ 1.0910e-03,  7.5531e-04, -1.7014e-03,  ...,  1.0147e-03,\n",
       "           1.3962e-03,  4.1962e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.16.mlp.up_proj.lora_A.weight': tensor([[-0.0024,  0.0118,  0.0046,  ..., -0.0045, -0.0130,  0.0102],\n",
       "         [ 0.0128,  0.0066,  0.0128,  ...,  0.0038,  0.0067, -0.0159],\n",
       "         [ 0.0144, -0.0007, -0.0077,  ...,  0.0050,  0.0146, -0.0065],\n",
       "         ...,\n",
       "         [-0.0017,  0.0096, -0.0112,  ..., -0.0029,  0.0063,  0.0165],\n",
       "         [-0.0115, -0.0027, -0.0021,  ..., -0.0098, -0.0060,  0.0065],\n",
       "         [-0.0076,  0.0104,  0.0137,  ..., -0.0115, -0.0153,  0.0058]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.16.mlp.up_proj.lora_B.weight': tensor([[-8.3160e-04, -4.9591e-04, -1.2493e-04,  ..., -2.2278e-03,\n",
       "          -6.9046e-04,  8.3542e-04],\n",
       "         [ 2.6245e-03,  7.8964e-04,  3.2349e-03,  ...,  2.1973e-03,\n",
       "          -1.8005e-03, -3.1433e-03],\n",
       "         [-1.7929e-03,  1.1215e-03, -3.0518e-03,  ..., -1.2741e-03,\n",
       "           4.1962e-04,  1.0061e-04],\n",
       "         ...,\n",
       "         [ 1.1673e-03, -1.1063e-03,  1.8005e-03,  ...,  1.2970e-03,\n",
       "          -1.5106e-03, -8.1253e-04],\n",
       "         [ 1.5945e-03,  1.2512e-03,  1.8692e-03,  ...,  7.7724e-05,\n",
       "          -1.4420e-03, -1.7700e-03],\n",
       "         [-4.9973e-04, -5.2643e-04, -1.7776e-03,  ...,  1.4038e-03,\n",
       "          -9.2697e-04,  7.8583e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.16.self_attn.k_proj.lora_A.weight': tensor([[-0.0037, -0.0068,  0.0054,  ...,  0.0103, -0.0087, -0.0171],\n",
       "         [ 0.0162, -0.0162, -0.0121,  ...,  0.0125,  0.0062,  0.0045],\n",
       "         [-0.0038, -0.0063, -0.0094,  ...,  0.0099, -0.0057, -0.0123],\n",
       "         ...,\n",
       "         [ 0.0103, -0.0129, -0.0160,  ..., -0.0026,  0.0110, -0.0129],\n",
       "         [ 0.0129,  0.0159, -0.0129,  ...,  0.0165,  0.0060,  0.0008],\n",
       "         [-0.0134, -0.0160, -0.0097,  ..., -0.0087, -0.0103,  0.0079]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.16.self_attn.k_proj.lora_B.weight': tensor([[ 1.6403e-03,  4.0054e-04,  2.0905e-03,  ...,  3.3188e-04,\n",
       "           1.0605e-03, -1.6022e-03],\n",
       "         [ 2.0695e-04,  1.8692e-03,  1.6403e-03,  ...,  7.2098e-04,\n",
       "          -3.7384e-03,  3.4027e-03],\n",
       "         [ 3.4637e-03,  1.4648e-03,  7.5150e-04,  ..., -1.7548e-03,\n",
       "           9.3842e-04,  1.3065e-04],\n",
       "         ...,\n",
       "         [ 3.8910e-04, -4.3106e-04, -3.0756e-05,  ..., -9.7656e-04,\n",
       "           4.0588e-03, -7.0572e-04],\n",
       "         [-6.5613e-04, -1.8845e-03,  1.2512e-03,  ...,  4.6730e-04,\n",
       "          -7.0572e-04, -2.0599e-03],\n",
       "         [ 1.4343e-03, -2.6550e-03,  1.6098e-03,  ...,  2.9755e-04,\n",
       "           2.2054e-05,  9.6893e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.16.self_attn.o_proj.lora_A.weight': tensor([[-0.0078, -0.0047,  0.0071,  ..., -0.0055, -0.0143,  0.0089],\n",
       "         [-0.0130,  0.0038, -0.0142,  ...,  0.0099,  0.0070, -0.0084],\n",
       "         [-0.0030,  0.0052, -0.0043,  ..., -0.0102,  0.0051,  0.0093],\n",
       "         ...,\n",
       "         [-0.0051, -0.0010,  0.0073,  ...,  0.0128, -0.0094,  0.0093],\n",
       "         [-0.0054,  0.0090,  0.0015,  ...,  0.0123, -0.0070, -0.0088],\n",
       "         [ 0.0022, -0.0079, -0.0091,  ..., -0.0160,  0.0041, -0.0068]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.16.self_attn.o_proj.lora_B.weight': tensor([[ 1.2398e-04,  1.3580e-03, -4.8256e-04,  ...,  2.3041e-03,\n",
       "           1.2741e-03, -1.3962e-03],\n",
       "         [ 5.2261e-04,  1.8616e-03,  2.2278e-03,  ...,  4.1199e-03,\n",
       "           1.8005e-03, -1.4572e-03],\n",
       "         [ 1.8539e-03, -1.5945e-03, -7.6675e-04,  ..., -1.7319e-03,\n",
       "           1.6785e-03,  8.8120e-04],\n",
       "         ...,\n",
       "         [-9.8419e-04, -2.3499e-03, -5.4932e-04,  ..., -2.5635e-03,\n",
       "          -5.4169e-04, -2.8839e-03],\n",
       "         [ 2.4719e-03,  1.4019e-04,  3.2187e-05,  ...,  4.3335e-03,\n",
       "           1.6708e-03,  4.5967e-04],\n",
       "         [-1.4420e-03, -2.4261e-03,  1.4648e-03,  ..., -8.8882e-04,\n",
       "           5.9128e-04, -7.7057e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.16.self_attn.q_proj.lora_A.weight': tensor([[ 0.0068, -0.0156,  0.0095,  ..., -0.0040,  0.0095, -0.0121],\n",
       "         [-0.0033,  0.0016,  0.0135,  ...,  0.0106,  0.0188, -0.0001],\n",
       "         [-0.0161, -0.0037, -0.0044,  ...,  0.0116, -0.0074,  0.0084],\n",
       "         ...,\n",
       "         [-0.0021,  0.0025, -0.0049,  ..., -0.0089,  0.0106,  0.0084],\n",
       "         [-0.0089,  0.0093,  0.0022,  ..., -0.0047, -0.0112,  0.0041],\n",
       "         [-0.0131, -0.0147, -0.0095,  ...,  0.0007,  0.0046,  0.0082]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.16.self_attn.q_proj.lora_B.weight': tensor([[ 2.3041e-03, -1.2207e-03, -1.5030e-03,  ..., -2.4567e-03,\n",
       "          -7.7724e-05, -5.9509e-04],\n",
       "         [ 1.3351e-03,  6.4850e-04,  3.9816e-05,  ...,  1.0910e-03,\n",
       "          -1.1673e-03,  9.3460e-04],\n",
       "         [ 7.3242e-04, -5.7983e-04, -2.9373e-04,  ..., -3.8147e-04,\n",
       "           2.0294e-03,  9.7656e-04],\n",
       "         ...,\n",
       "         [-1.1749e-03,  1.4801e-03, -6.7902e-04,  ...,  2.2125e-03,\n",
       "           7.6294e-04, -4.7874e-04],\n",
       "         [-1.1673e-03, -2.4223e-04, -1.0834e-03,  ..., -2.1362e-03,\n",
       "           7.1716e-04, -3.1433e-03],\n",
       "         [ 1.1902e-03,  2.4033e-04,  1.7014e-03,  ..., -1.1749e-03,\n",
       "          -8.8120e-04, -3.9482e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.16.self_attn.v_proj.lora_A.weight': tensor([[-0.0029,  0.0116, -0.0105,  ..., -0.0026,  0.0140, -0.0064],\n",
       "         [ 0.0064,  0.0146,  0.0096,  ...,  0.0082, -0.0110, -0.0099],\n",
       "         [-0.0022, -0.0131,  0.0134,  ...,  0.0012,  0.0123,  0.0053],\n",
       "         ...,\n",
       "         [-0.0007,  0.0031, -0.0044,  ..., -0.0109,  0.0018,  0.0132],\n",
       "         [ 0.0114,  0.0100,  0.0042,  ..., -0.0114,  0.0065, -0.0091],\n",
       "         [ 0.0104, -0.0049, -0.0005,  ...,  0.0029, -0.0110,  0.0006]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.16.self_attn.v_proj.lora_B.weight': tensor([[-8.8120e-04, -1.7471e-03,  3.8147e-04,  ..., -1.4114e-03,\n",
       "           3.7384e-04, -6.3896e-05],\n",
       "         [-1.2360e-03,  1.1673e-03,  5.7220e-04,  ...,  7.0190e-04,\n",
       "           1.4267e-03,  2.5482e-03],\n",
       "         [ 4.2114e-03, -5.7602e-04,  1.7776e-03,  ...,  1.3924e-04,\n",
       "          -6.9427e-04, -1.3046e-03],\n",
       "         ...,\n",
       "         [-4.0283e-03,  2.5482e-03, -2.2583e-03,  ...,  2.1839e-04,\n",
       "           6.7520e-04, -4.4823e-04],\n",
       "         [-1.9150e-03,  1.6556e-03, -1.6403e-03,  ..., -1.4954e-03,\n",
       "          -5.7602e-04,  8.6975e-04],\n",
       "         [-2.3651e-03,  2.8076e-03,  4.9973e-04,  ...,  5.6839e-04,\n",
       "           8.5831e-04, -4.1962e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.17.mlp.down_proj.lora_A.weight': tensor([[-0.0020, -0.0064,  0.0079,  ..., -0.0014, -0.0073, -0.0008],\n",
       "         [ 0.0033, -0.0115, -0.0069,  ...,  0.0047, -0.0052,  0.0119],\n",
       "         [ 0.0045, -0.0001, -0.0081,  ..., -0.0028, -0.0104, -0.0004],\n",
       "         ...,\n",
       "         [ 0.0063,  0.0056,  0.0047,  ..., -0.0001,  0.0094,  0.0089],\n",
       "         [ 0.0066,  0.0036,  0.0070,  ..., -0.0083, -0.0038, -0.0029],\n",
       "         [ 0.0022, -0.0050,  0.0073,  ..., -0.0031,  0.0002,  0.0087]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.17.mlp.down_proj.lora_B.weight': tensor([[-6.7902e-04, -1.7929e-03, -7.0190e-04,  ...,  1.0147e-03,\n",
       "          -1.0529e-03,  1.5106e-03],\n",
       "         [-2.3651e-03, -2.4719e-03, -5.4550e-04,  ...,  4.9591e-04,\n",
       "           4.8256e-04,  9.9182e-04],\n",
       "         [ 1.5869e-03, -9.6130e-04, -5.5695e-04,  ...,  1.5106e-03,\n",
       "           2.1553e-04,  3.2501e-03],\n",
       "         ...,\n",
       "         [-1.2131e-03,  4.2114e-03, -1.5335e-03,  ...,  1.7319e-03,\n",
       "           1.9226e-03,  2.5482e-03],\n",
       "         [-1.0014e-05, -3.0136e-04, -8.6784e-05,  ..., -1.3657e-03,\n",
       "          -1.2054e-03,  7.1335e-04],\n",
       "         [-1.0986e-03, -1.2131e-03, -1.3962e-03,  ..., -9.6512e-04,\n",
       "           1.4038e-03,  3.1433e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.17.mlp.gate_proj.lora_A.weight': tensor([[ 0.0035, -0.0069, -0.0029,  ...,  0.0117,  0.0129,  0.0079],\n",
       "         [-0.0027, -0.0137,  0.0128,  ..., -0.0006,  0.0084, -0.0039],\n",
       "         [ 0.0084, -0.0087,  0.0020,  ..., -0.0199, -0.0101, -0.0012],\n",
       "         ...,\n",
       "         [-0.0092,  0.0105,  0.0106,  ..., -0.0153, -0.0007,  0.0014],\n",
       "         [-0.0053,  0.0168, -0.0067,  ..., -0.0002, -0.0010, -0.0104],\n",
       "         [-0.0042, -0.0179,  0.0022,  ..., -0.0085, -0.0002, -0.0159]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.17.mlp.gate_proj.lora_B.weight': tensor([[-2.6512e-04, -3.1281e-04,  5.7983e-04,  ...,  3.2501e-03,\n",
       "           9.1171e-04, -1.2283e-03],\n",
       "         [ 1.8234e-03, -2.0905e-03, -2.0905e-03,  ..., -1.0605e-03,\n",
       "           1.3924e-04, -2.1744e-04],\n",
       "         [-5.6458e-04, -4.3869e-04, -1.8082e-03,  ..., -6.8665e-04,\n",
       "           1.1215e-03,  5.6839e-04],\n",
       "         ...,\n",
       "         [-2.7924e-03,  2.9182e-04,  7.8964e-04,  ..., -1.4877e-03,\n",
       "           6.5804e-05, -3.0212e-03],\n",
       "         [-7.8678e-05, -7.1335e-04,  1.5259e-04,  ...,  1.5945e-03,\n",
       "          -2.4872e-03, -1.7014e-03],\n",
       "         [ 7.9727e-04,  3.6240e-04,  2.3079e-04,  ..., -1.8234e-03,\n",
       "           2.8038e-04,  2.3651e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.17.mlp.up_proj.lora_A.weight': tensor([[-0.0120, -0.0060,  0.0041,  ..., -0.0095,  0.0061,  0.0065],\n",
       "         [ 0.0104, -0.0013,  0.0070,  ..., -0.0068, -0.0022, -0.0009],\n",
       "         [ 0.0172,  0.0071,  0.0009,  ...,  0.0075,  0.0117, -0.0139],\n",
       "         ...,\n",
       "         [ 0.0013,  0.0149, -0.0032,  ..., -0.0199,  0.0092, -0.0052],\n",
       "         [ 0.0020,  0.0148,  0.0057,  ..., -0.0025, -0.0056, -0.0063],\n",
       "         [ 0.0098, -0.0016, -0.0129,  ..., -0.0112,  0.0143,  0.0024]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.17.mlp.up_proj.lora_B.weight': tensor([[ 0.0018,  0.0020, -0.0020,  ...,  0.0015,  0.0016,  0.0007],\n",
       "         [ 0.0021,  0.0014,  0.0008,  ...,  0.0020,  0.0003,  0.0012],\n",
       "         [-0.0017,  0.0015,  0.0015,  ...,  0.0018,  0.0022,  0.0022],\n",
       "         ...,\n",
       "         [ 0.0012,  0.0007, -0.0024,  ...,  0.0021, -0.0015,  0.0003],\n",
       "         [-0.0002, -0.0014,  0.0012,  ..., -0.0023,  0.0009, -0.0018],\n",
       "         [ 0.0022, -0.0010,  0.0002,  ..., -0.0004,  0.0009, -0.0006]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.17.self_attn.k_proj.lora_A.weight': tensor([[ 0.0019,  0.0140, -0.0027,  ..., -0.0064, -0.0059,  0.0129],\n",
       "         [ 0.0098,  0.0123, -0.0161,  ..., -0.0151,  0.0103, -0.0060],\n",
       "         [-0.0110, -0.0113, -0.0186,  ...,  0.0078,  0.0159,  0.0120],\n",
       "         ...,\n",
       "         [ 0.0040,  0.0068,  0.0077,  ..., -0.0011,  0.0022, -0.0016],\n",
       "         [-0.0125,  0.0162, -0.0170,  ...,  0.0030, -0.0123,  0.0106],\n",
       "         [ 0.0075, -0.0157, -0.0134,  ..., -0.0073,  0.0003,  0.0069]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.17.self_attn.k_proj.lora_B.weight': tensor([[-0.0023,  0.0004,  0.0004,  ..., -0.0004, -0.0011,  0.0016],\n",
       "         [-0.0019, -0.0031, -0.0032,  ...,  0.0030, -0.0027, -0.0013],\n",
       "         [ 0.0001,  0.0012,  0.0008,  ..., -0.0020, -0.0014,  0.0011],\n",
       "         ...,\n",
       "         [ 0.0009, -0.0010,  0.0021,  ...,  0.0010,  0.0017, -0.0034],\n",
       "         [ 0.0014,  0.0006, -0.0034,  ..., -0.0021,  0.0013,  0.0014],\n",
       "         [ 0.0012,  0.0046,  0.0027,  ..., -0.0026,  0.0001,  0.0012]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.17.self_attn.o_proj.lora_A.weight': tensor([[ 0.0159, -0.0068, -0.0121,  ..., -0.0077, -0.0025, -0.0106],\n",
       "         [ 0.0134,  0.0162, -0.0170,  ..., -0.0074, -0.0095,  0.0023],\n",
       "         [ 0.0060,  0.0145, -0.0131,  ..., -0.0028,  0.0036,  0.0018],\n",
       "         ...,\n",
       "         [-0.0039,  0.0057, -0.0007,  ...,  0.0025,  0.0049,  0.0135],\n",
       "         [-0.0104, -0.0120, -0.0020,  ...,  0.0050,  0.0176,  0.0041],\n",
       "         [ 0.0009,  0.0007,  0.0038,  ..., -0.0066, -0.0052,  0.0015]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.17.self_attn.o_proj.lora_B.weight': tensor([[-0.0008, -0.0014,  0.0025,  ..., -0.0014, -0.0006,  0.0017],\n",
       "         [ 0.0002, -0.0011,  0.0015,  ..., -0.0014,  0.0024,  0.0021],\n",
       "         [-0.0022,  0.0006,  0.0021,  ...,  0.0023, -0.0003, -0.0016],\n",
       "         ...,\n",
       "         [ 0.0027, -0.0023, -0.0038,  ...,  0.0022,  0.0018,  0.0018],\n",
       "         [ 0.0013, -0.0010,  0.0011,  ..., -0.0014, -0.0007, -0.0009],\n",
       "         [ 0.0010, -0.0024,  0.0010,  ...,  0.0012, -0.0003,  0.0006]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.17.self_attn.q_proj.lora_A.weight': tensor([[ 0.0095,  0.0114, -0.0038,  ...,  0.0061,  0.0090, -0.0080],\n",
       "         [ 0.0077,  0.0024,  0.0031,  ..., -0.0135,  0.0067, -0.0114],\n",
       "         [-0.0126, -0.0080,  0.0131,  ..., -0.0047,  0.0015, -0.0121],\n",
       "         ...,\n",
       "         [-0.0046,  0.0038,  0.0057,  ..., -0.0055, -0.0143,  0.0063],\n",
       "         [-0.0124,  0.0110,  0.0146,  ...,  0.0087,  0.0073, -0.0019],\n",
       "         [-0.0127,  0.0001,  0.0003,  ...,  0.0074, -0.0075,  0.0100]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.17.self_attn.q_proj.lora_B.weight': tensor([[ 2.0752e-03,  1.7643e-04,  2.8992e-04,  ...,  3.6812e-04,\n",
       "           2.1935e-04, -1.4954e-03],\n",
       "         [ 1.2741e-03, -1.5869e-03, -1.2207e-04,  ..., -1.0300e-04,\n",
       "          -2.1973e-03, -1.7624e-03],\n",
       "         [ 7.0572e-04, -5.0354e-04,  1.4954e-03,  ...,  2.7466e-04,\n",
       "          -1.1978e-03,  2.7275e-04],\n",
       "         ...,\n",
       "         [ 1.3046e-03, -2.2736e-03,  3.0060e-03,  ..., -7.0190e-04,\n",
       "          -5.5695e-04, -1.1215e-03],\n",
       "         [-2.9755e-03,  1.4114e-03, -5.8899e-03,  ...,  8.9645e-04,\n",
       "          -4.3678e-04, -2.1362e-04],\n",
       "         [-2.2411e-04,  9.3079e-04,  7.0572e-04,  ...,  5.8746e-04,\n",
       "           2.7313e-03, -3.2663e-05]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.17.self_attn.v_proj.lora_A.weight': tensor([[-3.2196e-03, -3.5400e-03,  7.1716e-03,  ...,  3.4027e-03,\n",
       "          -1.2329e-02,  7.2327e-03],\n",
       "         [-3.4637e-03,  1.4038e-02,  1.6479e-02,  ...,  9.0942e-03,\n",
       "           1.0620e-02,  2.1667e-03],\n",
       "         [-1.3885e-03, -1.1414e-02, -3.0365e-03,  ..., -2.3804e-03,\n",
       "           4.1809e-03, -1.1108e-02],\n",
       "         ...,\n",
       "         [ 9.6436e-03, -1.3794e-02, -1.4420e-03,  ..., -8.0566e-03,\n",
       "          -1.2146e-02, -3.5248e-03],\n",
       "         [-4.5776e-04,  6.1512e-05,  1.0742e-02,  ..., -8.8501e-03,\n",
       "           1.4465e-02, -5.4016e-03],\n",
       "         [-8.0566e-03, -1.0132e-02,  9.7046e-03,  ...,  1.1108e-02,\n",
       "          -1.6113e-02,  1.1719e-02]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.17.self_attn.v_proj.lora_B.weight': tensor([[-5.2643e-04, -9.9945e-04,  9.0027e-04,  ..., -1.7014e-03,\n",
       "          -1.0147e-03, -1.0986e-03],\n",
       "         [-1.5106e-03, -4.8637e-04, -1.8692e-03,  ...,  4.8065e-04,\n",
       "           1.2436e-03, -1.0605e-03],\n",
       "         [-9.6130e-04, -9.1171e-04,  1.7090e-03,  ..., -2.3842e-04,\n",
       "          -1.8921e-03, -5.6458e-04],\n",
       "         ...,\n",
       "         [-1.3351e-04, -3.2187e-05, -1.9646e-04,  ..., -1.7929e-03,\n",
       "           2.7008e-03, -1.1215e-03],\n",
       "         [-1.2207e-03, -9.2697e-04,  1.3046e-03,  ..., -8.5449e-04,\n",
       "           4.0627e-04,  5.7983e-04],\n",
       "         [ 2.8992e-03,  3.2501e-03, -1.9379e-03,  ...,  1.5945e-03,\n",
       "           2.3460e-04, -1.3428e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.18.mlp.down_proj.lora_A.weight': tensor([[-9.2773e-03,  7.6904e-03,  5.6763e-03,  ...,  1.0803e-02,\n",
       "          -2.6093e-03, -1.0193e-02],\n",
       "         [-9.7656e-03,  5.7373e-03, -1.3504e-03,  ..., -1.7700e-03,\n",
       "          -6.1646e-03, -6.3171e-03],\n",
       "         [-1.1673e-03,  1.0071e-02,  9.2983e-05,  ...,  6.8054e-03,\n",
       "           6.6223e-03, -3.1433e-03],\n",
       "         ...,\n",
       "         [ 4.5776e-03, -2.1820e-03, -7.5684e-03,  ..., -5.6458e-04,\n",
       "          -1.2970e-03, -4.0054e-04],\n",
       "         [-1.0864e-02, -1.6479e-03,  1.0376e-02,  ...,  7.8125e-03,\n",
       "           7.7209e-03,  9.3994e-03],\n",
       "         [-2.8687e-03, -9.1553e-04, -7.2937e-03,  ..., -2.4414e-03,\n",
       "           7.2327e-03, -1.9150e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.18.mlp.down_proj.lora_B.weight': tensor([[ 9.9945e-04,  3.4637e-03,  8.8120e-04,  ...,  1.4648e-03,\n",
       "           4.5776e-04, -1.8234e-03],\n",
       "         [ 1.1063e-03,  1.0071e-03, -6.4850e-04,  ...,  8.9407e-06,\n",
       "          -1.4343e-03, -1.3809e-03],\n",
       "         [ 7.5531e-04,  1.1902e-03, -4.9973e-04,  ..., -4.6539e-04,\n",
       "          -1.1444e-03,  2.6512e-04],\n",
       "         ...,\n",
       "         [-9.2030e-05, -7.3242e-04,  5.6267e-05,  ..., -1.4420e-03,\n",
       "          -3.4332e-03,  7.2479e-04],\n",
       "         [-9.7275e-04,  1.8158e-03,  1.8234e-03,  ...,  1.4191e-03,\n",
       "           2.5749e-04, -1.9073e-03],\n",
       "         [ 2.3193e-03,  5.8746e-04, -2.7161e-03,  ..., -2.9297e-03,\n",
       "          -1.2512e-03, -2.6093e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.18.mlp.gate_proj.lora_A.weight': tensor([[ 0.0139, -0.0037, -0.0125,  ...,  0.0017,  0.0032, -0.0145],\n",
       "         [-0.0079, -0.0003, -0.0014,  ..., -0.0150, -0.0091, -0.0113],\n",
       "         [ 0.0011,  0.0025,  0.0020,  ..., -0.0056, -0.0115,  0.0002],\n",
       "         ...,\n",
       "         [ 0.0011, -0.0134, -0.0066,  ...,  0.0003,  0.0049, -0.0105],\n",
       "         [ 0.0114,  0.0022, -0.0153,  ...,  0.0123, -0.0172, -0.0111],\n",
       "         [-0.0023, -0.0079, -0.0134,  ...,  0.0003,  0.0117,  0.0016]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.18.mlp.gate_proj.lora_B.weight': tensor([[-3.2997e-04, -5.0068e-05,  4.1246e-05,  ..., -1.5259e-03,\n",
       "           3.0899e-04, -5.0049e-03],\n",
       "         [-1.4725e-03,  5.9509e-04, -5.4836e-05,  ...,  3.3569e-04,\n",
       "           1.0300e-03, -1.8692e-03],\n",
       "         [-2.6321e-04, -1.0529e-03,  9.0790e-04,  ...,  1.3504e-03,\n",
       "          -1.5564e-03, -4.6539e-04],\n",
       "         ...,\n",
       "         [-3.0518e-03, -1.0834e-03, -1.5411e-03,  ...,  2.2430e-03,\n",
       "           3.8338e-04, -1.1015e-04],\n",
       "         [-1.9531e-03, -1.3962e-03, -4.7913e-03,  ...,  1.0834e-03,\n",
       "          -3.4332e-04, -1.2665e-03],\n",
       "         [ 2.1057e-03,  5.7602e-04, -2.7771e-03,  ...,  9.2697e-04,\n",
       "           2.3193e-03, -4.0627e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.18.mlp.up_proj.lora_A.weight': tensor([[ 0.0164,  0.0060, -0.0110,  ..., -0.0052, -0.0130,  0.0024],\n",
       "         [-0.0045, -0.0114,  0.0128,  ..., -0.0074,  0.0061, -0.0028],\n",
       "         [-0.0146, -0.0039, -0.0145,  ...,  0.0082,  0.0108,  0.0092],\n",
       "         ...,\n",
       "         [ 0.0109,  0.0130,  0.0077,  ..., -0.0093, -0.0106,  0.0071],\n",
       "         [ 0.0064, -0.0131, -0.0049,  ...,  0.0005,  0.0077, -0.0037],\n",
       "         [-0.0136, -0.0024,  0.0144,  ..., -0.0053, -0.0087, -0.0009]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.18.mlp.up_proj.lora_B.weight': tensor([[ 3.6716e-05,  6.5613e-04, -2.0447e-03,  ..., -6.3705e-04,\n",
       "          -7.5531e-04, -1.8005e-03],\n",
       "         [ 3.3188e-04,  5.4932e-04,  1.8120e-04,  ...,  1.2741e-03,\n",
       "           9.8419e-04, -1.1139e-03],\n",
       "         [-9.7275e-04,  5.2643e-04,  1.4114e-03,  ..., -1.4343e-03,\n",
       "           1.6479e-03,  1.1292e-03],\n",
       "         ...,\n",
       "         [ 1.2741e-03,  4.7607e-03, -3.4485e-03,  ...,  3.9368e-03,\n",
       "          -2.6703e-03, -1.4544e-05],\n",
       "         [ 1.1215e-03, -1.6556e-03,  1.6632e-03,  ...,  4.7112e-04,\n",
       "           2.9449e-03,  9.8419e-04],\n",
       "         [-2.4719e-03, -4.3335e-03, -2.9755e-03,  ..., -2.1210e-03,\n",
       "          -6.9046e-04, -1.2970e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.18.self_attn.k_proj.lora_A.weight': tensor([[ 0.0068, -0.0132, -0.0155,  ..., -0.0073,  0.0118,  0.0130],\n",
       "         [ 0.0082,  0.0100,  0.0052,  ..., -0.0034,  0.0139,  0.0090],\n",
       "         [-0.0159,  0.0104,  0.0012,  ..., -0.0049,  0.0134,  0.0095],\n",
       "         ...,\n",
       "         [ 0.0127, -0.0036, -0.0088,  ...,  0.0106,  0.0134,  0.0110],\n",
       "         [-0.0121, -0.0066,  0.0033,  ...,  0.0093, -0.0103, -0.0143],\n",
       "         [ 0.0100,  0.0040,  0.0143,  ..., -0.0054,  0.0050, -0.0055]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.18.self_attn.k_proj.lora_B.weight': tensor([[ 1.1444e-03,  1.3504e-03,  7.2861e-04,  ...,  1.0071e-03,\n",
       "           3.0060e-03,  2.6398e-03],\n",
       "         [ 4.6492e-05,  4.6349e-04, -2.8038e-04,  ...,  1.0681e-03,\n",
       "          -1.3733e-03,  2.8229e-03],\n",
       "         [ 9.2506e-05,  1.5793e-03,  1.2589e-03,  ...,  2.7313e-03,\n",
       "           2.5635e-03,  1.5717e-03],\n",
       "         ...,\n",
       "         [ 2.0447e-03, -1.3733e-03, -9.0408e-04,  ...,  1.4420e-03,\n",
       "          -1.8477e-05,  3.5858e-04],\n",
       "         [ 1.6861e-03, -3.3112e-03, -1.0910e-03,  ...,  3.0975e-03,\n",
       "          -1.4420e-03, -3.6316e-03],\n",
       "         [-5.8746e-04,  8.8120e-04, -1.9989e-03,  ...,  2.4319e-04,\n",
       "          -3.0136e-04, -2.1667e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.18.self_attn.o_proj.lora_A.weight': tensor([[-3.9673e-03, -5.4550e-04, -5.4626e-03,  ...,  5.7678e-03,\n",
       "          -1.4404e-02,  1.0986e-02],\n",
       "         [ 1.0986e-02, -1.3550e-02, -1.1169e-02,  ..., -3.0060e-03,\n",
       "           1.0193e-02, -6.7139e-03],\n",
       "         [ 1.2085e-02,  2.3346e-03,  1.1169e-02,  ..., -3.8757e-03,\n",
       "          -1.2634e-02, -9.5825e-03],\n",
       "         ...,\n",
       "         [ 3.9368e-03, -4.4250e-03,  5.3711e-03,  ...,  3.9062e-03,\n",
       "           1.5015e-02,  5.0964e-03],\n",
       "         [ 1.1520e-03, -1.2329e-02, -7.0190e-03,  ...,  5.3167e-05,\n",
       "          -5.1270e-03, -6.8665e-03],\n",
       "         [ 1.4404e-02, -4.7607e-03, -1.6403e-03,  ..., -5.4016e-03,\n",
       "           1.1902e-02,  3.0823e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.18.self_attn.o_proj.lora_B.weight': tensor([[-5.4932e-04, -1.8477e-05, -2.7771e-03,  ...,  1.2360e-03,\n",
       "           9.2316e-04, -1.5030e-03],\n",
       "         [ 1.4267e-03, -1.1520e-03, -2.8534e-03,  ...,  2.2888e-03,\n",
       "          -1.3809e-03,  8.2779e-04],\n",
       "         [ 1.1826e-03, -4.8828e-04, -1.3046e-03,  ...,  1.8387e-03,\n",
       "           1.9226e-03, -1.5869e-03],\n",
       "         ...,\n",
       "         [ 3.0136e-04, -1.5640e-03,  1.4648e-03,  ...,  2.3499e-03,\n",
       "          -7.8964e-04,  2.8229e-04],\n",
       "         [ 1.4801e-03, -1.4648e-03, -6.7902e-04,  ...,  2.7847e-04,\n",
       "           2.1973e-03,  7.7438e-04],\n",
       "         [-1.1635e-04, -2.7466e-03,  1.4877e-03,  ...,  4.8637e-04,\n",
       "           1.4114e-03,  1.8120e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.18.self_attn.q_proj.lora_A.weight': tensor([[-6.1035e-03,  1.2512e-02,  3.6621e-03,  ...,  1.6846e-02,\n",
       "          -6.7749e-03, -8.5449e-03],\n",
       "         [-5.5542e-03,  4.5166e-03, -1.7090e-02,  ..., -5.1880e-03,\n",
       "          -1.4709e-02, -3.6926e-03],\n",
       "         [ 1.4099e-02,  1.8921e-03, -5.6152e-03,  ..., -5.7983e-03,\n",
       "           7.3853e-03,  3.3112e-03],\n",
       "         ...,\n",
       "         [ 1.3611e-02,  4.7302e-03, -7.7209e-03,  ...,  1.0498e-02,\n",
       "          -6.6833e-03,  8.7891e-03],\n",
       "         [-1.5717e-03, -1.5747e-02, -1.5381e-02,  ..., -9.3384e-03,\n",
       "          -1.2024e-02,  8.7280e-03],\n",
       "         [ 9.2773e-03, -3.8910e-03,  1.2207e-02,  ...,  7.5340e-05,\n",
       "          -1.0925e-02, -8.1177e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.18.self_attn.q_proj.lora_B.weight': tensor([[ 1.7776e-03,  2.0752e-03,  1.4400e-04,  ..., -2.4261e-03,\n",
       "          -6.0654e-04,  8.7738e-04],\n",
       "         [ 2.2278e-03, -2.2125e-03, -3.0756e-05,  ..., -8.0109e-04,\n",
       "           1.0061e-04,  3.6240e-04],\n",
       "         [ 9.6512e-04, -2.9602e-03, -1.2360e-03,  ..., -1.8234e-03,\n",
       "           6.5613e-04, -5.1498e-04],\n",
       "         ...,\n",
       "         [ 5.7936e-05,  1.0452e-03, -2.4567e-03,  ...,  8.2779e-04,\n",
       "          -2.9945e-04,  7.7438e-04],\n",
       "         [-3.7956e-04,  2.3193e-03,  5.9509e-04,  ..., -9.8419e-04,\n",
       "           3.1281e-04,  2.4796e-04],\n",
       "         [ 4.6539e-04, -1.0071e-03,  2.8229e-04,  ...,  1.0986e-03,\n",
       "           1.1520e-03,  1.3885e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.18.self_attn.v_proj.lora_A.weight': tensor([[-2.3956e-03, -3.7689e-03,  1.1047e-02,  ..., -3.0518e-03,\n",
       "           8.7891e-03,  5.4016e-03],\n",
       "         [-1.2329e-02,  3.6774e-03, -9.8267e-03,  ..., -1.3123e-02,\n",
       "          -4.3030e-03, -9.5825e-03],\n",
       "         [ 1.2329e-02, -1.3428e-02,  8.1062e-05,  ..., -4.6997e-03,\n",
       "           7.5989e-03,  8.4229e-03],\n",
       "         ...,\n",
       "         [ 4.4861e-03, -1.2695e-02,  1.0681e-02,  ...,  5.0659e-03,\n",
       "          -6.5002e-03,  5.7678e-03],\n",
       "         [-8.6060e-03,  1.2695e-02,  5.9509e-03,  ..., -1.3306e-02,\n",
       "           6.2561e-03, -8.3618e-03],\n",
       "         [-7.8735e-03, -1.9836e-03,  1.8158e-03,  ...,  4.9744e-03,\n",
       "          -4.2114e-03, -1.4160e-02]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.18.self_attn.v_proj.lora_B.weight': tensor([[-1.9379e-03, -3.3264e-03,  1.9302e-03,  ..., -2.3804e-03,\n",
       "          -1.7242e-03,  9.3460e-04],\n",
       "         [ 2.0294e-03,  1.7242e-03, -2.4872e-03,  ...,  2.5787e-03,\n",
       "           2.3041e-03,  1.3199e-03],\n",
       "         [-6.9809e-04, -8.0872e-04,  5.2261e-04,  ..., -4.9210e-04,\n",
       "          -1.5736e-04, -3.4714e-04],\n",
       "         ...,\n",
       "         [ 4.2915e-04, -9.8419e-04,  9.9182e-04,  ..., -1.2665e-03,\n",
       "           1.0223e-03,  7.1716e-04],\n",
       "         [ 7.8201e-05, -2.7008e-03,  2.7466e-03,  ..., -4.9210e-04,\n",
       "          -2.4719e-03,  9.0408e-04],\n",
       "         [-5.6839e-04, -1.0376e-03,  2.3270e-04,  ...,  1.9226e-03,\n",
       "           9.7275e-04,  8.5068e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.19.mlp.down_proj.lora_A.weight': tensor([[-5.8899e-03, -6.8665e-03, -3.7193e-04,  ..., -1.0132e-02,\n",
       "           6.8359e-03, -1.8835e-05],\n",
       "         [ 3.9062e-03,  6.6833e-03,  2.6550e-03,  ..., -7.6599e-03,\n",
       "          -2.0905e-03, -4.5166e-03],\n",
       "         [-7.0190e-03, -1.8845e-03,  3.5858e-03,  ..., -8.2397e-03,\n",
       "          -3.6621e-03,  4.7607e-03],\n",
       "         ...,\n",
       "         [ 6.3477e-03,  1.1215e-03,  5.5237e-03,  ...,  2.3193e-03,\n",
       "          -4.6997e-03,  6.5308e-03],\n",
       "         [-6.0120e-03, -4.9133e-03,  5.6152e-03,  ..., -5.4626e-03,\n",
       "           2.5635e-03,  6.4697e-03],\n",
       "         [ 4.9133e-03, -8.5449e-03, -6.3782e-03,  ...,  4.7302e-03,\n",
       "          -6.9275e-03, -6.1646e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.19.mlp.down_proj.lora_B.weight': tensor([[-2.4986e-04, -2.5272e-05, -1.8616e-03,  ..., -3.9482e-04,\n",
       "           2.1210e-03, -6.6376e-04],\n",
       "         [ 2.9945e-04,  9.9945e-04, -2.9755e-03,  ...,  1.7014e-03,\n",
       "          -8.3160e-04,  1.2398e-04],\n",
       "         [-8.6594e-04, -3.6880e-07,  2.7161e-03,  ...,  9.3842e-04,\n",
       "           2.0294e-03,  2.7161e-03],\n",
       "         ...,\n",
       "         [ 1.3351e-03,  1.1826e-03,  1.8234e-03,  ...,  8.6975e-04,\n",
       "           5.4169e-04,  1.8387e-03],\n",
       "         [ 1.5564e-03,  4.0283e-03,  6.5613e-04,  ...,  3.1090e-04,\n",
       "          -8.0109e-04, -2.1515e-03],\n",
       "         [-9.9945e-04,  1.7548e-04,  9.1171e-04,  ...,  2.0294e-03,\n",
       "          -1.6022e-03,  1.4648e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.19.mlp.gate_proj.lora_A.weight': tensor([[ 0.0010,  0.0058,  0.0042,  ...,  0.0115,  0.0106, -0.0153],\n",
       "         [ 0.0064, -0.0039,  0.0135,  ...,  0.0119, -0.0006,  0.0016],\n",
       "         [ 0.0050,  0.0011,  0.0129,  ...,  0.0071,  0.0017,  0.0100],\n",
       "         ...,\n",
       "         [ 0.0062, -0.0025, -0.0055,  ...,  0.0070, -0.0107,  0.0026],\n",
       "         [-0.0058,  0.0056, -0.0033,  ..., -0.0107,  0.0057,  0.0123],\n",
       "         [ 0.0016,  0.0077,  0.0008,  ..., -0.0139, -0.0062,  0.0046]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.19.mlp.gate_proj.lora_B.weight': tensor([[-0.0002, -0.0002,  0.0016,  ...,  0.0027,  0.0013, -0.0017],\n",
       "         [ 0.0009, -0.0008,  0.0035,  ...,  0.0040,  0.0029,  0.0029],\n",
       "         [ 0.0015,  0.0005, -0.0003,  ..., -0.0050,  0.0014, -0.0009],\n",
       "         ...,\n",
       "         [ 0.0014, -0.0005,  0.0007,  ..., -0.0006,  0.0026, -0.0004],\n",
       "         [ 0.0012,  0.0004,  0.0017,  ..., -0.0021,  0.0021, -0.0005],\n",
       "         [ 0.0002, -0.0030,  0.0007,  ..., -0.0024,  0.0013,  0.0005]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.19.mlp.up_proj.lora_A.weight': tensor([[ 0.0140,  0.0134,  0.0064,  ...,  0.0036, -0.0139, -0.0004],\n",
       "         [-0.0128, -0.0040, -0.0134,  ...,  0.0074,  0.0096, -0.0014],\n",
       "         [ 0.0064, -0.0103, -0.0117,  ...,  0.0089,  0.0023,  0.0107],\n",
       "         ...,\n",
       "         [ 0.0087, -0.0104, -0.0102,  ..., -0.0066,  0.0098,  0.0114],\n",
       "         [ 0.0089,  0.0125,  0.0092,  ...,  0.0090, -0.0151,  0.0123],\n",
       "         [ 0.0079, -0.0003,  0.0058,  ..., -0.0011, -0.0027, -0.0018]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.19.mlp.up_proj.lora_B.weight': tensor([[ 1.4496e-03,  4.8065e-04,  3.6049e-04,  ...,  2.3346e-03,\n",
       "          -5.6763e-03, -2.8076e-03],\n",
       "         [-3.6316e-03,  8.7357e-04,  3.6621e-03,  ..., -5.2261e-04,\n",
       "           1.7319e-03,  2.7657e-04],\n",
       "         [ 1.8234e-03, -1.6861e-03,  3.6955e-05,  ...,  6.7520e-04,\n",
       "          -1.9226e-03, -3.3760e-04],\n",
       "         ...,\n",
       "         [-2.6550e-03, -1.4343e-03,  1.6556e-03,  ..., -2.8839e-03,\n",
       "           2.4872e-03,  7.8583e-04],\n",
       "         [ 1.2283e-03,  3.0212e-03, -5.7678e-03,  ...,  5.4932e-03,\n",
       "           4.6387e-03,  4.5013e-04],\n",
       "         [ 3.1281e-03, -4.1389e-04,  1.4591e-04,  ...,  3.8605e-03,\n",
       "           2.2888e-03,  4.5538e-05]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.19.self_attn.k_proj.lora_A.weight': tensor([[ 0.0070, -0.0042,  0.0063,  ...,  0.0006, -0.0045, -0.0107],\n",
       "         [-0.0015,  0.0029, -0.0048,  ...,  0.0081,  0.0098,  0.0041],\n",
       "         [-0.0121, -0.0137, -0.0134,  ..., -0.0079,  0.0090, -0.0091],\n",
       "         ...,\n",
       "         [ 0.0011, -0.0020, -0.0015,  ...,  0.0125,  0.0144,  0.0096],\n",
       "         [ 0.0061,  0.0101,  0.0096,  ...,  0.0018,  0.0037, -0.0009],\n",
       "         [-0.0063, -0.0052,  0.0100,  ...,  0.0008,  0.0107,  0.0005]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.19.self_attn.k_proj.lora_B.weight': tensor([[-7.1716e-04, -5.2261e-04, -1.0757e-03,  ..., -1.1749e-03,\n",
       "          -1.0834e-03, -3.3379e-04],\n",
       "         [-1.5488e-03,  1.9836e-03, -2.5635e-03,  ...,  2.0504e-04,\n",
       "           1.2360e-03,  2.1744e-04],\n",
       "         [-1.1292e-03, -8.8882e-04, -9.1934e-04,  ...,  2.7466e-04,\n",
       "           3.4332e-04,  1.3580e-03],\n",
       "         ...,\n",
       "         [-1.6022e-04,  2.2769e-05, -2.7847e-04,  ...,  1.2054e-03,\n",
       "          -8.8882e-04,  8.0490e-04],\n",
       "         [-1.7166e-03, -4.1199e-04, -9.3842e-04,  ...,  1.5335e-03,\n",
       "          -7.0190e-04, -6.9427e-04],\n",
       "         [ 1.1749e-03,  3.7689e-03,  2.7657e-04,  ..., -4.9591e-04,\n",
       "           2.3956e-03, -2.3842e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.19.self_attn.o_proj.lora_A.weight': tensor([[ 1.0376e-03, -1.7357e-04,  8.8501e-03,  ...,  2.7161e-03,\n",
       "           1.0559e-02,  9.5215e-03],\n",
       "         [-1.6479e-02, -1.3550e-02, -6.8054e-03,  ..., -1.1353e-02,\n",
       "           1.6113e-02, -8.9111e-03],\n",
       "         [-1.5198e-02, -6.1646e-03, -4.7913e-03,  ...,  4.2114e-03,\n",
       "           5.0049e-03, -1.8921e-03],\n",
       "         ...,\n",
       "         [ 5.8899e-03,  1.0559e-02, -4.4556e-03,  ..., -1.7212e-02,\n",
       "          -7.2327e-03,  1.1047e-02],\n",
       "         [ 1.6403e-03,  1.0437e-02, -1.2512e-02,  ...,  1.8066e-02,\n",
       "           1.5945e-03, -8.5449e-03],\n",
       "         [-1.4832e-02,  3.6240e-05,  5.5237e-03,  ...,  1.0742e-02,\n",
       "           6.7444e-03,  7.2861e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.19.self_attn.o_proj.lora_B.weight': tensor([[ 0.0019,  0.0027,  0.0004,  ..., -0.0002,  0.0011,  0.0012],\n",
       "         [-0.0032, -0.0001,  0.0002,  ...,  0.0003,  0.0006, -0.0012],\n",
       "         [ 0.0013,  0.0003,  0.0023,  ...,  0.0018,  0.0030,  0.0007],\n",
       "         ...,\n",
       "         [-0.0012, -0.0037, -0.0016,  ...,  0.0010, -0.0028,  0.0003],\n",
       "         [-0.0007,  0.0027, -0.0006,  ..., -0.0010, -0.0012, -0.0007],\n",
       "         [-0.0024, -0.0015, -0.0007,  ...,  0.0003,  0.0039,  0.0045]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.19.self_attn.q_proj.lora_A.weight': tensor([[ 6.8054e-03,  8.7280e-03, -1.8845e-03,  ..., -6.2866e-03,\n",
       "          -1.1841e-02,  1.5991e-02],\n",
       "         [-9.2163e-03, -1.0254e-02, -1.3367e-02,  ...,  3.1662e-04,\n",
       "          -1.3428e-02,  1.0910e-03],\n",
       "         [ 8.0585e-05, -6.0425e-03,  7.0190e-03,  ...,  1.2634e-02,\n",
       "           3.9062e-03, -1.1047e-02],\n",
       "         ...,\n",
       "         [ 1.1414e-02,  1.9226e-03, -7.5378e-03,  ..., -4.8523e-03,\n",
       "          -9.3384e-03, -5.4016e-03],\n",
       "         [-1.2878e-02, -7.6904e-03,  3.2501e-03,  ..., -1.1047e-02,\n",
       "          -2.2888e-03, -1.0864e-02],\n",
       "         [ 7.3910e-05, -1.2451e-02, -7.9346e-03,  ..., -2.4109e-03,\n",
       "           9.8267e-03, -1.2207e-02]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.19.self_attn.q_proj.lora_B.weight': tensor([[ 1.7624e-03,  4.7112e-04, -4.9353e-05,  ..., -2.0599e-03,\n",
       "           2.1820e-03, -3.8147e-05],\n",
       "         [-4.3030e-03, -2.4261e-03, -1.7090e-03,  ..., -2.4414e-03,\n",
       "           1.9684e-03,  1.4648e-03],\n",
       "         [-1.1978e-03, -8.9169e-05,  1.2131e-03,  ..., -5.5313e-04,\n",
       "          -1.3580e-03,  1.5259e-04],\n",
       "         ...,\n",
       "         [ 1.1749e-03,  6.3324e-04, -1.7166e-03,  ..., -1.7548e-03,\n",
       "          -1.0872e-04, -2.2125e-03],\n",
       "         [ 1.5855e-05, -1.3447e-04,  1.0071e-03,  ..., -2.2984e-04,\n",
       "          -9.4986e-04, -5.6267e-05],\n",
       "         [ 1.9932e-04, -1.1063e-03, -2.9945e-04,  ...,  3.3379e-04,\n",
       "           4.7684e-04,  3.2654e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.19.self_attn.v_proj.lora_A.weight': tensor([[ 0.0051,  0.0068,  0.0089,  ..., -0.0070,  0.0178,  0.0146],\n",
       "         [-0.0069,  0.0095, -0.0136,  ..., -0.0099,  0.0096,  0.0032],\n",
       "         [ 0.0024, -0.0020,  0.0117,  ..., -0.0042, -0.0009,  0.0079],\n",
       "         ...,\n",
       "         [-0.0065, -0.0079,  0.0137,  ...,  0.0084,  0.0131, -0.0101],\n",
       "         [-0.0090, -0.0093,  0.0103,  ..., -0.0008, -0.0156, -0.0119],\n",
       "         [ 0.0115, -0.0016, -0.0148,  ..., -0.0127, -0.0070,  0.0112]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.19.self_attn.v_proj.lora_B.weight': tensor([[-3.4790e-03,  1.5926e-04,  3.4180e-03,  ..., -1.1292e-03,\n",
       "           1.6403e-03, -1.8768e-03],\n",
       "         [-2.0266e-05,  8.3160e-04, -1.6556e-03,  ..., -1.3161e-04,\n",
       "          -1.7929e-03,  1.3580e-03],\n",
       "         [ 2.2278e-03, -1.4191e-03, -2.3346e-03,  ...,  2.1973e-03,\n",
       "           1.1368e-03,  8.0872e-04],\n",
       "         ...,\n",
       "         [ 1.1215e-03, -9.0027e-04, -8.9264e-04,  ...,  1.5335e-03,\n",
       "          -5.4550e-04,  1.3885e-03],\n",
       "         [-2.6855e-03,  1.3504e-03,  2.2430e-03,  ..., -2.5024e-03,\n",
       "           1.6785e-03, -1.5411e-03],\n",
       "         [-1.4343e-03,  8.0490e-04,  5.8365e-04,  ..., -2.2125e-03,\n",
       "           2.1515e-03, -7.7438e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.2.mlp.down_proj.lora_A.weight': tensor([[ 0.0031, -0.0029,  0.0005,  ...,  0.0022, -0.0081, -0.0042],\n",
       "         [-0.0023,  0.0048,  0.0051,  ...,  0.0011,  0.0057, -0.0041],\n",
       "         [-0.0040,  0.0025,  0.0026,  ...,  0.0013,  0.0072,  0.0012],\n",
       "         ...,\n",
       "         [ 0.0075,  0.0049,  0.0101,  ...,  0.0053,  0.0101, -0.0031],\n",
       "         [-0.0076,  0.0060, -0.0028,  ..., -0.0056, -0.0054,  0.0098],\n",
       "         [-0.0042, -0.0067,  0.0030,  ...,  0.0063, -0.0027,  0.0036]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.2.mlp.down_proj.lora_B.weight': tensor([[-1.9360e-04, -3.2043e-03,  8.0490e-04,  ..., -4.1389e-04,\n",
       "          -1.0681e-03, -1.4496e-03],\n",
       "         [-1.1826e-03,  8.6594e-04,  4.2915e-04,  ..., -2.7084e-04,\n",
       "          -2.5635e-03,  1.4038e-03],\n",
       "         [-3.5286e-05,  1.9684e-03, -1.2054e-03,  ..., -2.3346e-03,\n",
       "          -1.2817e-03,  2.8381e-03],\n",
       "         ...,\n",
       "         [ 3.1090e-04,  2.0294e-03, -8.6212e-04,  ...,  6.5994e-04,\n",
       "          -1.2283e-03,  1.1086e-05],\n",
       "         [ 1.5793e-03,  1.1635e-04, -1.3275e-03,  ..., -2.2736e-03,\n",
       "          -3.2959e-03,  2.2583e-03],\n",
       "         [-1.2875e-04,  1.4801e-03,  4.0054e-04,  ...,  7.7438e-04,\n",
       "          -3.9101e-04, -2.6703e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.2.mlp.gate_proj.lora_A.weight': tensor([[ 1.1749e-03,  7.9727e-04, -6.2866e-03,  ..., -4.8218e-03,\n",
       "          -9.1553e-03,  1.1169e-02],\n",
       "         [ 8.1787e-03,  2.1362e-03,  7.8735e-03,  ...,  1.5320e-02,\n",
       "           1.6113e-02, -1.0559e-02],\n",
       "         [ 1.1963e-02,  1.7853e-03,  3.1128e-03,  ..., -6.0425e-03,\n",
       "          -3.2806e-04, -1.5991e-02],\n",
       "         ...,\n",
       "         [-1.1414e-02,  3.2196e-03, -4.0894e-03,  ..., -1.3367e-02,\n",
       "           4.0283e-03,  1.4246e-05],\n",
       "         [ 5.7373e-03, -7.1716e-03, -9.3384e-03,  ..., -1.1826e-03,\n",
       "          -4.7607e-03,  1.1780e-02],\n",
       "         [ 4.1199e-03,  6.4392e-03,  2.5787e-03,  ..., -8.9722e-03,\n",
       "           1.1047e-02,  1.3447e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.2.mlp.gate_proj.lora_B.weight': tensor([[ 0.0013,  0.0008,  0.0024,  ..., -0.0023,  0.0012,  0.0030],\n",
       "         [ 0.0008, -0.0012,  0.0030,  ..., -0.0036, -0.0035, -0.0011],\n",
       "         [-0.0004, -0.0005,  0.0009,  ..., -0.0010, -0.0006,  0.0014],\n",
       "         ...,\n",
       "         [-0.0004, -0.0025, -0.0027,  ...,  0.0003, -0.0027, -0.0014],\n",
       "         [ 0.0017,  0.0009,  0.0028,  ...,  0.0018,  0.0012, -0.0014],\n",
       "         [-0.0007,  0.0009,  0.0002,  ..., -0.0017,  0.0007,  0.0010]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.2.mlp.up_proj.lora_A.weight': tensor([[ 0.0082, -0.0076, -0.0017,  ..., -0.0102,  0.0128,  0.0056],\n",
       "         [-0.0132,  0.0012, -0.0039,  ...,  0.0133, -0.0026,  0.0071],\n",
       "         [-0.0036, -0.0126, -0.0066,  ...,  0.0021, -0.0126, -0.0109],\n",
       "         ...,\n",
       "         [-0.0036,  0.0008,  0.0090,  ...,  0.0145, -0.0048,  0.0083],\n",
       "         [-0.0029,  0.0068, -0.0112,  ...,  0.0084, -0.0084,  0.0076],\n",
       "         [ 0.0079, -0.0031, -0.0005,  ...,  0.0027, -0.0098, -0.0133]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.2.mlp.up_proj.lora_B.weight': tensor([[-1.7643e-04, -2.0142e-03,  1.8997e-03,  ..., -2.7865e-06,\n",
       "           8.1635e-04,  5.7983e-04],\n",
       "         [-9.9945e-04,  1.8787e-04, -1.3580e-03,  ...,  2.1820e-03,\n",
       "           4.7302e-04, -1.6022e-04],\n",
       "         [-1.2934e-05,  6.4468e-04,  1.1206e-04,  ..., -4.9973e-04,\n",
       "          -5.5695e-04, -2.1820e-03],\n",
       "         ...,\n",
       "         [ 1.3199e-03, -1.9302e-03,  1.9684e-03,  ...,  1.3256e-04,\n",
       "           2.2221e-04, -6.8665e-04],\n",
       "         [ 1.7395e-03,  1.9360e-04, -9.3079e-04,  ...,  4.1389e-04,\n",
       "           4.7302e-04, -2.4796e-04],\n",
       "         [-1.3351e-03,  1.0376e-03, -2.1973e-03,  ...,  2.3346e-03,\n",
       "          -2.3651e-03, -6.5613e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.2.self_attn.k_proj.lora_A.weight': tensor([[-0.0076, -0.0016,  0.0157,  ..., -0.0075, -0.0132, -0.0075],\n",
       "         [-0.0140, -0.0145, -0.0132,  ...,  0.0082, -0.0042, -0.0059],\n",
       "         [-0.0098,  0.0043, -0.0121,  ..., -0.0015,  0.0085, -0.0035],\n",
       "         ...,\n",
       "         [-0.0146, -0.0095,  0.0126,  ..., -0.0154, -0.0070,  0.0042],\n",
       "         [-0.0048,  0.0071, -0.0056,  ...,  0.0120,  0.0018,  0.0034],\n",
       "         [ 0.0098, -0.0034, -0.0071,  ..., -0.0143,  0.0070,  0.0043]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.2.self_attn.k_proj.lora_B.weight': tensor([[ 6.1035e-04,  1.2436e-03,  1.0376e-03,  ...,  8.5068e-04,\n",
       "          -5.3406e-04, -2.0599e-03],\n",
       "         [ 9.1553e-04, -3.6163e-03, -1.6479e-03,  ..., -3.7079e-03,\n",
       "           4.4250e-03,  3.5858e-04],\n",
       "         [ 4.0054e-05,  1.3885e-03,  1.2131e-03,  ...,  1.7395e-03,\n",
       "          -2.3346e-03,  1.0347e-04],\n",
       "         ...,\n",
       "         [ 2.3842e-04, -2.1515e-03, -7.0190e-04,  ..., -2.9945e-04,\n",
       "          -2.2888e-04, -1.5030e-03],\n",
       "         [ 5.6505e-05, -1.8463e-03, -2.6245e-03,  ..., -1.1520e-03,\n",
       "           2.5482e-03,  1.1673e-03],\n",
       "         [-1.9836e-03, -6.2943e-04,  2.1667e-03,  ...,  1.9989e-03,\n",
       "          -6.5994e-04,  1.1902e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.2.self_attn.o_proj.lora_A.weight': tensor([[-0.0004,  0.0116,  0.0130,  ...,  0.0091, -0.0026, -0.0114],\n",
       "         [ 0.0106, -0.0119, -0.0036,  ...,  0.0029, -0.0066, -0.0038],\n",
       "         [ 0.0090,  0.0142, -0.0167,  ...,  0.0128, -0.0077,  0.0004],\n",
       "         ...,\n",
       "         [-0.0047,  0.0105, -0.0085,  ..., -0.0010,  0.0125,  0.0119],\n",
       "         [ 0.0064,  0.0060,  0.0038,  ...,  0.0161, -0.0079,  0.0082],\n",
       "         [-0.0115, -0.0151,  0.0081,  ..., -0.0145, -0.0088, -0.0058]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.2.self_attn.o_proj.lora_B.weight': tensor([[ 0.0006,  0.0012,  0.0009,  ..., -0.0016, -0.0021,  0.0013],\n",
       "         [-0.0006,  0.0014,  0.0016,  ..., -0.0014, -0.0003, -0.0008],\n",
       "         [-0.0004, -0.0024, -0.0006,  ...,  0.0002,  0.0034,  0.0003],\n",
       "         ...,\n",
       "         [ 0.0013, -0.0002, -0.0002,  ...,  0.0033, -0.0015,  0.0006],\n",
       "         [-0.0015, -0.0004,  0.0026,  ...,  0.0011, -0.0022, -0.0020],\n",
       "         [ 0.0008,  0.0016, -0.0002,  ..., -0.0001,  0.0015,  0.0013]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.2.self_attn.q_proj.lora_A.weight': tensor([[-0.0103, -0.0042, -0.0028,  ..., -0.0081,  0.0156,  0.0077],\n",
       "         [-0.0136, -0.0134,  0.0143,  ..., -0.0131, -0.0018, -0.0027],\n",
       "         [-0.0019,  0.0017, -0.0004,  ...,  0.0045,  0.0101,  0.0003],\n",
       "         ...,\n",
       "         [ 0.0020,  0.0115, -0.0031,  ...,  0.0081,  0.0164, -0.0028],\n",
       "         [ 0.0064,  0.0107,  0.0039,  ..., -0.0061,  0.0123,  0.0062],\n",
       "         [ 0.0131,  0.0088, -0.0005,  ..., -0.0108, -0.0168,  0.0081]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.2.self_attn.q_proj.lora_B.weight': tensor([[-1.6327e-03, -1.0681e-03, -9.2697e-04,  ...,  1.1597e-03,\n",
       "          -1.0223e-03, -1.8463e-03],\n",
       "         [ 1.5640e-03,  1.4343e-03,  1.6098e-03,  ...,  3.3951e-04,\n",
       "           4.2152e-04,  2.1515e-03],\n",
       "         [ 1.0529e-03,  8.6212e-04,  7.2861e-04,  ...,  1.5945e-03,\n",
       "           1.1444e-03, -1.4343e-03],\n",
       "         ...,\n",
       "         [ 1.2665e-03,  1.9073e-03,  3.8862e-05,  ...,  2.1076e-04,\n",
       "           3.3379e-04, -3.3379e-04],\n",
       "         [-3.5706e-03, -3.7079e-03,  1.8921e-03,  ..., -2.2278e-03,\n",
       "          -1.9531e-03,  2.7618e-03],\n",
       "         [ 9.9182e-04,  7.7057e-04, -1.2665e-03,  ...,  4.0436e-04,\n",
       "           1.8311e-04, -5.5313e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.2.self_attn.v_proj.lora_A.weight': tensor([[-1.6357e-02,  1.4282e-02,  3.6011e-03,  ..., -7.9956e-03,\n",
       "          -1.4465e-02, -1.1414e-02],\n",
       "         [-6.2180e-04,  3.3264e-03, -5.6458e-03,  ..., -1.2390e-02,\n",
       "          -1.0803e-02, -5.0354e-04],\n",
       "         [ 4.9744e-03,  6.8054e-03, -8.9111e-03,  ..., -1.4526e-02,\n",
       "           1.4587e-02,  1.3550e-02],\n",
       "         ...,\n",
       "         [-5.2185e-03,  1.0925e-02, -2.4719e-03,  ..., -4.3335e-03,\n",
       "           1.6212e-04,  8.6308e-05],\n",
       "         [-1.5137e-02, -3.6621e-03,  1.0605e-03,  ..., -1.0925e-02,\n",
       "           9.1553e-03,  8.1787e-03],\n",
       "         [ 9.2773e-03,  1.1230e-02, -8.5449e-03,  ..., -3.2234e-04,\n",
       "           1.0376e-02,  3.5553e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.2.self_attn.v_proj.lora_B.weight': tensor([[ 2.8801e-04,  1.6785e-03, -3.6478e-05,  ..., -2.2430e-03,\n",
       "           6.4850e-04,  3.1281e-04],\n",
       "         [ 1.8158e-03, -3.1090e-04,  3.2349e-03,  ...,  7.1716e-04,\n",
       "           3.9673e-04, -1.3046e-03],\n",
       "         [-1.8406e-04,  3.8338e-04, -5.3024e-04,  ..., -7.5912e-04,\n",
       "          -2.1973e-03,  1.9684e-03],\n",
       "         ...,\n",
       "         [ 4.1771e-04, -2.2278e-03,  2.1515e-03,  ..., -7.0953e-04,\n",
       "          -3.3722e-03,  1.4191e-03],\n",
       "         [-1.5030e-03,  1.8024e-04, -1.2360e-03,  ..., -2.5787e-03,\n",
       "           1.6022e-03,  8.8882e-04],\n",
       "         [ 3.0136e-04, -7.0190e-04, -2.7161e-03,  ..., -5.4932e-04,\n",
       "          -9.6130e-04,  6.9046e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.20.mlp.down_proj.lora_A.weight': tensor([[ 0.0013,  0.0020,  0.0042,  ...,  0.0063, -0.0069,  0.0011],\n",
       "         [ 0.0009, -0.0049, -0.0052,  ..., -0.0066, -0.0058,  0.0060],\n",
       "         [-0.0049,  0.0099,  0.0036,  ..., -0.0102,  0.0075,  0.0060],\n",
       "         ...,\n",
       "         [ 0.0010, -0.0076, -0.0025,  ...,  0.0071, -0.0054, -0.0031],\n",
       "         [ 0.0039,  0.0029,  0.0097,  ...,  0.0031, -0.0087, -0.0002],\n",
       "         [ 0.0007,  0.0051,  0.0075,  ...,  0.0048, -0.0011,  0.0064]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.20.mlp.down_proj.lora_B.weight': tensor([[ 5.6458e-04,  1.0300e-03,  9.1553e-04,  ..., -2.8534e-03,\n",
       "          -6.3419e-05, -5.4550e-04],\n",
       "         [-2.4128e-04, -6.5613e-04, -4.1199e-04,  ..., -1.0376e-03,\n",
       "          -3.7003e-04, -9.6560e-06],\n",
       "         [-7.4768e-04,  2.8968e-05,  1.5106e-03,  ..., -2.8534e-03,\n",
       "          -1.2741e-03,  1.7319e-03],\n",
       "         ...,\n",
       "         [ 2.9297e-03, -2.2888e-03, -8.3160e-04,  ..., -2.8610e-04,\n",
       "          -3.1281e-04, -8.0109e-05],\n",
       "         [ 1.1368e-03, -2.3956e-03, -8.4305e-04,  ..., -2.3499e-03,\n",
       "           6.0654e-04, -9.7275e-04],\n",
       "         [-6.4468e-04, -6.0654e-04,  9.3842e-04,  ..., -1.4572e-03,\n",
       "          -2.5482e-03, -1.4343e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.20.mlp.gate_proj.lora_A.weight': tensor([[-0.0125, -0.0079,  0.0052,  ...,  0.0123, -0.0131, -0.0104],\n",
       "         [-0.0027,  0.0097, -0.0091,  ...,  0.0036,  0.0035,  0.0022],\n",
       "         [-0.0080, -0.0076, -0.0049,  ..., -0.0127,  0.0018, -0.0115],\n",
       "         ...,\n",
       "         [-0.0086, -0.0054,  0.0126,  ..., -0.0027, -0.0149,  0.0039],\n",
       "         [ 0.0148, -0.0041,  0.0029,  ..., -0.0074, -0.0095, -0.0056],\n",
       "         [ 0.0076, -0.0075, -0.0155,  ...,  0.0019,  0.0021, -0.0061]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.20.mlp.gate_proj.lora_B.weight': tensor([[-0.0034, -0.0031, -0.0045,  ..., -0.0035,  0.0040,  0.0029],\n",
       "         [-0.0014, -0.0027, -0.0049,  ...,  0.0023,  0.0002, -0.0052],\n",
       "         [ 0.0015,  0.0030,  0.0009,  ..., -0.0033, -0.0025, -0.0017],\n",
       "         ...,\n",
       "         [-0.0004,  0.0008,  0.0026,  ...,  0.0004, -0.0006, -0.0006],\n",
       "         [-0.0024,  0.0031,  0.0009,  ..., -0.0015,  0.0036,  0.0015],\n",
       "         [ 0.0038,  0.0011,  0.0014,  ..., -0.0014,  0.0011, -0.0011]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.20.mlp.up_proj.lora_A.weight': tensor([[ 0.0121,  0.0134, -0.0106,  ...,  0.0115, -0.0035,  0.0017],\n",
       "         [ 0.0058,  0.0071, -0.0118,  ..., -0.0194,  0.0069, -0.0084],\n",
       "         [ 0.0135, -0.0041,  0.0076,  ..., -0.0135,  0.0093,  0.0081],\n",
       "         ...,\n",
       "         [ 0.0110, -0.0099,  0.0151,  ...,  0.0082, -0.0125,  0.0048],\n",
       "         [-0.0113, -0.0075, -0.0028,  ..., -0.0154, -0.0064,  0.0078],\n",
       "         [-0.0110, -0.0079, -0.0092,  ...,  0.0049, -0.0058, -0.0164]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.20.mlp.up_proj.lora_B.weight': tensor([[-1.3769e-05, -1.3580e-03,  1.1520e-03,  ...,  4.4250e-03,\n",
       "           5.1880e-04,  9.1553e-05],\n",
       "         [ 1.3809e-03,  1.6174e-03, -3.2043e-03,  ..., -1.6098e-03,\n",
       "           8.5235e-06, -4.4823e-04],\n",
       "         [ 1.5106e-03, -7.8583e-04, -1.2054e-03,  ..., -1.1597e-03,\n",
       "           2.6550e-03, -2.1667e-03],\n",
       "         ...,\n",
       "         [-6.2561e-04, -1.7166e-03, -2.6321e-04,  ..., -7.3242e-04,\n",
       "           2.1973e-03,  2.6107e-05],\n",
       "         [ 3.1090e-04, -1.0376e-03,  1.0071e-03,  ...,  9.2697e-04,\n",
       "          -3.3722e-03, -1.0529e-03],\n",
       "         [ 2.5177e-03, -1.1139e-03, -6.9427e-04,  ..., -2.5940e-03,\n",
       "           1.5182e-03,  1.7929e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.20.self_attn.k_proj.lora_A.weight': tensor([[-1.0925e-02,  3.3417e-03, -1.1292e-02,  ...,  3.4180e-03,\n",
       "          -1.2573e-02,  1.0620e-02],\n",
       "         [-1.3580e-03,  9.7656e-03, -6.5002e-03,  ...,  4.3106e-04,\n",
       "          -1.6602e-02,  9.9182e-04],\n",
       "         [ 4.1809e-03, -2.3804e-03, -1.2131e-03,  ...,  1.5137e-02,\n",
       "           1.1841e-02,  1.3916e-02],\n",
       "         ...,\n",
       "         [-1.3245e-02, -5.4836e-05,  2.7924e-03,  ...,  7.2021e-03,\n",
       "           3.8605e-03,  8.8501e-03],\n",
       "         [-7.8735e-03,  3.1281e-03,  5.6763e-03,  ...,  1.5991e-02,\n",
       "          -1.1597e-02,  7.6904e-03],\n",
       "         [-4.6082e-03, -8.4839e-03, -5.2490e-03,  ...,  1.1902e-02,\n",
       "          -1.3672e-02,  7.6904e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.20.self_attn.k_proj.lora_B.weight': tensor([[-1.1110e-04,  1.2283e-03,  4.5776e-05,  ...,  1.0910e-03,\n",
       "           1.7090e-03,  1.2360e-03],\n",
       "         [ 2.0142e-03,  2.5024e-03, -3.3379e-04,  ..., -1.5869e-03,\n",
       "           2.1210e-03, -5.8365e-04],\n",
       "         [ 1.3885e-03, -3.6011e-03, -8.3923e-04,  ..., -7.2479e-04,\n",
       "           2.1515e-03,  1.0452e-03],\n",
       "         ...,\n",
       "         [-1.1292e-03, -1.1063e-03,  8.9264e-04,  ...,  3.0212e-03,\n",
       "           9.0790e-04, -2.7466e-03],\n",
       "         [ 1.8311e-03,  1.6174e-03,  2.1515e-03,  ...,  2.8534e-03,\n",
       "          -1.1902e-03, -1.6708e-03],\n",
       "         [-2.4567e-03, -9.0790e-04, -4.6387e-03,  ..., -1.3199e-03,\n",
       "          -3.3875e-03,  2.3651e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.20.self_attn.o_proj.lora_A.weight': tensor([[ 0.0029,  0.0024,  0.0041,  ...,  0.0079,  0.0127,  0.0043],\n",
       "         [ 0.0043,  0.0102,  0.0109,  ...,  0.0109,  0.0004,  0.0092],\n",
       "         [-0.0168,  0.0115, -0.0121,  ...,  0.0044, -0.0167,  0.0103],\n",
       "         ...,\n",
       "         [-0.0146, -0.0083,  0.0030,  ...,  0.0132, -0.0057, -0.0150],\n",
       "         [ 0.0092,  0.0131, -0.0052,  ..., -0.0068, -0.0051, -0.0082],\n",
       "         [ 0.0108,  0.0011,  0.0043,  ..., -0.0020,  0.0008,  0.0176]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.20.self_attn.o_proj.lora_B.weight': tensor([[-1.3275e-03, -2.7618e-03,  1.8311e-03,  ...,  2.3804e-03,\n",
       "          -4.1199e-04, -1.5945e-03],\n",
       "         [-2.7418e-05,  3.7956e-04,  9.4604e-04,  ..., -2.5787e-03,\n",
       "           2.2888e-03, -2.4261e-03],\n",
       "         [ 1.7395e-03,  7.8678e-05, -2.0294e-03,  ..., -2.2430e-03,\n",
       "          -3.4180e-03, -1.4343e-03],\n",
       "         ...,\n",
       "         [-6.2561e-04,  1.9684e-03, -1.1978e-03,  ..., -2.3499e-03,\n",
       "           1.9836e-03,  7.4863e-05],\n",
       "         [-2.9297e-03, -1.9455e-04, -6.0272e-04,  ..., -9.7656e-04,\n",
       "           6.5613e-04,  1.5640e-04],\n",
       "         [ 2.4986e-04,  7.2479e-05, -3.4523e-04,  ...,  1.0920e-04,\n",
       "          -3.5553e-03, -2.1515e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.20.self_attn.q_proj.lora_A.weight': tensor([[ 0.0022, -0.0107,  0.0071,  ..., -0.0142, -0.0126,  0.0110],\n",
       "         [ 0.0081,  0.0105, -0.0011,  ...,  0.0008, -0.0080, -0.0017],\n",
       "         [ 0.0089, -0.0172,  0.0110,  ...,  0.0061, -0.0107, -0.0146],\n",
       "         ...,\n",
       "         [-0.0118, -0.0033,  0.0157,  ..., -0.0039,  0.0066,  0.0036],\n",
       "         [ 0.0052, -0.0097,  0.0126,  ...,  0.0075, -0.0108, -0.0029],\n",
       "         [ 0.0010,  0.0063, -0.0094,  ...,  0.0063,  0.0120, -0.0152]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.20.self_attn.q_proj.lora_B.weight': tensor([[-0.0009, -0.0013,  0.0030,  ..., -0.0003, -0.0021,  0.0002],\n",
       "         [ 0.0008, -0.0008, -0.0055,  ...,  0.0022,  0.0022, -0.0013],\n",
       "         [ 0.0035,  0.0011, -0.0018,  ...,  0.0003,  0.0037,  0.0022],\n",
       "         ...,\n",
       "         [-0.0011, -0.0018, -0.0004,  ...,  0.0010, -0.0010,  0.0034],\n",
       "         [ 0.0017,  0.0002, -0.0014,  ...,  0.0001,  0.0015, -0.0021],\n",
       "         [ 0.0007,  0.0029,  0.0001,  ..., -0.0026,  0.0010,  0.0016]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.20.self_attn.v_proj.lora_A.weight': tensor([[-3.4180e-03, -8.4839e-03,  3.7003e-04,  ...,  5.8594e-03,\n",
       "           9.2316e-04, -5.1737e-05],\n",
       "         [-2.1839e-04, -4.3640e-03,  1.6357e-02,  ..., -1.1230e-02,\n",
       "           1.5198e-02, -2.0752e-03],\n",
       "         [ 1.5259e-02,  9.0027e-04,  6.4087e-03,  ..., -3.9482e-04,\n",
       "           1.5869e-02,  6.0120e-03],\n",
       "         ...,\n",
       "         [ 2.6941e-05,  9.3994e-03,  1.4221e-02,  ..., -3.1738e-03,\n",
       "          -1.1353e-02, -8.7891e-03],\n",
       "         [ 9.0332e-03, -8.9111e-03,  2.2125e-03,  ..., -1.2451e-02,\n",
       "          -1.3306e-02, -8.6670e-03],\n",
       "         [-1.0071e-02,  1.5747e-02, -2.3346e-03,  ..., -3.8452e-03,\n",
       "           5.8899e-03,  7.5378e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.20.self_attn.v_proj.lora_B.weight': tensor([[ 5.7220e-04, -8.6975e-04,  8.4686e-04,  ..., -5.7220e-04,\n",
       "          -1.5831e-04,  1.5640e-04],\n",
       "         [-6.4468e-04,  1.7548e-03, -8.7738e-04,  ...,  1.4648e-03,\n",
       "          -5.2261e-04,  2.3956e-03],\n",
       "         [-7.9727e-04, -2.6245e-03,  4.4632e-04,  ..., -2.0905e-03,\n",
       "           6.8665e-04,  2.1973e-03],\n",
       "         ...,\n",
       "         [-4.6921e-04, -8.1635e-04,  1.1826e-03,  ..., -4.0245e-04,\n",
       "          -9.0122e-05, -1.6212e-04],\n",
       "         [-1.3161e-04,  6.8283e-04, -1.1673e-03,  ...,  1.9379e-03,\n",
       "          -2.4414e-04,  8.0872e-04],\n",
       "         [-2.8229e-03, -2.0905e-03, -1.8005e-03,  ...,  3.0518e-04,\n",
       "           2.9602e-03,  4.9973e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.21.mlp.down_proj.lora_A.weight': tensor([[-0.0015,  0.0103,  0.0094,  ..., -0.0098,  0.0009, -0.0109],\n",
       "         [-0.0066, -0.0088, -0.0037,  ...,  0.0035, -0.0092, -0.0049],\n",
       "         [ 0.0084, -0.0045, -0.0034,  ..., -0.0020,  0.0024,  0.0042],\n",
       "         ...,\n",
       "         [ 0.0084, -0.0057,  0.0118,  ..., -0.0079,  0.0049,  0.0058],\n",
       "         [ 0.0022,  0.0027, -0.0029,  ..., -0.0099,  0.0005,  0.0029],\n",
       "         [ 0.0015, -0.0068, -0.0084,  ..., -0.0118,  0.0023,  0.0052]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.21.mlp.down_proj.lora_B.weight': tensor([[ 3.7384e-04,  4.7684e-05, -4.2534e-04,  ...,  1.6479e-03,\n",
       "           1.1749e-03, -1.4420e-03],\n",
       "         [-3.6316e-03,  2.4872e-03,  2.0294e-03,  ..., -2.5787e-03,\n",
       "           1.8845e-03,  4.7684e-04],\n",
       "         [ 2.6321e-04, -6.6757e-04,  9.4223e-04,  ...,  1.2493e-04,\n",
       "          -1.7319e-03, -4.5776e-04],\n",
       "         ...,\n",
       "         [ 8.3447e-06, -1.7166e-03,  1.0452e-03,  ..., -4.4823e-04,\n",
       "          -3.1738e-03,  2.7657e-04],\n",
       "         [-1.5640e-03,  1.3046e-03,  8.3923e-04,  ..., -1.7929e-03,\n",
       "          -1.2283e-03, -1.1826e-03],\n",
       "         [ 1.7319e-03, -1.3962e-03,  9.4986e-04,  ..., -3.5095e-04,\n",
       "           8.1635e-04,  4.2915e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.21.mlp.gate_proj.lora_A.weight': tensor([[ 0.0101,  0.0140, -0.0074,  ..., -0.0114, -0.0092,  0.0006],\n",
       "         [ 0.0117, -0.0063,  0.0150,  ...,  0.0007, -0.0165, -0.0030],\n",
       "         [ 0.0110, -0.0038, -0.0051,  ...,  0.0149, -0.0020, -0.0142],\n",
       "         ...,\n",
       "         [ 0.0049,  0.0066,  0.0142,  ..., -0.0060, -0.0003, -0.0036],\n",
       "         [ 0.0159, -0.0156, -0.0004,  ...,  0.0108, -0.0087,  0.0137],\n",
       "         [ 0.0012, -0.0021, -0.0164,  ..., -0.0029, -0.0009, -0.0103]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.21.mlp.gate_proj.lora_B.weight': tensor([[-1.7929e-03, -1.2398e-04,  3.6001e-05,  ...,  1.6403e-03,\n",
       "          -1.2207e-03, -7.9727e-04],\n",
       "         [ 3.4027e-03,  1.5793e-03,  4.6692e-03,  ...,  1.3351e-03,\n",
       "           8.8882e-04,  3.5706e-03],\n",
       "         [ 3.0060e-03,  2.1515e-03,  5.5237e-03,  ...,  2.5177e-03,\n",
       "          -2.3346e-03,  3.9673e-03],\n",
       "         ...,\n",
       "         [ 1.1015e-04,  5.6839e-04,  4.8065e-04,  ...,  3.3875e-03,\n",
       "           1.1597e-03,  1.1139e-03],\n",
       "         [ 3.1090e-04,  7.3242e-04, -1.2283e-03,  ..., -3.7193e-04,\n",
       "          -1.2112e-04, -1.4591e-04],\n",
       "         [ 4.5967e-04, -3.9062e-03, -5.1880e-04,  ..., -3.2234e-04,\n",
       "           1.3657e-03, -1.3275e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.21.mlp.up_proj.lora_A.weight': tensor([[-0.0062,  0.0167,  0.0145,  ..., -0.0109, -0.0112,  0.0003],\n",
       "         [-0.0125,  0.0065,  0.0049,  ...,  0.0040,  0.0135, -0.0010],\n",
       "         [ 0.0057, -0.0143,  0.0005,  ...,  0.0161,  0.0093,  0.0049],\n",
       "         ...,\n",
       "         [-0.0156,  0.0057, -0.0071,  ..., -0.0127, -0.0057, -0.0066],\n",
       "         [-0.0102, -0.0098, -0.0135,  ...,  0.0015,  0.0133, -0.0019],\n",
       "         [ 0.0009,  0.0129,  0.0022,  ...,  0.0123,  0.0110, -0.0052]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.21.mlp.up_proj.lora_B.weight': tensor([[-4.6730e-04,  9.1171e-04, -1.0681e-03,  ...,  5.2643e-04,\n",
       "           7.2479e-05,  3.2425e-04],\n",
       "         [ 1.0834e-03, -1.0395e-04,  1.8539e-03,  ...,  7.7820e-04,\n",
       "          -4.3869e-05,  1.2894e-03],\n",
       "         [ 2.8534e-03,  1.5945e-03,  3.1891e-03,  ..., -2.2888e-03,\n",
       "           1.4648e-03,  1.5182e-03],\n",
       "         ...,\n",
       "         [-1.6098e-03, -2.4319e-04,  1.9455e-04,  ...,  1.8921e-03,\n",
       "          -8.3923e-05,  1.4210e-04],\n",
       "         [-6.6757e-04, -2.8801e-04,  6.3705e-04,  ...,  3.8147e-04,\n",
       "           2.6941e-05, -4.4823e-04],\n",
       "         [-1.8158e-03, -2.7161e-03, -1.0910e-03,  ...,  7.1716e-04,\n",
       "           1.2207e-03, -3.4943e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.21.self_attn.k_proj.lora_A.weight': tensor([[ 0.0122, -0.0071,  0.0011,  ..., -0.0069,  0.0161,  0.0033],\n",
       "         [-0.0018,  0.0142,  0.0044,  ...,  0.0123,  0.0160,  0.0028],\n",
       "         [ 0.0110, -0.0078,  0.0011,  ...,  0.0021, -0.0149, -0.0184],\n",
       "         ...,\n",
       "         [-0.0099, -0.0099,  0.0057,  ..., -0.0103, -0.0049,  0.0044],\n",
       "         [-0.0108, -0.0075, -0.0042,  ..., -0.0022, -0.0081, -0.0139],\n",
       "         [-0.0078, -0.0017,  0.0112,  ...,  0.0044, -0.0072, -0.0049]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.21.self_attn.k_proj.lora_B.weight': tensor([[ 9.5749e-04,  4.5776e-05,  4.3106e-04,  ...,  1.3809e-03,\n",
       "           4.0245e-04, -4.2915e-04],\n",
       "         [ 2.6550e-03,  1.8082e-03, -1.9360e-04,  ...,  5.8365e-04,\n",
       "          -1.4038e-03,  8.6212e-04],\n",
       "         [-1.6212e-04,  4.5586e-04,  1.2970e-04,  ..., -2.0504e-04,\n",
       "          -4.3297e-04, -9.0122e-05],\n",
       "         ...,\n",
       "         [-3.8719e-04, -2.0447e-03, -1.8005e-03,  ...,  6.1417e-04,\n",
       "          -2.3804e-03, -6.1035e-04],\n",
       "         [ 4.3640e-03,  3.5248e-03, -2.0294e-03,  ..., -2.1973e-03,\n",
       "          -2.7924e-03, -7.9346e-04],\n",
       "         [ 4.3488e-04, -1.3504e-03, -1.8082e-03,  ...,  5.5695e-04,\n",
       "           1.9989e-03,  1.5106e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.21.self_attn.o_proj.lora_A.weight': tensor([[-1.7822e-02, -1.5869e-02,  5.7068e-03,  ...,  3.7842e-03,\n",
       "           3.8147e-03,  3.4332e-03],\n",
       "         [-2.3956e-03, -2.1362e-03, -1.0925e-02,  ..., -1.9302e-03,\n",
       "           7.8735e-03,  2.5635e-03],\n",
       "         [ 1.1902e-02,  9.9540e-06, -6.0120e-03,  ...,  1.2741e-03,\n",
       "           5.8746e-04,  3.4943e-03],\n",
       "         ...,\n",
       "         [-1.1963e-02,  7.7209e-03, -1.2085e-02,  ..., -5.0049e-03,\n",
       "           1.5747e-02, -1.1475e-02],\n",
       "         [ 1.2756e-02,  1.3367e-02,  1.1047e-02,  ..., -5.8899e-03,\n",
       "           1.8311e-03, -1.0803e-02],\n",
       "         [-5.1575e-03,  4.1809e-03, -7.1106e-03,  ...,  1.5259e-02,\n",
       "          -5.0354e-03,  9.9945e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.21.self_attn.o_proj.lora_B.weight': tensor([[ 1.6308e-04,  2.7008e-03, -6.4087e-04,  ...,  2.5177e-04,\n",
       "           4.0436e-04, -2.3556e-04],\n",
       "         [-1.8387e-03,  2.5558e-04,  7.7820e-04,  ...,  2.7847e-04,\n",
       "          -2.6855e-03,  1.0834e-03],\n",
       "         [-1.9302e-03,  1.0147e-03, -1.0910e-03,  ..., -3.9978e-03,\n",
       "          -1.5640e-04, -6.8665e-05],\n",
       "         ...,\n",
       "         [-9.8419e-04,  2.1057e-03, -1.4191e-03,  ...,  3.8147e-05,\n",
       "          -4.6349e-04, -2.4223e-04],\n",
       "         [ 2.2430e-03, -1.3046e-03, -1.2338e-05,  ..., -2.1515e-03,\n",
       "          -3.7193e-04, -1.6479e-03],\n",
       "         [-2.0447e-03, -4.6349e-04,  1.7548e-03,  ...,  1.1826e-03,\n",
       "          -1.6880e-04,  5.8746e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.21.self_attn.q_proj.lora_A.weight': tensor([[-0.0053,  0.0118, -0.0076,  ...,  0.0153, -0.0112, -0.0006],\n",
       "         [ 0.0017,  0.0099, -0.0015,  ...,  0.0056,  0.0033, -0.0065],\n",
       "         [ 0.0006,  0.0060, -0.0078,  ...,  0.0016,  0.0110, -0.0069],\n",
       "         ...,\n",
       "         [-0.0115,  0.0059,  0.0001,  ..., -0.0083, -0.0115,  0.0023],\n",
       "         [ 0.0084,  0.0060, -0.0115,  ...,  0.0151,  0.0025, -0.0042],\n",
       "         [-0.0048, -0.0101,  0.0080,  ..., -0.0076,  0.0027,  0.0041]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.21.self_attn.q_proj.lora_B.weight': tensor([[ 7.2861e-04,  1.5793e-03, -4.5300e-05,  ...,  2.1362e-03,\n",
       "          -4.1199e-03,  3.4637e-03],\n",
       "         [-1.7395e-03,  2.4109e-03, -6.0654e-04,  ...,  2.1667e-03,\n",
       "          -1.9302e-03,  1.9989e-03],\n",
       "         [-3.9816e-05,  9.8419e-04,  4.2343e-04,  ...,  1.1826e-03,\n",
       "          -1.0757e-03,  1.8768e-03],\n",
       "         ...,\n",
       "         [ 1.8597e-04,  8.6594e-04, -2.8229e-03,  ...,  1.8692e-03,\n",
       "           9.1553e-04,  4.5967e-04],\n",
       "         [-2.0752e-03, -3.7537e-03,  2.4872e-03,  ..., -4.6997e-03,\n",
       "           8.8882e-04,  5.5695e-04],\n",
       "         [ 1.5411e-03,  2.3746e-04,  2.1057e-03,  ..., -1.8921e-03,\n",
       "          -1.3962e-03, -6.5994e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.21.self_attn.v_proj.lora_A.weight': tensor([[-1.1536e-02, -1.2939e-02, -1.4282e-02,  ..., -1.2695e-02,\n",
       "           1.0498e-02, -1.1063e-03],\n",
       "         [ 5.8889e-05,  1.3672e-02, -3.2043e-03,  ...,  1.6968e-02,\n",
       "          -1.7090e-02, -9.0332e-03],\n",
       "         [-1.5991e-02, -1.9646e-04, -6.6223e-03,  ...,  7.3547e-03,\n",
       "           4.0588e-03, -6.5308e-03],\n",
       "         ...,\n",
       "         [-8.3618e-03,  1.0620e-02, -3.5706e-03,  ..., -9.8877e-03,\n",
       "           4.4556e-03, -5.4016e-03],\n",
       "         [ 2.2736e-03,  3.8757e-03,  1.1414e-02,  ...,  1.2512e-02,\n",
       "          -6.8054e-03, -9.4604e-03],\n",
       "         [ 4.0283e-03, -1.3184e-02, -2.0142e-03,  ..., -8.9722e-03,\n",
       "           1.5259e-02,  1.4282e-02]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.21.self_attn.v_proj.lora_B.weight': tensor([[ 1.5793e-03,  2.0599e-03, -2.2316e-04,  ..., -8.1253e-04,\n",
       "          -5.6028e-05,  5.8889e-05],\n",
       "         [-5.7220e-04,  1.1826e-03, -1.4954e-03,  ..., -2.5330e-03,\n",
       "           8.7738e-04, -1.0223e-03],\n",
       "         [ 7.4768e-04, -1.3046e-03, -6.5994e-04,  ...,  1.5335e-03,\n",
       "           1.2665e-03, -1.2970e-03],\n",
       "         ...,\n",
       "         [ 2.1057e-03, -1.1139e-03,  8.6594e-04,  ...,  6.9427e-04,\n",
       "          -3.6240e-04, -5.7220e-04],\n",
       "         [ 2.1362e-03,  2.2583e-03,  1.0777e-04,  ..., -1.8845e-03,\n",
       "           3.7193e-04,  9.3079e-04],\n",
       "         [ 1.8997e-03,  1.7395e-03,  4.3869e-04,  ..., -9.3460e-04,\n",
       "          -2.1839e-04,  1.7319e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.22.mlp.down_proj.lora_A.weight': tensor([[-0.0017,  0.0041, -0.0101,  ..., -0.0036,  0.0036,  0.0027],\n",
       "         [-0.0002, -0.0031, -0.0070,  ..., -0.0046, -0.0068, -0.0022],\n",
       "         [-0.0057,  0.0079,  0.0065,  ..., -0.0013, -0.0125, -0.0073],\n",
       "         ...,\n",
       "         [-0.0070,  0.0037,  0.0091,  ..., -0.0023, -0.0109,  0.0095],\n",
       "         [ 0.0027, -0.0045, -0.0070,  ...,  0.0064, -0.0038, -0.0065],\n",
       "         [ 0.0050,  0.0058,  0.0044,  ..., -0.0101,  0.0068,  0.0019]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.22.mlp.down_proj.lora_B.weight': tensor([[-5.1498e-04,  4.9973e-04, -1.7090e-03,  ...,  1.3428e-03,\n",
       "          -1.6479e-03, -1.4725e-03],\n",
       "         [-2.6245e-03, -8.9264e-04,  4.9744e-03,  ..., -1.3657e-03,\n",
       "           7.2861e-04,  6.3705e-04],\n",
       "         [-8.2016e-05,  1.9455e-04, -1.3580e-03,  ..., -2.9564e-04,\n",
       "           1.0300e-03,  1.4343e-03],\n",
       "         ...,\n",
       "         [-1.3428e-03, -1.5335e-03,  8.3923e-04,  ...,  3.7766e-04,\n",
       "           1.3962e-03,  1.5564e-03],\n",
       "         [ 1.5182e-03,  7.7438e-04, -4.5967e-04,  ..., -2.7084e-04,\n",
       "           4.1389e-04, -2.3651e-03],\n",
       "         [ 6.1798e-04, -6.7520e-04, -1.4687e-04,  ..., -2.5940e-04,\n",
       "          -3.3188e-04, -8.5068e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.22.mlp.gate_proj.lora_A.weight': tensor([[-0.0066, -0.0027, -0.0023,  ..., -0.0044, -0.0074,  0.0073],\n",
       "         [-0.0037,  0.0070,  0.0084,  ..., -0.0038,  0.0093, -0.0100],\n",
       "         [-0.0031, -0.0170,  0.0113,  ..., -0.0048, -0.0124,  0.0023],\n",
       "         ...,\n",
       "         [ 0.0107,  0.0113, -0.0060,  ..., -0.0071,  0.0107,  0.0014],\n",
       "         [ 0.0036,  0.0157, -0.0039,  ...,  0.0114, -0.0138,  0.0143],\n",
       "         [ 0.0159,  0.0036, -0.0057,  ...,  0.0139,  0.0096, -0.0195]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.22.mlp.gate_proj.lora_B.weight': tensor([[ 1.8845e-03,  6.3705e-04, -8.7357e-04,  ...,  6.4087e-04,\n",
       "           4.5776e-03, -2.2583e-03],\n",
       "         [-1.3504e-03, -9.3079e-04, -3.9482e-04,  ...,  2.6245e-03,\n",
       "           1.8768e-03, -3.7956e-04],\n",
       "         [ 2.2888e-03,  1.5163e-04,  2.9297e-03,  ..., -2.9373e-04,\n",
       "          -7.7057e-04,  1.7471e-03],\n",
       "         ...,\n",
       "         [ 1.2054e-03, -1.1215e-03, -1.8768e-03,  ..., -2.9945e-04,\n",
       "          -1.1444e-03,  4.9829e-05],\n",
       "         [-9.2697e-04,  3.2654e-03, -3.2959e-03,  ..., -3.3264e-03,\n",
       "           6.9809e-04, -1.3123e-03],\n",
       "         [-1.4400e-04,  3.6621e-04, -1.3809e-03,  ...,  8.5831e-04,\n",
       "          -1.4038e-03, -9.5749e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.22.mlp.up_proj.lora_A.weight': tensor([[ 0.0092,  0.0134, -0.0095,  ...,  0.0063, -0.0143, -0.0069],\n",
       "         [-0.0075,  0.0128,  0.0101,  ..., -0.0033,  0.0129, -0.0030],\n",
       "         [-0.0106,  0.0069, -0.0007,  ...,  0.0003, -0.0014, -0.0038],\n",
       "         ...,\n",
       "         [-0.0106,  0.0013, -0.0116,  ...,  0.0066, -0.0063, -0.0063],\n",
       "         [-0.0049, -0.0165,  0.0128,  ..., -0.0140,  0.0016, -0.0088],\n",
       "         [ 0.0040, -0.0092, -0.0145,  ...,  0.0020,  0.0046, -0.0011]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.22.mlp.up_proj.lora_B.weight': tensor([[ 8.8501e-04,  6.6757e-04,  5.5313e-04,  ...,  6.2180e-04,\n",
       "           3.7956e-04,  2.6398e-03],\n",
       "         [-6.4087e-04,  4.1809e-03, -5.8365e-04,  ..., -7.9155e-05,\n",
       "          -1.5335e-03,  6.7520e-04],\n",
       "         [-5.4598e-05, -2.8687e-03, -1.6861e-03,  ..., -3.4142e-04,\n",
       "          -2.5177e-03,  5.1498e-04],\n",
       "         ...,\n",
       "         [-2.2430e-03,  2.8687e-03,  2.5177e-03,  ..., -1.0681e-03,\n",
       "           1.4954e-03, -1.6022e-04],\n",
       "         [ 4.0283e-03, -2.2583e-03, -2.5940e-03,  ..., -3.0518e-03,\n",
       "          -3.0518e-03,  4.0588e-03],\n",
       "         [-4.5204e-04,  5.3787e-04,  9.0027e-04,  ..., -1.7853e-03,\n",
       "          -1.4725e-03,  2.4872e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.22.self_attn.k_proj.lora_A.weight': tensor([[ 0.0031,  0.0090, -0.0009,  ..., -0.0085, -0.0076,  0.0149],\n",
       "         [ 0.0118,  0.0072, -0.0046,  ..., -0.0012,  0.0106, -0.0067],\n",
       "         [-0.0119, -0.0023, -0.0124,  ...,  0.0028, -0.0043, -0.0038],\n",
       "         ...,\n",
       "         [-0.0126,  0.0039,  0.0037,  ...,  0.0108, -0.0057, -0.0057],\n",
       "         [ 0.0043,  0.0084,  0.0076,  ...,  0.0135, -0.0098,  0.0166],\n",
       "         [-0.0105,  0.0006,  0.0023,  ...,  0.0110, -0.0141,  0.0027]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.22.self_attn.k_proj.lora_B.weight': tensor([[-1.8158e-03, -1.6632e-03, -3.8910e-03,  ...,  7.2098e-04,\n",
       "           3.6163e-03, -8.0490e-04],\n",
       "         [-4.5471e-03, -3.2501e-03, -3.5095e-03,  ...,  2.3956e-03,\n",
       "           2.0447e-03, -9.7656e-04],\n",
       "         [-2.5787e-03,  3.1662e-04, -1.4343e-03,  ...,  1.3504e-03,\n",
       "          -5.2643e-04, -9.3079e-04],\n",
       "         ...,\n",
       "         [ 7.4863e-05, -4.9973e-04, -5.9509e-04,  ..., -1.0452e-03,\n",
       "           1.3046e-03,  4.0054e-04],\n",
       "         [-4.8828e-04,  2.0142e-03,  2.0447e-03,  ..., -1.5182e-03,\n",
       "          -7.7820e-04,  2.5024e-03],\n",
       "         [ 2.3651e-04,  1.4572e-03, -3.4904e-04,  ...,  1.0376e-03,\n",
       "          -9.7275e-04, -1.1292e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.22.self_attn.o_proj.lora_A.weight': tensor([[ 0.0031,  0.0007,  0.0073,  ...,  0.0068, -0.0153, -0.0055],\n",
       "         [ 0.0179, -0.0109, -0.0061,  ...,  0.0075,  0.0043, -0.0083],\n",
       "         [-0.0021,  0.0084,  0.0146,  ...,  0.0066,  0.0054, -0.0100],\n",
       "         ...,\n",
       "         [-0.0140, -0.0036,  0.0089,  ...,  0.0142, -0.0074, -0.0079],\n",
       "         [ 0.0029,  0.0096, -0.0078,  ..., -0.0100,  0.0125, -0.0082],\n",
       "         [-0.0086, -0.0073,  0.0001,  ..., -0.0043,  0.0063,  0.0028]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.22.self_attn.o_proj.lora_B.weight': tensor([[-0.0019,  0.0022,  0.0003,  ..., -0.0010, -0.0004, -0.0019],\n",
       "         [ 0.0004, -0.0014,  0.0003,  ...,  0.0029, -0.0026,  0.0004],\n",
       "         [ 0.0013,  0.0022, -0.0020,  ..., -0.0007,  0.0001,  0.0014],\n",
       "         ...,\n",
       "         [-0.0024,  0.0028, -0.0004,  ..., -0.0022,  0.0021,  0.0009],\n",
       "         [ 0.0015, -0.0022, -0.0013,  ..., -0.0006, -0.0006, -0.0001],\n",
       "         [ 0.0011, -0.0013,  0.0002,  ...,  0.0008, -0.0007,  0.0015]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.22.self_attn.q_proj.lora_A.weight': tensor([[-0.0049, -0.0029, -0.0146,  ...,  0.0030,  0.0067,  0.0146],\n",
       "         [ 0.0015,  0.0078,  0.0104,  ..., -0.0047,  0.0052,  0.0089],\n",
       "         [-0.0179, -0.0075,  0.0087,  ..., -0.0027, -0.0082, -0.0144],\n",
       "         ...,\n",
       "         [-0.0060,  0.0161, -0.0115,  ...,  0.0140,  0.0062,  0.0001],\n",
       "         [-0.0117, -0.0044,  0.0029,  ..., -0.0059, -0.0061, -0.0134],\n",
       "         [ 0.0091, -0.0049,  0.0051,  ..., -0.0012,  0.0007,  0.0131]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.22.self_attn.q_proj.lora_B.weight': tensor([[ 1.3809e-03, -1.0834e-03, -8.0109e-04,  ...,  4.5395e-04,\n",
       "           1.2207e-03,  5.6839e-04],\n",
       "         [-1.2360e-03, -3.8719e-04,  5.2643e-04,  ..., -1.9226e-03,\n",
       "           1.4572e-03, -1.4191e-03],\n",
       "         [ 1.1597e-03,  2.6550e-03, -1.2741e-03,  ...,  2.9297e-03,\n",
       "           2.2430e-03, -1.3657e-03],\n",
       "         ...,\n",
       "         [ 6.1035e-04,  1.4648e-03, -4.6158e-04,  ..., -5.1117e-04,\n",
       "          -1.9531e-03, -8.5449e-04],\n",
       "         [-8.0109e-04, -3.8910e-04, -8.7261e-05,  ..., -5.7602e-04,\n",
       "          -9.4223e-04, -1.1139e-03],\n",
       "         [-2.0142e-03, -1.6451e-05,  3.9101e-05,  ..., -1.6174e-03,\n",
       "          -5.6076e-04,  3.0708e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.22.self_attn.v_proj.lora_A.weight': tensor([[ 0.0092, -0.0048, -0.0033,  ..., -0.0082, -0.0009,  0.0073],\n",
       "         [-0.0142,  0.0038,  0.0106,  ...,  0.0109,  0.0004,  0.0030],\n",
       "         [-0.0121, -0.0059, -0.0100,  ..., -0.0116, -0.0111, -0.0089],\n",
       "         ...,\n",
       "         [ 0.0074, -0.0085, -0.0067,  ...,  0.0083,  0.0151, -0.0027],\n",
       "         [-0.0085,  0.0133,  0.0157,  ...,  0.0098, -0.0101, -0.0110],\n",
       "         [ 0.0087, -0.0070,  0.0139,  ..., -0.0128, -0.0135, -0.0098]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.22.self_attn.v_proj.lora_B.weight': tensor([[-9.8419e-04, -1.1826e-03,  4.0054e-04,  ...,  1.2436e-03,\n",
       "          -2.8992e-04,  1.9684e-03],\n",
       "         [-2.8419e-04,  4.5967e-04,  1.4191e-03,  ..., -4.4060e-04,\n",
       "          -1.2741e-03, -5.4550e-04],\n",
       "         [ 1.7929e-03, -6.7902e-04,  7.7438e-04,  ..., -3.6430e-04,\n",
       "           1.2283e-03, -1.1368e-03],\n",
       "         ...,\n",
       "         [-4.7493e-04, -6.0272e-04, -8.6594e-04,  ...,  5.1117e-04,\n",
       "          -1.4782e-04, -8.8501e-04],\n",
       "         [-2.1667e-03,  4.1199e-04,  9.3460e-04,  ...,  1.8768e-03,\n",
       "          -4.1199e-04,  2.7924e-03],\n",
       "         [ 1.5974e-05,  7.1716e-04,  5.2643e-04,  ..., -1.6174e-03,\n",
       "          -3.7193e-05,  3.1853e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.23.mlp.down_proj.lora_A.weight': tensor([[-0.0058, -0.0040, -0.0067,  ..., -0.0067, -0.0003,  0.0096],\n",
       "         [-0.0042, -0.0074, -0.0075,  ...,  0.0028, -0.0107, -0.0005],\n",
       "         [-0.0055,  0.0069, -0.0079,  ..., -0.0067,  0.0040, -0.0039],\n",
       "         ...,\n",
       "         [ 0.0012, -0.0095, -0.0075,  ...,  0.0004, -0.0087,  0.0096],\n",
       "         [-0.0002, -0.0083, -0.0008,  ..., -0.0012, -0.0007,  0.0080],\n",
       "         [ 0.0100, -0.0088,  0.0030,  ..., -0.0030, -0.0071, -0.0008]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.23.mlp.down_proj.lora_B.weight': tensor([[ 1.4801e-03, -3.3951e-04,  9.1553e-05,  ..., -9.2506e-05,\n",
       "           1.5335e-03, -7.1716e-04],\n",
       "         [-1.0986e-03,  7.6294e-04, -2.3804e-03,  ...,  9.0790e-04,\n",
       "           2.2736e-03, -4.4441e-04],\n",
       "         [ 2.7924e-03, -2.2793e-04, -9.8419e-04,  ...,  1.1673e-03,\n",
       "           2.1458e-04, -2.1515e-03],\n",
       "         ...,\n",
       "         [-1.0538e-04, -3.3951e-04, -5.9605e-05,  ...,  2.4872e-03,\n",
       "          -1.0300e-03,  1.1520e-03],\n",
       "         [ 2.0447e-03,  2.4915e-05, -6.2943e-05,  ...,  1.6327e-03,\n",
       "           9.8419e-04,  4.5395e-04],\n",
       "         [-1.0681e-03,  8.5068e-04, -1.0452e-03,  ..., -5.8365e-04,\n",
       "           2.4567e-03, -1.2360e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.23.mlp.gate_proj.lora_A.weight': tensor([[-0.0131,  0.0129,  0.0102,  ...,  0.0038,  0.0026,  0.0118],\n",
       "         [-0.0079, -0.0064,  0.0062,  ...,  0.0013,  0.0045,  0.0018],\n",
       "         [-0.0139,  0.0052, -0.0044,  ..., -0.0069, -0.0007, -0.0107],\n",
       "         ...,\n",
       "         [-0.0154, -0.0080, -0.0065,  ...,  0.0055, -0.0114, -0.0071],\n",
       "         [-0.0053,  0.0062, -0.0101,  ..., -0.0054, -0.0074, -0.0059],\n",
       "         [-0.0042, -0.0159,  0.0151,  ...,  0.0037, -0.0014, -0.0081]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.23.mlp.gate_proj.lora_B.weight': tensor([[-1.5869e-03,  1.8616e-03,  1.7319e-03,  ..., -2.3193e-03,\n",
       "          -7.7820e-04,  4.1199e-04],\n",
       "         [ 1.2207e-03,  2.5330e-03, -2.5482e-03,  ...,  1.8845e-03,\n",
       "           8.6594e-04,  5.7220e-04],\n",
       "         [ 1.3428e-03,  6.4850e-04, -7.7820e-04,  ...,  2.5940e-03,\n",
       "          -2.1210e-03, -5.2643e-04],\n",
       "         ...,\n",
       "         [-2.0752e-03, -6.4087e-03, -3.3569e-03,  ...,  6.7902e-04,\n",
       "          -2.9907e-03, -4.1504e-03],\n",
       "         [ 2.1515e-03,  2.2793e-04, -2.1458e-05,  ...,  2.5330e-03,\n",
       "           2.4319e-04, -2.8687e-03],\n",
       "         [ 1.7319e-03,  2.2888e-03,  2.4719e-03,  ...,  3.8757e-03,\n",
       "          -2.7924e-03, -1.0920e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.23.mlp.up_proj.lora_A.weight': tensor([[ 0.0030,  0.0112, -0.0035,  ..., -0.0084,  0.0042, -0.0015],\n",
       "         [-0.0087, -0.0043, -0.0038,  ..., -0.0074, -0.0159, -0.0101],\n",
       "         [ 0.0051,  0.0032, -0.0173,  ...,  0.0117, -0.0030, -0.0118],\n",
       "         ...,\n",
       "         [-0.0004,  0.0106, -0.0110,  ...,  0.0031, -0.0101, -0.0087],\n",
       "         [-0.0096,  0.0099,  0.0071,  ...,  0.0081, -0.0087, -0.0041],\n",
       "         [-0.0049,  0.0078, -0.0040,  ...,  0.0112, -0.0104, -0.0018]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.23.mlp.up_proj.lora_B.weight': tensor([[ 0.0030,  0.0012, -0.0008,  ..., -0.0014, -0.0015, -0.0015],\n",
       "         [-0.0001,  0.0018, -0.0006,  ..., -0.0015, -0.0010,  0.0017],\n",
       "         [-0.0031,  0.0015, -0.0005,  ..., -0.0011,  0.0010,  0.0003],\n",
       "         ...,\n",
       "         [ 0.0010, -0.0003,  0.0015,  ...,  0.0010, -0.0008,  0.0021],\n",
       "         [ 0.0005, -0.0032,  0.0018,  ..., -0.0015, -0.0007, -0.0035],\n",
       "         [-0.0003, -0.0010, -0.0012,  ..., -0.0003, -0.0028, -0.0003]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.23.self_attn.k_proj.lora_A.weight': tensor([[ 0.0172, -0.0051,  0.0120,  ..., -0.0024, -0.0114,  0.0031],\n",
       "         [ 0.0094, -0.0044, -0.0079,  ...,  0.0159, -0.0115, -0.0106],\n",
       "         [-0.0117, -0.0077, -0.0050,  ..., -0.0109,  0.0033,  0.0079],\n",
       "         ...,\n",
       "         [-0.0043,  0.0036,  0.0145,  ...,  0.0024, -0.0033, -0.0126],\n",
       "         [-0.0048,  0.0129, -0.0109,  ..., -0.0027,  0.0058,  0.0084],\n",
       "         [-0.0147, -0.0116,  0.0113,  ..., -0.0112, -0.0013, -0.0055]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.23.self_attn.k_proj.lora_B.weight': tensor([[ 1.2131e-03,  1.4877e-03, -1.2283e-03,  ...,  8.3923e-04,\n",
       "          -1.5640e-03,  3.4142e-04],\n",
       "         [ 1.3046e-03, -2.7466e-03, -1.9150e-03,  ...,  5.0659e-03,\n",
       "           1.4725e-03,  2.3956e-03],\n",
       "         [ 1.1292e-03,  9.1934e-04, -1.6098e-03,  ...,  6.7139e-03,\n",
       "           1.0757e-03,  4.5204e-04],\n",
       "         ...,\n",
       "         [-1.0223e-03,  1.5926e-04, -1.0910e-03,  ..., -1.7700e-03,\n",
       "          -3.3112e-03,  2.2125e-03],\n",
       "         [-1.0300e-04, -1.0376e-03, -5.1880e-04,  ...,  1.9836e-03,\n",
       "           1.3046e-03,  7.0953e-04],\n",
       "         [ 2.3651e-03,  3.6926e-03,  2.1973e-03,  ..., -2.8381e-03,\n",
       "           9.6798e-05, -1.2436e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.23.self_attn.o_proj.lora_A.weight': tensor([[-0.0106,  0.0104, -0.0079,  ..., -0.0129, -0.0100, -0.0008],\n",
       "         [ 0.0017,  0.0186,  0.0150,  ..., -0.0077, -0.0116, -0.0183],\n",
       "         [-0.0029,  0.0050,  0.0029,  ...,  0.0011, -0.0120,  0.0126],\n",
       "         ...,\n",
       "         [-0.0152,  0.0037,  0.0057,  ..., -0.0056, -0.0022, -0.0045],\n",
       "         [-0.0040, -0.0123,  0.0048,  ...,  0.0002,  0.0008, -0.0025],\n",
       "         [ 0.0041,  0.0104,  0.0055,  ...,  0.0019,  0.0110,  0.0157]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.23.self_attn.o_proj.lora_B.weight': tensor([[ 3.7079e-03,  1.5869e-03,  2.1210e-03,  ...,  7.5150e-04,\n",
       "           1.4305e-04, -2.7313e-03],\n",
       "         [-1.0834e-03,  1.1215e-03, -3.0365e-03,  ..., -4.1504e-03,\n",
       "           1.9684e-03,  3.3417e-03],\n",
       "         [-3.9368e-03,  1.8463e-03, -4.9973e-04,  ..., -3.8757e-03,\n",
       "          -1.2589e-03, -3.0365e-03],\n",
       "         ...,\n",
       "         [-1.9932e-04,  1.8616e-03,  5.3406e-04,  ..., -2.5330e-03,\n",
       "           3.6240e-04, -5.3024e-04],\n",
       "         [-1.7262e-04, -2.5635e-03, -1.3428e-03,  ..., -9.6512e-04,\n",
       "          -1.1215e-03,  9.1553e-05],\n",
       "         [ 9.6512e-04,  1.3657e-03,  7.5817e-05,  ..., -1.8616e-03,\n",
       "           1.1978e-03, -1.8997e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.23.self_attn.q_proj.lora_A.weight': tensor([[-0.0019,  0.0092,  0.0061,  ...,  0.0023, -0.0024, -0.0038],\n",
       "         [ 0.0064, -0.0028, -0.0093,  ...,  0.0192,  0.0010,  0.0065],\n",
       "         [-0.0077,  0.0098, -0.0013,  ..., -0.0104, -0.0051, -0.0145],\n",
       "         ...,\n",
       "         [ 0.0123,  0.0144, -0.0091,  ..., -0.0130,  0.0045, -0.0040],\n",
       "         [-0.0089, -0.0145, -0.0016,  ..., -0.0051,  0.0159, -0.0065],\n",
       "         [-0.0087, -0.0092, -0.0004,  ...,  0.0011,  0.0074, -0.0003]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.23.self_attn.q_proj.lora_B.weight': tensor([[-1.6975e-04,  1.4267e-03,  6.5327e-05,  ...,  6.7902e-04,\n",
       "          -1.0910e-03,  1.5564e-03],\n",
       "         [-1.4954e-03, -5.9128e-05,  5.6458e-04,  ..., -2.5482e-03,\n",
       "           2.0123e-04,  2.6321e-04],\n",
       "         [ 9.3079e-04, -1.9531e-03,  1.6479e-03,  ...,  1.2994e-05,\n",
       "           9.1934e-04,  2.1362e-03],\n",
       "         ...,\n",
       "         [ 1.5106e-03,  3.2654e-03,  1.2207e-03,  ..., -3.5706e-03,\n",
       "           2.6131e-04, -3.1281e-04],\n",
       "         [-3.7956e-04,  2.9683e-05,  1.2207e-03,  ..., -2.2650e-05,\n",
       "          -4.2152e-04, -1.2741e-03],\n",
       "         [ 2.2125e-03, -5.7459e-05, -1.5717e-03,  ..., -7.7820e-04,\n",
       "          -1.1215e-03,  1.5793e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.23.self_attn.v_proj.lora_A.weight': tensor([[-0.0143,  0.0135, -0.0093,  ...,  0.0064, -0.0081, -0.0015],\n",
       "         [-0.0034, -0.0041,  0.0107,  ..., -0.0077,  0.0007,  0.0076],\n",
       "         [-0.0069, -0.0088,  0.0065,  ..., -0.0109, -0.0007, -0.0016],\n",
       "         ...,\n",
       "         [ 0.0075,  0.0128,  0.0115,  ..., -0.0056,  0.0004, -0.0130],\n",
       "         [ 0.0020, -0.0031,  0.0103,  ...,  0.0057, -0.0050,  0.0135],\n",
       "         [-0.0129,  0.0156, -0.0087,  ..., -0.0108, -0.0023,  0.0104]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.23.self_attn.v_proj.lora_B.weight': tensor([[ 2.1820e-03, -2.1362e-03, -1.8997e-03,  ..., -1.5564e-03,\n",
       "           3.8910e-04, -3.9368e-03],\n",
       "         [ 5.3787e-04,  3.6049e-04,  2.9564e-05,  ...,  8.7357e-04,\n",
       "           1.3199e-03, -2.3651e-03],\n",
       "         [ 1.2054e-03, -9.9182e-04, -1.8311e-04,  ..., -1.2589e-03,\n",
       "          -2.4414e-03, -1.3962e-03],\n",
       "         ...,\n",
       "         [ 1.4114e-03, -2.6245e-03, -1.3657e-03,  ..., -2.3499e-03,\n",
       "          -1.0986e-03, -1.1597e-03],\n",
       "         [-1.9379e-03,  1.5945e-03,  6.7520e-04,  ...,  4.5776e-04,\n",
       "           1.0757e-03, -3.8910e-04],\n",
       "         [ 1.1978e-03,  1.0529e-03, -2.0142e-03,  ..., -1.6632e-03,\n",
       "           2.6093e-03, -1.2207e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.24.mlp.down_proj.lora_A.weight': tensor([[ 0.0056, -0.0085,  0.0021,  ..., -0.0035, -0.0022, -0.0019],\n",
       "         [ 0.0030, -0.0039,  0.0058,  ...,  0.0002, -0.0074, -0.0059],\n",
       "         [ 0.0050,  0.0028, -0.0107,  ...,  0.0052,  0.0033,  0.0042],\n",
       "         ...,\n",
       "         [ 0.0057, -0.0101, -0.0019,  ..., -0.0069,  0.0008,  0.0015],\n",
       "         [ 0.0007, -0.0011, -0.0068,  ..., -0.0120,  0.0031, -0.0104],\n",
       "         [ 0.0012, -0.0081, -0.0031,  ...,  0.0016, -0.0008,  0.0074]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.24.mlp.down_proj.lora_B.weight': tensor([[ 1.1597e-03,  1.8005e-03, -7.8583e-04,  ..., -5.9891e-04,\n",
       "           9.5963e-06, -3.3417e-03],\n",
       "         [ 9.6130e-04, -1.1673e-03, -1.3275e-03,  ..., -1.0376e-03,\n",
       "          -7.7057e-04,  3.9673e-04],\n",
       "         [ 2.6245e-03,  1.6403e-03, -9.3842e-04,  ...,  4.0293e-05,\n",
       "           1.8692e-03, -2.6398e-03],\n",
       "         ...,\n",
       "         [ 1.9073e-03, -1.1444e-03, -1.7853e-03,  ...,  1.6327e-03,\n",
       "           3.3264e-03, -1.7319e-03],\n",
       "         [ 2.3346e-03,  3.8910e-04,  9.1171e-04,  ...,  8.2779e-04,\n",
       "          -1.8158e-03,  3.2806e-03],\n",
       "         [ 5.3644e-05, -2.2888e-03,  2.4109e-03,  ..., -2.0623e-05,\n",
       "           1.2054e-03, -1.2817e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.24.mlp.gate_proj.lora_A.weight': tensor([[-0.0070, -0.0149,  0.0005,  ...,  0.0006,  0.0151, -0.0023],\n",
       "         [-0.0080, -0.0023, -0.0013,  ..., -0.0099, -0.0153,  0.0034],\n",
       "         [-0.0086, -0.0030, -0.0148,  ..., -0.0042, -0.0067, -0.0020],\n",
       "         ...,\n",
       "         [ 0.0106,  0.0056, -0.0039,  ...,  0.0075,  0.0013, -0.0005],\n",
       "         [-0.0058,  0.0102,  0.0059,  ...,  0.0081,  0.0075,  0.0134],\n",
       "         [ 0.0073,  0.0112, -0.0058,  ..., -0.0035,  0.0081, -0.0039]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.24.mlp.gate_proj.lora_B.weight': tensor([[-2.0447e-03, -1.6479e-03, -2.2278e-03,  ...,  1.4114e-04,\n",
       "           3.7766e-04,  1.0757e-03],\n",
       "         [-1.6556e-03,  2.3746e-04, -9.2983e-06,  ...,  2.2793e-04,\n",
       "          -3.0518e-04, -5.9891e-04],\n",
       "         [ 3.7384e-04,  1.5182e-03, -2.5177e-03,  ...,  4.7684e-04,\n",
       "          -9.9945e-04,  1.2665e-03],\n",
       "         ...,\n",
       "         [ 9.1553e-04,  2.5330e-03,  3.1891e-03,  ...,  3.9978e-03,\n",
       "           3.2616e-04, -6.2180e-04],\n",
       "         [-2.4109e-03, -1.6251e-03, -2.8839e-03,  ..., -3.3569e-04,\n",
       "           2.0695e-04,  8.8882e-04],\n",
       "         [-1.2398e-04,  9.3460e-04, -1.1292e-03,  ..., -1.1978e-03,\n",
       "           8.4686e-04,  2.7924e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.24.mlp.up_proj.lora_A.weight': tensor([[-1.3000e-02,  1.0620e-02,  3.0518e-03,  ...,  1.1475e-02,\n",
       "          -5.9204e-03,  1.1719e-02],\n",
       "         [-9.4604e-03,  3.4180e-03, -1.0132e-02,  ...,  2.8992e-03,\n",
       "           2.4872e-03,  2.2650e-06],\n",
       "         [ 3.8910e-03, -1.3428e-02,  1.2268e-02,  ...,  2.5177e-04,\n",
       "           1.7929e-03, -7.4158e-03],\n",
       "         ...,\n",
       "         [-3.8910e-03, -1.4038e-02, -1.2024e-02,  ..., -1.0803e-02,\n",
       "           1.6968e-02, -7.8125e-03],\n",
       "         [-2.9144e-03,  7.0190e-03,  1.7578e-02,  ..., -6.4697e-03,\n",
       "           1.3428e-02, -1.1108e-02],\n",
       "         [-1.1719e-02, -9.9487e-03, -8.3008e-03,  ...,  9.0942e-03,\n",
       "           1.5320e-02, -1.2390e-02]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.24.mlp.up_proj.lora_B.weight': tensor([[ 5.6505e-05, -1.0376e-03, -1.2741e-03,  ...,  1.5411e-03,\n",
       "          -1.8463e-03, -8.2493e-05],\n",
       "         [-2.1820e-03,  1.5106e-03, -1.3351e-03,  ...,  1.7090e-03,\n",
       "          -4.5538e-05, -1.4725e-03],\n",
       "         [-1.1826e-03, -3.5553e-03, -2.8381e-03,  ...,  1.2207e-03,\n",
       "          -3.2196e-03, -5.6982e-05],\n",
       "         ...,\n",
       "         [-2.1515e-03, -4.9591e-04,  5.8746e-04,  ..., -1.6785e-04,\n",
       "           3.2349e-03, -4.4632e-04],\n",
       "         [-1.3351e-04, -1.4648e-03,  2.5558e-04,  ...,  2.1667e-03,\n",
       "           1.2589e-03, -1.3828e-04],\n",
       "         [-6.3419e-05,  1.4648e-03, -1.1139e-03,  ...,  1.6251e-03,\n",
       "          -5.1117e-04, -2.0294e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.24.self_attn.k_proj.lora_A.weight': tensor([[ 5.9509e-03, -4.3030e-03, -3.2234e-04,  ..., -9.4604e-03,\n",
       "           1.3245e-02, -6.4392e-03],\n",
       "         [-1.6235e-02,  8.1787e-03, -1.0315e-02,  ...,  4.8523e-03,\n",
       "          -6.7139e-03,  1.7700e-02],\n",
       "         [ 1.9226e-03,  6.5613e-03,  9.1553e-03,  ...,  8.9111e-03,\n",
       "           3.4027e-03,  2.6703e-03],\n",
       "         ...,\n",
       "         [ 9.7656e-03, -1.2451e-02, -1.9684e-03,  ..., -9.0942e-03,\n",
       "           1.1230e-02, -1.3855e-02],\n",
       "         [ 8.0566e-03,  1.2329e-02,  5.8289e-03,  ...,  6.5613e-03,\n",
       "           2.8038e-04, -2.3346e-03],\n",
       "         [-1.0071e-02,  9.3937e-05, -4.9438e-03,  ..., -1.2878e-02,\n",
       "          -3.1738e-03, -8.2397e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.24.self_attn.k_proj.lora_B.weight': tensor([[-1.4191e-03, -6.4392e-03,  8.6212e-04,  ...,  1.0681e-03,\n",
       "          -9.3937e-05,  3.7231e-03],\n",
       "         [ 4.4060e-04, -1.6251e-03, -1.2207e-03,  ...,  1.4801e-03,\n",
       "           8.6212e-04, -9.2697e-04],\n",
       "         [-3.8757e-03, -1.3123e-03,  1.8768e-03,  ...,  4.0283e-03,\n",
       "           7.9346e-04,  4.0817e-04],\n",
       "         ...,\n",
       "         [-2.5368e-04,  1.9684e-03,  2.7618e-03,  ...,  6.6757e-04,\n",
       "          -1.0681e-03, -3.2043e-03],\n",
       "         [ 2.6703e-04, -3.5524e-05, -9.1934e-04,  ...,  2.3174e-04,\n",
       "          -3.4790e-03,  1.8234e-03],\n",
       "         [-3.4790e-03,  3.9673e-03,  1.5068e-04,  ...,  5.7220e-04,\n",
       "           5.1270e-03,  6.2561e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.24.self_attn.o_proj.lora_A.weight': tensor([[ 0.0110, -0.0092, -0.0087,  ...,  0.0114,  0.0123, -0.0021],\n",
       "         [-0.0007,  0.0085,  0.0139,  ...,  0.0112,  0.0074,  0.0028],\n",
       "         [-0.0115,  0.0131,  0.0134,  ..., -0.0116, -0.0139, -0.0065],\n",
       "         ...,\n",
       "         [-0.0114, -0.0041, -0.0044,  ...,  0.0095, -0.0089,  0.0131],\n",
       "         [-0.0038, -0.0118, -0.0129,  ..., -0.0010,  0.0162,  0.0057],\n",
       "         [-0.0129, -0.0009,  0.0203,  ..., -0.0149,  0.0148,  0.0029]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.24.self_attn.o_proj.lora_B.weight': tensor([[-0.0001, -0.0007, -0.0002,  ...,  0.0026,  0.0003,  0.0015],\n",
       "         [-0.0037, -0.0009, -0.0022,  ...,  0.0003,  0.0012,  0.0028],\n",
       "         [ 0.0004,  0.0024, -0.0010,  ..., -0.0017, -0.0011, -0.0007],\n",
       "         ...,\n",
       "         [-0.0028, -0.0004,  0.0004,  ...,  0.0028,  0.0002,  0.0020],\n",
       "         [ 0.0003, -0.0005, -0.0002,  ...,  0.0004, -0.0012,  0.0002],\n",
       "         [-0.0020, -0.0016, -0.0038,  ...,  0.0010,  0.0005,  0.0013]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.24.self_attn.q_proj.lora_A.weight': tensor([[ 0.0128,  0.0121, -0.0016,  ...,  0.0042,  0.0086, -0.0071],\n",
       "         [-0.0004,  0.0064, -0.0004,  ..., -0.0068, -0.0066,  0.0114],\n",
       "         [-0.0161,  0.0133,  0.0186,  ..., -0.0111, -0.0081, -0.0110],\n",
       "         ...,\n",
       "         [ 0.0073,  0.0167,  0.0088,  ..., -0.0014, -0.0142,  0.0006],\n",
       "         [ 0.0048,  0.0026, -0.0126,  ...,  0.0052, -0.0027, -0.0034],\n",
       "         [-0.0008,  0.0052,  0.0115,  ...,  0.0101,  0.0136, -0.0145]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.24.self_attn.q_proj.lora_B.weight': tensor([[-1.9302e-03,  7.1335e-04, -9.7275e-04,  ..., -1.6327e-03,\n",
       "           2.9297e-03, -5.0735e-04],\n",
       "         [-6.3181e-06,  2.8381e-03, -1.1063e-03,  ...,  5.5313e-04,\n",
       "           1.8997e-03, -4.3335e-03],\n",
       "         [-1.4954e-03,  3.3264e-03,  7.8583e-04,  ...,  7.3624e-04,\n",
       "           2.3041e-03, -3.9673e-03],\n",
       "         ...,\n",
       "         [-1.8997e-03, -1.6098e-03,  5.1498e-04,  ...,  9.0027e-04,\n",
       "          -2.4261e-03,  3.6621e-03],\n",
       "         [-9.7275e-04, -3.6926e-03,  3.8757e-03,  ..., -4.1246e-05,\n",
       "          -4.1199e-03,  2.3804e-03],\n",
       "         [ 3.2501e-03,  1.1139e-03, -3.9291e-04,  ..., -4.2114e-03,\n",
       "           2.5482e-03, -7.0190e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.24.self_attn.v_proj.lora_A.weight': tensor([[-0.0045, -0.0156, -0.0090,  ...,  0.0118, -0.0114, -0.0016],\n",
       "         [-0.0081, -0.0121, -0.0143,  ..., -0.0096,  0.0168,  0.0084],\n",
       "         [-0.0139,  0.0098, -0.0156,  ..., -0.0072,  0.0015,  0.0147],\n",
       "         ...,\n",
       "         [-0.0143,  0.0031, -0.0086,  ...,  0.0125, -0.0161, -0.0113],\n",
       "         [ 0.0001,  0.0026,  0.0020,  ...,  0.0166,  0.0001,  0.0028],\n",
       "         [-0.0094,  0.0030,  0.0148,  ...,  0.0002, -0.0041, -0.0056]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.24.self_attn.v_proj.lora_B.weight': tensor([[-0.0002, -0.0016, -0.0018,  ...,  0.0012, -0.0003,  0.0005],\n",
       "         [ 0.0009, -0.0023, -0.0022,  ...,  0.0008,  0.0013,  0.0006],\n",
       "         [ 0.0011, -0.0018, -0.0019,  ...,  0.0010,  0.0007,  0.0014],\n",
       "         ...,\n",
       "         [-0.0009,  0.0006,  0.0016,  ..., -0.0015, -0.0003, -0.0037],\n",
       "         [-0.0015,  0.0018,  0.0022,  ..., -0.0039,  0.0018,  0.0012],\n",
       "         [ 0.0003, -0.0032, -0.0011,  ...,  0.0007, -0.0005,  0.0023]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.25.mlp.down_proj.lora_A.weight': tensor([[ 0.0030,  0.0029,  0.0018,  ..., -0.0017,  0.0102,  0.0004],\n",
       "         [-0.0064,  0.0016,  0.0059,  ..., -0.0007,  0.0058,  0.0014],\n",
       "         [ 0.0092,  0.0009, -0.0041,  ..., -0.0060, -0.0020, -0.0078],\n",
       "         ...,\n",
       "         [ 0.0037,  0.0047, -0.0014,  ...,  0.0064,  0.0065,  0.0064],\n",
       "         [-0.0093, -0.0045, -0.0080,  ..., -0.0103,  0.0068,  0.0084],\n",
       "         [ 0.0039,  0.0018,  0.0065,  ..., -0.0037,  0.0078, -0.0067]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.25.mlp.down_proj.lora_B.weight': tensor([[ 2.2411e-04, -3.2616e-04, -3.0708e-04,  ...,  8.7357e-04,\n",
       "          -1.0986e-03, -3.5095e-03],\n",
       "         [-7.3624e-04, -2.7313e-03,  1.1215e-03,  ..., -2.2278e-03,\n",
       "           7.3624e-04,  1.1978e-03],\n",
       "         [ 3.3875e-03,  1.1215e-03, -1.0452e-03,  ...,  3.8300e-03,\n",
       "          -6.6757e-04, -3.2806e-04],\n",
       "         ...,\n",
       "         [-1.9684e-03,  7.7820e-04,  6.1035e-04,  ..., -1.0910e-03,\n",
       "          -2.1057e-03,  1.4496e-03],\n",
       "         [ 3.1433e-03, -1.3123e-03, -8.5831e-04,  ...,  4.1771e-04,\n",
       "           2.5630e-06, -1.7395e-03],\n",
       "         [ 2.9602e-03, -8.0490e-04, -1.8311e-03,  ...,  1.3649e-05,\n",
       "           8.2493e-05,  1.3733e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.25.mlp.gate_proj.lora_A.weight': tensor([[-0.0052,  0.0010,  0.0052,  ..., -0.0011,  0.0164, -0.0143],\n",
       "         [-0.0102, -0.0173,  0.0004,  ..., -0.0062,  0.0023,  0.0175],\n",
       "         [ 0.0121,  0.0147, -0.0048,  ..., -0.0099,  0.0053,  0.0073],\n",
       "         ...,\n",
       "         [-0.0073, -0.0052,  0.0039,  ...,  0.0004,  0.0035,  0.0143],\n",
       "         [-0.0148, -0.0014,  0.0004,  ..., -0.0067,  0.0105,  0.0101],\n",
       "         [-0.0132, -0.0034,  0.0007,  ..., -0.0104,  0.0132,  0.0064]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.25.mlp.gate_proj.lora_B.weight': tensor([[-1.1597e-03, -2.4109e-03,  1.0681e-03,  ..., -4.1389e-04,\n",
       "          -1.1292e-03, -2.7313e-03],\n",
       "         [ 1.3657e-03,  1.8768e-03,  1.1520e-03,  ..., -7.1716e-04,\n",
       "           1.0300e-03,  3.8147e-03],\n",
       "         [-2.8992e-03,  2.2736e-03,  1.1826e-03,  ...,  2.1210e-03,\n",
       "           9.9182e-04,  9.3079e-04],\n",
       "         ...,\n",
       "         [-9.7275e-04,  1.5793e-03, -1.2054e-03,  ...,  1.7548e-03,\n",
       "          -3.2349e-03,  1.1749e-03],\n",
       "         [ 3.8147e-04, -1.8768e-03,  3.2043e-04,  ..., -9.1934e-04,\n",
       "           7.7820e-04,  7.4387e-04],\n",
       "         [-2.4567e-03, -6.4468e-04,  5.6982e-05,  ...,  3.2654e-03,\n",
       "          -1.1749e-03, -2.3499e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.25.mlp.up_proj.lora_A.weight': tensor([[-0.0123, -0.0057,  0.0019,  ..., -0.0002,  0.0043,  0.0104],\n",
       "         [-0.0127, -0.0098, -0.0029,  ..., -0.0027, -0.0014, -0.0013],\n",
       "         [ 0.0045, -0.0108,  0.0143,  ..., -0.0131, -0.0038,  0.0142],\n",
       "         ...,\n",
       "         [ 0.0096, -0.0079, -0.0131,  ..., -0.0025,  0.0051, -0.0035],\n",
       "         [ 0.0004,  0.0004,  0.0109,  ..., -0.0022, -0.0070, -0.0079],\n",
       "         [-0.0143,  0.0084, -0.0009,  ...,  0.0055, -0.0110, -0.0073]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.25.mlp.up_proj.lora_B.weight': tensor([[ 1.5793e-03, -8.6975e-04,  3.0060e-03,  ..., -5.8746e-04,\n",
       "           1.4496e-03, -2.9755e-03],\n",
       "         [-1.4365e-05, -2.4109e-03,  9.4986e-04,  ...,  1.5259e-03,\n",
       "           1.2054e-03, -3.5858e-04],\n",
       "         [ 2.8534e-03, -1.6499e-04,  2.2888e-03,  ...,  6.0272e-04,\n",
       "           1.1292e-03,  3.0365e-03],\n",
       "         ...,\n",
       "         [-3.7842e-03, -2.4109e-03, -3.2616e-04,  ...,  2.3079e-04,\n",
       "          -1.4267e-03, -9.0408e-04],\n",
       "         [-1.4954e-03,  4.8828e-04, -9.7275e-04,  ...,  2.6398e-03,\n",
       "          -1.0681e-03, -1.2970e-03],\n",
       "         [ 1.1063e-03,  1.8845e-03,  1.1826e-03,  ..., -5.4932e-04,\n",
       "          -3.1738e-03, -9.1934e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.25.self_attn.k_proj.lora_A.weight': tensor([[ 3.2806e-03, -1.4893e-02, -1.0071e-02,  ..., -1.0803e-02,\n",
       "          -1.0376e-02, -7.3547e-03],\n",
       "         [ 3.4180e-03, -4.7607e-03,  4.6692e-03,  ...,  1.1292e-02,\n",
       "          -9.3384e-03,  1.0395e-04],\n",
       "         [ 6.5002e-03,  1.1353e-02,  1.4404e-02,  ...,  1.6602e-02,\n",
       "          -5.5542e-03,  7.5378e-03],\n",
       "         ...,\n",
       "         [-1.0437e-02,  1.3916e-02,  1.2573e-02,  ...,  7.3242e-03,\n",
       "           8.4686e-04, -1.4771e-02],\n",
       "         [-1.3504e-03, -1.6327e-03, -1.4709e-02,  ..., -1.8477e-05,\n",
       "          -9.1553e-03, -4.9438e-03],\n",
       "         [ 7.8735e-03,  1.6479e-02,  3.5248e-03,  ...,  3.2806e-03,\n",
       "          -2.7313e-03,  7.2327e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.25.self_attn.k_proj.lora_B.weight': tensor([[-7.6294e-04,  8.1253e-04,  4.8637e-04,  ...,  1.7242e-03,\n",
       "           8.7738e-04,  1.9836e-03],\n",
       "         [ 1.2512e-03, -4.4250e-03, -2.8076e-03,  ..., -1.1902e-03,\n",
       "           1.0529e-03, -2.5177e-03],\n",
       "         [ 1.3962e-03,  6.1512e-05,  9.9945e-04,  ..., -9.7656e-04,\n",
       "          -8.4686e-04,  3.2806e-03],\n",
       "         ...,\n",
       "         [-6.5231e-04,  2.4109e-03,  2.3956e-03,  ..., -8.2397e-04,\n",
       "          -1.1444e-03,  9.2697e-04],\n",
       "         [ 1.1520e-03, -1.3638e-04, -7.4387e-04,  ..., -1.3580e-03,\n",
       "           1.7395e-03, -3.2501e-03],\n",
       "         [-4.7302e-04,  2.2602e-04,  1.7395e-03,  ..., -1.8120e-04,\n",
       "          -2.5635e-03,  1.3428e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.25.self_attn.o_proj.lora_A.weight': tensor([[ 0.0074, -0.0156,  0.0134,  ...,  0.0054, -0.0048,  0.0128],\n",
       "         [ 0.0167,  0.0101, -0.0018,  ...,  0.0086,  0.0038, -0.0110],\n",
       "         [-0.0156, -0.0085,  0.0104,  ...,  0.0112,  0.0078,  0.0009],\n",
       "         ...,\n",
       "         [-0.0069,  0.0128, -0.0067,  ..., -0.0041, -0.0034,  0.0050],\n",
       "         [ 0.0109,  0.0129, -0.0101,  ...,  0.0009,  0.0160,  0.0063],\n",
       "         [-0.0042, -0.0069,  0.0089,  ..., -0.0135, -0.0067, -0.0126]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.25.self_attn.o_proj.lora_B.weight': tensor([[ 0.0013,  0.0006, -0.0006,  ..., -0.0006, -0.0005, -0.0007],\n",
       "         [-0.0017, -0.0004,  0.0007,  ...,  0.0002, -0.0007, -0.0035],\n",
       "         [ 0.0010, -0.0009, -0.0009,  ..., -0.0008, -0.0024,  0.0001],\n",
       "         ...,\n",
       "         [ 0.0009,  0.0015, -0.0006,  ..., -0.0004, -0.0014, -0.0018],\n",
       "         [ 0.0010, -0.0008, -0.0014,  ...,  0.0009,  0.0010, -0.0011],\n",
       "         [-0.0017, -0.0005,  0.0013,  ..., -0.0008,  0.0004, -0.0010]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.25.self_attn.q_proj.lora_A.weight': tensor([[-0.0083,  0.0120,  0.0064,  ..., -0.0148, -0.0078, -0.0053],\n",
       "         [ 0.0053, -0.0091, -0.0155,  ...,  0.0117,  0.0035, -0.0093],\n",
       "         [ 0.0061,  0.0167, -0.0022,  ..., -0.0038,  0.0123,  0.0128],\n",
       "         ...,\n",
       "         [ 0.0030,  0.0014,  0.0121,  ...,  0.0036,  0.0106, -0.0139],\n",
       "         [-0.0141, -0.0009,  0.0036,  ..., -0.0175,  0.0130,  0.0085],\n",
       "         [-0.0146,  0.0074, -0.0061,  ..., -0.0064,  0.0129,  0.0020]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.25.self_attn.q_proj.lora_B.weight': tensor([[ 6.3705e-04, -1.5717e-03, -1.1368e-03,  ..., -5.5542e-03,\n",
       "           1.4801e-03, -4.8828e-04],\n",
       "         [-2.2278e-03,  2.4414e-03, -1.4496e-03,  ...,  4.8828e-04,\n",
       "          -9.2316e-04,  9.7752e-05],\n",
       "         [-1.0376e-03, -4.4060e-04, -5.3024e-04,  ..., -7.4387e-04,\n",
       "          -4.0054e-04, -2.0695e-04],\n",
       "         ...,\n",
       "         [-1.4496e-03,  1.6022e-03, -1.9836e-03,  ...,  1.1139e-03,\n",
       "          -1.2436e-03, -1.9989e-03],\n",
       "         [ 2.8839e-03, -9.9945e-04,  1.3428e-03,  ..., -2.4567e-03,\n",
       "           1.4191e-03,  5.1498e-04],\n",
       "         [-1.4801e-03,  6.7139e-04, -1.7014e-03,  ...,  1.3733e-03,\n",
       "          -9.3460e-04, -4.6730e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.25.self_attn.v_proj.lora_A.weight': tensor([[ 0.0154, -0.0033, -0.0031,  ...,  0.0020, -0.0063, -0.0091],\n",
       "         [ 0.0126,  0.0047, -0.0045,  ...,  0.0126,  0.0071, -0.0110],\n",
       "         [-0.0004, -0.0036,  0.0034,  ..., -0.0025, -0.0045,  0.0091],\n",
       "         ...,\n",
       "         [ 0.0122,  0.0026,  0.0133,  ..., -0.0037,  0.0040, -0.0046],\n",
       "         [-0.0089,  0.0145, -0.0044,  ...,  0.0106, -0.0073, -0.0090],\n",
       "         [-0.0154,  0.0179, -0.0011,  ...,  0.0120,  0.0072, -0.0069]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.25.self_attn.v_proj.lora_B.weight': tensor([[-2.8381e-03, -1.5869e-03,  1.6327e-03,  ..., -2.2278e-03,\n",
       "           1.6327e-03,  2.6855e-03],\n",
       "         [-9.9182e-04, -7.3242e-04, -1.1826e-03,  ..., -5.9891e-04,\n",
       "          -6.1417e-04,  9.3842e-04],\n",
       "         [ 2.8253e-05,  1.9684e-03, -4.6730e-05,  ...,  1.1292e-03,\n",
       "          -2.2430e-03, -3.7384e-04],\n",
       "         ...,\n",
       "         [ 1.4420e-03,  1.7090e-03, -3.9864e-04,  ...,  1.1597e-03,\n",
       "          -2.3041e-03, -3.8910e-04],\n",
       "         [ 1.5030e-03, -9.9945e-04, -2.7161e-03,  ...,  1.7776e-03,\n",
       "          -9.4223e-04, -2.1973e-03],\n",
       "         [-7.4863e-05,  1.4954e-03,  4.4250e-04,  ...,  5.7983e-04,\n",
       "          -1.6785e-03,  2.2316e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.26.mlp.down_proj.lora_A.weight': tensor([[ 0.0112,  0.0027,  0.0045,  ..., -0.0073, -0.0045, -0.0044],\n",
       "         [ 0.0003, -0.0024,  0.0058,  ...,  0.0074, -0.0106,  0.0029],\n",
       "         [ 0.0005,  0.0067,  0.0011,  ..., -0.0071,  0.0016,  0.0059],\n",
       "         ...,\n",
       "         [ 0.0020,  0.0026, -0.0020,  ..., -0.0083, -0.0074, -0.0010],\n",
       "         [-0.0018, -0.0090, -0.0019,  ...,  0.0018, -0.0005,  0.0105],\n",
       "         [ 0.0056,  0.0013,  0.0093,  ..., -0.0093,  0.0055, -0.0067]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.26.mlp.down_proj.lora_B.weight': tensor([[-1.2894e-03,  4.1580e-04, -6.5994e-04,  ..., -2.6245e-03,\n",
       "          -7.5150e-04,  1.3351e-04],\n",
       "         [ 8.7261e-05, -7.4768e-04, -8.5449e-04,  ...,  1.0681e-03,\n",
       "          -2.1515e-03, -7.1335e-04],\n",
       "         [-1.3504e-03,  3.6621e-04, -8.9264e-04,  ...,  8.2397e-04,\n",
       "          -6.2943e-04,  2.2888e-03],\n",
       "         ...,\n",
       "         [ 1.1520e-03,  1.6861e-03, -3.2349e-03,  ..., -5.0735e-04,\n",
       "           3.0365e-03, -5.1880e-04],\n",
       "         [-1.5259e-03, -3.0365e-03,  4.6387e-03,  ..., -1.8921e-03,\n",
       "           2.2125e-03, -2.0142e-03],\n",
       "         [-4.2725e-04, -1.3962e-03,  2.0447e-03,  ...,  2.6093e-03,\n",
       "          -4.8256e-04, -2.0123e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.26.mlp.gate_proj.lora_A.weight': tensor([[ 0.0005, -0.0019, -0.0007,  ...,  0.0165,  0.0092,  0.0028],\n",
       "         [-0.0060, -0.0091,  0.0107,  ..., -0.0011, -0.0024, -0.0120],\n",
       "         [ 0.0023,  0.0052,  0.0025,  ..., -0.0067,  0.0129,  0.0112],\n",
       "         ...,\n",
       "         [ 0.0084,  0.0086,  0.0061,  ...,  0.0065,  0.0074, -0.0065],\n",
       "         [-0.0008,  0.0079,  0.0156,  ...,  0.0002,  0.0177, -0.0019],\n",
       "         [ 0.0035,  0.0061, -0.0160,  ..., -0.0039,  0.0010,  0.0170]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.26.mlp.gate_proj.lora_B.weight': tensor([[ 7.7057e-04,  7.0953e-04,  1.7853e-03,  ...,  1.3428e-03,\n",
       "           1.4954e-03, -2.7924e-03],\n",
       "         [-3.0899e-04, -1.0300e-04, -2.8992e-04,  ...,  3.2654e-03,\n",
       "           8.0109e-04,  2.5177e-04],\n",
       "         [ 2.3499e-03,  1.8616e-03,  3.0975e-03,  ..., -5.6076e-04,\n",
       "          -1.5182e-03,  1.4267e-03],\n",
       "         ...,\n",
       "         [ 5.1498e-05,  2.5558e-04,  2.1515e-03,  ..., -7.5912e-04,\n",
       "           1.1902e-03,  1.5564e-03],\n",
       "         [ 1.4420e-03, -4.2343e-04, -1.5259e-03,  ..., -1.1978e-03,\n",
       "          -2.8076e-03,  3.3379e-04],\n",
       "         [ 1.7319e-03,  7.4768e-04, -1.3275e-03,  ..., -1.3962e-03,\n",
       "          -1.2283e-03,  3.2349e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.26.mlp.up_proj.lora_A.weight': tensor([[ 0.0022, -0.0125, -0.0121,  ...,  0.0135, -0.0014, -0.0050],\n",
       "         [ 0.0022, -0.0125,  0.0105,  ..., -0.0140,  0.0019, -0.0115],\n",
       "         [ 0.0015,  0.0045, -0.0015,  ..., -0.0109,  0.0040, -0.0101],\n",
       "         ...,\n",
       "         [-0.0124, -0.0047, -0.0120,  ...,  0.0073, -0.0003,  0.0049],\n",
       "         [ 0.0090,  0.0145,  0.0063,  ...,  0.0073,  0.0049,  0.0148],\n",
       "         [ 0.0138,  0.0115,  0.0064,  ...,  0.0143, -0.0048,  0.0055]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.26.mlp.up_proj.lora_B.weight': tensor([[-0.0013, -0.0014,  0.0016,  ...,  0.0015,  0.0009, -0.0019],\n",
       "         [-0.0002, -0.0021, -0.0030,  ..., -0.0011,  0.0004,  0.0002],\n",
       "         [-0.0012, -0.0007, -0.0002,  ...,  0.0004, -0.0017,  0.0019],\n",
       "         ...,\n",
       "         [ 0.0029, -0.0010,  0.0017,  ..., -0.0001,  0.0007, -0.0002],\n",
       "         [ 0.0007, -0.0001,  0.0012,  ...,  0.0001, -0.0041,  0.0013],\n",
       "         [ 0.0007,  0.0009,  0.0012,  ..., -0.0004, -0.0016, -0.0017]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.26.self_attn.k_proj.lora_A.weight': tensor([[ 7.6294e-03,  1.1292e-02,  8.7280e-03,  ..., -1.0193e-02,\n",
       "           8.9722e-03,  7.8735e-03],\n",
       "         [ 1.7090e-02, -3.5095e-03, -2.5330e-03,  ..., -8.0566e-03,\n",
       "           1.3916e-02, -8.4839e-03],\n",
       "         [-3.5858e-03,  9.2030e-05, -3.8147e-04,  ...,  1.2512e-02,\n",
       "          -1.4038e-02, -1.3428e-02],\n",
       "         ...,\n",
       "         [ 2.0752e-03,  3.9368e-03,  1.1539e-04,  ...,  6.3477e-03,\n",
       "           5.1270e-03, -1.3184e-02],\n",
       "         [ 1.1719e-02, -4.9438e-03, -2.8381e-03,  ...,  1.1108e-02,\n",
       "          -1.5747e-02, -7.6599e-03],\n",
       "         [-1.8066e-02, -3.8452e-03, -5.8289e-03,  ..., -8.9111e-03,\n",
       "          -8.3160e-04, -1.4114e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.26.self_attn.k_proj.lora_B.weight': tensor([[ 0.0003, -0.0004,  0.0018,  ...,  0.0005, -0.0013,  0.0012],\n",
       "         [ 0.0024, -0.0013,  0.0003,  ...,  0.0022, -0.0003,  0.0005],\n",
       "         [-0.0004,  0.0005,  0.0004,  ..., -0.0010,  0.0011, -0.0008],\n",
       "         ...,\n",
       "         [ 0.0005, -0.0027, -0.0012,  ..., -0.0006, -0.0002, -0.0012],\n",
       "         [-0.0026,  0.0033,  0.0033,  ..., -0.0014, -0.0011,  0.0010],\n",
       "         [-0.0018,  0.0023,  0.0009,  ..., -0.0018, -0.0013,  0.0005]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.26.self_attn.o_proj.lora_A.weight': tensor([[-0.0056,  0.0055, -0.0140,  ..., -0.0156,  0.0043,  0.0108],\n",
       "         [ 0.0071, -0.0002,  0.0143,  ..., -0.0032, -0.0144,  0.0074],\n",
       "         [-0.0020,  0.0081, -0.0052,  ..., -0.0005, -0.0099,  0.0118],\n",
       "         ...,\n",
       "         [ 0.0023,  0.0154,  0.0109,  ...,  0.0166,  0.0111,  0.0039],\n",
       "         [ 0.0170,  0.0094, -0.0098,  ..., -0.0090,  0.0135, -0.0113],\n",
       "         [ 0.0035, -0.0168, -0.0055,  ...,  0.0068, -0.0009, -0.0029]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.26.self_attn.o_proj.lora_B.weight': tensor([[-2.6894e-04, -6.7902e-04, -1.1597e-03,  ...,  1.5411e-03,\n",
       "           2.2430e-03,  9.9182e-04],\n",
       "         [-1.0605e-03,  3.3722e-03, -2.3499e-03,  ...,  6.5613e-04,\n",
       "          -4.1962e-04,  2.5635e-03],\n",
       "         [ 1.0986e-03,  8.8501e-04,  5.1880e-04,  ...,  2.7466e-03,\n",
       "           2.1973e-03, -4.8447e-04],\n",
       "         ...,\n",
       "         [-3.1471e-04,  5.1117e-04, -8.6975e-04,  ..., -8.0490e-04,\n",
       "          -7.6294e-06,  3.0518e-04],\n",
       "         [ 1.6479e-03, -2.1667e-03,  1.5182e-03,  ...,  1.0910e-03,\n",
       "           3.7384e-04,  3.9482e-04],\n",
       "         [-1.6251e-03,  4.7874e-04, -1.7548e-03,  ...,  2.3041e-03,\n",
       "           1.6937e-03,  7.7057e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.26.self_attn.q_proj.lora_A.weight': tensor([[-0.0076,  0.0100,  0.0008,  ..., -0.0078,  0.0121, -0.0053],\n",
       "         [ 0.0028,  0.0020,  0.0065,  ..., -0.0193, -0.0024, -0.0062],\n",
       "         [-0.0064, -0.0093, -0.0076,  ...,  0.0074,  0.0135,  0.0045],\n",
       "         ...,\n",
       "         [-0.0092, -0.0061,  0.0063,  ..., -0.0150, -0.0095,  0.0096],\n",
       "         [ 0.0041, -0.0008, -0.0014,  ...,  0.0090, -0.0082,  0.0074],\n",
       "         [ 0.0060, -0.0077,  0.0043,  ...,  0.0148,  0.0107,  0.0002]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.26.self_attn.q_proj.lora_B.weight': tensor([[-1.9455e-04,  1.0071e-03, -1.3428e-03,  ...,  4.0245e-04,\n",
       "           5.3644e-05, -2.2583e-03],\n",
       "         [-2.0885e-04, -1.2589e-03, -1.3123e-03,  ...,  2.1057e-03,\n",
       "          -2.3041e-03,  5.1117e-04],\n",
       "         [ 5.4169e-04,  3.7956e-04,  1.7929e-03,  ...,  5.4550e-04,\n",
       "           1.6327e-03, -1.2970e-03],\n",
       "         ...,\n",
       "         [ 7.5531e-04,  3.4485e-03, -2.5024e-03,  ...,  4.8637e-04,\n",
       "           2.8229e-03, -2.7275e-04],\n",
       "         [-6.2561e-04, -4.6158e-04,  1.9531e-03,  ...,  4.6158e-04,\n",
       "           6.2943e-04, -1.0452e-03],\n",
       "         [-1.3123e-03, -8.5068e-04,  2.5330e-03,  ..., -2.0027e-04,\n",
       "          -3.2043e-03, -1.6022e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.26.self_attn.v_proj.lora_A.weight': tensor([[-0.0120,  0.0041,  0.0031,  ..., -0.0144,  0.0017,  0.0098],\n",
       "         [ 0.0115, -0.0027,  0.0130,  ...,  0.0039, -0.0002,  0.0145],\n",
       "         [-0.0083, -0.0133,  0.0150,  ..., -0.0165, -0.0131, -0.0091],\n",
       "         ...,\n",
       "         [ 0.0091, -0.0070,  0.0005,  ...,  0.0072, -0.0143, -0.0098],\n",
       "         [ 0.0070, -0.0034, -0.0104,  ...,  0.0055,  0.0072, -0.0021],\n",
       "         [-0.0093,  0.0040,  0.0109,  ...,  0.0100, -0.0111, -0.0027]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.26.self_attn.v_proj.lora_B.weight': tensor([[ 6.1035e-04,  7.1716e-04, -4.5967e-04,  ..., -7.1716e-04,\n",
       "          -1.3351e-03, -1.2436e-03],\n",
       "         [-8.2016e-04, -2.4319e-05,  6.8665e-04,  ...,  5.6076e-04,\n",
       "           9.8228e-05,  6.8665e-04],\n",
       "         [-3.8719e-04, -1.7395e-03,  1.7929e-03,  ...,  9.8419e-04,\n",
       "           8.5831e-04,  2.7084e-04],\n",
       "         ...,\n",
       "         [-7.9632e-05, -1.6689e-04, -1.6689e-04,  ..., -6.7520e-04,\n",
       "           6.0272e-04,  3.6240e-05],\n",
       "         [-7.7438e-04, -5.5313e-04,  3.1090e-04,  ...,  1.0452e-03,\n",
       "           9.1171e-04,  9.4604e-04],\n",
       "         [ 8.7738e-04,  2.5749e-04, -8.5068e-04,  ..., -1.6251e-03,\n",
       "          -5.4121e-05, -1.0452e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.27.mlp.down_proj.lora_A.weight': tensor([[ 9.6512e-04,  7.6599e-03,  1.9073e-03,  ...,  2.8461e-06,\n",
       "          -2.7466e-03, -7.3853e-03],\n",
       "         [-2.3193e-03,  8.6060e-03,  9.9487e-03,  ...,  1.5640e-03,\n",
       "           5.5542e-03, -2.4109e-03],\n",
       "         [-2.2430e-03,  1.8387e-03,  2.3956e-03,  ..., -2.2583e-03,\n",
       "           2.5330e-03,  6.7520e-04],\n",
       "         ...,\n",
       "         [-4.1389e-04,  1.4191e-03, -1.9226e-03,  ...,  4.0283e-03,\n",
       "          -2.9755e-03, -5.5847e-03],\n",
       "         [ 1.0132e-02, -3.3112e-03, -5.9204e-03,  ..., -8.3618e-03,\n",
       "           8.8501e-03,  7.9346e-03],\n",
       "         [-4.5776e-03,  8.9111e-03,  2.7618e-03,  ..., -6.5918e-03,\n",
       "           1.0986e-02, -8.6975e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.27.mlp.down_proj.lora_B.weight': tensor([[ 1.6708e-03, -8.7738e-04,  3.6163e-03,  ...,  4.1008e-04,\n",
       "           2.4796e-04,  7.0572e-05],\n",
       "         [ 3.9673e-03,  2.5749e-05,  1.5945e-03,  ...,  1.5488e-03,\n",
       "          -1.2970e-03,  6.2943e-04],\n",
       "         [-1.5068e-04,  2.2583e-03,  1.2283e-03,  ...,  1.7471e-03,\n",
       "           1.5564e-03,  2.0142e-03],\n",
       "         ...,\n",
       "         [ 1.5945e-03, -1.4572e-03,  2.5558e-04,  ...,  1.2589e-03,\n",
       "           1.3046e-03, -1.6403e-03],\n",
       "         [ 2.8381e-03, -4.7874e-04, -7.4005e-04,  ...,  2.4872e-03,\n",
       "          -1.8005e-03,  6.9046e-04],\n",
       "         [ 1.7853e-03,  1.8692e-03,  1.2360e-03,  ...,  2.8229e-04,\n",
       "          -7.7820e-04, -2.0905e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.27.mlp.gate_proj.lora_A.weight': tensor([[ 0.0072,  0.0137, -0.0042,  ...,  0.0101, -0.0093,  0.0012],\n",
       "         [ 0.0078,  0.0108,  0.0027,  ...,  0.0038,  0.0045, -0.0025],\n",
       "         [-0.0087, -0.0143, -0.0091,  ..., -0.0009,  0.0132,  0.0024],\n",
       "         ...,\n",
       "         [-0.0139,  0.0032, -0.0106,  ..., -0.0104,  0.0048, -0.0035],\n",
       "         [ 0.0109,  0.0118,  0.0081,  ...,  0.0043,  0.0145, -0.0118],\n",
       "         [ 0.0160, -0.0110, -0.0033,  ...,  0.0115,  0.0153,  0.0032]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.27.mlp.gate_proj.lora_B.weight': tensor([[-0.0024, -0.0030, -0.0023,  ...,  0.0032, -0.0027,  0.0020],\n",
       "         [-0.0005,  0.0005,  0.0022,  ...,  0.0010, -0.0005, -0.0036],\n",
       "         [ 0.0003, -0.0008,  0.0018,  ...,  0.0030,  0.0026,  0.0013],\n",
       "         ...,\n",
       "         [-0.0006, -0.0023, -0.0014,  ..., -0.0006, -0.0007, -0.0019],\n",
       "         [-0.0016,  0.0008,  0.0006,  ...,  0.0012, -0.0026,  0.0005],\n",
       "         [-0.0006, -0.0031, -0.0044,  ...,  0.0021,  0.0012,  0.0004]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.27.mlp.up_proj.lora_A.weight': tensor([[ 0.0167,  0.0063, -0.0135,  ...,  0.0128, -0.0081,  0.0121],\n",
       "         [-0.0095,  0.0120, -0.0048,  ..., -0.0136,  0.0096,  0.0048],\n",
       "         [ 0.0114,  0.0090,  0.0142,  ..., -0.0052, -0.0036,  0.0014],\n",
       "         ...,\n",
       "         [-0.0126,  0.0010, -0.0110,  ..., -0.0043,  0.0053,  0.0112],\n",
       "         [-0.0029, -0.0101, -0.0114,  ..., -0.0181,  0.0033,  0.0048],\n",
       "         [-0.0121,  0.0165, -0.0065,  ...,  0.0095,  0.0098, -0.0118]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.27.mlp.up_proj.lora_B.weight': tensor([[-1.2512e-03,  5.0735e-04, -6.5231e-04,  ...,  1.2131e-03,\n",
       "          -1.9264e-04,  4.7302e-04],\n",
       "         [-2.2125e-03, -3.2234e-04, -3.3264e-03,  ..., -2.6703e-05,\n",
       "           1.4782e-04, -3.9368e-03],\n",
       "         [-2.2736e-03,  1.4420e-03, -2.7008e-03,  ..., -4.2915e-04,\n",
       "           2.8610e-04, -2.0752e-03],\n",
       "         ...,\n",
       "         [-4.8828e-03,  2.1362e-03, -3.4790e-03,  ..., -2.8076e-03,\n",
       "           2.9602e-03, -4.5776e-03],\n",
       "         [-3.6049e-04,  3.2616e-04,  5.2643e-04,  ...,  7.4387e-05,\n",
       "          -3.2425e-04, -1.9550e-04],\n",
       "         [ 1.4420e-03,  4.5204e-04, -2.8038e-04,  ...,  3.3722e-03,\n",
       "           5.6458e-04, -2.5482e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.27.self_attn.k_proj.lora_A.weight': tensor([[ 0.0113, -0.0033, -0.0048,  ..., -0.0078, -0.0095,  0.0149],\n",
       "         [ 0.0069,  0.0085,  0.0143,  ..., -0.0117,  0.0038,  0.0072],\n",
       "         [ 0.0134, -0.0151, -0.0061,  ...,  0.0159,  0.0032, -0.0118],\n",
       "         ...,\n",
       "         [-0.0117, -0.0019, -0.0171,  ..., -0.0053,  0.0097, -0.0021],\n",
       "         [-0.0120, -0.0060,  0.0055,  ...,  0.0026, -0.0079,  0.0044],\n",
       "         [ 0.0050,  0.0148, -0.0119,  ..., -0.0030,  0.0109,  0.0041]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.27.self_attn.k_proj.lora_B.weight': tensor([[-2.7618e-03,  2.7466e-03, -1.8539e-03,  ..., -1.6403e-03,\n",
       "           1.6098e-03, -2.3804e-03],\n",
       "         [ 1.9989e-03, -7.8678e-05, -3.5286e-04,  ..., -5.3024e-04,\n",
       "          -4.5013e-04,  1.9836e-03],\n",
       "         [-5.3406e-04, -2.0142e-03,  3.8719e-04,  ...,  2.2221e-04,\n",
       "          -1.9989e-03,  1.3885e-03],\n",
       "         ...,\n",
       "         [-8.5068e-04,  1.6327e-03,  1.6403e-03,  ..., -6.4468e-04,\n",
       "           9.9945e-04, -1.1292e-03],\n",
       "         [-8.6212e-04, -7.8964e-04,  3.4485e-03,  ...,  1.8616e-03,\n",
       "           3.0212e-03, -2.1667e-03],\n",
       "         [ 1.4877e-03,  9.4604e-04, -2.9449e-03,  ..., -1.9073e-03,\n",
       "          -1.7014e-03,  1.1292e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.27.self_attn.o_proj.lora_A.weight': tensor([[-1.7212e-02,  1.7578e-02,  4.4861e-03,  ...,  4.6730e-05,\n",
       "           1.0498e-02,  7.1106e-03],\n",
       "         [ 6.3477e-03, -1.9646e-04, -1.4404e-02,  ..., -5.4016e-03,\n",
       "           2.3041e-03, -6.5613e-03],\n",
       "         [-9.8877e-03,  4.3640e-03, -1.3000e-02,  ..., -1.3367e-02,\n",
       "           5.0354e-03,  1.6724e-02],\n",
       "         ...,\n",
       "         [ 5.7068e-03, -1.4954e-02, -6.6833e-03,  ..., -1.0071e-02,\n",
       "          -3.5858e-03,  9.3384e-03],\n",
       "         [-7.5531e-04, -9.8877e-03, -3.0670e-03,  ...,  9.6436e-03,\n",
       "          -1.2329e-02,  4.5471e-03],\n",
       "         [ 9.7046e-03, -1.3428e-03,  9.1553e-03,  ..., -7.1411e-03,\n",
       "           1.2817e-02,  7.8735e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.27.self_attn.o_proj.lora_B.weight': tensor([[-1.1826e-03, -7.3242e-04, -8.5068e-04,  ..., -7.4005e-04,\n",
       "           3.4714e-04, -3.9482e-04],\n",
       "         [-1.8997e-03,  1.3580e-03, -1.3275e-03,  ..., -4.6730e-04,\n",
       "          -4.1199e-03,  8.9264e-04],\n",
       "         [ 1.0529e-03,  1.1368e-03, -1.5335e-03,  ...,  2.3041e-03,\n",
       "           5.7220e-05, -3.4332e-04],\n",
       "         ...,\n",
       "         [-6.2180e-04, -7.6294e-04, -1.2894e-03,  ..., -8.0872e-04,\n",
       "          -1.8387e-03,  2.0905e-03],\n",
       "         [-1.2064e-04, -3.6049e-04,  2.5330e-03,  ...,  2.3651e-03,\n",
       "           2.1362e-03, -3.0518e-03],\n",
       "         [ 1.9302e-03,  1.1063e-03,  7.4005e-04,  ..., -1.2283e-03,\n",
       "          -2.5024e-03,  4.1723e-05]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.27.self_attn.q_proj.lora_A.weight': tensor([[-0.0104,  0.0044, -0.0143,  ...,  0.0030, -0.0016,  0.0015],\n",
       "         [ 0.0067, -0.0107, -0.0049,  ..., -0.0107, -0.0073,  0.0045],\n",
       "         [ 0.0024,  0.0030, -0.0007,  ...,  0.0131, -0.0134,  0.0154],\n",
       "         ...,\n",
       "         [-0.0130, -0.0107,  0.0001,  ..., -0.0106, -0.0146, -0.0167],\n",
       "         [ 0.0034, -0.0045,  0.0118,  ...,  0.0015,  0.0104, -0.0124],\n",
       "         [-0.0130, -0.0092, -0.0052,  ..., -0.0102,  0.0010,  0.0032]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.27.self_attn.q_proj.lora_B.weight': tensor([[-3.1090e-04,  2.1172e-04, -1.1978e-03,  ...,  3.3760e-04,\n",
       "           2.8229e-03,  5.2261e-04],\n",
       "         [-2.6550e-03,  1.8082e-03,  1.2970e-04,  ...,  3.1891e-03,\n",
       "           8.0872e-04,  3.8147e-04],\n",
       "         [ 1.5640e-03, -2.6398e-03,  1.9741e-04,  ..., -3.2501e-03,\n",
       "           1.2302e-04,  5.9509e-04],\n",
       "         ...,\n",
       "         [ 2.3804e-03,  3.0823e-03,  1.5411e-03,  ..., -3.3417e-03,\n",
       "           8.9264e-04, -6.8283e-04],\n",
       "         [-1.0300e-03,  1.6708e-03,  7.9632e-05,  ..., -1.5335e-03,\n",
       "          -3.7384e-04, -1.0071e-03],\n",
       "         [ 1.2589e-03,  4.3678e-04, -1.3199e-03,  ..., -3.1281e-04,\n",
       "          -5.3024e-04,  1.0529e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.27.self_attn.v_proj.lora_A.weight': tensor([[ 0.0049,  0.0063,  0.0166,  ..., -0.0116, -0.0011,  0.0104],\n",
       "         [-0.0121, -0.0053,  0.0076,  ...,  0.0014, -0.0139, -0.0109],\n",
       "         [ 0.0131, -0.0086,  0.0142,  ...,  0.0032, -0.0011, -0.0110],\n",
       "         ...,\n",
       "         [-0.0137,  0.0062, -0.0140,  ..., -0.0130, -0.0009, -0.0045],\n",
       "         [-0.0121, -0.0012, -0.0114,  ..., -0.0030, -0.0076, -0.0067],\n",
       "         [ 0.0070, -0.0120, -0.0161,  ..., -0.0089, -0.0053,  0.0122]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.27.self_attn.v_proj.lora_B.weight': tensor([[ 8.7357e-04, -2.6894e-04, -1.5488e-03,  ...,  1.1215e-03,\n",
       "           2.5177e-04, -1.0757e-03],\n",
       "         [-1.2360e-03, -1.0376e-03, -1.0757e-03,  ..., -8.9264e-04,\n",
       "           7.3624e-04,  4.0436e-04],\n",
       "         [ 1.1086e-05,  4.1389e-04,  6.4468e-04,  ..., -1.1673e-03,\n",
       "           2.6093e-03,  1.5869e-03],\n",
       "         ...,\n",
       "         [-5.6839e-04, -1.5030e-03, -1.0376e-03,  ...,  2.0294e-03,\n",
       "           1.2741e-03,  2.4796e-04],\n",
       "         [ 2.2507e-04,  1.6937e-03,  8.1253e-04,  ..., -8.3542e-04,\n",
       "          -4.0627e-04, -3.8147e-05],\n",
       "         [ 3.9291e-04, -1.1978e-03, -6.7353e-06,  ...,  1.4191e-03,\n",
       "           2.4414e-04, -7.2479e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.28.mlp.down_proj.lora_A.weight': tensor([[-0.0092,  0.0031,  0.0063,  ..., -0.0096, -0.0060,  0.0083],\n",
       "         [ 0.0054, -0.0023,  0.0037,  ..., -0.0085,  0.0054,  0.0067],\n",
       "         [ 0.0066,  0.0052,  0.0110,  ...,  0.0042,  0.0060, -0.0018],\n",
       "         ...,\n",
       "         [-0.0063,  0.0092, -0.0042,  ...,  0.0050, -0.0039, -0.0098],\n",
       "         [-0.0125,  0.0034, -0.0063,  ...,  0.0012,  0.0023,  0.0039],\n",
       "         [-0.0160, -0.0072, -0.0029,  ..., -0.0042,  0.0041,  0.0043]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.28.mlp.down_proj.lora_B.weight': tensor([[-9.0790e-04, -5.2261e-04, -8.3160e-04,  ..., -2.1648e-04,\n",
       "          -5.2643e-04,  1.9073e-04],\n",
       "         [ 7.9346e-04,  1.1292e-03, -1.6861e-03,  ..., -6.7902e-04,\n",
       "          -1.4648e-03, -2.9144e-03],\n",
       "         [-2.1820e-03,  1.3275e-03, -1.2131e-03,  ...,  2.8801e-04,\n",
       "           1.1902e-03,  2.1820e-03],\n",
       "         ...,\n",
       "         [-6.4373e-05,  1.9379e-03,  5.0354e-04,  ...,  8.7738e-04,\n",
       "          -1.0071e-03, -1.6098e-03],\n",
       "         [ 1.4877e-03,  2.7618e-03, -1.9836e-03,  ...,  6.8665e-04,\n",
       "          -8.9645e-04,  4.2343e-04],\n",
       "         [-4.3678e-04,  6.7520e-04, -1.1444e-03,  ..., -1.3504e-03,\n",
       "           2.8801e-04, -7.6675e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.28.mlp.gate_proj.lora_A.weight': tensor([[ 1.3062e-02,  3.1662e-04, -5.0049e-03,  ...,  1.4893e-02,\n",
       "           3.5553e-03,  6.7444e-03],\n",
       "         [-1.5015e-02, -4.8218e-03,  1.6235e-02,  ..., -1.4973e-04,\n",
       "          -1.0498e-02,  1.3794e-02],\n",
       "         [ 1.1215e-03,  6.3171e-03, -1.1597e-02,  ..., -4.1504e-03,\n",
       "           9.0332e-03,  1.7319e-03],\n",
       "         ...,\n",
       "         [-5.0049e-03, -1.2878e-02, -1.1780e-02,  ...,  1.2573e-02,\n",
       "          -1.2756e-02,  3.9978e-03],\n",
       "         [-9.7046e-03, -1.5869e-02,  2.8229e-03,  ...,  4.1008e-05,\n",
       "          -1.2390e-02, -1.2085e-02],\n",
       "         [ 1.3794e-02, -1.7319e-03, -1.3000e-02,  ...,  1.0620e-02,\n",
       "          -4.7913e-03, -1.6113e-02]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.28.mlp.gate_proj.lora_B.weight': tensor([[-5.9128e-04,  1.1368e-03,  7.8678e-05,  ..., -1.0834e-03,\n",
       "          -2.3956e-03, -1.2493e-04],\n",
       "         [-3.9291e-04, -7.5531e-04, -1.9455e-03,  ...,  3.3951e-04,\n",
       "           1.4954e-03,  2.8839e-03],\n",
       "         [ 2.6855e-03,  6.6376e-04, -3.0518e-03,  ..., -3.7766e-04,\n",
       "          -2.6321e-04,  8.8882e-04],\n",
       "         ...,\n",
       "         [ 3.0060e-03,  1.8234e-03, -8.1635e-04,  ...,  8.1253e-04,\n",
       "          -1.1368e-03, -2.5787e-03],\n",
       "         [-2.1362e-03, -2.3956e-03,  1.8501e-04,  ..., -2.3346e-03,\n",
       "          -9.0122e-05,  9.3842e-04],\n",
       "         [-1.0834e-03, -1.6785e-03, -5.3024e-04,  ..., -8.6212e-04,\n",
       "          -1.4648e-03,  2.4261e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.28.mlp.up_proj.lora_A.weight': tensor([[ 0.0053, -0.0031,  0.0054,  ...,  0.0118, -0.0057, -0.0051],\n",
       "         [ 0.0141, -0.0108,  0.0128,  ..., -0.0120,  0.0135,  0.0024],\n",
       "         [ 0.0073, -0.0115, -0.0110,  ...,  0.0079,  0.0054,  0.0152],\n",
       "         ...,\n",
       "         [ 0.0115, -0.0027, -0.0186,  ..., -0.0058,  0.0048,  0.0067],\n",
       "         [ 0.0098,  0.0040,  0.0140,  ..., -0.0106, -0.0035,  0.0041],\n",
       "         [ 0.0153,  0.0103,  0.0106,  ..., -0.0104,  0.0108,  0.0054]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.28.mlp.up_proj.lora_B.weight': tensor([[ 3.4142e-04, -1.3504e-03,  1.1826e-03,  ..., -2.0599e-03,\n",
       "           9.8419e-04,  1.2283e-03],\n",
       "         [ 5.1117e-04,  7.3910e-06, -2.1744e-04,  ...,  7.6294e-04,\n",
       "           1.9379e-03, -1.1292e-03],\n",
       "         [-1.6861e-03, -1.1063e-03,  1.7548e-04,  ...,  7.5531e-04,\n",
       "          -1.0681e-03,  7.2479e-04],\n",
       "         ...,\n",
       "         [-9.0790e-04,  1.2283e-03,  2.8381e-03,  ...,  3.1090e-04,\n",
       "          -7.6294e-04, -1.1368e-03],\n",
       "         [ 1.7776e-03, -7.1335e-04, -2.8992e-03,  ...,  1.1325e-05,\n",
       "          -7.1335e-04, -3.8300e-03],\n",
       "         [ 1.3580e-03,  1.3809e-03, -5.4932e-04,  ..., -3.6240e-04,\n",
       "           2.1210e-03, -1.8158e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.28.self_attn.k_proj.lora_A.weight': tensor([[-0.0023, -0.0034, -0.0046,  ..., -0.0128, -0.0095, -0.0101],\n",
       "         [ 0.0143,  0.0093, -0.0104,  ...,  0.0125,  0.0139, -0.0068],\n",
       "         [ 0.0149, -0.0059, -0.0084,  ...,  0.0099,  0.0087, -0.0102],\n",
       "         ...,\n",
       "         [-0.0003, -0.0125, -0.0008,  ...,  0.0005,  0.0103, -0.0096],\n",
       "         [ 0.0074, -0.0129, -0.0013,  ..., -0.0089, -0.0156, -0.0093],\n",
       "         [-0.0126,  0.0040, -0.0020,  ...,  0.0173,  0.0093, -0.0109]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.28.self_attn.k_proj.lora_B.weight': tensor([[ 1.8463e-03, -8.0872e-04, -1.7319e-03,  ...,  6.3896e-05,\n",
       "           5.7602e-04,  2.9564e-04],\n",
       "         [ 1.7319e-03,  8.1062e-05,  3.1662e-04,  ...,  1.6327e-03,\n",
       "           1.0147e-03,  8.5831e-04],\n",
       "         [-6.2180e-04,  7.2861e-04, -5.8746e-04,  ..., -1.3657e-03,\n",
       "          -6.8283e-04,  1.3428e-03],\n",
       "         ...,\n",
       "         [-4.4632e-04, -1.0910e-03, -4.5967e-04,  ...,  2.0599e-03,\n",
       "          -1.0376e-03,  1.6327e-03],\n",
       "         [ 1.3885e-03,  1.5488e-03,  1.8845e-03,  ..., -6.6757e-04,\n",
       "          -2.3499e-03, -8.2779e-04],\n",
       "         [-1.7319e-03, -2.0447e-03, -3.5858e-03,  ...,  2.2888e-03,\n",
       "           9.8419e-04,  1.4725e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.28.self_attn.o_proj.lora_A.weight': tensor([[-0.0120, -0.0101,  0.0119,  ...,  0.0014, -0.0152, -0.0078],\n",
       "         [ 0.0146,  0.0073,  0.0002,  ...,  0.0049, -0.0108, -0.0037],\n",
       "         [-0.0131, -0.0148, -0.0008,  ...,  0.0095,  0.0151,  0.0139],\n",
       "         ...,\n",
       "         [ 0.0071, -0.0088,  0.0032,  ..., -0.0022,  0.0085, -0.0146],\n",
       "         [ 0.0114,  0.0070,  0.0132,  ..., -0.0035,  0.0134, -0.0085],\n",
       "         [-0.0044,  0.0171, -0.0057,  ..., -0.0129, -0.0096,  0.0070]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.28.self_attn.o_proj.lora_B.weight': tensor([[ 1.1444e-03, -2.4261e-03, -1.6594e-04,  ..., -2.0752e-03,\n",
       "          -7.9346e-04, -1.5945e-03],\n",
       "         [-2.7466e-03, -1.4343e-03,  1.4038e-03,  ..., -3.3569e-03,\n",
       "           1.4973e-04,  5.9509e-04],\n",
       "         [ 1.9531e-03, -1.9226e-03,  1.6499e-04,  ...,  2.4414e-04,\n",
       "          -4.8447e-04, -9.4223e-04],\n",
       "         ...,\n",
       "         [-1.7624e-03,  9.8228e-05, -1.1673e-03,  ..., -1.4114e-04,\n",
       "           8.2779e-04,  1.7014e-03],\n",
       "         [ 1.8158e-03, -1.3447e-04,  3.2196e-03,  ...,  2.8610e-04,\n",
       "           6.5994e-04, -9.4223e-04],\n",
       "         [-3.0365e-03,  1.2815e-05,  3.5095e-04,  ...,  2.8610e-04,\n",
       "           1.9684e-03,  2.6398e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.28.self_attn.q_proj.lora_A.weight': tensor([[ 1.1292e-02, -1.1108e-02, -1.6968e-02,  ...,  1.1169e-02,\n",
       "           3.9673e-03, -1.8463e-03],\n",
       "         [ 6.9580e-03, -1.0864e-02, -1.0742e-02,  ..., -7.1411e-03,\n",
       "           1.4221e-02, -2.8534e-03],\n",
       "         [-1.6968e-02, -1.2512e-03,  5.4321e-03,  ...,  1.1414e-02,\n",
       "           4.4556e-03,  5.4626e-03],\n",
       "         ...,\n",
       "         [-1.0864e-02,  6.3419e-05, -6.2256e-03,  ..., -1.0559e-02,\n",
       "          -7.5989e-03,  8.9111e-03],\n",
       "         [-3.3417e-03,  1.8463e-03,  1.7212e-02,  ...,  9.9487e-03,\n",
       "           7.4158e-03, -1.1841e-02],\n",
       "         [ 4.0817e-04, -1.3184e-02,  1.0620e-02,  ...,  7.8735e-03,\n",
       "          -3.6316e-03, -1.4648e-02]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.28.self_attn.q_proj.lora_B.weight': tensor([[ 1.7319e-03,  4.5776e-05,  9.8419e-04,  ..., -1.3580e-03,\n",
       "           2.0294e-03,  1.7242e-03],\n",
       "         [-8.5068e-04, -7.3242e-04,  3.2997e-04,  ...,  1.7548e-03,\n",
       "           1.3657e-03,  1.7262e-04],\n",
       "         [ 3.6240e-04, -7.9346e-04, -1.2512e-03,  ..., -5.4932e-04,\n",
       "          -2.4128e-04, -8.3160e-04],\n",
       "         ...,\n",
       "         [-2.4414e-03,  1.0529e-03, -1.5163e-04,  ..., -1.8845e-03,\n",
       "           2.1362e-04,  8.2397e-04],\n",
       "         [-3.3264e-03,  3.0518e-04, -5.3406e-04,  ...,  8.8501e-04,\n",
       "          -5.7983e-04,  2.8419e-04],\n",
       "         [-1.1978e-03,  1.3199e-03, -1.2398e-04,  ..., -8.5449e-04,\n",
       "           5.6458e-04,  2.6093e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.28.self_attn.v_proj.lora_A.weight': tensor([[-1.5381e-02, -6.8665e-05,  6.2866e-03,  ...,  5.5237e-03,\n",
       "          -8.3618e-03,  1.8555e-02],\n",
       "         [-1.2283e-03,  2.0266e-05, -1.0925e-02,  ..., -5.0354e-03,\n",
       "           2.7618e-03,  1.1536e-02],\n",
       "         [ 1.4648e-02,  8.9722e-03,  8.6594e-04,  ...,  1.3550e-02,\n",
       "           1.2878e-02, -2.3937e-04],\n",
       "         ...,\n",
       "         [-5.3406e-03, -2.8381e-03,  1.1963e-02,  ...,  4.1199e-03,\n",
       "          -8.7280e-03, -1.4404e-02],\n",
       "         [ 1.2268e-02, -1.3245e-02,  7.1716e-03,  ..., -2.3041e-03,\n",
       "          -6.4392e-03, -2.2583e-03],\n",
       "         [-7.4768e-03,  7.7209e-03,  4.5166e-03,  ..., -1.6846e-02,\n",
       "           1.6357e-02, -2.0294e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.28.self_attn.v_proj.lora_B.weight': tensor([[-1.0147e-03, -6.3324e-04, -6.6376e-04,  ...,  8.5831e-04,\n",
       "           1.1597e-03,  6.2561e-04],\n",
       "         [ 1.8005e-03,  1.9531e-03,  1.7166e-03,  ..., -1.9226e-03,\n",
       "          -1.9836e-03, -1.8234e-03],\n",
       "         [-1.4801e-03, -1.2589e-03, -1.6251e-03,  ...,  1.1978e-03,\n",
       "           1.0986e-03,  8.8120e-04],\n",
       "         ...,\n",
       "         [ 1.7166e-03,  1.4801e-03,  6.6280e-05,  ..., -1.1673e-03,\n",
       "          -8.7357e-04, -1.6861e-03],\n",
       "         [ 5.6458e-04,  1.7738e-04, -1.0300e-03,  ..., -4.7684e-04,\n",
       "          -9.9659e-05,  1.0109e-04],\n",
       "         [-1.1673e-03, -5.7602e-04, -2.0142e-03,  ...,  4.8256e-04,\n",
       "           1.7700e-03,  1.1597e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.29.mlp.down_proj.lora_A.weight': tensor([[ 0.0002,  0.0096,  0.0033,  ..., -0.0078, -0.0045,  0.0067],\n",
       "         [-0.0023, -0.0004, -0.0055,  ...,  0.0077,  0.0044, -0.0015],\n",
       "         [-0.0082,  0.0030, -0.0085,  ...,  0.0084, -0.0036, -0.0020],\n",
       "         ...,\n",
       "         [-0.0047, -0.0072,  0.0052,  ..., -0.0128, -0.0036,  0.0059],\n",
       "         [-0.0069, -0.0012, -0.0078,  ..., -0.0064, -0.0062, -0.0092],\n",
       "         [-0.0047, -0.0069,  0.0032,  ..., -0.0001,  0.0034,  0.0087]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.29.mlp.down_proj.lora_B.weight': tensor([[ 9.4986e-04,  1.1902e-03,  1.0071e-03,  ...,  1.9073e-03,\n",
       "           9.3460e-04,  1.5335e-03],\n",
       "         [ 2.3346e-03,  5.9509e-04, -2.1553e-04,  ...,  1.1444e-03,\n",
       "          -1.9989e-03,  2.0447e-03],\n",
       "         [ 2.8229e-03, -6.1035e-05,  2.3499e-03,  ...,  3.5095e-04,\n",
       "          -1.0834e-03,  1.8158e-03],\n",
       "         ...,\n",
       "         [-2.8839e-03, -2.2888e-03, -1.8311e-03,  ...,  5.8746e-04,\n",
       "          -8.7738e-04, -3.0975e-03],\n",
       "         [ 2.1667e-03, -1.0071e-03,  3.0060e-03,  ...,  6.5994e-04,\n",
       "           2.3804e-03, -1.4343e-03],\n",
       "         [-4.2419e-03,  1.3580e-03, -2.5177e-03,  ..., -1.2360e-03,\n",
       "           4.3869e-04,  4.1771e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.29.mlp.gate_proj.lora_A.weight': tensor([[-9.0332e-03,  1.6968e-02, -9.5825e-03,  ..., -6.2256e-03,\n",
       "          -1.5625e-02, -4.3335e-03],\n",
       "         [ 1.7944e-02, -1.0498e-02,  1.8978e-04,  ...,  1.5320e-02,\n",
       "          -1.2634e-02, -7.5989e-03],\n",
       "         [ 9.9487e-03, -1.5320e-02, -1.4099e-02,  ..., -4.6997e-03,\n",
       "           5.6152e-03, -1.1230e-02],\n",
       "         ...,\n",
       "         [-1.2207e-02, -1.3550e-02,  1.2695e-02,  ...,  9.2030e-05,\n",
       "          -8.1177e-03, -6.5613e-04],\n",
       "         [-5.3711e-03,  6.8665e-03, -1.0437e-02,  ..., -1.0437e-02,\n",
       "           1.1230e-02, -9.9487e-03],\n",
       "         [ 7.3853e-03, -1.4526e-02, -4.7302e-03,  ...,  3.6926e-03,\n",
       "           9.1553e-03,  1.3580e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.29.mlp.gate_proj.lora_B.weight': tensor([[-0.0007,  0.0008, -0.0009,  ..., -0.0019,  0.0005, -0.0005],\n",
       "         [ 0.0009, -0.0003, -0.0014,  ..., -0.0006,  0.0023, -0.0011],\n",
       "         [ 0.0021,  0.0014, -0.0032,  ..., -0.0025,  0.0045, -0.0013],\n",
       "         ...,\n",
       "         [ 0.0012, -0.0006,  0.0007,  ...,  0.0016, -0.0003,  0.0014],\n",
       "         [-0.0021, -0.0017, -0.0019,  ..., -0.0003,  0.0010,  0.0006],\n",
       "         [ 0.0008,  0.0031, -0.0021,  ...,  0.0029,  0.0026,  0.0023]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.29.mlp.up_proj.lora_A.weight': tensor([[ 5.1880e-03,  5.6763e-03, -4.1199e-03,  ...,  5.5542e-03,\n",
       "          -1.0010e-02,  6.7234e-05],\n",
       "         [ 1.2878e-02,  6.7749e-03,  1.0559e-02,  ...,  1.5030e-03,\n",
       "          -7.6599e-03,  4.2419e-03],\n",
       "         [-3.5706e-03,  5.7068e-03,  5.5542e-03,  ..., -8.9722e-03,\n",
       "           1.3550e-02, -1.2085e-02],\n",
       "         ...,\n",
       "         [-3.7842e-03, -1.0986e-02,  2.7313e-03,  ..., -1.3733e-02,\n",
       "          -1.2207e-02, -3.8910e-03],\n",
       "         [ 8.2779e-04, -1.7822e-02,  1.4282e-02,  ..., -1.4282e-02,\n",
       "           1.9684e-03,  1.3977e-02],\n",
       "         [ 1.0376e-02, -3.5858e-03,  3.2043e-03,  ...,  1.1658e-02,\n",
       "           9.5215e-03, -8.3008e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.29.mlp.up_proj.lora_B.weight': tensor([[-8.9645e-04,  1.7881e-05,  1.9531e-03,  ...,  1.2817e-03,\n",
       "           1.2684e-04, -4.6692e-03],\n",
       "         [ 5.1880e-04,  8.8120e-04, -6.1035e-04,  ..., -4.9210e-04,\n",
       "          -7.8964e-04,  1.9989e-03],\n",
       "         [ 4.6492e-05,  4.1389e-04,  5.1498e-04,  ...,  1.4267e-03,\n",
       "          -8.4305e-04, -4.6730e-04],\n",
       "         ...,\n",
       "         [ 1.4343e-03, -2.0142e-03,  1.8082e-03,  ..., -4.0817e-04,\n",
       "           2.9297e-03,  4.7874e-04],\n",
       "         [-8.6308e-05,  5.2261e-04,  1.5106e-03,  ..., -1.1902e-03,\n",
       "          -2.1667e-03,  9.9182e-04],\n",
       "         [ 1.4191e-03,  2.0142e-03, -2.9182e-04,  ..., -5.4169e-04,\n",
       "          -2.8839e-03,  1.8787e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.29.self_attn.k_proj.lora_A.weight': tensor([[ 0.0019, -0.0011,  0.0007,  ..., -0.0063,  0.0045,  0.0070],\n",
       "         [-0.0087, -0.0125,  0.0126,  ..., -0.0131,  0.0102, -0.0120],\n",
       "         [ 0.0016,  0.0112,  0.0143,  ..., -0.0134, -0.0104, -0.0050],\n",
       "         ...,\n",
       "         [ 0.0059, -0.0072, -0.0173,  ...,  0.0017, -0.0053,  0.0087],\n",
       "         [-0.0064,  0.0041,  0.0107,  ..., -0.0047,  0.0001, -0.0139],\n",
       "         [-0.0112, -0.0073,  0.0126,  ...,  0.0017,  0.0025,  0.0079]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.29.self_attn.k_proj.lora_B.weight': tensor([[-1.3046e-03, -3.8605e-03, -3.4790e-03,  ...,  4.7088e-06,\n",
       "           2.6245e-03,  2.5940e-03],\n",
       "         [ 1.5640e-04,  1.6785e-03,  2.1057e-03,  ..., -6.3705e-04,\n",
       "          -1.2970e-03, -8.9645e-04],\n",
       "         [-1.4496e-03,  1.2283e-03,  3.3379e-04,  ..., -3.5286e-04,\n",
       "          -2.6703e-04,  1.8158e-03],\n",
       "         ...,\n",
       "         [ 9.2316e-04, -1.6785e-03, -9.1934e-04,  ..., -9.9945e-04,\n",
       "           1.5926e-04, -7.2861e-04],\n",
       "         [-1.3885e-03,  5.8746e-04, -1.6556e-03,  ...,  1.7471e-03,\n",
       "           4.2725e-04,  1.3351e-03],\n",
       "         [ 1.1292e-03, -1.0967e-04, -3.2806e-04,  ..., -1.0681e-03,\n",
       "           3.7231e-03, -1.8692e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.29.self_attn.o_proj.lora_A.weight': tensor([[ 0.0101, -0.0087,  0.0126,  ...,  0.0107, -0.0013, -0.0031],\n",
       "         [ 0.0043, -0.0104,  0.0127,  ...,  0.0012,  0.0016,  0.0047],\n",
       "         [ 0.0006,  0.0071, -0.0109,  ...,  0.0105, -0.0028, -0.0059],\n",
       "         ...,\n",
       "         [ 0.0057,  0.0060,  0.0032,  ...,  0.0068, -0.0115,  0.0155],\n",
       "         [ 0.0116,  0.0048,  0.0045,  ..., -0.0175, -0.0064, -0.0030],\n",
       "         [-0.0114, -0.0135,  0.0051,  ..., -0.0062,  0.0055,  0.0056]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.29.self_attn.o_proj.lora_B.weight': tensor([[-1.4114e-03,  3.0136e-04,  1.9455e-04,  ..., -7.3624e-04,\n",
       "           6.4087e-04, -9.6130e-04],\n",
       "         [ 2.2430e-03, -3.0899e-04, -2.6321e-04,  ..., -2.4414e-03,\n",
       "           6.5994e-04,  1.4648e-03],\n",
       "         [-3.5286e-04,  1.1826e-03, -3.0212e-03,  ...,  1.4420e-03,\n",
       "           1.8921e-03, -1.6785e-03],\n",
       "         ...,\n",
       "         [ 8.1253e-04, -6.0797e-05,  1.8692e-03,  ..., -9.6893e-04,\n",
       "           1.1215e-03, -1.4782e-04],\n",
       "         [-1.1826e-03, -1.7014e-03,  1.0452e-03,  ..., -2.0599e-03,\n",
       "           1.0300e-03,  4.5166e-03],\n",
       "         [ 2.2736e-03, -2.2278e-03,  2.7084e-04,  ..., -8.5449e-04,\n",
       "           1.6327e-03, -3.8719e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.29.self_attn.q_proj.lora_A.weight': tensor([[ 0.0028,  0.0114,  0.0080,  ...,  0.0042, -0.0189,  0.0115],\n",
       "         [-0.0179,  0.0165, -0.0008,  ...,  0.0078,  0.0115,  0.0075],\n",
       "         [ 0.0136,  0.0006, -0.0118,  ..., -0.0083,  0.0024,  0.0029],\n",
       "         ...,\n",
       "         [-0.0037,  0.0021, -0.0172,  ...,  0.0084, -0.0001,  0.0040],\n",
       "         [-0.0056, -0.0138, -0.0057,  ...,  0.0173,  0.0065, -0.0015],\n",
       "         [ 0.0044,  0.0013,  0.0125,  ..., -0.0058, -0.0044,  0.0103]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.29.self_attn.q_proj.lora_B.weight': tensor([[ 1.2283e-03, -2.4109e-03, -1.1539e-04,  ..., -2.0599e-03,\n",
       "          -1.0223e-03, -1.2360e-03],\n",
       "         [-2.5024e-03, -1.6174e-03, -3.1281e-03,  ..., -1.2512e-03,\n",
       "           5.5695e-04,  3.2806e-03],\n",
       "         [-8.5068e-04, -3.2997e-04, -1.0376e-03,  ...,  2.8610e-04,\n",
       "           6.3324e-04,  3.6316e-03],\n",
       "         ...,\n",
       "         [-5.8889e-05, -1.7624e-03,  4.3488e-04,  ..., -2.3804e-03,\n",
       "          -5.7602e-04, -8.9645e-04],\n",
       "         [-6.3324e-04,  3.4332e-03,  1.4420e-03,  ...,  4.8256e-04,\n",
       "           1.1826e-03, -2.6894e-04],\n",
       "         [-8.2016e-04,  3.2806e-03,  1.6174e-03,  ...,  2.9564e-04,\n",
       "           3.8338e-04, -7.9346e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.29.self_attn.v_proj.lora_A.weight': tensor([[-1.1492e-04,  7.6599e-03,  7.2632e-03,  ...,  1.5625e-02,\n",
       "           4.2419e-03,  9.4223e-04],\n",
       "         [-1.6235e-02,  8.5831e-04,  5.0964e-03,  ...,  1.8555e-02,\n",
       "          -1.5015e-02, -2.9144e-03],\n",
       "         [-1.5736e-04, -7.6904e-03,  3.7079e-03,  ..., -8.9722e-03,\n",
       "          -1.4496e-03, -1.0315e-02],\n",
       "         ...,\n",
       "         [ 1.2665e-03, -1.3672e-02, -1.2024e-02,  ...,  4.0588e-03,\n",
       "          -3.5248e-03, -8.7891e-03],\n",
       "         [ 8.0490e-04, -7.2021e-03, -6.9275e-03,  ...,  4.6082e-03,\n",
       "           8.3008e-03, -8.8501e-03],\n",
       "         [-1.0986e-02, -1.1536e-02,  1.4007e-05,  ..., -2.7771e-03,\n",
       "           4.3945e-03,  9.8877e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.29.self_attn.v_proj.lora_B.weight': tensor([[ 3.9101e-04,  1.5106e-03,  2.2583e-03,  ..., -1.8234e-03,\n",
       "          -9.0027e-04,  1.4954e-03],\n",
       "         [ 5.3406e-04, -4.9210e-04, -9.6130e-04,  ...,  4.3678e-04,\n",
       "           1.4038e-03, -4.0817e-04],\n",
       "         [-8.0109e-04, -2.4986e-04,  8.5068e-04,  ...,  9.4986e-04,\n",
       "          -6.7139e-04,  4.8065e-04],\n",
       "         ...,\n",
       "         [-3.5286e-04, -1.6975e-04,  1.3428e-03,  ..., -6.4468e-04,\n",
       "          -4.3640e-03,  7.4387e-04],\n",
       "         [ 1.2016e-04, -1.5545e-04,  5.6267e-05,  ..., -1.8597e-04,\n",
       "          -8.2016e-04,  1.0669e-05],\n",
       "         [ 2.4261e-03,  3.5095e-04, -1.9169e-04,  ..., -6.0272e-04,\n",
       "           1.1978e-03,  3.6430e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.3.mlp.down_proj.lora_A.weight': tensor([[ 0.0020, -0.0009, -0.0020,  ..., -0.0039, -0.0057, -0.0098],\n",
       "         [-0.0082, -0.0015,  0.0044,  ..., -0.0040,  0.0027,  0.0089],\n",
       "         [-0.0078, -0.0031, -0.0116,  ...,  0.0003,  0.0076,  0.0118],\n",
       "         ...,\n",
       "         [-0.0021,  0.0078,  0.0063,  ...,  0.0023, -0.0062,  0.0004],\n",
       "         [ 0.0043,  0.0061,  0.0014,  ..., -0.0060,  0.0118, -0.0008],\n",
       "         [ 0.0007,  0.0090,  0.0023,  ...,  0.0077,  0.0038,  0.0090]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.3.mlp.down_proj.lora_B.weight': tensor([[ 0.0008,  0.0014,  0.0034,  ..., -0.0017, -0.0010, -0.0007],\n",
       "         [ 0.0012,  0.0010,  0.0007,  ...,  0.0004, -0.0014,  0.0009],\n",
       "         [-0.0016, -0.0014, -0.0032,  ..., -0.0038,  0.0033, -0.0013],\n",
       "         ...,\n",
       "         [-0.0002, -0.0005, -0.0022,  ..., -0.0022, -0.0001,  0.0019],\n",
       "         [ 0.0004, -0.0006,  0.0021,  ...,  0.0029,  0.0017,  0.0002],\n",
       "         [ 0.0043, -0.0028, -0.0006,  ..., -0.0027,  0.0021, -0.0013]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.3.mlp.gate_proj.lora_A.weight': tensor([[-0.0033, -0.0022,  0.0054,  ...,  0.0167,  0.0112,  0.0137],\n",
       "         [-0.0109,  0.0060,  0.0128,  ...,  0.0124,  0.0156, -0.0066],\n",
       "         [-0.0069, -0.0019,  0.0056,  ..., -0.0109, -0.0091,  0.0078],\n",
       "         ...,\n",
       "         [ 0.0008,  0.0115,  0.0037,  ..., -0.0034,  0.0110,  0.0084],\n",
       "         [ 0.0173,  0.0046, -0.0134,  ..., -0.0030,  0.0037, -0.0052],\n",
       "         [ 0.0076, -0.0005,  0.0035,  ...,  0.0059, -0.0030,  0.0015]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.3.mlp.gate_proj.lora_B.weight': tensor([[-1.5717e-03, -1.9455e-03, -4.3488e-04,  ...,  3.0823e-03,\n",
       "          -9.0790e-04, -1.1978e-03],\n",
       "         [ 1.2283e-03, -4.9973e-04,  6.9046e-04,  ...,  1.8539e-03,\n",
       "           1.2436e-03, -3.8910e-04],\n",
       "         [-9.9945e-04, -6.8665e-04,  1.3275e-03,  ...,  2.6855e-03,\n",
       "          -2.7008e-03,  6.7139e-04],\n",
       "         ...,\n",
       "         [-1.4191e-03, -1.9531e-03,  1.8311e-03,  ...,  2.4261e-03,\n",
       "          -6.5613e-04, -1.0605e-03],\n",
       "         [-9.2316e-04,  1.4114e-03, -2.6855e-03,  ..., -7.1335e-04,\n",
       "          -2.2888e-03, -2.7313e-03],\n",
       "         [-1.4343e-03,  1.8768e-03,  4.6492e-05,  ...,  2.4109e-03,\n",
       "           1.3733e-03, -1.2436e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.3.mlp.up_proj.lora_A.weight': tensor([[ 0.0036, -0.0027,  0.0131,  ...,  0.0074, -0.0075,  0.0002],\n",
       "         [-0.0032, -0.0128, -0.0038,  ...,  0.0140, -0.0131,  0.0015],\n",
       "         [-0.0139,  0.0125, -0.0091,  ..., -0.0059, -0.0032, -0.0035],\n",
       "         ...,\n",
       "         [ 0.0054,  0.0042,  0.0027,  ..., -0.0088,  0.0047,  0.0121],\n",
       "         [ 0.0093, -0.0098, -0.0049,  ..., -0.0106,  0.0099, -0.0042],\n",
       "         [ 0.0029, -0.0105, -0.0082,  ..., -0.0092, -0.0082,  0.0067]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.3.mlp.up_proj.lora_B.weight': tensor([[-2.3804e-03, -2.1515e-03, -1.3962e-03,  ..., -1.9836e-03,\n",
       "          -1.3504e-03, -4.3869e-04],\n",
       "         [ 4.2915e-04, -2.0905e-03, -6.3324e-04,  ..., -1.2207e-03,\n",
       "          -1.0757e-03, -8.8882e-04],\n",
       "         [ 3.8338e-04,  2.0447e-03, -6.5994e-04,  ...,  8.6212e-04,\n",
       "          -1.5717e-03, -1.5106e-03],\n",
       "         ...,\n",
       "         [ 3.0670e-03,  1.6327e-03,  3.6621e-03,  ...,  2.2888e-03,\n",
       "           9.4986e-04,  1.7776e-03],\n",
       "         [ 1.0071e-03,  4.8065e-04, -1.2360e-03,  ...,  1.8234e-03,\n",
       "          -6.5231e-04,  5.7936e-05],\n",
       "         [ 9.7656e-04, -5.4932e-04,  2.5635e-03,  ...,  1.0147e-03,\n",
       "          -2.1973e-03,  1.2064e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.3.self_attn.k_proj.lora_A.weight': tensor([[-0.0114,  0.0085,  0.0037,  ..., -0.0097,  0.0075,  0.0030],\n",
       "         [ 0.0076, -0.0026,  0.0144,  ..., -0.0064,  0.0010, -0.0103],\n",
       "         [-0.0098,  0.0016, -0.0187,  ...,  0.0075,  0.0031,  0.0060],\n",
       "         ...,\n",
       "         [-0.0114, -0.0063,  0.0042,  ..., -0.0041,  0.0036,  0.0025],\n",
       "         [-0.0105, -0.0066,  0.0115,  ..., -0.0077,  0.0125, -0.0016],\n",
       "         [ 0.0042, -0.0079,  0.0066,  ...,  0.0110,  0.0014, -0.0153]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.3.self_attn.k_proj.lora_B.weight': tensor([[ 0.0008, -0.0012,  0.0022,  ...,  0.0001, -0.0002, -0.0019],\n",
       "         [-0.0011,  0.0015, -0.0010,  ...,  0.0019,  0.0012,  0.0006],\n",
       "         [-0.0003,  0.0005, -0.0006,  ...,  0.0007,  0.0016, -0.0012],\n",
       "         ...,\n",
       "         [-0.0011,  0.0007,  0.0001,  ...,  0.0004, -0.0024,  0.0008],\n",
       "         [-0.0012, -0.0002, -0.0003,  ...,  0.0002,  0.0018, -0.0005],\n",
       "         [-0.0008,  0.0011,  0.0003,  ...,  0.0014,  0.0022, -0.0013]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.3.self_attn.o_proj.lora_A.weight': tensor([[-1.0071e-02, -1.1475e-02, -1.0498e-02,  ..., -5.1880e-03,\n",
       "          -1.0193e-02,  1.0620e-02],\n",
       "         [-6.6528e-03, -2.4872e-03,  5.2490e-03,  ..., -3.5477e-04,\n",
       "           2.5482e-03, -2.2430e-03],\n",
       "         [-9.7046e-03, -2.1362e-03, -1.6357e-02,  ...,  1.0193e-02,\n",
       "           1.4404e-02,  3.2349e-03],\n",
       "         ...,\n",
       "         [ 8.9645e-05,  1.5640e-03,  3.9368e-03,  ...,  5.9204e-03,\n",
       "          -9.0332e-03,  6.5002e-03],\n",
       "         [ 1.3794e-02,  1.1963e-02, -3.6316e-03,  ...,  1.1841e-02,\n",
       "           6.2943e-04, -4.1504e-03],\n",
       "         [-3.8910e-03, -9.5215e-03,  2.0905e-03,  ...,  4.6997e-03,\n",
       "           6.3477e-03,  1.7090e-02]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.3.self_attn.o_proj.lora_B.weight': tensor([[-2.2125e-03,  7.7248e-05, -1.8463e-03,  ..., -3.2234e-04,\n",
       "          -7.5912e-04, -6.9046e-04],\n",
       "         [-7.1526e-05,  1.7929e-03,  1.6632e-03,  ...,  2.6703e-03,\n",
       "          -5.5313e-04, -6.7139e-04],\n",
       "         [ 2.2888e-03,  1.7929e-03,  2.5635e-03,  ...,  1.0300e-03,\n",
       "           2.5787e-03,  1.3351e-03],\n",
       "         ...,\n",
       "         [ 2.3041e-03,  2.5558e-04, -2.3499e-03,  ...,  1.1673e-03,\n",
       "           1.7624e-03,  8.5068e-04],\n",
       "         [-3.1281e-04,  1.6327e-03,  1.0452e-03,  ...,  2.6703e-03,\n",
       "           5.1880e-04,  2.8801e-04],\n",
       "         [-7.4387e-04, -1.4725e-03, -8.3160e-04,  ...,  2.0142e-03,\n",
       "           1.1215e-03, -2.0294e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.3.self_attn.q_proj.lora_A.weight': tensor([[-0.0053, -0.0133,  0.0028,  ..., -0.0102, -0.0118, -0.0070],\n",
       "         [-0.0126,  0.0010,  0.0131,  ...,  0.0073,  0.0156, -0.0120],\n",
       "         [ 0.0108, -0.0028,  0.0065,  ...,  0.0047, -0.0006,  0.0065],\n",
       "         ...,\n",
       "         [-0.0148, -0.0001,  0.0128,  ...,  0.0108,  0.0039,  0.0120],\n",
       "         [-0.0030, -0.0154, -0.0079,  ..., -0.0120, -0.0058, -0.0129],\n",
       "         [-0.0062, -0.0093, -0.0091,  ..., -0.0123,  0.0054,  0.0165]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.3.self_attn.q_proj.lora_B.weight': tensor([[ 1.0147e-03,  1.6403e-03, -1.5182e-03,  ...,  1.3885e-03,\n",
       "           9.7275e-05,  2.2888e-03],\n",
       "         [-1.9684e-03, -9.0790e-04,  1.4725e-03,  ..., -1.9836e-03,\n",
       "          -1.0376e-03,  9.2316e-04],\n",
       "         [-1.7014e-03, -1.9836e-03,  1.5945e-03,  ..., -7.4768e-04,\n",
       "          -5.0735e-04, -2.1820e-03],\n",
       "         ...,\n",
       "         [ 3.3569e-04, -2.6703e-04, -1.1368e-03,  ..., -2.7275e-04,\n",
       "          -2.1362e-03, -1.6098e-03],\n",
       "         [-1.0443e-04, -1.1597e-03,  1.3504e-03,  ...,  3.5763e-05,\n",
       "           1.9302e-03,  1.0071e-03],\n",
       "         [-4.5013e-04, -1.7166e-03,  4.9973e-04,  ..., -9.4986e-04,\n",
       "           2.1667e-03, -2.5940e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.3.self_attn.v_proj.lora_A.weight': tensor([[-0.0098, -0.0001,  0.0056,  ...,  0.0014,  0.0010,  0.0012],\n",
       "         [ 0.0131, -0.0022,  0.0006,  ..., -0.0088, -0.0087,  0.0029],\n",
       "         [-0.0146,  0.0004,  0.0053,  ...,  0.0087, -0.0067, -0.0114],\n",
       "         ...,\n",
       "         [-0.0043,  0.0123, -0.0095,  ...,  0.0016,  0.0013,  0.0052],\n",
       "         [ 0.0133, -0.0077,  0.0124,  ..., -0.0023, -0.0005, -0.0091],\n",
       "         [ 0.0056,  0.0120, -0.0119,  ..., -0.0030, -0.0118,  0.0118]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.3.self_attn.v_proj.lora_B.weight': tensor([[ 1.4343e-03, -7.5150e-04, -1.8997e-03,  ...,  1.7624e-03,\n",
       "          -7.5912e-04, -1.3199e-03],\n",
       "         [ 2.0752e-03,  7.0190e-04, -1.2970e-03,  ...,  7.5912e-04,\n",
       "          -1.0986e-03, -1.2436e-03],\n",
       "         [ 1.1349e-04,  1.0223e-03, -1.2064e-04,  ..., -1.1749e-03,\n",
       "          -1.2512e-03, -2.9182e-04],\n",
       "         ...,\n",
       "         [-8.1635e-04, -9.3079e-04, -3.8338e-04,  ...,  8.0872e-04,\n",
       "           9.0122e-05,  1.9360e-04],\n",
       "         [-1.7357e-04, -9.3842e-04, -9.1934e-04,  ...,  9.7275e-04,\n",
       "           2.0599e-03, -1.4420e-03],\n",
       "         [-1.0300e-03,  1.4038e-03,  4.3945e-03,  ..., -2.1973e-03,\n",
       "          -6.9427e-04,  2.3956e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.30.mlp.down_proj.lora_A.weight': tensor([[-6.4697e-03, -2.8839e-03,  3.8452e-03,  ...,  3.1853e-04,\n",
       "          -7.8735e-03, -6.9885e-03],\n",
       "         [ 6.6833e-03,  7.3242e-03, -7.5073e-03,  ..., -8.6670e-03,\n",
       "          -2.9755e-03,  5.5237e-03],\n",
       "         [-1.5411e-03,  3.0823e-03, -3.9368e-03,  ...,  7.2632e-03,\n",
       "           5.4321e-03, -9.7656e-03],\n",
       "         ...,\n",
       "         [ 7.2632e-03, -9.0942e-03, -5.8289e-03,  ..., -6.3782e-03,\n",
       "          -3.9062e-03,  2.3556e-04],\n",
       "         [-5.8289e-03, -2.0142e-03,  6.5804e-05,  ...,  1.5335e-03,\n",
       "           5.5847e-03,  2.7008e-03],\n",
       "         [ 3.9368e-03,  2.2125e-03,  2.5787e-03,  ..., -2.3651e-03,\n",
       "          -1.3809e-03, -3.1891e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.30.mlp.down_proj.lora_B.weight': tensor([[ 1.1292e-03, -2.0504e-04,  8.9264e-04,  ...,  2.4109e-03,\n",
       "          -9.6512e-04,  7.4005e-04],\n",
       "         [ 3.9291e-04,  1.1902e-03, -7.5531e-04,  ..., -3.7003e-04,\n",
       "           2.1667e-03,  7.8583e-04],\n",
       "         [ 7.1526e-05,  6.6376e-04, -1.5411e-03,  ...,  1.1520e-03,\n",
       "          -4.2343e-04, -1.5640e-03],\n",
       "         ...,\n",
       "         [-2.6093e-03,  2.6093e-03,  1.6785e-03,  ...,  3.2616e-04,\n",
       "          -8.8882e-04,  1.5793e-03],\n",
       "         [ 8.6212e-04,  8.6212e-04, -1.7395e-03,  ...,  8.7261e-05,\n",
       "          -7.7820e-04,  2.8229e-03],\n",
       "         [-1.6403e-03,  1.1110e-04,  2.1820e-03,  ..., -5.9891e-04,\n",
       "           1.1749e-03, -3.2997e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.30.mlp.gate_proj.lora_A.weight': tensor([[-0.0145,  0.0058, -0.0085,  ...,  0.0049,  0.0160,  0.0079],\n",
       "         [-0.0159, -0.0061,  0.0017,  ...,  0.0005, -0.0157, -0.0118],\n",
       "         [ 0.0059, -0.0094, -0.0039,  ..., -0.0036, -0.0108,  0.0016],\n",
       "         ...,\n",
       "         [-0.0021, -0.0003,  0.0141,  ...,  0.0063,  0.0025, -0.0060],\n",
       "         [ 0.0025,  0.0127, -0.0076,  ...,  0.0136,  0.0046,  0.0035],\n",
       "         [ 0.0062, -0.0132,  0.0012,  ...,  0.0022, -0.0023,  0.0150]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.30.mlp.gate_proj.lora_B.weight': tensor([[ 1.3046e-03,  1.0757e-03, -2.9755e-04,  ..., -7.0190e-04,\n",
       "           2.1076e-04, -2.5558e-04],\n",
       "         [-7.7438e-04,  3.1471e-04, -1.5411e-03,  ..., -1.1444e-03,\n",
       "          -4.6921e-04,  3.2806e-03],\n",
       "         [ 1.0452e-03,  3.6774e-03,  2.6855e-03,  ...,  8.3923e-04,\n",
       "          -2.9755e-04, -2.6245e-03],\n",
       "         ...,\n",
       "         [-1.8692e-03, -5.3644e-05, -1.0605e-03,  ..., -5.0354e-04,\n",
       "          -9.9182e-04,  1.0757e-03],\n",
       "         [ 2.0752e-03, -1.3123e-03,  9.6130e-04,  ...,  3.6621e-03,\n",
       "          -2.6703e-03, -1.1673e-03],\n",
       "         [-6.7139e-04,  1.4267e-03, -1.8387e-03,  ...,  4.5395e-04,\n",
       "           4.9591e-04,  5.1880e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.30.mlp.up_proj.lora_A.weight': tensor([[-0.0013, -0.0064,  0.0045,  ..., -0.0026,  0.0105, -0.0026],\n",
       "         [ 0.0010,  0.0012,  0.0046,  ...,  0.0054, -0.0086,  0.0092],\n",
       "         [-0.0081, -0.0151,  0.0126,  ..., -0.0128, -0.0120, -0.0084],\n",
       "         ...,\n",
       "         [ 0.0138, -0.0062, -0.0025,  ...,  0.0096, -0.0111,  0.0052],\n",
       "         [ 0.0044, -0.0095, -0.0106,  ..., -0.0046,  0.0126,  0.0028],\n",
       "         [ 0.0074, -0.0056, -0.0076,  ..., -0.0092, -0.0023, -0.0061]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.30.mlp.up_proj.lora_B.weight': tensor([[ 5.7983e-04, -4.0283e-03,  3.4180e-03,  ...,  2.5482e-03,\n",
       "           1.9531e-03, -2.9144e-03],\n",
       "         [ 2.7771e-03,  6.5994e-04, -2.4414e-03,  ..., -1.0223e-03,\n",
       "          -4.0588e-03, -5.0735e-04],\n",
       "         [-6.0425e-03, -1.9431e-05, -1.0605e-03,  ..., -2.1973e-03,\n",
       "          -3.1128e-03, -2.5787e-03],\n",
       "         ...,\n",
       "         [ 2.8992e-03,  1.1368e-03, -1.0986e-03,  ..., -2.3956e-03,\n",
       "          -1.1597e-03,  5.6839e-04],\n",
       "         [ 3.9101e-04, -2.3499e-03,  3.1433e-03,  ...,  1.1673e-03,\n",
       "           1.5488e-03, -2.5177e-03],\n",
       "         [ 3.5286e-04,  3.7537e-03, -4.2343e-04,  ..., -2.2736e-03,\n",
       "           2.0504e-04, -3.6430e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.30.self_attn.k_proj.lora_A.weight': tensor([[-0.0102, -0.0042,  0.0035,  ..., -0.0096,  0.0060,  0.0060],\n",
       "         [ 0.0006, -0.0065,  0.0090,  ...,  0.0053, -0.0103,  0.0146],\n",
       "         [ 0.0120,  0.0065, -0.0127,  ...,  0.0097, -0.0031, -0.0105],\n",
       "         ...,\n",
       "         [-0.0134,  0.0086, -0.0029,  ..., -0.0069,  0.0089,  0.0030],\n",
       "         [ 0.0126, -0.0155,  0.0162,  ...,  0.0037,  0.0146,  0.0053],\n",
       "         [-0.0005,  0.0040,  0.0023,  ...,  0.0076,  0.0107, -0.0094]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.30.self_attn.k_proj.lora_B.weight': tensor([[ 1.9455e-03, -1.1444e-03,  2.9945e-04,  ..., -4.1008e-04,\n",
       "           1.4801e-03, -1.0223e-03],\n",
       "         [ 1.7395e-03,  4.5776e-03,  2.3041e-03,  ...,  3.0365e-03,\n",
       "          -1.0986e-03, -7.7820e-04],\n",
       "         [ 7.7248e-05, -3.8719e-04,  2.4567e-03,  ..., -1.9455e-04,\n",
       "           3.3617e-05, -9.1934e-04],\n",
       "         ...,\n",
       "         [ 9.9945e-04, -2.0294e-03,  2.0313e-04,  ..., -8.8501e-04,\n",
       "          -1.2875e-04, -6.5231e-04],\n",
       "         [ 2.7008e-03, -3.3760e-04, -4.6921e-04,  ..., -8.4305e-04,\n",
       "           2.3346e-03,  1.1597e-03],\n",
       "         [-1.5106e-03, -1.5182e-03,  7.2098e-04,  ..., -1.3275e-03,\n",
       "           1.3046e-03,  1.7471e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.30.self_attn.o_proj.lora_A.weight': tensor([[-0.0167,  0.0134,  0.0123,  ..., -0.0056, -0.0147, -0.0021],\n",
       "         [ 0.0038, -0.0036,  0.0090,  ...,  0.0004,  0.0025,  0.0108],\n",
       "         [-0.0134, -0.0052, -0.0105,  ..., -0.0113,  0.0059,  0.0057],\n",
       "         ...,\n",
       "         [ 0.0020,  0.0089,  0.0031,  ..., -0.0036,  0.0014,  0.0092],\n",
       "         [ 0.0102,  0.0038,  0.0079,  ..., -0.0041,  0.0134,  0.0103],\n",
       "         [ 0.0016,  0.0100, -0.0067,  ...,  0.0076, -0.0018,  0.0098]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.30.self_attn.o_proj.lora_B.weight': tensor([[ 9.1171e-04,  1.0986e-03, -4.2152e-04,  ..., -2.1210e-03,\n",
       "          -1.1139e-03,  1.3046e-03],\n",
       "         [-1.2817e-03, -1.4496e-03, -1.4725e-03,  ..., -1.3123e-03,\n",
       "          -1.9455e-03,  1.3123e-03],\n",
       "         [ 2.1667e-03,  3.9978e-03,  1.0376e-03,  ...,  3.7231e-03,\n",
       "           1.8539e-03,  1.4343e-03],\n",
       "         ...,\n",
       "         [ 1.2894e-03, -1.7853e-03, -1.3504e-03,  ...,  6.5231e-04,\n",
       "           2.2030e-04, -2.8992e-03],\n",
       "         [ 5.3787e-04, -9.2506e-05,  2.6703e-03,  ..., -2.7161e-03,\n",
       "           1.1902e-03,  4.6349e-04],\n",
       "         [-2.5177e-04, -1.3809e-03,  9.5367e-04,  ...,  1.6861e-03,\n",
       "          -1.2589e-03, -1.3046e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.30.self_attn.q_proj.lora_A.weight': tensor([[-1.3428e-03, -3.8910e-03,  2.6245e-03,  ..., -1.0132e-02,\n",
       "          -2.2736e-03, -1.1780e-02],\n",
       "         [ 7.0190e-03,  1.6357e-02, -8.5449e-03,  ...,  2.8839e-03,\n",
       "           1.4420e-03,  7.1411e-03],\n",
       "         [-8.6060e-03,  1.3489e-02,  6.9580e-03,  ...,  1.2451e-02,\n",
       "           1.1597e-02, -9.5367e-05],\n",
       "         ...,\n",
       "         [-1.4099e-02, -5.2795e-03, -1.0986e-02,  ...,  1.1536e-02,\n",
       "          -8.9722e-03, -5.7678e-03],\n",
       "         [-7.7515e-03, -5.6152e-03, -3.6774e-03,  ...,  1.1902e-02,\n",
       "           1.8799e-02, -1.0315e-02],\n",
       "         [ 1.0071e-02,  1.4587e-02,  3.4485e-03,  ..., -1.5015e-02,\n",
       "           3.6621e-03, -7.2021e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.30.self_attn.q_proj.lora_B.weight': tensor([[ 0.0004,  0.0020,  0.0005,  ...,  0.0008, -0.0016, -0.0005],\n",
       "         [-0.0019, -0.0013, -0.0038,  ..., -0.0033, -0.0018, -0.0002],\n",
       "         [-0.0008, -0.0023,  0.0013,  ...,  0.0010,  0.0029, -0.0003],\n",
       "         ...,\n",
       "         [-0.0004,  0.0017,  0.0001,  ...,  0.0009,  0.0013, -0.0028],\n",
       "         [-0.0005,  0.0003,  0.0011,  ...,  0.0018,  0.0006, -0.0008],\n",
       "         [ 0.0003,  0.0005,  0.0024,  ...,  0.0006, -0.0002,  0.0002]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.30.self_attn.v_proj.lora_A.weight': tensor([[-0.0071,  0.0010, -0.0120,  ..., -0.0117,  0.0065, -0.0046],\n",
       "         [ 0.0034, -0.0074,  0.0070,  ...,  0.0022, -0.0040, -0.0138],\n",
       "         [ 0.0157, -0.0095,  0.0178,  ...,  0.0120,  0.0019, -0.0098],\n",
       "         ...,\n",
       "         [-0.0084,  0.0134, -0.0112,  ...,  0.0047, -0.0121, -0.0107],\n",
       "         [ 0.0093, -0.0077,  0.0063,  ...,  0.0102,  0.0063,  0.0109],\n",
       "         [ 0.0002,  0.0059,  0.0079,  ...,  0.0043,  0.0101, -0.0008]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.30.self_attn.v_proj.lora_B.weight': tensor([[ 7.7057e-04, -4.3678e-04,  6.5231e-04,  ...,  5.2261e-04,\n",
       "          -4.4250e-04, -1.0986e-03],\n",
       "         [-8.7738e-04, -6.5613e-04, -2.0599e-03,  ..., -2.8801e-04,\n",
       "           9.5367e-04,  8.8120e-04],\n",
       "         [ 2.9564e-04, -2.0142e-03, -1.8082e-03,  ..., -1.0347e-04,\n",
       "          -7.9632e-05, -8.7261e-05],\n",
       "         ...,\n",
       "         [-3.7766e-04,  8.4400e-05,  9.3460e-04,  ...,  3.2806e-03,\n",
       "          -5.8365e-04,  2.3041e-03],\n",
       "         [ 1.4343e-03,  1.0223e-03,  2.0885e-04,  ..., -3.8910e-03,\n",
       "          -1.1749e-03, -7.0953e-04],\n",
       "         [ 3.2616e-04,  7.7248e-05, -7.8964e-04,  ...,  9.7656e-04,\n",
       "           4.0245e-04,  3.3264e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.31.mlp.down_proj.lora_A.weight': tensor([[ 0.0057, -0.0027,  0.0106,  ...,  0.0076, -0.0091,  0.0014],\n",
       "         [ 0.0027,  0.0077, -0.0047,  ..., -0.0013,  0.0095,  0.0007],\n",
       "         [ 0.0075,  0.0031,  0.0037,  ..., -0.0078, -0.0035, -0.0046],\n",
       "         ...,\n",
       "         [ 0.0034,  0.0041, -0.0077,  ...,  0.0066,  0.0012,  0.0076],\n",
       "         [-0.0068,  0.0005, -0.0031,  ...,  0.0068, -0.0066,  0.0094],\n",
       "         [-0.0076, -0.0032,  0.0089,  ...,  0.0064,  0.0087, -0.0060]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.31.mlp.down_proj.lora_B.weight': tensor([[-1.3199e-03, -1.5564e-03,  7.2479e-04,  ..., -3.1662e-04,\n",
       "           2.1820e-03, -2.7466e-03],\n",
       "         [ 1.3351e-04,  1.6098e-03,  3.9864e-04,  ..., -3.6240e-04,\n",
       "           3.3569e-03, -2.5558e-04],\n",
       "         [ 2.1515e-03, -1.2741e-03, -1.8883e-04,  ...,  1.8387e-03,\n",
       "           3.2234e-04,  2.1839e-04],\n",
       "         ...,\n",
       "         [ 9.8419e-04, -1.5793e-03, -2.1362e-03,  ..., -1.2589e-03,\n",
       "          -3.3569e-04, -1.7452e-04],\n",
       "         [-2.3041e-03, -8.8120e-04,  9.2697e-04,  ..., -2.5558e-04,\n",
       "          -1.7776e-03,  1.5182e-03],\n",
       "         [ 3.6430e-04, -1.6308e-04,  2.2125e-03,  ...,  5.2452e-06,\n",
       "           1.8692e-03, -1.5030e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.31.mlp.gate_proj.lora_A.weight': tensor([[-0.0104,  0.0094, -0.0148,  ..., -0.0125,  0.0035,  0.0073],\n",
       "         [ 0.0157, -0.0089,  0.0067,  ...,  0.0119, -0.0044,  0.0056],\n",
       "         [-0.0092, -0.0052,  0.0031,  ..., -0.0036, -0.0072, -0.0039],\n",
       "         ...,\n",
       "         [ 0.0009,  0.0049, -0.0113,  ..., -0.0125, -0.0159, -0.0107],\n",
       "         [ 0.0082,  0.0065, -0.0039,  ...,  0.0145, -0.0058,  0.0134],\n",
       "         [-0.0042, -0.0135, -0.0035,  ...,  0.0116, -0.0083, -0.0063]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.31.mlp.gate_proj.lora_B.weight': tensor([[-0.0007, -0.0004,  0.0024,  ...,  0.0019,  0.0002, -0.0004],\n",
       "         [ 0.0029, -0.0008, -0.0007,  ..., -0.0041, -0.0042, -0.0010],\n",
       "         [-0.0008, -0.0003,  0.0022,  ...,  0.0011,  0.0012, -0.0020],\n",
       "         ...,\n",
       "         [-0.0016,  0.0025,  0.0005,  ...,  0.0029,  0.0016, -0.0011],\n",
       "         [-0.0020,  0.0006, -0.0013,  ..., -0.0011, -0.0001, -0.0030],\n",
       "         [-0.0046,  0.0023,  0.0022,  ...,  0.0004,  0.0017,  0.0020]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.31.mlp.up_proj.lora_A.weight': tensor([[-0.0078,  0.0118,  0.0015,  ..., -0.0063,  0.0005, -0.0120],\n",
       "         [ 0.0156,  0.0083, -0.0074,  ..., -0.0012, -0.0153, -0.0128],\n",
       "         [-0.0086,  0.0137, -0.0027,  ..., -0.0084,  0.0098,  0.0021],\n",
       "         ...,\n",
       "         [-0.0070,  0.0051,  0.0126,  ..., -0.0071,  0.0126,  0.0090],\n",
       "         [ 0.0063,  0.0041, -0.0144,  ...,  0.0064,  0.0013, -0.0087],\n",
       "         [ 0.0075,  0.0125,  0.0145,  ..., -0.0056, -0.0040,  0.0120]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.31.mlp.up_proj.lora_B.weight': tensor([[-1.0605e-03,  2.8076e-03, -1.7548e-03,  ...,  7.3624e-04,\n",
       "          -1.5640e-04, -1.1368e-03],\n",
       "         [-1.8001e-05,  2.4719e-03,  3.3875e-03,  ...,  1.2589e-03,\n",
       "           9.0408e-04, -2.5024e-03],\n",
       "         [ 1.5354e-04, -3.7003e-04,  2.8839e-03,  ..., -3.8385e-05,\n",
       "           1.6327e-03, -5.1117e-04],\n",
       "         ...,\n",
       "         [ 1.5030e-03, -1.2970e-03,  2.1362e-03,  ..., -1.0529e-03,\n",
       "          -1.3275e-03,  1.2817e-03],\n",
       "         [-7.1716e-04, -6.0272e-04,  1.4954e-03,  ..., -1.2970e-03,\n",
       "           8.0490e-04, -1.2741e-03],\n",
       "         [-4.2915e-04, -5.5313e-04,  9.0790e-04,  ...,  6.3324e-04,\n",
       "           4.4823e-04,  9.8419e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.31.self_attn.k_proj.lora_A.weight': tensor([[-1.1475e-02, -7.4768e-03, -9.0942e-03,  ..., -6.6833e-03,\n",
       "          -5.9814e-03, -5.0659e-03],\n",
       "         [ 1.0681e-04,  3.1128e-03,  6.3477e-03,  ..., -3.9978e-03,\n",
       "           3.5095e-03,  1.0010e-02],\n",
       "         [ 2.2583e-03, -1.3977e-02, -1.0925e-02,  ...,  5.3101e-03,\n",
       "          -8.4229e-03, -6.4392e-03],\n",
       "         ...,\n",
       "         [ 1.5991e-02, -1.5381e-02,  2.7776e-05,  ...,  4.9744e-03,\n",
       "          -6.6528e-03, -2.2736e-03],\n",
       "         [-1.5503e-02, -8.4839e-03,  9.6436e-03,  ..., -8.4839e-03,\n",
       "           1.0071e-02, -1.3306e-02],\n",
       "         [-1.5030e-03, -1.3000e-02,  3.5553e-03,  ..., -3.0365e-03,\n",
       "          -3.0518e-03,  3.7079e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.31.self_attn.k_proj.lora_B.weight': tensor([[ 3.2654e-03,  1.3504e-03,  1.2817e-03,  ...,  9.0027e-04,\n",
       "          -2.5940e-04, -5.9509e-04],\n",
       "         [ 1.5564e-03,  2.9907e-03, -3.2234e-04,  ..., -1.1292e-03,\n",
       "          -2.3499e-03,  6.4850e-04],\n",
       "         [-3.5095e-04, -2.8801e-04, -1.6327e-03,  ..., -4.2152e-04,\n",
       "           1.1902e-03, -1.7242e-03],\n",
       "         ...,\n",
       "         [ 1.8597e-04, -1.5869e-03, -9.3460e-05,  ...,  2.6550e-03,\n",
       "           1.9455e-04, -2.0599e-04],\n",
       "         [-1.8215e-04,  1.0681e-03, -9.9945e-04,  ..., -5.0306e-05,\n",
       "          -1.2741e-03, -1.9684e-03],\n",
       "         [-5.3883e-05, -2.8534e-03, -2.3270e-04,  ...,  3.3112e-03,\n",
       "          -9.1934e-04, -8.1253e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.31.self_attn.o_proj.lora_A.weight': tensor([[-0.0085, -0.0038,  0.0060,  ...,  0.0129,  0.0086, -0.0115],\n",
       "         [ 0.0027, -0.0051, -0.0090,  ...,  0.0077, -0.0044,  0.0125],\n",
       "         [-0.0091,  0.0044, -0.0040,  ..., -0.0030, -0.0115, -0.0084],\n",
       "         ...,\n",
       "         [ 0.0142, -0.0102, -0.0054,  ..., -0.0118,  0.0099,  0.0045],\n",
       "         [-0.0038,  0.0135, -0.0061,  ...,  0.0013,  0.0095, -0.0016],\n",
       "         [-0.0029, -0.0115,  0.0121,  ..., -0.0045, -0.0042,  0.0082]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.31.self_attn.o_proj.lora_B.weight': tensor([[-4.5967e-04,  8.7738e-04,  9.1934e-04,  ..., -1.3733e-03,\n",
       "           7.8583e-04,  9.9182e-04],\n",
       "         [ 1.0223e-03, -1.9684e-03,  9.7275e-04,  ...,  2.7466e-03,\n",
       "          -1.3885e-03,  5.1117e-04],\n",
       "         [ 6.8283e-04, -9.6893e-04,  1.4420e-03,  ...,  7.0190e-04,\n",
       "           2.2125e-03, -2.4567e-03],\n",
       "         ...,\n",
       "         [-1.3924e-04, -6.0272e-04,  1.9684e-03,  ...,  1.7700e-03,\n",
       "           2.4796e-04,  2.4109e-03],\n",
       "         [-1.6556e-03,  1.1292e-03, -1.0529e-03,  ..., -2.6703e-03,\n",
       "           2.9602e-03, -1.2970e-03],\n",
       "         [ 1.4954e-03, -3.6001e-05, -4.7874e-04,  ...,  1.8787e-04,\n",
       "          -2.1362e-03,  2.5482e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.31.self_attn.q_proj.lora_A.weight': tensor([[-0.0084,  0.0013,  0.0125,  ...,  0.0012, -0.0004, -0.0101],\n",
       "         [-0.0151,  0.0022,  0.0131,  ..., -0.0036, -0.0043,  0.0028],\n",
       "         [ 0.0124,  0.0109, -0.0072,  ..., -0.0014,  0.0096,  0.0025],\n",
       "         ...,\n",
       "         [ 0.0091, -0.0005,  0.0068,  ...,  0.0002,  0.0134, -0.0030],\n",
       "         [-0.0060, -0.0056, -0.0048,  ...,  0.0019,  0.0176,  0.0059],\n",
       "         [-0.0121, -0.0092,  0.0079,  ..., -0.0131, -0.0161, -0.0136]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.31.self_attn.q_proj.lora_B.weight': tensor([[ 1.1368e-03,  4.8523e-03,  1.2207e-03,  ..., -1.8616e-03,\n",
       "          -2.6245e-03,  5.9128e-04],\n",
       "         [ 3.4637e-03,  3.1433e-03,  2.1515e-03,  ..., -8.8501e-04,\n",
       "          -5.9509e-03,  4.6692e-03],\n",
       "         [-1.0071e-03, -1.2665e-03,  9.6512e-04,  ..., -8.2397e-04,\n",
       "          -2.8801e-04, -1.9302e-03],\n",
       "         ...,\n",
       "         [ 6.1035e-04, -3.3722e-03,  1.4801e-03,  ...,  1.9073e-03,\n",
       "           8.5068e-04, -7.6771e-05],\n",
       "         [ 1.8158e-03,  1.6403e-03,  1.7776e-03,  ..., -1.4973e-04,\n",
       "          -2.7313e-03,  2.6245e-03],\n",
       "         [ 1.8311e-03, -1.6098e-03,  2.3499e-03,  ...,  5.6076e-04,\n",
       "          -6.0272e-04, -1.2207e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.31.self_attn.v_proj.lora_A.weight': tensor([[ 0.0085,  0.0145, -0.0135,  ...,  0.0151,  0.0065, -0.0048],\n",
       "         [-0.0070, -0.0057, -0.0112,  ...,  0.0117, -0.0107,  0.0092],\n",
       "         [-0.0090,  0.0098,  0.0094,  ...,  0.0099,  0.0032, -0.0117],\n",
       "         ...,\n",
       "         [ 0.0115,  0.0029,  0.0039,  ...,  0.0069,  0.0080, -0.0050],\n",
       "         [-0.0173, -0.0028,  0.0005,  ...,  0.0092,  0.0061,  0.0110],\n",
       "         [ 0.0148,  0.0053,  0.0005,  ...,  0.0068, -0.0083, -0.0161]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.31.self_attn.v_proj.lora_B.weight': tensor([[ 1.5182e-03, -8.3160e-04,  3.2806e-04,  ..., -1.9073e-04,\n",
       "           1.0910e-03, -3.3951e-04],\n",
       "         [-3.3722e-03,  2.5630e-05, -7.7820e-04,  ..., -1.6708e-03,\n",
       "           2.1973e-03, -8.8882e-04],\n",
       "         [ 3.1433e-03,  3.6011e-03,  1.2207e-03,  ..., -4.9591e-04,\n",
       "          -2.8839e-03, -2.4109e-03],\n",
       "         ...,\n",
       "         [ 1.7242e-03,  1.1139e-03,  7.6294e-04,  ..., -1.1826e-03,\n",
       "          -1.6327e-03, -1.0147e-03],\n",
       "         [-8.4305e-04, -5.6076e-04, -5.6076e-04,  ...,  4.1008e-04,\n",
       "           4.0817e-04,  1.1826e-03],\n",
       "         [ 1.7452e-04, -8.4305e-04,  1.2207e-03,  ...,  5.8746e-04,\n",
       "          -1.2283e-03,  1.0529e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.4.mlp.down_proj.lora_A.weight': tensor([[ 9.2773e-03,  4.9133e-03, -2.0981e-05,  ..., -3.6621e-03,\n",
       "          -1.1978e-03,  6.2866e-03],\n",
       "         [ 5.1270e-03, -5.8899e-03, -6.3171e-03,  ...,  7.2937e-03,\n",
       "          -9.2163e-03, -5.1880e-03],\n",
       "         [-7.5073e-03,  7.5684e-03,  1.6785e-03,  ...,  7.4463e-03,\n",
       "           1.2360e-03, -4.1504e-03],\n",
       "         ...,\n",
       "         [-4.3678e-04,  2.1362e-03,  1.0452e-03,  ..., -3.3417e-03,\n",
       "           2.1820e-03, -5.4321e-03],\n",
       "         [ 6.4087e-03, -5.1880e-03, -3.4180e-03,  ...,  6.0425e-03,\n",
       "          -9.1553e-03, -4.8828e-03],\n",
       "         [-2.7924e-03,  1.3550e-02,  3.7956e-04,  ...,  5.4321e-03,\n",
       "          -3.9978e-03, -1.2024e-02]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.4.mlp.down_proj.lora_B.weight': tensor([[ 1.8158e-03, -1.2741e-03,  6.7520e-04,  ..., -8.7738e-04,\n",
       "          -5.2750e-06,  6.1417e-04],\n",
       "         [-2.4261e-03, -2.4109e-03, -4.8637e-04,  ..., -9.0027e-04,\n",
       "          -2.5368e-04,  5.5313e-04],\n",
       "         [-1.9169e-04,  5.7602e-04,  1.6022e-03,  ...,  8.3542e-04,\n",
       "          -1.9531e-03,  2.0447e-03],\n",
       "         ...,\n",
       "         [ 1.4267e-03,  1.0681e-03,  1.7319e-03,  ..., -2.4414e-03,\n",
       "           1.7624e-03,  2.3499e-03],\n",
       "         [ 1.0729e-04,  3.0136e-04,  2.1973e-03,  ...,  2.6093e-03,\n",
       "          -2.8687e-03,  8.0109e-04],\n",
       "         [ 8.8501e-04,  1.8158e-03,  7.9727e-04,  ..., -1.3733e-03,\n",
       "          -1.7624e-03, -1.9360e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.4.mlp.gate_proj.lora_A.weight': tensor([[-4.9744e-03,  1.0864e-02,  1.0559e-02,  ..., -1.0986e-02,\n",
       "          -1.3367e-02, -1.2634e-02],\n",
       "         [-1.4038e-02,  1.2146e-02, -8.2397e-03,  ...,  3.6011e-03,\n",
       "           9.5215e-03,  5.3711e-03],\n",
       "         [ 8.0490e-04, -7.2002e-05, -8.8501e-03,  ..., -1.3428e-02,\n",
       "          -1.4404e-02, -4.1504e-03],\n",
       "         ...,\n",
       "         [-2.0447e-03,  1.0681e-03, -2.0447e-03,  ...,  1.1169e-02,\n",
       "           1.0620e-02,  7.8125e-03],\n",
       "         [-5.0354e-03, -8.4839e-03,  1.0498e-02,  ...,  8.2397e-03,\n",
       "           5.9509e-03, -1.2512e-02],\n",
       "         [-1.5442e-02, -1.2390e-02, -9.8267e-03,  ...,  1.4099e-02,\n",
       "           5.1575e-03,  1.2085e-02]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.4.mlp.gate_proj.lora_B.weight': tensor([[ 0.0014,  0.0015, -0.0008,  ...,  0.0006,  0.0014,  0.0012],\n",
       "         [ 0.0008,  0.0017,  0.0028,  ...,  0.0012, -0.0016,  0.0007],\n",
       "         [-0.0007,  0.0005, -0.0014,  ...,  0.0010, -0.0021,  0.0010],\n",
       "         ...,\n",
       "         [-0.0015,  0.0009,  0.0004,  ...,  0.0006, -0.0013, -0.0012],\n",
       "         [-0.0023, -0.0018, -0.0005,  ...,  0.0044, -0.0010, -0.0018],\n",
       "         [-0.0020,  0.0006, -0.0010,  ...,  0.0008,  0.0015,  0.0017]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.4.mlp.up_proj.lora_A.weight': tensor([[ 0.0076,  0.0043, -0.0154,  ...,  0.0001, -0.0156, -0.0076],\n",
       "         [ 0.0033,  0.0081, -0.0078,  ...,  0.0045, -0.0042, -0.0089],\n",
       "         [-0.0018, -0.0157,  0.0166,  ...,  0.0108,  0.0037, -0.0047],\n",
       "         ...,\n",
       "         [ 0.0065, -0.0146,  0.0115,  ...,  0.0046,  0.0028,  0.0079],\n",
       "         [ 0.0059, -0.0104, -0.0037,  ...,  0.0002,  0.0150, -0.0099],\n",
       "         [ 0.0127, -0.0083, -0.0109,  ..., -0.0014,  0.0009,  0.0028]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.4.mlp.up_proj.lora_B.weight': tensor([[ 7.7057e-04, -7.0190e-04, -9.9182e-04,  ..., -1.1139e-03,\n",
       "          -1.0376e-03,  1.1673e-03],\n",
       "         [ 3.8147e-04,  2.4128e-04, -1.5163e-04,  ..., -6.0320e-05,\n",
       "           1.1292e-03, -1.3123e-03],\n",
       "         [ 5.3406e-04,  8.5068e-04, -4.0817e-04,  ..., -7.6294e-04,\n",
       "           2.2278e-03, -2.3346e-03],\n",
       "         ...,\n",
       "         [-1.3292e-05, -8.6212e-04, -7.1716e-04,  ...,  6.9427e-04,\n",
       "           1.8005e-03, -9.0408e-04],\n",
       "         [-1.4343e-03, -3.1433e-03,  1.2970e-04,  ...,  6.4850e-05,\n",
       "           2.1362e-03, -2.6226e-05],\n",
       "         [ 3.8147e-04,  1.0757e-03, -1.8978e-04,  ..., -2.7084e-04,\n",
       "           2.1210e-03,  1.6937e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.4.self_attn.k_proj.lora_A.weight': tensor([[ 0.0069, -0.0107,  0.0060,  ..., -0.0135, -0.0067,  0.0094],\n",
       "         [ 0.0035, -0.0146, -0.0014,  ..., -0.0017,  0.0058,  0.0029],\n",
       "         [ 0.0125, -0.0009, -0.0102,  ..., -0.0152, -0.0054,  0.0136],\n",
       "         ...,\n",
       "         [-0.0060, -0.0027, -0.0131,  ...,  0.0131, -0.0058, -0.0136],\n",
       "         [ 0.0151, -0.0014,  0.0031,  ..., -0.0090,  0.0027, -0.0084],\n",
       "         [-0.0154,  0.0162, -0.0112,  ..., -0.0127,  0.0020,  0.0103]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.4.self_attn.k_proj.lora_B.weight': tensor([[ 1.1063e-03, -1.8539e-03, -9.5844e-05,  ..., -1.7929e-03,\n",
       "          -3.3569e-04, -7.0095e-05],\n",
       "         [ 2.3956e-03,  5.0735e-04, -1.2817e-03,  ..., -1.5259e-03,\n",
       "          -4.2343e-04, -7.3433e-05],\n",
       "         [-7.8201e-04,  1.1368e-03,  1.6880e-04,  ...,  1.0529e-03,\n",
       "          -4.9591e-04,  7.6294e-04],\n",
       "         ...,\n",
       "         [ 1.4687e-04,  1.9989e-03, -1.6327e-03,  ..., -3.1128e-03,\n",
       "          -2.2173e-05, -7.5531e-04],\n",
       "         [ 3.2043e-03,  2.2430e-03, -1.1597e-03,  ..., -1.8234e-03,\n",
       "          -8.4305e-04, -4.6349e-04],\n",
       "         [ 2.5177e-03, -6.7902e-04,  1.8692e-03,  ...,  7.6675e-04,\n",
       "          -1.2817e-03,  1.2894e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.4.self_attn.o_proj.lora_A.weight': tensor([[ 0.0098, -0.0070,  0.0151,  ..., -0.0023,  0.0048, -0.0011],\n",
       "         [-0.0140, -0.0060, -0.0125,  ...,  0.0092,  0.0034,  0.0008],\n",
       "         [ 0.0077,  0.0047,  0.0105,  ...,  0.0136, -0.0074,  0.0001],\n",
       "         ...,\n",
       "         [-0.0045, -0.0093,  0.0061,  ..., -0.0025,  0.0095,  0.0112],\n",
       "         [-0.0049,  0.0077,  0.0151,  ...,  0.0082, -0.0079, -0.0060],\n",
       "         [-0.0017,  0.0071, -0.0076,  ..., -0.0076,  0.0051,  0.0115]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.4.self_attn.o_proj.lora_B.weight': tensor([[ 1.7548e-03,  2.5392e-05, -2.1362e-03,  ...,  1.2283e-03,\n",
       "          -1.0376e-03, -9.6893e-04],\n",
       "         [ 2.2736e-03,  6.7902e-04, -5.6458e-04,  ...,  3.7575e-04,\n",
       "           8.3923e-04, -6.9141e-05],\n",
       "         [-2.0752e-03,  3.7994e-03,  2.2278e-03,  ..., -7.8583e-04,\n",
       "           1.6861e-03,  1.6308e-04],\n",
       "         ...,\n",
       "         [ 3.4637e-03, -2.6822e-05, -5.3406e-04,  ...,  8.8501e-04,\n",
       "          -8.4305e-04, -1.6556e-03],\n",
       "         [ 7.8201e-04,  3.9339e-05,  2.7084e-04,  ...,  1.2665e-03,\n",
       "          -2.7537e-05, -2.3723e-05],\n",
       "         [-4.2915e-04, -1.4801e-03,  1.6403e-03,  ..., -9.8419e-04,\n",
       "           1.3885e-03, -6.1417e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.4.self_attn.q_proj.lora_A.weight': tensor([[-0.0048, -0.0078, -0.0022,  ...,  0.0054, -0.0159, -0.0132],\n",
       "         [-0.0077, -0.0085,  0.0129,  ..., -0.0112, -0.0135, -0.0069],\n",
       "         [ 0.0132,  0.0130,  0.0170,  ..., -0.0145,  0.0138, -0.0058],\n",
       "         ...,\n",
       "         [ 0.0041, -0.0025,  0.0056,  ...,  0.0031, -0.0112,  0.0078],\n",
       "         [-0.0096, -0.0129,  0.0081,  ..., -0.0076,  0.0098, -0.0107],\n",
       "         [ 0.0004, -0.0115, -0.0121,  ..., -0.0039, -0.0059, -0.0011]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.4.self_attn.q_proj.lora_B.weight': tensor([[-6.2561e-04,  4.2534e-04,  4.0817e-04,  ...,  1.0147e-03,\n",
       "          -1.0529e-03,  1.0300e-03],\n",
       "         [-2.3346e-03,  4.2725e-04,  2.8229e-03,  ...,  1.0757e-03,\n",
       "           9.4223e-04, -8.5831e-04],\n",
       "         [-6.4373e-05,  7.7438e-04, -1.6861e-03,  ..., -3.2234e-04,\n",
       "          -7.7057e-04, -1.3733e-03],\n",
       "         ...,\n",
       "         [ 8.6212e-04,  1.1826e-03, -1.0452e-03,  ...,  1.0376e-03,\n",
       "           3.0994e-05,  6.9427e-04],\n",
       "         [-2.5330e-03, -7.4387e-04,  3.7994e-03,  ..., -1.5182e-03,\n",
       "          -2.2888e-03, -9.7275e-04],\n",
       "         [ 1.0681e-03, -1.6098e-03,  2.8229e-03,  ..., -1.6479e-03,\n",
       "          -3.8605e-03, -9.0790e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.4.self_attn.v_proj.lora_A.weight': tensor([[ 0.0121,  0.0128, -0.0110,  ..., -0.0111,  0.0181,  0.0055],\n",
       "         [ 0.0066, -0.0148, -0.0071,  ..., -0.0089,  0.0045,  0.0002],\n",
       "         [ 0.0027, -0.0036, -0.0071,  ...,  0.0045, -0.0098, -0.0051],\n",
       "         ...,\n",
       "         [-0.0019, -0.0019, -0.0147,  ..., -0.0148, -0.0189, -0.0141],\n",
       "         [ 0.0053,  0.0132, -0.0115,  ...,  0.0032, -0.0195, -0.0134],\n",
       "         [-0.0043, -0.0127,  0.0066,  ..., -0.0116,  0.0193, -0.0022]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.4.self_attn.v_proj.lora_B.weight': tensor([[-1.9455e-03,  7.4387e-04,  4.2725e-04,  ...,  2.1553e-04,\n",
       "          -6.1417e-04, -5.9128e-04],\n",
       "         [ 1.1396e-04,  6.0272e-04,  1.3962e-03,  ..., -1.1215e-03,\n",
       "          -9.1171e-04,  1.6708e-03],\n",
       "         [ 1.2894e-03,  1.5335e-03, -9.3460e-05,  ..., -1.7853e-03,\n",
       "          -5.4550e-04,  7.5150e-04],\n",
       "         ...,\n",
       "         [-7.7820e-04, -7.6771e-05, -6.0654e-04,  ...,  1.0605e-03,\n",
       "           6.3324e-04,  2.9802e-07],\n",
       "         [ 8.8120e-04,  6.9618e-05,  8.2397e-04,  ..., -1.2512e-03,\n",
       "          -8.6594e-04,  2.1172e-04],\n",
       "         [-8.3160e-04, -5.6839e-04, -8.3542e-04,  ...,  3.9673e-04,\n",
       "           4.1962e-04, -7.4387e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.5.mlp.down_proj.lora_A.weight': tensor([[-2.6524e-06, -7.0190e-03, -2.5787e-03,  ...,  1.1841e-02,\n",
       "          -2.3041e-03, -1.2512e-03],\n",
       "         [ 7.5989e-03, -1.1368e-03,  7.8125e-03,  ..., -4.1199e-04,\n",
       "           4.6692e-03, -1.4877e-04],\n",
       "         [-5.0659e-03, -3.4027e-03, -4.2152e-04,  ...,  1.5869e-03,\n",
       "           6.9580e-03, -6.2866e-03],\n",
       "         ...,\n",
       "         [-1.9455e-03, -4.0894e-03,  8.6060e-03,  ..., -1.0223e-03,\n",
       "          -2.5330e-03,  8.1177e-03],\n",
       "         [-3.4790e-03, -5.6076e-04,  4.2114e-03,  ...,  2.3041e-03,\n",
       "          -6.1340e-03,  5.8289e-03],\n",
       "         [-9.8419e-04,  1.2207e-03, -9.2773e-03,  ..., -2.9755e-03,\n",
       "           2.5482e-03, -3.4180e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.5.mlp.down_proj.lora_B.weight': tensor([[-6.1035e-05,  2.3193e-03, -1.4114e-03,  ...,  7.4768e-04,\n",
       "          -1.6403e-03, -7.8964e-04],\n",
       "         [ 5.3024e-04, -2.5940e-04,  2.2278e-03,  ..., -1.7262e-04,\n",
       "          -1.3351e-03,  2.9564e-04],\n",
       "         [-1.8616e-03, -2.8381e-03,  9.6512e-04,  ...,  5.3406e-05,\n",
       "           7.2861e-04, -2.4719e-03],\n",
       "         ...,\n",
       "         [-1.7700e-03,  6.6757e-04,  5.8365e-04,  ...,  6.3705e-04,\n",
       "          -7.0953e-04, -5.6076e-04],\n",
       "         [ 2.7847e-04,  2.6375e-06, -2.0752e-03,  ...,  3.3417e-03,\n",
       "           9.4891e-05,  2.3499e-03],\n",
       "         [-2.4872e-03, -2.7466e-03,  4.7913e-03,  ...,  8.6212e-04,\n",
       "           2.0752e-03,  1.0395e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.5.mlp.gate_proj.lora_A.weight': tensor([[ 0.0101,  0.0084, -0.0192,  ..., -0.0050, -0.0088, -0.0044],\n",
       "         [-0.0043,  0.0143,  0.0033,  ...,  0.0044,  0.0087, -0.0124],\n",
       "         [ 0.0028, -0.0067,  0.0084,  ...,  0.0029,  0.0140,  0.0092],\n",
       "         ...,\n",
       "         [ 0.0033,  0.0175,  0.0082,  ..., -0.0022, -0.0077, -0.0139],\n",
       "         [-0.0179,  0.0032, -0.0146,  ..., -0.0032, -0.0159, -0.0116],\n",
       "         [ 0.0029,  0.0164, -0.0132,  ...,  0.0049,  0.0039, -0.0181]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.5.mlp.gate_proj.lora_B.weight': tensor([[-0.0010, -0.0015, -0.0004,  ...,  0.0020, -0.0028,  0.0025],\n",
       "         [-0.0016,  0.0002,  0.0002,  ...,  0.0016, -0.0012, -0.0016],\n",
       "         [-0.0016,  0.0016,  0.0019,  ..., -0.0026, -0.0006, -0.0018],\n",
       "         ...,\n",
       "         [-0.0004,  0.0008,  0.0004,  ...,  0.0002,  0.0016,  0.0015],\n",
       "         [ 0.0009, -0.0024,  0.0007,  ...,  0.0012,  0.0006, -0.0009],\n",
       "         [-0.0017, -0.0014,  0.0001,  ..., -0.0031,  0.0004, -0.0014]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.5.mlp.up_proj.lora_A.weight': tensor([[ 0.0123,  0.0070, -0.0037,  ...,  0.0095, -0.0003, -0.0107],\n",
       "         [-0.0023,  0.0116,  0.0066,  ..., -0.0008, -0.0127, -0.0151],\n",
       "         [ 0.0077,  0.0038, -0.0134,  ...,  0.0144,  0.0036,  0.0138],\n",
       "         ...,\n",
       "         [-0.0011, -0.0106, -0.0110,  ..., -0.0029,  0.0079, -0.0067],\n",
       "         [ 0.0104, -0.0096, -0.0157,  ...,  0.0078,  0.0054, -0.0004],\n",
       "         [-0.0077,  0.0041,  0.0047,  ..., -0.0057,  0.0126, -0.0127]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.5.mlp.up_proj.lora_B.weight': tensor([[-1.5926e-04,  1.5450e-04, -9.1171e-04,  ...,  1.0529e-03,\n",
       "           9.9945e-04,  6.9809e-04],\n",
       "         [ 5.7220e-04, -4.7874e-04,  1.5411e-03,  ...,  1.1520e-03,\n",
       "           6.8283e-04, -4.2534e-04],\n",
       "         [-1.0986e-03, -1.4877e-04, -4.2419e-03,  ..., -3.4523e-04,\n",
       "          -1.3657e-03, -2.5940e-03],\n",
       "         ...,\n",
       "         [ 3.5048e-05,  7.4005e-04,  6.0654e-04,  ...,  1.3256e-04,\n",
       "          -2.6321e-04,  8.5449e-04],\n",
       "         [ 6.1417e-04,  1.0376e-03, -1.0757e-03,  ...,  9.9945e-04,\n",
       "           1.2741e-03, -8.4686e-04],\n",
       "         [ 2.0752e-03,  2.7084e-04, -2.3956e-03,  ...,  2.8992e-04,\n",
       "          -1.0071e-03, -1.5869e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.5.self_attn.k_proj.lora_A.weight': tensor([[-0.0014,  0.0149, -0.0161,  ...,  0.0026,  0.0110, -0.0139],\n",
       "         [ 0.0021,  0.0145, -0.0075,  ...,  0.0151,  0.0002,  0.0078],\n",
       "         [-0.0023,  0.0065, -0.0153,  ..., -0.0072,  0.0103,  0.0080],\n",
       "         ...,\n",
       "         [-0.0100, -0.0166,  0.0027,  ..., -0.0069,  0.0120, -0.0121],\n",
       "         [ 0.0090,  0.0148,  0.0160,  ..., -0.0034, -0.0045,  0.0145],\n",
       "         [-0.0075,  0.0090, -0.0150,  ...,  0.0077,  0.0040,  0.0011]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.5.self_attn.k_proj.lora_B.weight': tensor([[-3.2616e-04, -1.7405e-05, -1.8234e-03,  ...,  9.7656e-04,\n",
       "           1.1520e-03, -5.2214e-05],\n",
       "         [ 2.7008e-03,  2.9945e-04,  2.7466e-03,  ..., -1.5182e-03,\n",
       "          -3.2043e-03,  5.7602e-04],\n",
       "         [-5.3787e-04,  4.2114e-03,  4.9210e-04,  ...,  2.6245e-03,\n",
       "           1.8616e-03, -2.6093e-03],\n",
       "         ...,\n",
       "         [-5.7220e-04,  1.0986e-03,  6.1798e-04,  ...,  1.5793e-03,\n",
       "          -1.8158e-03,  8.1635e-04],\n",
       "         [-5.1880e-04, -1.8311e-03, -1.0681e-03,  ..., -3.1471e-05,\n",
       "           2.1820e-03,  1.7929e-03],\n",
       "         [-6.2943e-04,  1.1063e-03,  3.4332e-04,  ...,  1.4572e-03,\n",
       "          -1.6251e-03,  1.3428e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.5.self_attn.o_proj.lora_A.weight': tensor([[ 0.0088,  0.0044,  0.0148,  ..., -0.0122,  0.0123, -0.0070],\n",
       "         [-0.0016,  0.0080,  0.0074,  ..., -0.0143, -0.0087,  0.0101],\n",
       "         [ 0.0048, -0.0004, -0.0051,  ..., -0.0156,  0.0090, -0.0132],\n",
       "         ...,\n",
       "         [-0.0018, -0.0162, -0.0101,  ...,  0.0045,  0.0055, -0.0080],\n",
       "         [-0.0042, -0.0067, -0.0109,  ..., -0.0096, -0.0009, -0.0087],\n",
       "         [ 0.0001, -0.0115, -0.0134,  ...,  0.0069,  0.0193, -0.0122]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.5.self_attn.o_proj.lora_B.weight': tensor([[ 5.9128e-04, -1.8616e-03,  3.4943e-03,  ...,  1.6785e-03,\n",
       "           2.3041e-03,  9.4223e-04],\n",
       "         [-1.2589e-03,  7.8583e-04, -3.0899e-04,  ...,  3.3951e-04,\n",
       "          -1.0834e-03, -3.9482e-04],\n",
       "         [-2.2430e-03, -5.4550e-04, -1.7014e-03,  ..., -1.8463e-03,\n",
       "          -2.0447e-03, -1.4343e-03],\n",
       "         ...,\n",
       "         [ 1.1902e-03,  1.5335e-03,  1.8239e-05,  ..., -7.7057e-04,\n",
       "           6.8665e-04, -6.1035e-04],\n",
       "         [-1.2207e-03,  8.5068e-04, -4.8637e-04,  ..., -1.6556e-03,\n",
       "          -3.2043e-03,  7.1716e-04],\n",
       "         [-1.2054e-03, -2.5482e-03, -1.5411e-03,  ...,  6.2943e-04,\n",
       "          -1.6022e-03, -2.4719e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.5.self_attn.q_proj.lora_A.weight': tensor([[ 0.0047,  0.0129,  0.0047,  ..., -0.0033, -0.0032,  0.0165],\n",
       "         [ 0.0050,  0.0161,  0.0019,  ..., -0.0061, -0.0048, -0.0133],\n",
       "         [ 0.0098,  0.0095, -0.0184,  ..., -0.0043, -0.0036,  0.0070],\n",
       "         ...,\n",
       "         [-0.0049, -0.0038, -0.0048,  ..., -0.0092,  0.0061, -0.0162],\n",
       "         [ 0.0181,  0.0059, -0.0076,  ..., -0.0005,  0.0100, -0.0062],\n",
       "         [ 0.0035, -0.0033,  0.0085,  ...,  0.0117, -0.0123,  0.0053]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.5.self_attn.q_proj.lora_B.weight': tensor([[-2.7618e-03,  1.1215e-03, -4.6730e-05,  ...,  1.6174e-03,\n",
       "          -1.3580e-03, -1.9169e-04],\n",
       "         [ 4.6539e-04,  4.6158e-04, -8.4686e-04,  ...,  7.6294e-04,\n",
       "           1.9531e-03,  4.6921e-04],\n",
       "         [ 3.9062e-03,  1.9646e-04,  1.5793e-03,  ..., -1.3924e-04,\n",
       "           6.1035e-04,  1.6861e-03],\n",
       "         ...,\n",
       "         [ 1.3885e-03, -1.3046e-03, -7.8678e-05,  ..., -3.7079e-03,\n",
       "          -1.8158e-03, -3.0212e-03],\n",
       "         [-2.0294e-03,  1.2894e-03,  9.4986e-04,  ...,  2.8534e-03,\n",
       "          -2.1973e-03, -2.0294e-03],\n",
       "         [ 1.2512e-03, -1.8787e-04, -1.9684e-03,  ..., -3.9368e-03,\n",
       "           8.2016e-04,  4.0436e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.5.self_attn.v_proj.lora_A.weight': tensor([[ 0.0120, -0.0128, -0.0092,  ..., -0.0032,  0.0074, -0.0143],\n",
       "         [-0.0061,  0.0107,  0.0131,  ..., -0.0064,  0.0145, -0.0057],\n",
       "         [ 0.0133, -0.0029, -0.0070,  ..., -0.0153, -0.0143,  0.0032],\n",
       "         ...,\n",
       "         [-0.0103, -0.0114, -0.0122,  ...,  0.0042, -0.0094,  0.0081],\n",
       "         [-0.0077,  0.0056, -0.0151,  ...,  0.0009, -0.0129, -0.0088],\n",
       "         [-0.0008, -0.0063,  0.0151,  ..., -0.0103, -0.0060,  0.0087]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.5.self_attn.v_proj.lora_B.weight': tensor([[ 1.5182e-03,  3.2043e-03,  2.0027e-04,  ...,  1.8997e-03,\n",
       "           1.2512e-03, -1.1673e-03],\n",
       "         [-5.0354e-04, -1.2054e-03,  5.3167e-05,  ..., -1.4191e-03,\n",
       "          -9.1553e-04,  9.0790e-04],\n",
       "         [-4.8637e-04,  1.1749e-03, -1.1969e-04,  ..., -1.5640e-03,\n",
       "           8.5831e-04, -3.2425e-04],\n",
       "         ...,\n",
       "         [-5.9128e-04, -2.0905e-03,  2.2888e-03,  ..., -3.6163e-03,\n",
       "          -1.8158e-03,  3.9062e-03],\n",
       "         [ 5.6028e-05, -6.2943e-04, -1.4114e-03,  ..., -1.7700e-03,\n",
       "          -1.3046e-03,  2.0981e-04],\n",
       "         [-1.1444e-03, -1.2436e-03, -7.8583e-04,  ..., -2.0695e-04,\n",
       "           1.4591e-04, -4.2915e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.6.mlp.down_proj.lora_A.weight': tensor([[ 3.0670e-03, -3.3569e-03, -8.5449e-03,  ...,  3.1433e-03,\n",
       "          -1.9989e-03,  1.9150e-03],\n",
       "         [-4.5166e-03, -1.7471e-03,  1.0132e-02,  ...,  9.6436e-03,\n",
       "          -2.4109e-03,  8.4229e-03],\n",
       "         [-9.4986e-04,  1.4725e-03,  8.9722e-03,  ...,  1.1902e-02,\n",
       "           2.8381e-03,  6.7139e-03],\n",
       "         ...,\n",
       "         [ 1.6251e-03,  4.4556e-03, -3.7994e-03,  ...,  8.7261e-05,\n",
       "           3.2501e-03,  6.4087e-03],\n",
       "         [ 1.7242e-03,  7.2021e-03,  5.8289e-03,  ...,  8.8501e-03,\n",
       "          -3.4523e-04,  4.2114e-03],\n",
       "         [-8.2779e-04, -3.9062e-03,  5.5542e-03,  ..., -1.2268e-02,\n",
       "           6.7902e-04, -4.7874e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.6.mlp.down_proj.lora_B.weight': tensor([[-1.8921e-03, -2.8839e-03, -2.7618e-03,  ..., -4.6997e-03,\n",
       "           2.7657e-04, -1.2493e-04],\n",
       "         [ 1.9455e-04,  1.3580e-03, -1.0681e-03,  ..., -4.6387e-03,\n",
       "           2.0752e-03, -2.0504e-04],\n",
       "         [ 1.8692e-03,  2.4719e-03,  1.1368e-03,  ...,  5.5134e-07,\n",
       "          -1.9073e-04,  7.2479e-04],\n",
       "         ...,\n",
       "         [-1.6785e-03,  7.8201e-04, -1.6689e-04,  ..., -4.8447e-04,\n",
       "          -5.5695e-04, -1.4420e-03],\n",
       "         [-7.2479e-04,  1.0605e-03,  3.7384e-04,  ...,  1.6403e-03,\n",
       "          -1.6479e-03,  1.0452e-03],\n",
       "         [ 2.2221e-04,  5.0049e-03,  3.3875e-03,  ...,  9.4604e-04,\n",
       "           5.0354e-04, -9.9182e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.6.mlp.gate_proj.lora_A.weight': tensor([[ 1.1841e-02, -8.6060e-03, -5.9605e-06,  ...,  5.1270e-03,\n",
       "          -9.7275e-04,  1.0498e-02],\n",
       "         [ 1.3672e-02, -2.0905e-03,  9.4604e-03,  ...,  1.4465e-02,\n",
       "           5.4321e-03, -1.5564e-03],\n",
       "         [-6.3171e-03, -3.2043e-03, -2.9449e-03,  ..., -7.7057e-04,\n",
       "          -1.9073e-03,  1.1353e-02],\n",
       "         ...,\n",
       "         [-4.3945e-03, -2.4719e-03,  1.3046e-03,  ..., -1.2634e-02,\n",
       "          -1.3733e-02,  7.6294e-03],\n",
       "         [ 1.8692e-03,  1.7334e-02, -5.4932e-03,  ...,  1.2390e-02,\n",
       "          -1.3000e-02, -1.0071e-02],\n",
       "         [-4.9133e-03, -9.1553e-03,  6.4697e-03,  ...,  1.3794e-02,\n",
       "          -1.1063e-03,  1.2024e-02]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.6.mlp.gate_proj.lora_B.weight': tensor([[-1.3828e-04, -9.4604e-04, -1.1597e-03,  ..., -3.0823e-03,\n",
       "          -8.6594e-04,  6.9427e-04],\n",
       "         [-1.2755e-05, -1.0529e-03,  1.0986e-03,  ...,  2.3270e-04,\n",
       "           1.3657e-03, -7.6294e-04],\n",
       "         [ 6.7902e-04,  7.0333e-06,  5.6458e-04,  ..., -8.9264e-04,\n",
       "          -1.1063e-03, -2.9755e-04],\n",
       "         ...,\n",
       "         [-6.1512e-05,  2.2507e-04,  3.7766e-04,  ...,  2.1973e-03,\n",
       "           7.3624e-04, -1.9073e-03],\n",
       "         [-1.8234e-03, -6.5231e-04,  1.7395e-03,  ...,  1.3580e-03,\n",
       "           1.2589e-03, -1.5030e-03],\n",
       "         [ 3.6163e-03,  7.5912e-04, -1.5945e-03,  ...,  1.3885e-03,\n",
       "          -1.4267e-03,  2.2736e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.6.mlp.up_proj.lora_A.weight': tensor([[-1.0986e-02,  1.7090e-02, -6.1417e-04,  ..., -9.9487e-03,\n",
       "           3.2654e-03,  8.8501e-03],\n",
       "         [ 1.4099e-02, -2.9144e-03, -1.2878e-02,  ...,  5.7373e-03,\n",
       "          -7.1411e-03, -3.0975e-03],\n",
       "         [-1.3611e-02, -1.5869e-03, -4.7445e-05,  ...,  9.5215e-03,\n",
       "           9.7656e-03, -1.3428e-02],\n",
       "         ...,\n",
       "         [-4.7913e-03, -8.0566e-03, -5.5237e-03,  ..., -3.7079e-03,\n",
       "          -1.4893e-02, -5.4932e-03],\n",
       "         [ 1.3885e-03,  7.7820e-03, -6.7749e-03,  ...,  4.9133e-03,\n",
       "           1.2741e-03,  1.5137e-02],\n",
       "         [ 4.1504e-03,  1.0437e-02,  8.0566e-03,  ..., -1.8539e-03,\n",
       "           1.1230e-02, -9.2163e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.6.mlp.up_proj.lora_B.weight': tensor([[-1.4191e-03, -4.9973e-04,  1.0681e-03,  ..., -2.2888e-03,\n",
       "          -1.2360e-03, -2.2888e-03],\n",
       "         [-2.3956e-03,  5.3346e-06, -3.6469e-03,  ..., -3.7537e-03,\n",
       "           9.7752e-05,  1.0605e-03],\n",
       "         [-4.5013e-04,  1.0605e-03,  2.5940e-04,  ...,  8.5831e-04,\n",
       "           1.8997e-03,  9.4223e-04],\n",
       "         ...,\n",
       "         [ 6.5994e-04, -3.6316e-03,  1.1826e-03,  ..., -9.7275e-04,\n",
       "          -2.4080e-05,  4.1771e-04],\n",
       "         [-1.5411e-03, -1.2817e-03, -1.7395e-03,  ..., -1.6022e-03,\n",
       "          -4.4703e-07, -1.3809e-03],\n",
       "         [-2.8076e-03,  2.4567e-03, -1.0376e-03,  ..., -1.0376e-03,\n",
       "          -3.3264e-03,  1.4591e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.6.self_attn.k_proj.lora_A.weight': tensor([[-0.0109, -0.0020, -0.0126,  ...,  0.0024,  0.0074,  0.0143],\n",
       "         [ 0.0052, -0.0005,  0.0141,  ..., -0.0119,  0.0071,  0.0003],\n",
       "         [ 0.0095,  0.0121, -0.0043,  ..., -0.0003, -0.0050,  0.0194],\n",
       "         ...,\n",
       "         [-0.0081, -0.0080,  0.0004,  ..., -0.0140,  0.0033,  0.0076],\n",
       "         [ 0.0022, -0.0087, -0.0015,  ...,  0.0071, -0.0162,  0.0051],\n",
       "         [-0.0181, -0.0016, -0.0176,  ..., -0.0063,  0.0008, -0.0032]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.6.self_attn.k_proj.lora_B.weight': tensor([[-7.3910e-05,  2.2888e-05,  1.2741e-03,  ...,  8.3923e-04,\n",
       "          -2.1362e-03, -2.8534e-03],\n",
       "         [-9.3079e-04,  3.0975e-03, -2.2125e-03,  ..., -1.0147e-03,\n",
       "          -2.7275e-04,  1.4343e-03],\n",
       "         [-2.2736e-03,  1.9379e-03, -3.4180e-03,  ..., -1.4725e-03,\n",
       "           3.2501e-03,  4.0894e-03],\n",
       "         ...,\n",
       "         [ 1.0910e-03, -1.2207e-03,  2.4414e-03,  ...,  1.5945e-03,\n",
       "           1.1139e-03, -9.4223e-04],\n",
       "         [ 1.8082e-03, -1.4572e-03, -1.0605e-03,  ..., -1.6861e-03,\n",
       "          -2.6131e-04, -1.1215e-03],\n",
       "         [-3.4904e-04,  8.4305e-04, -9.3079e-04,  ..., -1.0910e-03,\n",
       "          -1.3962e-03, -1.3962e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.6.self_attn.o_proj.lora_A.weight': tensor([[-0.0055,  0.0082,  0.0060,  ...,  0.0067,  0.0006,  0.0125],\n",
       "         [-0.0030, -0.0066,  0.0036,  ..., -0.0003, -0.0059,  0.0037],\n",
       "         [-0.0107, -0.0050, -0.0033,  ..., -0.0079, -0.0114, -0.0121],\n",
       "         ...,\n",
       "         [ 0.0127,  0.0036,  0.0023,  ...,  0.0076, -0.0101,  0.0148],\n",
       "         [-0.0103, -0.0135,  0.0099,  ...,  0.0087, -0.0076,  0.0120],\n",
       "         [ 0.0069, -0.0143,  0.0122,  ..., -0.0076,  0.0108, -0.0062]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.6.self_attn.o_proj.lora_B.weight': tensor([[ 3.2654e-03, -2.6703e-03,  2.7008e-03,  ...,  1.4114e-03,\n",
       "          -1.9836e-03, -1.9684e-03],\n",
       "         [-4.4632e-04,  5.6076e-04, -1.5869e-03,  ..., -1.1826e-03,\n",
       "           8.3923e-05, -9.5367e-04],\n",
       "         [-1.0605e-03,  2.9907e-03,  5.5313e-04,  ...,  2.4567e-03,\n",
       "           1.8768e-03,  2.7924e-03],\n",
       "         ...,\n",
       "         [ 1.3962e-03,  2.6703e-03,  1.9684e-03,  ...,  2.3193e-03,\n",
       "           2.3193e-03,  1.3657e-03],\n",
       "         [ 1.2207e-03, -1.6838e-06,  7.1716e-04,  ...,  1.3504e-03,\n",
       "           1.0986e-03, -5.4550e-04],\n",
       "         [-3.3760e-04, -1.2970e-04,  1.1368e-03,  ...,  1.4954e-03,\n",
       "           1.8082e-03,  4.9210e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.6.self_attn.q_proj.lora_A.weight': tensor([[ 0.0078, -0.0121,  0.0121,  ...,  0.0069,  0.0049,  0.0074],\n",
       "         [ 0.0005, -0.0143,  0.0060,  ..., -0.0079, -0.0029, -0.0033],\n",
       "         [-0.0129,  0.0004,  0.0092,  ...,  0.0110,  0.0134,  0.0010],\n",
       "         ...,\n",
       "         [-0.0093, -0.0131, -0.0123,  ..., -0.0013,  0.0095, -0.0002],\n",
       "         [-0.0021,  0.0177, -0.0063,  ...,  0.0068, -0.0006,  0.0012],\n",
       "         [ 0.0010,  0.0057,  0.0011,  ..., -0.0121, -0.0110,  0.0151]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.6.self_attn.q_proj.lora_B.weight': tensor([[ 1.4648e-03,  7.1716e-04, -1.2894e-03,  ...,  3.7689e-03,\n",
       "          -1.2338e-05,  3.7003e-04],\n",
       "         [-2.1667e-03, -2.8839e-03, -3.8300e-03,  ..., -2.5330e-03,\n",
       "           1.0986e-03, -4.9973e-04],\n",
       "         [ 2.9564e-04, -2.4719e-03,  6.8283e-04,  ..., -3.4027e-03,\n",
       "           1.1110e-04,  2.2888e-03],\n",
       "         ...,\n",
       "         [-2.8229e-03, -9.0408e-04,  1.0300e-03,  ..., -2.4567e-03,\n",
       "           1.1444e-03,  1.8539e-03],\n",
       "         [-4.7112e-04, -1.7166e-03,  1.8997e-03,  ..., -1.2589e-03,\n",
       "           1.4496e-03,  8.0109e-04],\n",
       "         [ 1.3809e-03,  2.1057e-03, -1.6174e-03,  ...,  2.3346e-03,\n",
       "          -1.8311e-03, -2.3193e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.6.self_attn.v_proj.lora_A.weight': tensor([[ 0.0047,  0.0043,  0.0148,  ...,  0.0002, -0.0076, -0.0106],\n",
       "         [-0.0025, -0.0067, -0.0037,  ..., -0.0013, -0.0107, -0.0007],\n",
       "         [-0.0037,  0.0170, -0.0176,  ..., -0.0043,  0.0084, -0.0028],\n",
       "         ...,\n",
       "         [ 0.0120, -0.0093,  0.0123,  ...,  0.0027,  0.0044, -0.0145],\n",
       "         [-0.0036,  0.0153, -0.0104,  ..., -0.0130, -0.0063,  0.0074],\n",
       "         [ 0.0133, -0.0074,  0.0072,  ..., -0.0063, -0.0101,  0.0004]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.6.self_attn.v_proj.lora_B.weight': tensor([[-3.9062e-03,  4.0894e-03,  1.6327e-03,  ..., -2.2430e-03,\n",
       "           3.4790e-03, -1.2283e-03],\n",
       "         [-1.5945e-03, -1.0605e-03, -1.5259e-03,  ...,  1.1139e-03,\n",
       "          -1.9226e-03, -1.0824e-04],\n",
       "         [-6.1417e-04, -5.2643e-04, -9.2316e-04,  ...,  2.1057e-03,\n",
       "          -1.2207e-03, -2.8076e-03],\n",
       "         ...,\n",
       "         [ 1.0986e-03,  2.8229e-04, -9.0027e-04,  ...,  3.6049e-04,\n",
       "          -6.9141e-05, -1.6098e-03],\n",
       "         [-1.5640e-03,  1.1368e-03,  2.2888e-03,  ..., -2.6093e-03,\n",
       "           1.6785e-03, -1.6937e-03],\n",
       "         [-1.2512e-03, -1.8406e-04, -9.3460e-04,  ...,  1.7395e-03,\n",
       "          -1.5793e-03,  5.6458e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.7.mlp.down_proj.lora_A.weight': tensor([[-0.0089, -0.0067, -0.0036,  ...,  0.0049,  0.0019,  0.0021],\n",
       "         [ 0.0045,  0.0081,  0.0040,  ..., -0.0010, -0.0013, -0.0030],\n",
       "         [ 0.0090,  0.0009,  0.0056,  ...,  0.0121, -0.0060,  0.0110],\n",
       "         ...,\n",
       "         [-0.0054,  0.0012, -0.0021,  ...,  0.0103, -0.0021, -0.0078],\n",
       "         [-0.0035,  0.0046, -0.0018,  ..., -0.0078,  0.0005,  0.0062],\n",
       "         [ 0.0073,  0.0076, -0.0085,  ...,  0.0124,  0.0055, -0.0024]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.7.mlp.down_proj.lora_B.weight': tensor([[ 1.4877e-03,  8.6594e-04, -1.0147e-03,  ...,  1.2436e-03,\n",
       "          -3.7003e-04,  1.7548e-03],\n",
       "         [-3.2654e-03,  2.9602e-03,  1.4114e-03,  ...,  5.2452e-05,\n",
       "          -2.1973e-03,  1.3428e-03],\n",
       "         [ 1.4496e-03,  4.4060e-04,  3.0327e-04,  ...,  2.3041e-03,\n",
       "           7.0572e-04,  3.0365e-03],\n",
       "         ...,\n",
       "         [ 9.3937e-05,  1.8921e-03, -1.2131e-03,  ..., -1.7548e-03,\n",
       "           5.7983e-04, -4.6158e-04],\n",
       "         [ 2.0905e-03, -1.8463e-03,  8.7738e-04,  ..., -8.0872e-04,\n",
       "           1.7242e-03,  3.3569e-04],\n",
       "         [-6.7234e-05, -1.5182e-03,  1.4496e-03,  ...,  1.2512e-03,\n",
       "           2.6855e-03,  2.7313e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.7.mlp.gate_proj.lora_A.weight': tensor([[ 0.0082, -0.0117,  0.0092,  ...,  0.0061,  0.0052,  0.0144],\n",
       "         [-0.0059, -0.0105,  0.0045,  ..., -0.0126,  0.0084,  0.0081],\n",
       "         [ 0.0059,  0.0127, -0.0065,  ..., -0.0043, -0.0099, -0.0069],\n",
       "         ...,\n",
       "         [-0.0060,  0.0050,  0.0027,  ...,  0.0100, -0.0011,  0.0170],\n",
       "         [-0.0175,  0.0085, -0.0123,  ...,  0.0148, -0.0057,  0.0118],\n",
       "         [-0.0087,  0.0004,  0.0136,  ..., -0.0117,  0.0042, -0.0025]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.7.mlp.gate_proj.lora_B.weight': tensor([[-2.2736e-03,  1.3428e-03, -1.3351e-03,  ...,  5.4550e-04,\n",
       "          -1.1902e-03,  4.3488e-04],\n",
       "         [ 1.5259e-03, -3.5477e-04,  4.4107e-05,  ..., -9.5367e-04,\n",
       "           3.5477e-04,  2.1820e-03],\n",
       "         [-2.6093e-03,  1.5182e-03, -1.6327e-03,  ..., -1.2741e-03,\n",
       "          -2.6550e-03, -1.9150e-03],\n",
       "         ...,\n",
       "         [ 2.5024e-03, -2.1362e-04,  1.0376e-03,  ...,  7.2098e-04,\n",
       "           2.1667e-03, -1.1444e-03],\n",
       "         [ 1.9379e-03,  2.2793e-04,  1.1673e-03,  ...,  7.4387e-04,\n",
       "           2.1057e-03, -6.3324e-04],\n",
       "         [ 2.2430e-03, -4.4250e-03,  4.1425e-06,  ..., -1.2064e-04,\n",
       "           2.1210e-03,  1.9226e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.7.mlp.up_proj.lora_A.weight': tensor([[ 0.0092, -0.0159,  0.0099,  ...,  0.0127, -0.0128, -0.0067],\n",
       "         [-0.0007,  0.0103, -0.0120,  ...,  0.0015, -0.0042, -0.0147],\n",
       "         [ 0.0138,  0.0043, -0.0049,  ..., -0.0123, -0.0047,  0.0005],\n",
       "         ...,\n",
       "         [ 0.0171, -0.0018, -0.0102,  ..., -0.0025, -0.0089, -0.0148],\n",
       "         [ 0.0143, -0.0099,  0.0111,  ...,  0.0107, -0.0042,  0.0032],\n",
       "         [-0.0030,  0.0089, -0.0155,  ...,  0.0030, -0.0008, -0.0164]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.7.mlp.up_proj.lora_B.weight': tensor([[ 4.2534e-04, -3.5477e-04,  1.6403e-03,  ..., -3.0823e-03,\n",
       "          -1.5335e-03, -1.2589e-03],\n",
       "         [-1.2970e-03, -2.3007e-05, -1.9455e-03,  ..., -2.2736e-03,\n",
       "          -9.1553e-04, -1.9684e-03],\n",
       "         [-1.4591e-04,  3.5095e-03,  2.2125e-03,  ...,  1.2207e-03,\n",
       "           1.8311e-03, -1.3885e-03],\n",
       "         ...,\n",
       "         [ 1.1368e-03,  2.8381e-03,  1.0223e-03,  ...,  1.7624e-03,\n",
       "          -1.8005e-03,  9.8419e-04],\n",
       "         [ 1.0071e-03,  2.4414e-04,  1.5640e-03,  ...,  5.6076e-04,\n",
       "           4.5776e-04, -3.5400e-03],\n",
       "         [ 7.2479e-04,  1.9989e-03, -4.6539e-04,  ...,  3.9673e-04,\n",
       "          -9.2316e-04, -8.6975e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.7.self_attn.k_proj.lora_A.weight': tensor([[ 0.0036,  0.0143,  0.0012,  ...,  0.0106,  0.0098, -0.0029],\n",
       "         [-0.0049, -0.0139,  0.0008,  ...,  0.0090,  0.0072, -0.0019],\n",
       "         [-0.0063,  0.0119,  0.0160,  ...,  0.0022, -0.0099,  0.0002],\n",
       "         ...,\n",
       "         [ 0.0037,  0.0024,  0.0123,  ...,  0.0045, -0.0039, -0.0063],\n",
       "         [ 0.0113, -0.0045,  0.0068,  ...,  0.0128, -0.0113, -0.0101],\n",
       "         [ 0.0150, -0.0076,  0.0050,  ...,  0.0098, -0.0135, -0.0029]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.7.self_attn.k_proj.lora_B.weight': tensor([[-1.2131e-03, -3.5095e-03, -3.2043e-03,  ...,  1.4725e-03,\n",
       "           1.1253e-04, -2.6703e-03],\n",
       "         [ 7.3242e-04, -2.2888e-03,  1.1444e-03,  ..., -2.1210e-03,\n",
       "           2.3041e-03, -2.0447e-03],\n",
       "         [-1.8463e-03, -4.0894e-03, -1.6479e-03,  ...,  3.8528e-04,\n",
       "           1.9684e-03, -8.5068e-04],\n",
       "         ...,\n",
       "         [ 1.8997e-03,  2.1076e-04, -3.1853e-04,  ...,  4.0588e-03,\n",
       "           1.6861e-03,  1.6327e-03],\n",
       "         [-7.3624e-04,  9.7752e-05,  7.2861e-04,  ..., -1.2589e-03,\n",
       "           1.6098e-03,  1.6556e-03],\n",
       "         [ 1.8387e-03, -1.5945e-03, -4.0054e-04,  ..., -1.5793e-03,\n",
       "          -6.2180e-04, -2.8038e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.7.self_attn.o_proj.lora_A.weight': tensor([[-0.0070, -0.0077,  0.0089,  ..., -0.0115,  0.0141,  0.0148],\n",
       "         [-0.0041,  0.0005,  0.0046,  ..., -0.0109, -0.0140, -0.0139],\n",
       "         [ 0.0145, -0.0033, -0.0075,  ...,  0.0073,  0.0139, -0.0054],\n",
       "         ...,\n",
       "         [-0.0081,  0.0011,  0.0096,  ..., -0.0047, -0.0097,  0.0040],\n",
       "         [-0.0044,  0.0154, -0.0148,  ..., -0.0052,  0.0095,  0.0096],\n",
       "         [-0.0096, -0.0082, -0.0161,  ..., -0.0023,  0.0162, -0.0043]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.7.self_attn.o_proj.lora_B.weight': tensor([[-0.0013,  0.0022,  0.0021,  ..., -0.0011, -0.0021, -0.0015],\n",
       "         [ 0.0006,  0.0015,  0.0013,  ..., -0.0002,  0.0013, -0.0013],\n",
       "         [ 0.0008, -0.0030, -0.0022,  ...,  0.0024,  0.0016,  0.0016],\n",
       "         ...,\n",
       "         [ 0.0011,  0.0001, -0.0009,  ...,  0.0013, -0.0006, -0.0014],\n",
       "         [ 0.0003, -0.0021, -0.0003,  ...,  0.0009,  0.0001,  0.0002],\n",
       "         [-0.0023, -0.0030, -0.0031,  ...,  0.0023,  0.0017,  0.0044]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.7.self_attn.q_proj.lora_A.weight': tensor([[-0.0104,  0.0114, -0.0007,  ..., -0.0066,  0.0060, -0.0079],\n",
       "         [-0.0125,  0.0036, -0.0149,  ..., -0.0055,  0.0121,  0.0106],\n",
       "         [ 0.0039,  0.0107,  0.0184,  ...,  0.0021,  0.0126,  0.0100],\n",
       "         ...,\n",
       "         [-0.0012,  0.0194, -0.0106,  ...,  0.0018, -0.0046,  0.0019],\n",
       "         [ 0.0016,  0.0117, -0.0034,  ..., -0.0048, -0.0098,  0.0062],\n",
       "         [-0.0086, -0.0057, -0.0028,  ...,  0.0095,  0.0084,  0.0085]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.7.self_attn.q_proj.lora_B.weight': tensor([[ 1.5945e-03,  1.7071e-04, -3.0365e-03,  ..., -1.6403e-03,\n",
       "          -1.6403e-03,  2.9907e-03],\n",
       "         [ 6.0272e-04,  7.8201e-04,  1.4648e-03,  ...,  9.0408e-04,\n",
       "          -1.1139e-03,  1.5869e-03],\n",
       "         [ 1.7624e-03,  1.8921e-03, -2.4719e-03,  ..., -2.3804e-03,\n",
       "           3.1948e-05,  1.8539e-03],\n",
       "         ...,\n",
       "         [ 8.6212e-04,  1.1749e-03,  1.6174e-03,  ..., -3.7384e-04,\n",
       "           3.0060e-03, -2.3499e-03],\n",
       "         [-2.6703e-04, -3.3569e-04, -4.5967e-04,  ...,  2.9564e-04,\n",
       "          -2.1267e-04,  1.9073e-03],\n",
       "         [ 7.2098e-04,  1.1978e-03, -3.4332e-04,  ...,  3.3569e-04,\n",
       "          -1.9836e-03,  1.2665e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.7.self_attn.v_proj.lora_A.weight': tensor([[-0.0006, -0.0023,  0.0156,  ..., -0.0033,  0.0050,  0.0031],\n",
       "         [-0.0050, -0.0031, -0.0126,  ...,  0.0116,  0.0037,  0.0092],\n",
       "         [ 0.0034,  0.0042,  0.0106,  ..., -0.0121, -0.0106, -0.0063],\n",
       "         ...,\n",
       "         [ 0.0087,  0.0033, -0.0024,  ...,  0.0080, -0.0135, -0.0014],\n",
       "         [ 0.0002,  0.0144,  0.0129,  ...,  0.0081,  0.0001,  0.0131],\n",
       "         [-0.0104,  0.0086,  0.0035,  ...,  0.0134, -0.0021, -0.0013]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.7.self_attn.v_proj.lora_B.weight': tensor([[-0.0001,  0.0009, -0.0001,  ...,  0.0020, -0.0005, -0.0010],\n",
       "         [ 0.0012, -0.0002, -0.0017,  ...,  0.0001,  0.0004, -0.0013],\n",
       "         [-0.0015, -0.0011, -0.0007,  ..., -0.0011,  0.0009,  0.0003],\n",
       "         ...,\n",
       "         [-0.0012, -0.0011, -0.0006,  ..., -0.0010,  0.0008,  0.0014],\n",
       "         [-0.0006, -0.0014,  0.0004,  ..., -0.0003,  0.0012, -0.0011],\n",
       "         [ 0.0015, -0.0003,  0.0013,  ...,  0.0017, -0.0016,  0.0007]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.8.mlp.down_proj.lora_A.weight': tensor([[ 0.0014, -0.0070,  0.0043,  ...,  0.0019, -0.0035,  0.0030],\n",
       "         [ 0.0025, -0.0069,  0.0070,  ..., -0.0054,  0.0135,  0.0108],\n",
       "         [ 0.0089, -0.0024,  0.0066,  ..., -0.0071, -0.0075,  0.0070],\n",
       "         ...,\n",
       "         [ 0.0075,  0.0018,  0.0059,  ...,  0.0042, -0.0038,  0.0107],\n",
       "         [ 0.0049,  0.0052,  0.0110,  ..., -0.0024, -0.0079,  0.0065],\n",
       "         [ 0.0046, -0.0052, -0.0045,  ...,  0.0025, -0.0032, -0.0047]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.8.mlp.down_proj.lora_B.weight': tensor([[ 1.8597e-04,  9.4223e-04,  2.0142e-03,  ..., -4.5204e-04,\n",
       "          -2.1210e-03,  1.8234e-03],\n",
       "         [-1.0681e-03,  5.4550e-04,  2.6093e-03,  ...,  1.3199e-03,\n",
       "           1.7929e-03, -9.1553e-05],\n",
       "         [-1.6556e-03, -1.4267e-03,  8.3542e-04,  ..., -3.2501e-03,\n",
       "          -1.1978e-03, -1.7242e-03],\n",
       "         ...,\n",
       "         [ 1.9836e-03, -9.9945e-04, -6.2180e-04,  ...,  4.0054e-04,\n",
       "          -1.3199e-03,  1.0073e-05],\n",
       "         [ 5.1117e-04,  3.0823e-03,  6.4850e-04,  ..., -1.1978e-03,\n",
       "          -2.4414e-03,  1.4877e-03],\n",
       "         [ 1.8692e-03,  1.0681e-03,  3.7193e-04,  ..., -4.3030e-03,\n",
       "           4.2343e-04, -1.2684e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.8.mlp.gate_proj.lora_A.weight': tensor([[ 0.0090, -0.0146, -0.0069,  ...,  0.0006, -0.0064, -0.0078],\n",
       "         [ 0.0131, -0.0037,  0.0038,  ..., -0.0052,  0.0111, -0.0009],\n",
       "         [ 0.0014,  0.0017,  0.0063,  ...,  0.0019,  0.0051,  0.0132],\n",
       "         ...,\n",
       "         [-0.0179, -0.0112,  0.0036,  ...,  0.0160,  0.0036,  0.0042],\n",
       "         [ 0.0028, -0.0118,  0.0098,  ..., -0.0112,  0.0131, -0.0037],\n",
       "         [-0.0068,  0.0034, -0.0111,  ...,  0.0053, -0.0051,  0.0150]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.8.mlp.gate_proj.lora_B.weight': tensor([[ 0.0007,  0.0015, -0.0014,  ..., -0.0009, -0.0012,  0.0011],\n",
       "         [ 0.0013,  0.0014,  0.0001,  ...,  0.0012,  0.0009,  0.0012],\n",
       "         [-0.0006,  0.0017, -0.0016,  ..., -0.0012, -0.0007,  0.0010],\n",
       "         ...,\n",
       "         [-0.0003, -0.0007,  0.0025,  ..., -0.0014,  0.0014, -0.0023],\n",
       "         [-0.0003,  0.0025, -0.0025,  ..., -0.0020, -0.0009,  0.0006],\n",
       "         [-0.0002,  0.0012,  0.0008,  ...,  0.0007, -0.0010, -0.0004]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.8.mlp.up_proj.lora_A.weight': tensor([[ 4.3335e-03,  3.8910e-03, -2.3499e-03,  ...,  5.5847e-03,\n",
       "           1.3245e-02, -8.3542e-04],\n",
       "         [ 1.3489e-02,  1.4160e-02,  4.1809e-03,  ..., -5.6763e-03,\n",
       "           1.0986e-02, -2.5482e-03],\n",
       "         [-2.5330e-03,  4.7913e-03,  2.4261e-03,  ..., -9.3994e-03,\n",
       "           3.2959e-03,  1.0498e-02],\n",
       "         ...,\n",
       "         [ 5.0659e-03,  8.3618e-03,  1.3611e-02,  ...,  1.5015e-02,\n",
       "          -1.0559e-02,  1.4801e-03],\n",
       "         [-7.1106e-03, -1.1414e-02,  1.3245e-02,  ...,  3.5763e-05,\n",
       "          -4.6921e-04,  3.3112e-03],\n",
       "         [-3.3417e-03,  1.1169e-02, -2.5482e-03,  ..., -9.5215e-03,\n",
       "           2.5177e-04,  5.7678e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.8.mlp.up_proj.lora_B.weight': tensor([[-6.6757e-04, -1.1826e-03,  6.7711e-05,  ..., -5.3787e-04,\n",
       "          -1.3046e-03, -3.8757e-03],\n",
       "         [-5.1117e-04, -9.6512e-04, -4.0054e-05,  ...,  3.7231e-03,\n",
       "           3.8910e-04, -1.0757e-03],\n",
       "         [ 9.0122e-05, -1.3123e-03,  1.7700e-03,  ..., -2.4986e-04,\n",
       "          -1.9989e-03, -3.4714e-04],\n",
       "         ...,\n",
       "         [ 9.6130e-04, -5.9509e-04, -5.1498e-04,  ...,  1.1673e-03,\n",
       "           1.6556e-03,  5.5313e-04],\n",
       "         [ 1.9836e-03,  1.0757e-03,  1.5030e-03,  ..., -1.3275e-03,\n",
       "          -1.2589e-03,  8.8120e-04],\n",
       "         [-2.5749e-04, -2.4261e-03, -3.5667e-04,  ..., -1.5926e-04,\n",
       "           6.6757e-04,  3.8910e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.8.self_attn.k_proj.lora_A.weight': tensor([[ 0.0135, -0.0145,  0.0078,  ..., -0.0073, -0.0136, -0.0103],\n",
       "         [-0.0011,  0.0166,  0.0168,  ..., -0.0141, -0.0093, -0.0125],\n",
       "         [-0.0151, -0.0102,  0.0102,  ...,  0.0002,  0.0159, -0.0165],\n",
       "         ...,\n",
       "         [ 0.0096, -0.0079,  0.0089,  ..., -0.0052, -0.0111, -0.0111],\n",
       "         [ 0.0024,  0.0072, -0.0101,  ..., -0.0021,  0.0081, -0.0127],\n",
       "         [ 0.0022,  0.0025,  0.0044,  ..., -0.0107,  0.0081, -0.0044]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.8.self_attn.k_proj.lora_B.weight': tensor([[ 1.8768e-03,  1.4114e-03, -1.2207e-03,  ...,  8.6594e-04,\n",
       "          -8.4400e-05,  6.2943e-04],\n",
       "         [ 1.5335e-03, -1.2493e-04,  4.7874e-04,  ..., -1.2159e-04,\n",
       "           1.6098e-03,  1.7090e-03],\n",
       "         [ 1.4191e-03,  5.2214e-05,  4.9210e-04,  ..., -1.5793e-03,\n",
       "           2.2411e-04, -1.6098e-03],\n",
       "         ...,\n",
       "         [-1.9150e-03,  1.7624e-03, -1.2970e-03,  ...,  1.4114e-04,\n",
       "           3.3112e-03,  1.4343e-03],\n",
       "         [ 3.2425e-04, -1.4725e-03,  8.2397e-04,  ..., -8.1635e-04,\n",
       "           3.5858e-04,  1.5717e-03],\n",
       "         [ 2.9602e-03, -8.5449e-04,  2.4719e-03,  ...,  3.7842e-03,\n",
       "          -3.2959e-03, -2.1362e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.8.self_attn.o_proj.lora_A.weight': tensor([[ 0.0171, -0.0103,  0.0123,  ..., -0.0044,  0.0101, -0.0172],\n",
       "         [-0.0038, -0.0075,  0.0084,  ..., -0.0082, -0.0143,  0.0048],\n",
       "         [ 0.0130,  0.0139,  0.0114,  ...,  0.0062, -0.0022, -0.0057],\n",
       "         ...,\n",
       "         [ 0.0008,  0.0087, -0.0140,  ..., -0.0081,  0.0094, -0.0028],\n",
       "         [-0.0051,  0.0095,  0.0140,  ..., -0.0084, -0.0020,  0.0088],\n",
       "         [ 0.0073, -0.0109, -0.0084,  ...,  0.0037, -0.0047,  0.0150]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.8.self_attn.o_proj.lora_B.weight': tensor([[-1.0071e-03, -3.1433e-03,  2.8076e-03,  ...,  1.1597e-03,\n",
       "          -1.2589e-03,  1.6861e-03],\n",
       "         [-2.4414e-03, -2.0447e-03,  6.9141e-05,  ...,  2.6703e-03,\n",
       "          -1.1063e-03,  2.0981e-04],\n",
       "         [-4.8065e-04, -9.2316e-04,  4.7112e-04,  ..., -3.4332e-04,\n",
       "           1.9455e-04,  3.3264e-03],\n",
       "         ...,\n",
       "         [-1.9684e-03, -2.4872e-03,  1.6022e-03,  ...,  2.7466e-03,\n",
       "          -5.1880e-04, -1.2741e-03],\n",
       "         [ 1.3199e-03,  1.3046e-03, -8.2397e-04,  ..., -2.8687e-03,\n",
       "           3.9864e-04, -6.9046e-04],\n",
       "         [ 1.8692e-03,  1.5717e-03,  6.3324e-04,  ..., -1.3053e-05,\n",
       "           8.3542e-04,  3.3264e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.8.self_attn.q_proj.lora_A.weight': tensor([[-0.0098, -0.0104,  0.0049,  ..., -0.0145, -0.0013, -0.0114],\n",
       "         [ 0.0064, -0.0126, -0.0029,  ...,  0.0030, -0.0010,  0.0092],\n",
       "         [ 0.0033, -0.0148, -0.0128,  ..., -0.0144,  0.0034, -0.0074],\n",
       "         ...,\n",
       "         [ 0.0129,  0.0183, -0.0156,  ..., -0.0038, -0.0094,  0.0129],\n",
       "         [-0.0124,  0.0160, -0.0016,  ..., -0.0064, -0.0171, -0.0099],\n",
       "         [ 0.0175, -0.0021, -0.0093,  ...,  0.0040,  0.0057, -0.0036]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.8.self_attn.q_proj.lora_B.weight': tensor([[ 1.3962e-03,  3.8338e-04, -7.8964e-04,  ...,  1.4267e-03,\n",
       "          -1.7471e-03, -2.8687e-03],\n",
       "         [ 1.0300e-03, -1.7090e-03, -2.9144e-03,  ..., -5.2214e-05,\n",
       "           2.7275e-04,  1.0452e-03],\n",
       "         [ 1.7776e-03,  5.5313e-04, -2.5787e-03,  ...,  8.5831e-04,\n",
       "           1.0071e-03,  5.6458e-04],\n",
       "         ...,\n",
       "         [-9.5749e-04, -1.8215e-04,  1.5106e-03,  ..., -4.9210e-04,\n",
       "          -7.8201e-04,  8.0490e-04],\n",
       "         [-1.8768e-03, -5.9891e-04, -3.7193e-04,  ...,  8.2016e-04,\n",
       "           8.9645e-04,  1.0605e-03],\n",
       "         [-7.0953e-04, -1.8215e-04,  2.2602e-04,  ...,  9.3460e-04,\n",
       "           8.1635e-04,  2.1667e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.8.self_attn.v_proj.lora_A.weight': tensor([[ 7.5378e-03,  5.4932e-03, -5.7983e-03,  ...,  1.1475e-02,\n",
       "           1.2085e-02,  1.6785e-03],\n",
       "         [ 1.0620e-02, -8.3008e-03, -1.5974e-05,  ..., -2.0752e-03,\n",
       "           2.5787e-03, -1.1963e-02],\n",
       "         [-7.6599e-03, -6.1951e-03,  1.3672e-02,  ..., -7.6599e-03,\n",
       "          -1.0254e-02, -1.6556e-03],\n",
       "         ...,\n",
       "         [ 9.2773e-03, -1.1719e-02,  1.0437e-02,  ...,  7.0190e-03,\n",
       "          -4.8256e-04, -6.5613e-03],\n",
       "         [-2.9449e-03,  9.5825e-03,  9.5825e-03,  ...,  1.3794e-02,\n",
       "          -1.4526e-02,  8.1177e-03],\n",
       "         [ 2.0142e-03, -4.2419e-03,  7.9346e-03,  ...,  3.0212e-03,\n",
       "          -6.6833e-03,  1.2329e-02]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.8.self_attn.v_proj.lora_B.weight': tensor([[ 0.0010,  0.0010, -0.0036,  ..., -0.0004,  0.0001,  0.0012],\n",
       "         [ 0.0005,  0.0008, -0.0019,  ..., -0.0006,  0.0020,  0.0007],\n",
       "         [ 0.0025,  0.0025,  0.0021,  ..., -0.0018, -0.0012,  0.0036],\n",
       "         ...,\n",
       "         [ 0.0021,  0.0002, -0.0035,  ..., -0.0005,  0.0020,  0.0021],\n",
       "         [-0.0017, -0.0010, -0.0011,  ...,  0.0012, -0.0011, -0.0007],\n",
       "         [ 0.0028,  0.0019, -0.0019,  ..., -0.0017,  0.0021,  0.0032]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.9.mlp.down_proj.lora_A.weight': tensor([[-0.0048, -0.0042,  0.0039,  ..., -0.0090,  0.0067,  0.0025],\n",
       "         [ 0.0110, -0.0049,  0.0051,  ...,  0.0011,  0.0021,  0.0089],\n",
       "         [ 0.0078,  0.0045,  0.0046,  ...,  0.0012,  0.0010,  0.0009],\n",
       "         ...,\n",
       "         [ 0.0037, -0.0070, -0.0006,  ..., -0.0050,  0.0088, -0.0008],\n",
       "         [-0.0001,  0.0030, -0.0041,  ..., -0.0069,  0.0017, -0.0004],\n",
       "         [-0.0045,  0.0038, -0.0028,  ...,  0.0090,  0.0040, -0.0074]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.9.mlp.down_proj.lora_B.weight': tensor([[-0.0002, -0.0023, -0.0014,  ...,  0.0013,  0.0011,  0.0005],\n",
       "         [-0.0016, -0.0013, -0.0005,  ..., -0.0021, -0.0009,  0.0006],\n",
       "         [ 0.0012,  0.0015,  0.0013,  ...,  0.0004, -0.0014, -0.0008],\n",
       "         ...,\n",
       "         [ 0.0011, -0.0012, -0.0018,  ..., -0.0006,  0.0014,  0.0005],\n",
       "         [ 0.0028,  0.0017, -0.0019,  ...,  0.0023,  0.0018, -0.0020],\n",
       "         [ 0.0005,  0.0022, -0.0021,  ...,  0.0010, -0.0003, -0.0017]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.9.mlp.gate_proj.lora_A.weight': tensor([[-0.0081,  0.0029, -0.0141,  ...,  0.0036, -0.0095, -0.0120],\n",
       "         [-0.0082, -0.0011,  0.0143,  ..., -0.0104, -0.0012,  0.0022],\n",
       "         [ 0.0026,  0.0073, -0.0041,  ..., -0.0024, -0.0172,  0.0041],\n",
       "         ...,\n",
       "         [-0.0128, -0.0063,  0.0093,  ...,  0.0156,  0.0053, -0.0091],\n",
       "         [ 0.0036, -0.0021, -0.0008,  ...,  0.0027,  0.0032,  0.0015],\n",
       "         [-0.0194,  0.0046, -0.0142,  ..., -0.0170, -0.0135,  0.0103]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.9.mlp.gate_proj.lora_B.weight': tensor([[ 2.1935e-04,  6.7902e-04, -2.3651e-03,  ..., -3.5858e-04,\n",
       "           6.3705e-04,  1.0376e-03],\n",
       "         [ 1.4877e-03,  7.6294e-04,  1.2207e-03,  ..., -1.4267e-03,\n",
       "           1.4114e-03, -1.1597e-03],\n",
       "         [ 1.2741e-03, -2.6941e-05,  3.0136e-04,  ..., -1.7471e-03,\n",
       "           1.7090e-03, -6.4468e-04],\n",
       "         ...,\n",
       "         [ 1.7090e-03,  2.5787e-03,  1.7548e-03,  ..., -4.2343e-04,\n",
       "          -6.1798e-04,  2.9449e-03],\n",
       "         [ 2.6550e-03,  9.9945e-04, -6.4468e-04,  ...,  8.5068e-04,\n",
       "          -3.4332e-04,  7.4387e-04],\n",
       "         [-1.5564e-03,  1.6861e-03,  1.7319e-03,  ...,  5.9891e-04,\n",
       "          -2.0146e-05, -3.6774e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.9.mlp.up_proj.lora_A.weight': tensor([[ 0.0026, -0.0068,  0.0050,  ...,  0.0087, -0.0151, -0.0044],\n",
       "         [ 0.0015, -0.0009,  0.0080,  ...,  0.0006,  0.0005,  0.0058],\n",
       "         [ 0.0053,  0.0078, -0.0042,  ...,  0.0043, -0.0021, -0.0168],\n",
       "         ...,\n",
       "         [-0.0162, -0.0079, -0.0111,  ...,  0.0188, -0.0014,  0.0168],\n",
       "         [-0.0152,  0.0157,  0.0017,  ...,  0.0124, -0.0135,  0.0051],\n",
       "         [ 0.0066, -0.0160,  0.0097,  ...,  0.0115,  0.0097, -0.0100]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.9.mlp.up_proj.lora_B.weight': tensor([[ 8.8215e-05, -1.1673e-03,  2.1820e-03,  ...,  5.3024e-04,\n",
       "          -1.8539e-03,  3.2959e-03],\n",
       "         [-1.6174e-03, -6.5613e-04, -1.4801e-03,  ..., -5.1498e-04,\n",
       "          -1.1292e-03, -8.3542e-04],\n",
       "         [-1.6251e-03,  6.1035e-04,  4.7493e-04,  ...,  1.5564e-03,\n",
       "           9.4223e-04, -1.3351e-03],\n",
       "         ...,\n",
       "         [-6.8665e-04, -1.1444e-03, -1.7090e-03,  ..., -2.2030e-04,\n",
       "           1.8845e-03,  6.2180e-04],\n",
       "         [-2.6550e-03,  2.9182e-04, -5.4169e-04,  ...,  2.0905e-03,\n",
       "           1.5030e-03,  1.5793e-03],\n",
       "         [-1.4877e-03, -1.5793e-03,  6.7902e-04,  ...,  3.2806e-04,\n",
       "          -7.6675e-04,  4.4250e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.9.self_attn.k_proj.lora_A.weight': tensor([[-0.0134, -0.0171, -0.0109,  ..., -0.0082,  0.0123, -0.0075],\n",
       "         [-0.0151, -0.0010,  0.0008,  ...,  0.0072, -0.0134, -0.0151],\n",
       "         [-0.0116, -0.0151,  0.0014,  ...,  0.0157,  0.0150,  0.0121],\n",
       "         ...,\n",
       "         [ 0.0162,  0.0131,  0.0097,  ...,  0.0012,  0.0150,  0.0134],\n",
       "         [ 0.0074,  0.0069, -0.0145,  ...,  0.0067, -0.0068, -0.0100],\n",
       "         [-0.0148,  0.0093, -0.0166,  ..., -0.0011, -0.0159,  0.0078]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.9.self_attn.k_proj.lora_B.weight': tensor([[-0.0009, -0.0015, -0.0012,  ...,  0.0014, -0.0007, -0.0011],\n",
       "         [-0.0017, -0.0006, -0.0010,  ...,  0.0013, -0.0008, -0.0003],\n",
       "         [ 0.0010, -0.0017, -0.0007,  ...,  0.0006, -0.0008, -0.0007],\n",
       "         ...,\n",
       "         [ 0.0012, -0.0007, -0.0014,  ...,  0.0006,  0.0006, -0.0017],\n",
       "         [ 0.0027,  0.0001, -0.0007,  ...,  0.0014,  0.0002, -0.0012],\n",
       "         [-0.0006, -0.0002, -0.0009,  ..., -0.0015, -0.0041, -0.0019]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.9.self_attn.o_proj.lora_A.weight': tensor([[-1.3489e-02, -5.9509e-03, -2.8687e-03,  ..., -3.5048e-05,\n",
       "           1.2024e-02,  1.4160e-02],\n",
       "         [ 1.5640e-03,  1.4282e-02,  1.2878e-02,  ..., -1.3306e-02,\n",
       "           8.2397e-03, -1.3542e-04],\n",
       "         [ 9.0790e-04, -5.6458e-03, -1.2573e-02,  ...,  1.6602e-02,\n",
       "           7.0496e-03,  1.0498e-02],\n",
       "         ...,\n",
       "         [-1.6602e-02,  6.8665e-03,  5.0354e-03,  ..., -5.8594e-03,\n",
       "          -2.1820e-03,  1.5747e-02],\n",
       "         [-3.0060e-03, -3.0975e-03, -1.4420e-03,  ..., -1.2573e-02,\n",
       "          -7.5989e-03,  8.5449e-03],\n",
       "         [ 5.1498e-04, -1.1047e-02, -9.8877e-03,  ...,  9.7046e-03,\n",
       "           1.2878e-02, -7.5150e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.9.self_attn.o_proj.lora_B.weight': tensor([[ 1.7929e-03,  2.5940e-03,  8.0109e-04,  ..., -3.4485e-03,\n",
       "           4.6349e-04, -3.1891e-03],\n",
       "         [ 2.0752e-03,  2.2888e-03, -1.4191e-03,  ..., -1.1778e-04,\n",
       "          -7.4863e-05, -1.1673e-03],\n",
       "         [-7.2098e-04, -9.6893e-04, -7.7820e-04,  ...,  1.2817e-03,\n",
       "          -7.3624e-04,  2.3499e-03],\n",
       "         ...,\n",
       "         [-9.4604e-04,  8.8501e-04, -2.5024e-03,  ..., -2.3041e-03,\n",
       "           3.6430e-04,  2.4261e-03],\n",
       "         [ 1.1520e-03,  9.1553e-05,  9.6130e-04,  ..., -4.1008e-04,\n",
       "           1.3809e-03, -1.0605e-03],\n",
       "         [ 1.1902e-03, -1.6098e-03,  6.7139e-04,  ..., -1.0147e-03,\n",
       "          -3.1281e-03, -6.5613e-04]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.9.self_attn.q_proj.lora_A.weight': tensor([[ 0.0066, -0.0084, -0.0123,  ...,  0.0142, -0.0042, -0.0095],\n",
       "         [-0.0131, -0.0029, -0.0078,  ...,  0.0014, -0.0121,  0.0048],\n",
       "         [-0.0074, -0.0029, -0.0141,  ...,  0.0131,  0.0098,  0.0099],\n",
       "         ...,\n",
       "         [ 0.0153,  0.0127, -0.0090,  ...,  0.0134, -0.0015,  0.0100],\n",
       "         [ 0.0017,  0.0062, -0.0188,  ..., -0.0164, -0.0045,  0.0007],\n",
       "         [ 0.0016,  0.0004,  0.0152,  ..., -0.0062, -0.0129,  0.0075]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.9.self_attn.q_proj.lora_B.weight': tensor([[-0.0015,  0.0012,  0.0015,  ..., -0.0016, -0.0014,  0.0019],\n",
       "         [ 0.0009, -0.0007,  0.0011,  ..., -0.0008, -0.0013, -0.0010],\n",
       "         [ 0.0014, -0.0009, -0.0005,  ...,  0.0014,  0.0014, -0.0013],\n",
       "         ...,\n",
       "         [-0.0008,  0.0020,  0.0028,  ...,  0.0018,  0.0004, -0.0004],\n",
       "         [ 0.0012,  0.0004,  0.0045,  ...,  0.0019, -0.0008, -0.0022],\n",
       "         [ 0.0011, -0.0021, -0.0028,  ..., -0.0005, -0.0021, -0.0002]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.9.self_attn.v_proj.lora_A.weight': tensor([[-0.0099,  0.0087,  0.0105,  ..., -0.0087,  0.0067,  0.0131],\n",
       "         [ 0.0046,  0.0148, -0.0077,  ..., -0.0021,  0.0034,  0.0025],\n",
       "         [ 0.0071,  0.0072, -0.0106,  ..., -0.0100, -0.0035,  0.0089],\n",
       "         ...,\n",
       "         [-0.0140, -0.0139,  0.0091,  ..., -0.0028, -0.0170,  0.0023],\n",
       "         [ 0.0147,  0.0167,  0.0039,  ...,  0.0129,  0.0112, -0.0036],\n",
       "         [-0.0179, -0.0175,  0.0142,  ...,  0.0059,  0.0129, -0.0104]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.layers.9.self_attn.v_proj.lora_B.weight': tensor([[ 0.0004,  0.0003,  0.0017,  ..., -0.0012,  0.0012, -0.0004],\n",
       "         [-0.0016,  0.0012, -0.0003,  ..., -0.0015,  0.0016, -0.0012],\n",
       "         [ 0.0008, -0.0003, -0.0002,  ...,  0.0012, -0.0011,  0.0014],\n",
       "         ...,\n",
       "         [-0.0008, -0.0018, -0.0010,  ..., -0.0015, -0.0010, -0.0008],\n",
       "         [-0.0028,  0.0009,  0.0040,  ..., -0.0020, -0.0014,  0.0017],\n",
       "         [ 0.0006,  0.0007,  0.0021,  ...,  0.0005,  0.0032,  0.0001]],\n",
       "        device='cuda:0', dtype=torch.bfloat16)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from safetensors import safe_open\n",
    "\n",
    "tensors = {}\n",
    "with safe_open(\n",
    "    \"/media/yesindeed/DATADRIVE1/mount/remote_cse/experiments/med_vlm_benchmark/vqa/SLAKE/LLaVA-1.5/train_lora_V_seed42_llava/adapter_model.safetensors\",\n",
    "    framework=\"pt\",\n",
    "    device=0,\n",
    ") as f:\n",
    "    for k in f.keys():\n",
    "        tensors[k] = f.get_tensor(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.lora_A.weight': tensor([[ 0.0026,  0.0228,  0.0096,  ..., -0.0151,  0.0247,  0.0103],\n",
       "         [-0.0293,  0.0243,  0.0271,  ..., -0.0195,  0.0064, -0.0063],\n",
       "         [-0.0256,  0.0176, -0.0181,  ..., -0.0197,  0.0262,  0.0090],\n",
       "         ...,\n",
       "         [-0.0188, -0.0146, -0.0231,  ..., -0.0046, -0.0083, -0.0145],\n",
       "         [-0.0159,  0.0233,  0.0093,  ..., -0.0060, -0.0144, -0.0250],\n",
       "         [ 0.0251,  0.0198,  0.0013,  ...,  0.0023,  0.0015,  0.0063]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.lora_A.weight': tensor([[-2.2430e-03,  4.2114e-03, -9.3994e-03,  ..., -1.1902e-02,\n",
       "          -1.2085e-02, -6.1512e-05],\n",
       "         [ 3.2806e-03,  1.3062e-02, -1.4893e-02,  ...,  5.2185e-03,\n",
       "          -8.7280e-03, -1.3916e-02],\n",
       "         [ 1.2512e-02, -1.2573e-02,  4.2725e-03,  ..., -5.5847e-03,\n",
       "           7.4158e-03,  8.0109e-05],\n",
       "         ...,\n",
       "         [ 3.5858e-03, -1.5198e-02, -7.0801e-03,  ..., -1.0559e-02,\n",
       "           7.3547e-03,  9.8877e-03],\n",
       "         [-9.3994e-03, -8.4839e-03,  9.0027e-04,  ..., -1.9150e-03,\n",
       "          -2.0294e-03,  1.4771e-02],\n",
       "         [-1.4771e-02, -9.3384e-03, -7.1411e-03,  ...,  1.4832e-02,\n",
       "           1.3306e-02,  2.6703e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.lora_A.weight': tensor([[ 0.0115, -0.0045, -0.0120,  ...,  0.0266,  0.0081,  0.0078],\n",
       "         [ 0.0199,  0.0075, -0.0038,  ..., -0.0066,  0.0017,  0.0067],\n",
       "         [-0.0182, -0.0184,  0.0045,  ...,  0.0299,  0.0133, -0.0018],\n",
       "         ...,\n",
       "         [-0.0068,  0.0060,  0.0273,  ..., -0.0256, -0.0238, -0.0171],\n",
       "         [ 0.0168, -0.0033, -0.0015,  ..., -0.0034, -0.0289, -0.0074],\n",
       "         [ 0.0188, -0.0291, -0.0138,  ..., -0.0120,  0.0070, -0.0166]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.lora_A.weight': tensor([[-0.0090,  0.0130, -0.0176,  ...,  0.0041,  0.0259, -0.0084],\n",
       "         [ 0.0037,  0.0248,  0.0161,  ...,  0.0286,  0.0188,  0.0120],\n",
       "         [-0.0215, -0.0256,  0.0085,  ..., -0.0147, -0.0249, -0.0094],\n",
       "         ...,\n",
       "         [ 0.0233,  0.0166,  0.0188,  ..., -0.0114,  0.0201,  0.0021],\n",
       "         [ 0.0239,  0.0266, -0.0190,  ..., -0.0166,  0.0173, -0.0304],\n",
       "         [ 0.0162,  0.0125, -0.0232,  ...,  0.0152, -0.0074,  0.0017]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.lora_A.weight': tensor([[-0.0123,  0.0238,  0.0286,  ..., -0.0271,  0.0232, -0.0031],\n",
       "         [ 0.0208,  0.0089,  0.0023,  ..., -0.0106,  0.0132,  0.0105],\n",
       "         [-0.0072,  0.0157,  0.0243,  ...,  0.0303,  0.0120, -0.0046],\n",
       "         ...,\n",
       "         [-0.0136,  0.0265, -0.0244,  ..., -0.0052, -0.0282, -0.0281],\n",
       "         [ 0.0093, -0.0249, -0.0161,  ..., -0.0079, -0.0221,  0.0118],\n",
       "         [-0.0126, -0.0134, -0.0250,  ...,  0.0111,  0.0232, -0.0165]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.lora_A.weight': tensor([[ 3.0518e-02, -1.0864e-02,  1.6724e-02,  ...,  1.5503e-02,\n",
       "           5.3711e-03, -6.5002e-03],\n",
       "         [ 1.8311e-02,  2.1484e-02, -1.4648e-02,  ..., -1.7578e-02,\n",
       "           3.0160e-05,  7.8735e-03],\n",
       "         [-2.2949e-02,  4.7913e-03,  2.2705e-02,  ...,  1.0132e-02,\n",
       "          -4.3335e-03, -2.9907e-02],\n",
       "         ...,\n",
       "         [-2.3193e-02,  1.5381e-02, -2.3438e-02,  ..., -1.3672e-02,\n",
       "           1.5259e-02, -2.4902e-02],\n",
       "         [ 8.4839e-03, -4.4861e-03,  1.0986e-02,  ..., -9.9487e-03,\n",
       "          -6.8054e-03, -4.2343e-04],\n",
       "         [-2.1851e-02, -1.8677e-02,  1.8433e-02,  ...,  6.9885e-03,\n",
       "           2.4902e-02,  9.4604e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.lora_A.weight': tensor([[-1.9165e-02,  9.8267e-03, -2.6489e-02,  ..., -2.4536e-02,\n",
       "           2.0386e-02, -3.8910e-03],\n",
       "         [-2.4658e-02, -3.7956e-04, -3.0151e-02,  ...,  1.4404e-02,\n",
       "          -3.7231e-03, -2.0142e-02],\n",
       "         [ 2.1973e-02, -1.1597e-02,  6.3477e-03,  ..., -2.8076e-02,\n",
       "           2.7100e-02,  8.9722e-03],\n",
       "         ...,\n",
       "         [ 1.6479e-02,  1.3306e-02,  9.8877e-03,  ...,  2.9785e-02,\n",
       "          -1.7014e-03,  6.4468e-04],\n",
       "         [-1.3977e-02,  3.7384e-03,  3.5095e-03,  ..., -1.9653e-02,\n",
       "           8.8692e-05,  1.1780e-02],\n",
       "         [-2.9053e-02, -7.3624e-04,  3.1433e-03,  ..., -2.2339e-02,\n",
       "          -8.3923e-04,  1.7334e-02]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.lora_A.weight': tensor([[-0.0142,  0.0058,  0.0053,  ..., -0.0044, -0.0117, -0.0030],\n",
       "         [-0.0050, -0.0145, -0.0124,  ..., -0.0004, -0.0129,  0.0038],\n",
       "         [-0.0090, -0.0063, -0.0100,  ..., -0.0015,  0.0024,  0.0065],\n",
       "         ...,\n",
       "         [ 0.0110,  0.0054, -0.0127,  ...,  0.0126, -0.0077,  0.0036],\n",
       "         [ 0.0052,  0.0053, -0.0092,  ..., -0.0019, -0.0139, -0.0027],\n",
       "         [-0.0059, -0.0137,  0.0135,  ...,  0.0124, -0.0111, -0.0050]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.lora_A.weight': tensor([[-1.5991e-02, -2.2705e-02, -8.8501e-03,  ..., -1.4404e-02,\n",
       "          -1.0132e-02,  1.6357e-02],\n",
       "         [-3.2043e-03, -2.5757e-02, -1.6479e-02,  ..., -5.3406e-03,\n",
       "           2.7222e-02,  1.7456e-02],\n",
       "         [ 7.5817e-05,  2.4292e-02, -8.4839e-03,  ..., -2.4780e-02,\n",
       "          -1.6937e-03, -9.9487e-03],\n",
       "         ...,\n",
       "         [-1.4771e-02,  7.9346e-03, -8.5449e-03,  ...,  2.0386e-02,\n",
       "           3.0884e-02,  3.0762e-02],\n",
       "         [ 1.8311e-03, -1.8066e-02,  2.5269e-02,  ...,  1.9409e-02,\n",
       "           1.2634e-02, -6.0730e-03],\n",
       "         [-1.1749e-03, -2.9419e-02,  2.4536e-02,  ...,  2.4780e-02,\n",
       "          -9.4604e-03, -1.3611e-02]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.lora_A.weight': tensor([[ 0.0256, -0.0089, -0.0226,  ..., -0.0294,  0.0194, -0.0077],\n",
       "         [-0.0192, -0.0181, -0.0044,  ..., -0.0099,  0.0049, -0.0096],\n",
       "         [-0.0131, -0.0272, -0.0089,  ...,  0.0074, -0.0248, -0.0087],\n",
       "         ...,\n",
       "         [-0.0152,  0.0214, -0.0058,  ...,  0.0277, -0.0042, -0.0148],\n",
       "         [ 0.0237,  0.0108, -0.0220,  ...,  0.0033, -0.0069,  0.0288],\n",
       "         [-0.0042, -0.0212,  0.0065,  ...,  0.0114, -0.0254, -0.0225]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.lora_A.weight': tensor([[ 0.0165,  0.0188, -0.0240,  ..., -0.0005, -0.0259, -0.0128],\n",
       "         [ 0.0226,  0.0210, -0.0084,  ..., -0.0215,  0.0249, -0.0186],\n",
       "         [-0.0040, -0.0194,  0.0023,  ..., -0.0215, -0.0004,  0.0310],\n",
       "         ...,\n",
       "         [ 0.0082, -0.0073, -0.0240,  ..., -0.0049,  0.0064, -0.0280],\n",
       "         [ 0.0100, -0.0125,  0.0186,  ...,  0.0084,  0.0056, -0.0165],\n",
       "         [ 0.0194,  0.0221, -0.0201,  ...,  0.0117, -0.0095, -0.0153]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.lora_A.weight': tensor([[-0.0084, -0.0030,  0.0292,  ..., -0.0090,  0.0036, -0.0282],\n",
       "         [ 0.0215, -0.0250, -0.0087,  ..., -0.0129,  0.0142,  0.0251],\n",
       "         [ 0.0216,  0.0219,  0.0261,  ...,  0.0022,  0.0088, -0.0265],\n",
       "         ...,\n",
       "         [-0.0165,  0.0024,  0.0286,  ..., -0.0125, -0.0300, -0.0286],\n",
       "         [-0.0140, -0.0066, -0.0149,  ...,  0.0273, -0.0084,  0.0069],\n",
       "         [-0.0288,  0.0264, -0.0072,  ..., -0.0063,  0.0073, -0.0047]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.lora_A.weight': tensor([[ 0.0262, -0.0074, -0.0240,  ..., -0.0244, -0.0212,  0.0059],\n",
       "         [ 0.0128, -0.0046, -0.0117,  ..., -0.0029, -0.0020,  0.0221],\n",
       "         [ 0.0061,  0.0134,  0.0010,  ...,  0.0310,  0.0032,  0.0192],\n",
       "         ...,\n",
       "         [ 0.0046, -0.0289, -0.0165,  ...,  0.0122,  0.0068,  0.0020],\n",
       "         [-0.0178, -0.0048,  0.0101,  ..., -0.0292,  0.0197, -0.0047],\n",
       "         [ 0.0156, -0.0027,  0.0289,  ...,  0.0217, -0.0190,  0.0059]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.lora_A.weight': tensor([[-0.0080, -0.0103,  0.0095,  ...,  0.0030,  0.0015, -0.0079],\n",
       "         [-0.0022, -0.0123,  0.0085,  ...,  0.0003, -0.0038,  0.0095],\n",
       "         [-0.0036,  0.0090,  0.0079,  ..., -0.0123, -0.0071,  0.0080],\n",
       "         ...,\n",
       "         [ 0.0013, -0.0128,  0.0154,  ...,  0.0092,  0.0095, -0.0110],\n",
       "         [ 0.0107, -0.0073,  0.0131,  ..., -0.0121,  0.0144,  0.0017],\n",
       "         [-0.0013,  0.0003,  0.0135,  ..., -0.0148,  0.0118, -0.0040]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.lora_A.weight': tensor([[ 0.0060, -0.0066,  0.0026,  ..., -0.0243,  0.0254,  0.0276],\n",
       "         [-0.0267,  0.0160, -0.0109,  ...,  0.0113, -0.0162, -0.0260],\n",
       "         [ 0.0280,  0.0166, -0.0160,  ...,  0.0054,  0.0182,  0.0280],\n",
       "         ...,\n",
       "         [-0.0137, -0.0092,  0.0079,  ...,  0.0305, -0.0146, -0.0010],\n",
       "         [ 0.0167,  0.0052,  0.0099,  ...,  0.0014, -0.0009,  0.0204],\n",
       "         [ 0.0029, -0.0031, -0.0041,  ..., -0.0262, -0.0250,  0.0072]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.lora_A.weight': tensor([[ 0.0067,  0.0052,  0.0222,  ...,  0.0099,  0.0260,  0.0066],\n",
       "         [ 0.0088,  0.0195,  0.0019,  ..., -0.0175,  0.0107, -0.0114],\n",
       "         [ 0.0129, -0.0276,  0.0219,  ..., -0.0281,  0.0009, -0.0152],\n",
       "         ...,\n",
       "         [ 0.0007, -0.0251, -0.0272,  ..., -0.0017, -0.0237,  0.0054],\n",
       "         [ 0.0238,  0.0214,  0.0192,  ..., -0.0305,  0.0245, -0.0267],\n",
       "         [-0.0087, -0.0242,  0.0256,  ...,  0.0056, -0.0032,  0.0293]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.lora_A.weight': tensor([[-0.0238, -0.0075, -0.0200,  ..., -0.0024, -0.0167,  0.0140],\n",
       "         [-0.0209,  0.0006, -0.0097,  ...,  0.0035, -0.0276,  0.0018],\n",
       "         [ 0.0142, -0.0211,  0.0182,  ...,  0.0260,  0.0088, -0.0281],\n",
       "         ...,\n",
       "         [ 0.0093, -0.0143,  0.0066,  ..., -0.0062, -0.0063,  0.0291],\n",
       "         [-0.0182, -0.0198, -0.0086,  ...,  0.0111,  0.0144,  0.0040],\n",
       "         [-0.0209, -0.0121, -0.0267,  ..., -0.0264, -0.0145,  0.0248]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.lora_A.weight': tensor([[ 0.0175,  0.0094, -0.0143,  ...,  0.0276, -0.0067, -0.0060],\n",
       "         [-0.0020,  0.0272, -0.0061,  ..., -0.0052,  0.0033,  0.0106],\n",
       "         [ 0.0183,  0.0145, -0.0117,  ..., -0.0239,  0.0056,  0.0051],\n",
       "         ...,\n",
       "         [ 0.0112,  0.0286,  0.0018,  ..., -0.0045, -0.0099,  0.0210],\n",
       "         [-0.0116, -0.0190, -0.0005,  ...,  0.0015,  0.0052,  0.0010],\n",
       "         [ 0.0038,  0.0115,  0.0130,  ..., -0.0015, -0.0006, -0.0156]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.lora_A.weight': tensor([[ 0.0081, -0.0056,  0.0110,  ...,  0.0117, -0.0123,  0.0146],\n",
       "         [-0.0014,  0.0210, -0.0181,  ..., -0.0120, -0.0126, -0.0143],\n",
       "         [ 0.0205,  0.0063,  0.0271,  ...,  0.0151, -0.0073, -0.0057],\n",
       "         ...,\n",
       "         [ 0.0310, -0.0248,  0.0022,  ...,  0.0042, -0.0089,  0.0250],\n",
       "         [ 0.0165, -0.0016,  0.0031,  ..., -0.0262,  0.0303,  0.0293],\n",
       "         [-0.0183, -0.0232, -0.0311,  ..., -0.0125, -0.0067,  0.0079]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.lora_A.weight': tensor([[-0.0042, -0.0055,  0.0156,  ..., -0.0012, -0.0075,  0.0013],\n",
       "         [ 0.0146, -0.0003, -0.0154,  ...,  0.0072,  0.0031, -0.0049],\n",
       "         [-0.0033,  0.0105,  0.0023,  ..., -0.0130, -0.0126,  0.0003],\n",
       "         ...,\n",
       "         [-0.0122,  0.0112, -0.0063,  ..., -0.0025,  0.0027, -0.0153],\n",
       "         [ 0.0032,  0.0099,  0.0112,  ..., -0.0063, -0.0026,  0.0092],\n",
       "         [ 0.0117, -0.0104,  0.0006,  ..., -0.0006, -0.0066, -0.0024]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.lora_A.weight': tensor([[-0.0041,  0.0225, -0.0293,  ..., -0.0117, -0.0173, -0.0162],\n",
       "         [ 0.0164, -0.0210, -0.0073,  ..., -0.0225, -0.0061,  0.0222],\n",
       "         [-0.0054,  0.0234, -0.0256,  ...,  0.0018,  0.0186, -0.0139],\n",
       "         ...,\n",
       "         [ 0.0079, -0.0226, -0.0253,  ...,  0.0024, -0.0282, -0.0035],\n",
       "         [-0.0027, -0.0236, -0.0269,  ...,  0.0043, -0.0151,  0.0110],\n",
       "         [-0.0214,  0.0251,  0.0056,  ...,  0.0164,  0.0017, -0.0189]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.lora_A.weight': tensor([[-0.0113, -0.0280, -0.0076,  ...,  0.0092,  0.0016,  0.0205],\n",
       "         [ 0.0212,  0.0236, -0.0025,  ...,  0.0229,  0.0119,  0.0298],\n",
       "         [-0.0098, -0.0255, -0.0028,  ...,  0.0234,  0.0109, -0.0154],\n",
       "         ...,\n",
       "         [-0.0031, -0.0165,  0.0276,  ...,  0.0223,  0.0275, -0.0130],\n",
       "         [-0.0227, -0.0251, -0.0073,  ..., -0.0052, -0.0227, -0.0155],\n",
       "         [ 0.0032,  0.0303,  0.0155,  ..., -0.0026,  0.0208,  0.0024]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.lora_A.weight': tensor([[ 0.0092,  0.0157, -0.0138,  ...,  0.0140, -0.0308, -0.0237],\n",
       "         [-0.0019, -0.0157, -0.0122,  ...,  0.0250,  0.0238, -0.0085],\n",
       "         [-0.0141,  0.0140, -0.0018,  ...,  0.0037,  0.0009,  0.0283],\n",
       "         ...,\n",
       "         [-0.0189,  0.0250,  0.0203,  ..., -0.0079,  0.0189, -0.0187],\n",
       "         [-0.0272,  0.0228, -0.0099,  ..., -0.0306, -0.0056,  0.0082],\n",
       "         [ 0.0199, -0.0262,  0.0146,  ...,  0.0016,  0.0280, -0.0153]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.lora_A.weight': tensor([[ 1.5198e-02, -1.2939e-02, -2.6245e-02,  ..., -2.1851e-02,\n",
       "          -2.3438e-02,  3.8910e-04],\n",
       "         [ 6.9809e-04,  2.3438e-02,  2.2339e-02,  ...,  4.2114e-03,\n",
       "          -4.7302e-03, -2.2583e-03],\n",
       "         [-9.5215e-03,  1.7822e-02, -2.5635e-02,  ...,  1.6968e-02,\n",
       "          -1.9287e-02, -1.1301e-04],\n",
       "         ...,\n",
       "         [ 7.0953e-04, -1.7212e-02, -2.5879e-02,  ..., -1.1169e-02,\n",
       "          -2.6123e-02,  2.1362e-02],\n",
       "         [-1.1520e-03, -3.1250e-02,  2.2705e-02,  ...,  2.9297e-02,\n",
       "           1.4282e-02, -2.1606e-02],\n",
       "         [ 2.0752e-02,  2.9175e-02,  7.8125e-03,  ...,  1.8234e-03,\n",
       "           1.0559e-02,  7.7724e-05]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.lora_A.weight': tensor([[-0.0085, -0.0287,  0.0081,  ..., -0.0134,  0.0070, -0.0303],\n",
       "         [-0.0103,  0.0079,  0.0300,  ..., -0.0118,  0.0173,  0.0305],\n",
       "         [ 0.0110,  0.0244, -0.0166,  ..., -0.0254,  0.0259, -0.0243],\n",
       "         ...,\n",
       "         [ 0.0182, -0.0254,  0.0114,  ...,  0.0010, -0.0309, -0.0010],\n",
       "         [ 0.0266, -0.0221, -0.0012,  ...,  0.0184,  0.0212, -0.0178],\n",
       "         [-0.0236, -0.0047,  0.0119,  ..., -0.0164, -0.0033,  0.0109]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.lora_A.weight': tensor([[-0.0008,  0.0067, -0.0137,  ...,  0.0080,  0.0076, -0.0088],\n",
       "         [-0.0073,  0.0112, -0.0049,  ..., -0.0074, -0.0046, -0.0153],\n",
       "         [ 0.0044,  0.0006,  0.0097,  ..., -0.0151, -0.0127,  0.0104],\n",
       "         ...,\n",
       "         [-0.0044, -0.0113, -0.0033,  ..., -0.0150,  0.0089,  0.0118],\n",
       "         [ 0.0051,  0.0081, -0.0003,  ..., -0.0156, -0.0085,  0.0142],\n",
       "         [ 0.0153,  0.0099,  0.0094,  ..., -0.0142,  0.0032, -0.0030]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.lora_A.weight': tensor([[ 0.0232, -0.0073, -0.0294,  ...,  0.0141,  0.0182,  0.0200],\n",
       "         [-0.0047,  0.0225, -0.0219,  ...,  0.0087, -0.0299,  0.0200],\n",
       "         [-0.0260,  0.0295, -0.0170,  ...,  0.0167, -0.0244,  0.0312],\n",
       "         ...,\n",
       "         [-0.0078, -0.0144,  0.0289,  ..., -0.0270, -0.0262,  0.0062],\n",
       "         [-0.0072,  0.0046,  0.0228,  ...,  0.0265, -0.0190,  0.0110],\n",
       "         [-0.0245, -0.0089,  0.0051,  ..., -0.0278,  0.0197,  0.0002]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.lora_A.weight': tensor([[ 0.0250, -0.0270,  0.0028,  ..., -0.0310,  0.0260,  0.0243],\n",
       "         [-0.0087,  0.0049, -0.0260,  ...,  0.0139, -0.0265,  0.0262],\n",
       "         [-0.0222,  0.0040,  0.0293,  ..., -0.0082, -0.0088,  0.0242],\n",
       "         ...,\n",
       "         [-0.0004, -0.0261,  0.0134,  ..., -0.0018, -0.0231,  0.0248],\n",
       "         [ 0.0227, -0.0280, -0.0025,  ..., -0.0208,  0.0082,  0.0206],\n",
       "         [-0.0011,  0.0287, -0.0250,  ..., -0.0194, -0.0040,  0.0016]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.lora_A.weight': tensor([[-0.0118, -0.0145, -0.0182,  ..., -0.0009, -0.0272,  0.0104],\n",
       "         [-0.0025, -0.0043,  0.0121,  ...,  0.0154, -0.0242,  0.0051],\n",
       "         [-0.0203,  0.0034,  0.0239,  ...,  0.0217, -0.0004, -0.0293],\n",
       "         ...,\n",
       "         [ 0.0182, -0.0267, -0.0031,  ...,  0.0227, -0.0135, -0.0200],\n",
       "         [ 0.0166,  0.0299,  0.0011,  ..., -0.0057, -0.0107, -0.0071],\n",
       "         [ 0.0189,  0.0161, -0.0203,  ...,  0.0212, -0.0081,  0.0222]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.lora_A.weight': tensor([[-0.0112, -0.0002, -0.0006,  ..., -0.0006, -0.0138, -0.0097],\n",
       "         [ 0.0167, -0.0051,  0.0170,  ..., -0.0217, -0.0088,  0.0014],\n",
       "         [ 0.0306,  0.0008,  0.0049,  ..., -0.0280,  0.0310,  0.0236],\n",
       "         ...,\n",
       "         [-0.0172, -0.0076, -0.0206,  ..., -0.0065, -0.0229, -0.0231],\n",
       "         [ 0.0150,  0.0063,  0.0172,  ..., -0.0057, -0.0052,  0.0262],\n",
       "         [-0.0090, -0.0022, -0.0267,  ...,  0.0234, -0.0077, -0.0150]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.lora_A.weight': tensor([[ 0.0084, -0.0245, -0.0254,  ..., -0.0086,  0.0162, -0.0104],\n",
       "         [-0.0166,  0.0162,  0.0015,  ...,  0.0193, -0.0240, -0.0086],\n",
       "         [-0.0215, -0.0205, -0.0128,  ...,  0.0024,  0.0291,  0.0305],\n",
       "         ...,\n",
       "         [-0.0068,  0.0083,  0.0151,  ...,  0.0017, -0.0142, -0.0259],\n",
       "         [ 0.0079, -0.0193,  0.0125,  ...,  0.0183,  0.0214, -0.0139],\n",
       "         [ 0.0116,  0.0265, -0.0145,  ..., -0.0087, -0.0254,  0.0204]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.lora_A.weight': tensor([[-0.0128, -0.0154,  0.0060,  ..., -0.0098,  0.0152, -0.0102],\n",
       "         [-0.0140,  0.0079, -0.0074,  ...,  0.0003, -0.0011, -0.0123],\n",
       "         [-0.0063,  0.0003,  0.0151,  ...,  0.0005,  0.0049, -0.0067],\n",
       "         ...,\n",
       "         [-0.0044, -0.0053, -0.0041,  ..., -0.0032,  0.0057,  0.0025],\n",
       "         [-0.0018,  0.0064, -0.0015,  ...,  0.0074,  0.0122,  0.0029],\n",
       "         [-0.0039,  0.0131, -0.0138,  ...,  0.0058, -0.0098, -0.0042]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.lora_A.weight': tensor([[-0.0248,  0.0171,  0.0051,  ...,  0.0286, -0.0080, -0.0118],\n",
       "         [ 0.0187,  0.0286,  0.0188,  ...,  0.0007,  0.0135,  0.0195],\n",
       "         [-0.0109,  0.0216, -0.0300,  ...,  0.0190, -0.0239, -0.0157],\n",
       "         ...,\n",
       "         [-0.0121, -0.0142, -0.0023,  ...,  0.0116,  0.0159,  0.0266],\n",
       "         [ 0.0281, -0.0275,  0.0075,  ...,  0.0024, -0.0049, -0.0142],\n",
       "         [-0.0304,  0.0170, -0.0115,  ...,  0.0261,  0.0233,  0.0139]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.lora_A.weight': tensor([[-0.0189, -0.0134,  0.0287,  ..., -0.0010, -0.0259,  0.0061],\n",
       "         [ 0.0273, -0.0006,  0.0210,  ..., -0.0273, -0.0140, -0.0250],\n",
       "         [-0.0077,  0.0134, -0.0293,  ...,  0.0260,  0.0303,  0.0179],\n",
       "         ...,\n",
       "         [-0.0168, -0.0299, -0.0159,  ..., -0.0054, -0.0154, -0.0101],\n",
       "         [ 0.0006, -0.0050,  0.0297,  ...,  0.0195, -0.0240, -0.0261],\n",
       "         [-0.0145,  0.0138,  0.0114,  ...,  0.0021,  0.0209,  0.0264]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.lora_A.weight': tensor([[ 0.0209, -0.0216,  0.0062,  ..., -0.0139,  0.0078,  0.0183],\n",
       "         [ 0.0098, -0.0023, -0.0016,  ..., -0.0243, -0.0192, -0.0145],\n",
       "         [-0.0149, -0.0238, -0.0289,  ...,  0.0247,  0.0234,  0.0188],\n",
       "         ...,\n",
       "         [-0.0128, -0.0031,  0.0280,  ...,  0.0001,  0.0065,  0.0133],\n",
       "         [ 0.0140, -0.0022,  0.0029,  ...,  0.0281, -0.0251,  0.0019],\n",
       "         [ 0.0291, -0.0021,  0.0078,  ...,  0.0293, -0.0190, -0.0066]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.lora_A.weight': tensor([[ 0.0209,  0.0105,  0.0212,  ..., -0.0071, -0.0172,  0.0248],\n",
       "         [-0.0013, -0.0231, -0.0278,  ..., -0.0110,  0.0308, -0.0074],\n",
       "         [ 0.0161,  0.0243,  0.0192,  ..., -0.0034,  0.0141,  0.0011],\n",
       "         ...,\n",
       "         [ 0.0109, -0.0067,  0.0156,  ...,  0.0101, -0.0184,  0.0056],\n",
       "         [-0.0203,  0.0155, -0.0148,  ...,  0.0187,  0.0133,  0.0231],\n",
       "         [ 0.0247, -0.0300, -0.0233,  ...,  0.0153,  0.0038, -0.0249]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.lora_A.weight': tensor([[-0.0253, -0.0160, -0.0294,  ...,  0.0057, -0.0060,  0.0287],\n",
       "         [-0.0135, -0.0264, -0.0110,  ..., -0.0043, -0.0208,  0.0173],\n",
       "         [ 0.0189,  0.0097, -0.0294,  ...,  0.0203, -0.0266,  0.0132],\n",
       "         ...,\n",
       "         [ 0.0194, -0.0135, -0.0236,  ..., -0.0160,  0.0250, -0.0248],\n",
       "         [ 0.0189,  0.0098, -0.0182,  ..., -0.0272,  0.0292, -0.0181],\n",
       "         [ 0.0146,  0.0188, -0.0005,  ..., -0.0221,  0.0177,  0.0215]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.lora_A.weight': tensor([[ 0.0096,  0.0092,  0.0146,  ...,  0.0003, -0.0148,  0.0081],\n",
       "         [-0.0005, -0.0104,  0.0126,  ..., -0.0038, -0.0153,  0.0090],\n",
       "         [-0.0146,  0.0007,  0.0132,  ...,  0.0101, -0.0151, -0.0123],\n",
       "         ...,\n",
       "         [-0.0055, -0.0039,  0.0025,  ...,  0.0098,  0.0056, -0.0113],\n",
       "         [ 0.0003,  0.0067, -0.0012,  ...,  0.0007, -0.0085,  0.0075],\n",
       "         [ 0.0142, -0.0035, -0.0086,  ..., -0.0145, -0.0154,  0.0052]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.lora_A.weight': tensor([[ 2.9541e-02,  9.7046e-03, -2.4902e-02,  ...,  6.7444e-03,\n",
       "           2.1118e-02,  1.7090e-02],\n",
       "         [-1.1780e-02,  9.0942e-03, -1.4587e-02,  ..., -9.6436e-03,\n",
       "           2.6489e-02, -1.8066e-02],\n",
       "         [ 2.6611e-02, -7.5684e-03,  2.4780e-02,  ...,  2.3193e-02,\n",
       "          -2.6245e-02, -2.1362e-02],\n",
       "         ...,\n",
       "         [-2.1973e-02, -1.9897e-02,  1.3611e-02,  ...,  2.6489e-02,\n",
       "          -2.7222e-02, -2.9541e-02],\n",
       "         [ 2.5635e-02,  1.4465e-02, -1.6479e-02,  ..., -8.9722e-03,\n",
       "          -3.0708e-04,  1.6308e-04],\n",
       "         [ 9.6798e-05, -1.3184e-02, -1.6724e-02,  ...,  8.7891e-03,\n",
       "           1.0681e-02,  2.9907e-02]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.lora_A.weight': tensor([[-3.0396e-02,  5.0964e-03, -2.8687e-02,  ...,  9.2773e-03,\n",
       "          -2.6245e-02,  1.9775e-02],\n",
       "         [-2.3193e-02, -1.0437e-02,  2.6855e-02,  ...,  5.9891e-04,\n",
       "          -1.8433e-02, -1.1963e-02],\n",
       "         [-2.3926e-02, -2.7954e-02, -5.6267e-05,  ...,  7.4463e-03,\n",
       "          -2.2095e-02,  1.6235e-02],\n",
       "         ...,\n",
       "         [-2.1515e-03, -1.7090e-02, -9.5825e-03,  ..., -2.2949e-02,\n",
       "           3.6163e-03,  3.1281e-03],\n",
       "         [ 1.1719e-02, -9.5215e-03,  2.2949e-02,  ..., -1.8433e-02,\n",
       "          -5.4626e-03,  4.3106e-04],\n",
       "         [-2.2461e-02, -1.2634e-02,  2.7222e-02,  ..., -1.1841e-02,\n",
       "          -2.1362e-02, -2.3560e-02]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.lora_A.weight': tensor([[ 0.0264,  0.0038,  0.0044,  ...,  0.0165, -0.0054,  0.0067],\n",
       "         [ 0.0154, -0.0248,  0.0041,  ..., -0.0190,  0.0193, -0.0173],\n",
       "         [-0.0172, -0.0298, -0.0132,  ..., -0.0306, -0.0217, -0.0146],\n",
       "         ...,\n",
       "         [-0.0067, -0.0155, -0.0266,  ...,  0.0148,  0.0219, -0.0286],\n",
       "         [-0.0034, -0.0142,  0.0059,  ..., -0.0140, -0.0056, -0.0254],\n",
       "         [ 0.0234,  0.0310, -0.0232,  ..., -0.0232,  0.0267,  0.0216]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.lora_A.weight': tensor([[-0.0146, -0.0121,  0.0092,  ...,  0.0154,  0.0190, -0.0101],\n",
       "         [-0.0074,  0.0094,  0.0126,  ..., -0.0014,  0.0048,  0.0265],\n",
       "         [-0.0030,  0.0243,  0.0239,  ..., -0.0162, -0.0294, -0.0060],\n",
       "         ...,\n",
       "         [-0.0231, -0.0222,  0.0152,  ..., -0.0128, -0.0058, -0.0297],\n",
       "         [-0.0075,  0.0273, -0.0306,  ...,  0.0187,  0.0043, -0.0135],\n",
       "         [-0.0228, -0.0177, -0.0249,  ..., -0.0272,  0.0292,  0.0144]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.lora_A.weight': tensor([[ 0.0136, -0.0132,  0.0150,  ...,  0.0159,  0.0152, -0.0176],\n",
       "         [ 0.0061, -0.0120, -0.0111,  ...,  0.0096,  0.0146,  0.0188],\n",
       "         [ 0.0308, -0.0187,  0.0262,  ...,  0.0113, -0.0302, -0.0228],\n",
       "         ...,\n",
       "         [-0.0152,  0.0150,  0.0197,  ..., -0.0096, -0.0125, -0.0308],\n",
       "         [ 0.0198,  0.0311, -0.0124,  ..., -0.0219, -0.0270,  0.0091],\n",
       "         [ 0.0087, -0.0013, -0.0258,  ...,  0.0275, -0.0060,  0.0277]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.lora_A.weight': tensor([[-0.0073, -0.0115, -0.0029,  ...,  0.0150, -0.0059,  0.0136],\n",
       "         [-0.0112, -0.0097, -0.0011,  ...,  0.0063, -0.0143, -0.0008],\n",
       "         [ 0.0134, -0.0071,  0.0093,  ..., -0.0046, -0.0156,  0.0146],\n",
       "         ...,\n",
       "         [-0.0079,  0.0086,  0.0017,  ...,  0.0150,  0.0017,  0.0024],\n",
       "         [-0.0128,  0.0116, -0.0095,  ..., -0.0137, -0.0099, -0.0049],\n",
       "         [-0.0018, -0.0037, -0.0011,  ..., -0.0014, -0.0036,  0.0054]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.lora_A.weight': tensor([[-0.0040,  0.0041,  0.0286,  ..., -0.0172, -0.0166,  0.0278],\n",
       "         [-0.0297,  0.0306, -0.0078,  ...,  0.0203, -0.0073,  0.0214],\n",
       "         [-0.0050,  0.0150, -0.0309,  ...,  0.0039,  0.0300,  0.0223],\n",
       "         ...,\n",
       "         [ 0.0311, -0.0138, -0.0171,  ..., -0.0011, -0.0002, -0.0176],\n",
       "         [-0.0170,  0.0181,  0.0050,  ...,  0.0005, -0.0225, -0.0298],\n",
       "         [ 0.0020,  0.0078, -0.0186,  ...,  0.0105,  0.0291,  0.0204]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.lora_A.weight': tensor([[-0.0033, -0.0162,  0.0079,  ...,  0.0204, -0.0053,  0.0277],\n",
       "         [-0.0091,  0.0054, -0.0162,  ...,  0.0088,  0.0011, -0.0295],\n",
       "         [ 0.0229, -0.0112, -0.0032,  ...,  0.0024,  0.0176, -0.0162],\n",
       "         ...,\n",
       "         [ 0.0234,  0.0055,  0.0204,  ...,  0.0267,  0.0182, -0.0098],\n",
       "         [-0.0193,  0.0097,  0.0081,  ...,  0.0306, -0.0087, -0.0031],\n",
       "         [-0.0157, -0.0200, -0.0270,  ...,  0.0015,  0.0283,  0.0116]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.lora_A.weight': tensor([[ 9.5825e-03,  7.5073e-03, -1.5137e-02,  ...,  5.4626e-03,\n",
       "           9.0027e-04,  2.7710e-02],\n",
       "         [ 1.5991e-02,  2.1240e-02, -6.1646e-03,  ..., -5.0964e-03,\n",
       "           2.7710e-02,  2.0752e-02],\n",
       "         [ 2.2949e-02,  8.6060e-03,  2.7222e-02,  ..., -2.9541e-02,\n",
       "          -2.4902e-02,  9.2163e-03],\n",
       "         ...,\n",
       "         [-4.2725e-03,  8.0566e-03, -4.8523e-03,  ...,  4.3631e-05,\n",
       "          -2.1606e-02, -2.4902e-02],\n",
       "         [-2.6489e-02,  5.7373e-03,  4.3640e-03,  ...,  1.1658e-02,\n",
       "          -1.8066e-02,  1.8433e-02],\n",
       "         [-1.2695e-02,  1.9409e-02, -2.5024e-02,  ...,  1.2024e-02,\n",
       "          -2.9175e-02,  2.2217e-02]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.lora_A.weight': tensor([[ 0.0199, -0.0181,  0.0123,  ..., -0.0005, -0.0002,  0.0249],\n",
       "         [-0.0209, -0.0065,  0.0304,  ..., -0.0065, -0.0098,  0.0289],\n",
       "         [-0.0283,  0.0015, -0.0015,  ..., -0.0227, -0.0108, -0.0040],\n",
       "         ...,\n",
       "         [-0.0104, -0.0020,  0.0170,  ..., -0.0103, -0.0010, -0.0157],\n",
       "         [ 0.0173, -0.0198, -0.0098,  ..., -0.0234,  0.0262,  0.0199],\n",
       "         [ 0.0106, -0.0308, -0.0242,  ...,  0.0162, -0.0192, -0.0188]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.lora_A.weight': tensor([[ 0.0294,  0.0121, -0.0033,  ...,  0.0066,  0.0034,  0.0159],\n",
       "         [-0.0243, -0.0228, -0.0197,  ...,  0.0175, -0.0192, -0.0221],\n",
       "         [-0.0028, -0.0153, -0.0203,  ..., -0.0219, -0.0217, -0.0021],\n",
       "         ...,\n",
       "         [ 0.0103, -0.0142,  0.0190,  ...,  0.0042, -0.0244,  0.0093],\n",
       "         [-0.0051,  0.0225,  0.0234,  ...,  0.0311, -0.0085, -0.0308],\n",
       "         [-0.0043, -0.0208,  0.0273,  ..., -0.0156,  0.0009,  0.0073]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.lora_A.weight': tensor([[-0.0113,  0.0107, -0.0098,  ...,  0.0042,  0.0011, -0.0020],\n",
       "         [ 0.0083,  0.0047,  0.0081,  ...,  0.0092,  0.0011, -0.0085],\n",
       "         [ 0.0105, -0.0092,  0.0042,  ..., -0.0125,  0.0003,  0.0115],\n",
       "         ...,\n",
       "         [-0.0120, -0.0052, -0.0120,  ...,  0.0014,  0.0083,  0.0102],\n",
       "         [-0.0056, -0.0149, -0.0113,  ...,  0.0126, -0.0115,  0.0117],\n",
       "         [ 0.0089, -0.0042, -0.0055,  ..., -0.0056, -0.0025,  0.0146]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.lora_A.weight': tensor([[-0.0017, -0.0200,  0.0201,  ...,  0.0271,  0.0227,  0.0023],\n",
       "         [ 0.0033,  0.0082,  0.0250,  ..., -0.0292, -0.0145,  0.0075],\n",
       "         [ 0.0256,  0.0062, -0.0136,  ...,  0.0161,  0.0033,  0.0208],\n",
       "         ...,\n",
       "         [ 0.0295,  0.0061,  0.0131,  ...,  0.0027,  0.0016,  0.0123],\n",
       "         [ 0.0226,  0.0098, -0.0192,  ...,  0.0266, -0.0272,  0.0107],\n",
       "         [ 0.0019, -0.0255,  0.0247,  ...,  0.0031, -0.0096, -0.0110]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.lora_A.weight': tensor([[-7.9346e-03,  1.3916e-02,  1.4587e-02,  ..., -2.7344e-02,\n",
       "          -2.1667e-03, -3.0273e-02],\n",
       "         [ 5.1880e-03,  1.3916e-02,  1.7944e-02,  ..., -4.4556e-03,\n",
       "          -1.2207e-02,  2.3438e-02],\n",
       "         [ 6.2561e-03,  2.4536e-02,  1.6602e-02,  ..., -9.7656e-04,\n",
       "           9.1553e-05,  1.9775e-02],\n",
       "         ...,\n",
       "         [ 1.3306e-02, -1.2085e-02,  3.2196e-03,  ...,  1.5991e-02,\n",
       "           1.8066e-02, -7.3853e-03],\n",
       "         [-2.4414e-02, -1.9775e-02,  2.6978e-02,  ...,  1.7700e-02,\n",
       "           2.0752e-02,  2.2888e-03],\n",
       "         [ 2.3071e-02, -6.0730e-03, -2.3315e-02,  ...,  2.3682e-02,\n",
       "           5.5847e-03,  3.0640e-02]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.lora_A.weight': tensor([[-0.0221,  0.0042, -0.0261,  ...,  0.0055,  0.0026, -0.0001],\n",
       "         [-0.0299,  0.0189,  0.0020,  ..., -0.0153, -0.0117,  0.0232],\n",
       "         [ 0.0305,  0.0114, -0.0070,  ..., -0.0019,  0.0238, -0.0068],\n",
       "         ...,\n",
       "         [ 0.0024, -0.0029, -0.0107,  ...,  0.0276,  0.0181,  0.0193],\n",
       "         [-0.0260, -0.0009, -0.0156,  ..., -0.0254,  0.0282,  0.0135],\n",
       "         [-0.0010,  0.0120,  0.0046,  ..., -0.0139,  0.0033,  0.0186]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.lora_A.weight': tensor([[ 0.0028, -0.0097, -0.0160,  ...,  0.0164,  0.0205, -0.0098],\n",
       "         [-0.0160,  0.0116, -0.0010,  ..., -0.0072, -0.0308,  0.0089],\n",
       "         [-0.0149,  0.0044, -0.0002,  ..., -0.0164,  0.0045,  0.0099],\n",
       "         ...,\n",
       "         [ 0.0044, -0.0047,  0.0081,  ...,  0.0275,  0.0231, -0.0024],\n",
       "         [-0.0134,  0.0203, -0.0112,  ..., -0.0072, -0.0160,  0.0239],\n",
       "         [ 0.0123,  0.0087, -0.0212,  ...,  0.0118,  0.0007,  0.0254]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.lora_A.weight': tensor([[ 0.0247,  0.0264, -0.0239,  ...,  0.0120,  0.0089, -0.0251],\n",
       "         [-0.0199,  0.0054, -0.0298,  ..., -0.0303,  0.0187, -0.0264],\n",
       "         [ 0.0146,  0.0087,  0.0096,  ..., -0.0197, -0.0211,  0.0175],\n",
       "         ...,\n",
       "         [-0.0249, -0.0245, -0.0156,  ..., -0.0103, -0.0198,  0.0005],\n",
       "         [ 0.0293, -0.0087,  0.0310,  ...,  0.0095,  0.0242, -0.0157],\n",
       "         [-0.0251,  0.0238,  0.0053,  ..., -0.0256, -0.0168,  0.0102]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.lora_A.weight': tensor([[-0.0131, -0.0060, -0.0152,  ..., -0.0146,  0.0028,  0.0007],\n",
       "         [-0.0134,  0.0079,  0.0126,  ..., -0.0147, -0.0114,  0.0143],\n",
       "         [ 0.0092, -0.0018,  0.0128,  ...,  0.0121, -0.0062, -0.0134],\n",
       "         ...,\n",
       "         [-0.0085, -0.0155,  0.0047,  ..., -0.0004,  0.0145, -0.0103],\n",
       "         [-0.0041,  0.0045, -0.0128,  ...,  0.0104, -0.0009,  0.0096],\n",
       "         [-0.0054,  0.0027,  0.0135,  ...,  0.0122,  0.0156,  0.0070]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.lora_A.weight': tensor([[-0.0250,  0.0085, -0.0190,  ...,  0.0117,  0.0142, -0.0031],\n",
       "         [ 0.0064, -0.0099, -0.0125,  ...,  0.0278,  0.0091,  0.0262],\n",
       "         [ 0.0272, -0.0027,  0.0286,  ..., -0.0306,  0.0017,  0.0152],\n",
       "         ...,\n",
       "         [ 0.0215, -0.0100, -0.0214,  ..., -0.0291, -0.0124, -0.0089],\n",
       "         [ 0.0187,  0.0012,  0.0132,  ..., -0.0312, -0.0188,  0.0294],\n",
       "         [-0.0074, -0.0306, -0.0160,  ..., -0.0254, -0.0280,  0.0183]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.lora_A.weight': tensor([[ 0.0117,  0.0297,  0.0222,  ...,  0.0105, -0.0269, -0.0233],\n",
       "         [-0.0186,  0.0041,  0.0092,  ...,  0.0053, -0.0283, -0.0053],\n",
       "         [ 0.0297,  0.0275, -0.0093,  ...,  0.0135,  0.0287, -0.0056],\n",
       "         ...,\n",
       "         [-0.0041,  0.0131, -0.0054,  ...,  0.0153, -0.0041,  0.0069],\n",
       "         [ 0.0052,  0.0300, -0.0110,  ...,  0.0197, -0.0046, -0.0203],\n",
       "         [ 0.0311, -0.0026,  0.0184,  ..., -0.0233,  0.0298,  0.0239]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.lora_A.weight': tensor([[ 0.0204,  0.0122, -0.0226,  ..., -0.0299, -0.0001,  0.0016],\n",
       "         [ 0.0222, -0.0264, -0.0194,  ..., -0.0234,  0.0123,  0.0030],\n",
       "         [-0.0126,  0.0087, -0.0042,  ..., -0.0175,  0.0035, -0.0231],\n",
       "         ...,\n",
       "         [ 0.0231,  0.0145,  0.0206,  ...,  0.0110,  0.0206,  0.0054],\n",
       "         [-0.0264, -0.0145,  0.0311,  ...,  0.0266,  0.0136,  0.0204],\n",
       "         [ 0.0031, -0.0220,  0.0021,  ..., -0.0244,  0.0090,  0.0200]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.lora_A.weight': tensor([[ 0.0132, -0.0227,  0.0137,  ...,  0.0175,  0.0273,  0.0117],\n",
       "         [-0.0102,  0.0300,  0.0148,  ...,  0.0078, -0.0137, -0.0070],\n",
       "         [ 0.0227,  0.0234,  0.0002,  ...,  0.0024, -0.0189,  0.0312],\n",
       "         ...,\n",
       "         [-0.0262, -0.0254, -0.0287,  ..., -0.0171,  0.0239,  0.0159],\n",
       "         [ 0.0228,  0.0209, -0.0309,  ..., -0.0030,  0.0261, -0.0110],\n",
       "         [-0.0255, -0.0034,  0.0282,  ...,  0.0016, -0.0303, -0.0129]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.lora_A.weight': tensor([[-1.6968e-02, -2.5879e-02,  1.9653e-02,  ...,  3.0640e-02,\n",
       "          -1.1963e-02,  2.0630e-02],\n",
       "         [-1.3428e-02, -5.4932e-03, -1.5747e-02,  ..., -2.8809e-02,\n",
       "           2.4536e-02, -3.0762e-02],\n",
       "         [-2.6245e-02, -2.8320e-02, -1.5869e-02,  ...,  2.4048e-02,\n",
       "           2.2217e-02,  1.1963e-02],\n",
       "         ...,\n",
       "         [-1.2268e-02,  1.6235e-02, -1.4709e-02,  ..., -6.9046e-04,\n",
       "          -1.3916e-02,  3.2196e-03],\n",
       "         [-2.1973e-02, -3.0518e-02,  1.2329e-02,  ..., -8.2397e-03,\n",
       "           1.9043e-02, -3.4790e-03],\n",
       "         [ 1.3855e-02,  4.0531e-05,  7.7209e-03,  ...,  1.4160e-02,\n",
       "           1.5381e-02, -2.2095e-02]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.lora_A.weight': tensor([[ 0.0076,  0.0023, -0.0125,  ..., -0.0084,  0.0086,  0.0080],\n",
       "         [-0.0038,  0.0148,  0.0024,  ..., -0.0006, -0.0093, -0.0038],\n",
       "         [-0.0090,  0.0154, -0.0059,  ...,  0.0121, -0.0101,  0.0101],\n",
       "         ...,\n",
       "         [-0.0035,  0.0014,  0.0154,  ..., -0.0127,  0.0010, -0.0085],\n",
       "         [ 0.0077, -0.0048, -0.0017,  ...,  0.0005, -0.0117, -0.0050],\n",
       "         [ 0.0128,  0.0100,  0.0006,  ...,  0.0045, -0.0022, -0.0099]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.lora_A.weight': tensor([[ 2.0630e-02, -1.3184e-02,  3.0518e-02,  ..., -1.8082e-03,\n",
       "          -2.6367e-02,  8.2970e-05],\n",
       "         [ 2.8809e-02, -2.4414e-02,  2.0386e-02,  ...,  9.9487e-03,\n",
       "          -1.1536e-02, -1.1108e-02],\n",
       "         [ 9.2163e-03, -2.3315e-02,  2.6733e-02,  ..., -2.3315e-02,\n",
       "          -2.2461e-02, -1.0010e-02],\n",
       "         ...,\n",
       "         [-1.0925e-02, -2.7924e-03, -1.8677e-02,  ...,  1.3306e-02,\n",
       "          -1.1963e-02,  1.9653e-02],\n",
       "         [ 3.0640e-02,  3.0151e-02, -1.7578e-02,  ..., -2.2583e-02,\n",
       "           2.4902e-02,  8.1787e-03],\n",
       "         [ 1.2390e-02,  2.5024e-02, -1.2390e-02,  ...,  1.4526e-02,\n",
       "           1.6968e-02, -3.0884e-02]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.lora_A.weight': tensor([[-0.0205, -0.0192,  0.0280,  ...,  0.0255, -0.0194, -0.0101],\n",
       "         [ 0.0026,  0.0062, -0.0107,  ..., -0.0225, -0.0232,  0.0184],\n",
       "         [-0.0134, -0.0186,  0.0162,  ..., -0.0167,  0.0305,  0.0265],\n",
       "         ...,\n",
       "         [-0.0045,  0.0308, -0.0038,  ..., -0.0036, -0.0067, -0.0052],\n",
       "         [ 0.0226, -0.0231, -0.0283,  ...,  0.0233,  0.0194, -0.0069],\n",
       "         [-0.0166, -0.0159, -0.0294,  ..., -0.0056, -0.0292,  0.0128]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.lora_A.weight': tensor([[-0.0305,  0.0039, -0.0127,  ..., -0.0151,  0.0152,  0.0303],\n",
       "         [-0.0220,  0.0045, -0.0014,  ...,  0.0063, -0.0082,  0.0085],\n",
       "         [-0.0228, -0.0159,  0.0157,  ..., -0.0062, -0.0136, -0.0128],\n",
       "         ...,\n",
       "         [-0.0208, -0.0104, -0.0199,  ...,  0.0104, -0.0058, -0.0255],\n",
       "         [ 0.0238,  0.0284,  0.0176,  ..., -0.0277, -0.0092,  0.0289],\n",
       "         [-0.0009,  0.0278, -0.0119,  ...,  0.0173,  0.0302,  0.0012]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.lora_A.weight': tensor([[-0.0286,  0.0273,  0.0199,  ..., -0.0181,  0.0089, -0.0078],\n",
       "         [-0.0177,  0.0050,  0.0018,  ..., -0.0167,  0.0210, -0.0096],\n",
       "         [-0.0269,  0.0077, -0.0028,  ..., -0.0189,  0.0171, -0.0022],\n",
       "         ...,\n",
       "         [ 0.0050,  0.0255, -0.0276,  ...,  0.0170,  0.0094,  0.0205],\n",
       "         [-0.0162, -0.0281, -0.0009,  ..., -0.0064,  0.0029,  0.0281],\n",
       "         [-0.0198, -0.0082,  0.0275,  ..., -0.0118,  0.0067,  0.0260]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.lora_A.weight': tensor([[-0.0142,  0.0243, -0.0129,  ...,  0.0178,  0.0228, -0.0183],\n",
       "         [-0.0048, -0.0171, -0.0126,  ...,  0.0115,  0.0058, -0.0066],\n",
       "         [-0.0281,  0.0176, -0.0108,  ...,  0.0145,  0.0173,  0.0187],\n",
       "         ...,\n",
       "         [ 0.0005,  0.0203,  0.0128,  ...,  0.0150,  0.0190, -0.0026],\n",
       "         [-0.0089,  0.0260,  0.0189,  ...,  0.0164, -0.0177,  0.0311],\n",
       "         [ 0.0029, -0.0205,  0.0219,  ..., -0.0171, -0.0206, -0.0204]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.lora_A.weight': tensor([[ 0.0005,  0.0091,  0.0148,  ...,  0.0156, -0.0114,  0.0147],\n",
       "         [ 0.0037, -0.0020, -0.0046,  ..., -0.0072,  0.0120, -0.0040],\n",
       "         [ 0.0047,  0.0046, -0.0065,  ..., -0.0033, -0.0033, -0.0014],\n",
       "         ...,\n",
       "         [ 0.0123,  0.0002, -0.0124,  ...,  0.0099,  0.0111,  0.0076],\n",
       "         [ 0.0048,  0.0128,  0.0150,  ...,  0.0105, -0.0062, -0.0091],\n",
       "         [ 0.0129, -0.0004,  0.0048,  ...,  0.0120, -0.0068, -0.0082]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.lora_A.weight': tensor([[ 0.0183,  0.0047, -0.0079,  ..., -0.0211,  0.0117,  0.0311],\n",
       "         [-0.0098,  0.0258,  0.0214,  ...,  0.0247, -0.0303, -0.0194],\n",
       "         [ 0.0078, -0.0044,  0.0231,  ...,  0.0284,  0.0010, -0.0211],\n",
       "         ...,\n",
       "         [ 0.0049, -0.0192,  0.0205,  ...,  0.0120,  0.0002,  0.0008],\n",
       "         [-0.0179,  0.0003, -0.0234,  ...,  0.0275,  0.0205, -0.0304],\n",
       "         [ 0.0053, -0.0312,  0.0159,  ...,  0.0177, -0.0065,  0.0220]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.lora_A.weight': tensor([[-0.0135, -0.0291, -0.0265,  ..., -0.0126, -0.0211, -0.0289],\n",
       "         [-0.0248, -0.0114,  0.0254,  ...,  0.0258, -0.0205, -0.0270],\n",
       "         [-0.0086, -0.0084,  0.0234,  ..., -0.0168,  0.0010, -0.0111],\n",
       "         ...,\n",
       "         [-0.0269,  0.0080, -0.0106,  ..., -0.0013,  0.0183, -0.0281],\n",
       "         [ 0.0138,  0.0229, -0.0074,  ..., -0.0215,  0.0198, -0.0040],\n",
       "         [ 0.0211,  0.0221,  0.0094,  ...,  0.0009,  0.0192, -0.0002]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.lora_A.weight': tensor([[ 0.0200,  0.0128,  0.0269,  ...,  0.0164, -0.0160, -0.0245],\n",
       "         [-0.0267,  0.0069, -0.0093,  ...,  0.0039,  0.0221,  0.0215],\n",
       "         [-0.0099,  0.0134,  0.0120,  ..., -0.0198, -0.0070, -0.0115],\n",
       "         ...,\n",
       "         [-0.0052,  0.0309,  0.0130,  ...,  0.0148,  0.0193,  0.0275],\n",
       "         [ 0.0055, -0.0311,  0.0057,  ..., -0.0112,  0.0009,  0.0141],\n",
       "         [-0.0245, -0.0238, -0.0060,  ...,  0.0071, -0.0170,  0.0299]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.lora_A.weight': tensor([[ 1.1780e-02,  4.1199e-03,  2.1118e-02,  ...,  3.0823e-03,\n",
       "           1.3916e-02,  8.1787e-03],\n",
       "         [-2.2583e-02,  2.5391e-02, -6.1951e-03,  ...,  1.1292e-02,\n",
       "          -1.6113e-02,  2.0386e-02],\n",
       "         [-7.8583e-04, -1.4099e-02, -2.3438e-02,  ..., -2.1606e-02,\n",
       "           2.3193e-02,  7.1716e-03],\n",
       "         ...,\n",
       "         [-2.1118e-02, -2.9907e-02,  1.3672e-02,  ..., -2.5513e-02,\n",
       "           7.2632e-03, -1.6846e-02],\n",
       "         [ 1.1230e-02,  5.5237e-03, -1.5137e-02,  ...,  6.8665e-03,\n",
       "           2.3926e-02, -1.9531e-02],\n",
       "         [ 1.9287e-02,  9.7656e-03,  2.7832e-02,  ...,  6.5327e-05,\n",
       "          -1.3611e-02,  2.2827e-02]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.lora_A.weight': tensor([[ 0.0231, -0.0165,  0.0098,  ...,  0.0256, -0.0120, -0.0055],\n",
       "         [ 0.0113, -0.0303,  0.0266,  ...,  0.0253,  0.0079,  0.0287],\n",
       "         [ 0.0058,  0.0112, -0.0014,  ...,  0.0262, -0.0229,  0.0027],\n",
       "         ...,\n",
       "         [-0.0144, -0.0054, -0.0151,  ..., -0.0041, -0.0138,  0.0254],\n",
       "         [-0.0025,  0.0275,  0.0038,  ..., -0.0052,  0.0293,  0.0005],\n",
       "         [ 0.0267,  0.0040, -0.0210,  ...,  0.0018,  0.0096, -0.0065]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.lora_A.weight': tensor([[-0.0003,  0.0008,  0.0067,  ...,  0.0092,  0.0020,  0.0146],\n",
       "         [-0.0001,  0.0047, -0.0146,  ...,  0.0156,  0.0059,  0.0056],\n",
       "         [ 0.0088, -0.0042, -0.0030,  ...,  0.0156, -0.0018, -0.0144],\n",
       "         ...,\n",
       "         [-0.0154,  0.0050, -0.0003,  ...,  0.0010,  0.0133,  0.0050],\n",
       "         [ 0.0105,  0.0114,  0.0038,  ...,  0.0069, -0.0117, -0.0071],\n",
       "         [ 0.0004,  0.0143,  0.0063,  ..., -0.0045,  0.0038,  0.0114]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.lora_A.weight': tensor([[ 0.0023, -0.0250, -0.0211,  ...,  0.0038, -0.0205,  0.0300],\n",
       "         [-0.0143, -0.0226, -0.0116,  ...,  0.0239,  0.0214, -0.0089],\n",
       "         [ 0.0297,  0.0262, -0.0271,  ...,  0.0107,  0.0297, -0.0222],\n",
       "         ...,\n",
       "         [ 0.0120,  0.0214,  0.0096,  ...,  0.0042, -0.0255,  0.0025],\n",
       "         [-0.0177,  0.0117, -0.0159,  ..., -0.0124, -0.0125, -0.0109],\n",
       "         [ 0.0048,  0.0056,  0.0016,  ..., -0.0123, -0.0222, -0.0179]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.lora_A.weight': tensor([[ 0.0140, -0.0264, -0.0091,  ...,  0.0165,  0.0199, -0.0089],\n",
       "         [ 0.0221,  0.0303,  0.0129,  ..., -0.0277,  0.0206, -0.0020],\n",
       "         [-0.0153, -0.0176,  0.0245,  ...,  0.0003, -0.0137, -0.0176],\n",
       "         ...,\n",
       "         [-0.0048,  0.0019,  0.0069,  ...,  0.0281,  0.0033, -0.0298],\n",
       "         [-0.0303,  0.0120, -0.0019,  ...,  0.0141, -0.0011, -0.0276],\n",
       "         [-0.0119,  0.0148, -0.0295,  ..., -0.0136, -0.0098, -0.0084]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.lora_A.weight': tensor([[ 0.0226, -0.0002,  0.0260,  ...,  0.0175,  0.0242,  0.0087],\n",
       "         [ 0.0178,  0.0019,  0.0137,  ..., -0.0111, -0.0034, -0.0188],\n",
       "         [ 0.0114,  0.0108, -0.0014,  ...,  0.0134, -0.0021, -0.0177],\n",
       "         ...,\n",
       "         [-0.0236,  0.0272,  0.0123,  ...,  0.0199, -0.0300, -0.0282],\n",
       "         [-0.0205,  0.0164, -0.0216,  ...,  0.0054,  0.0204, -0.0305],\n",
       "         [ 0.0110, -0.0128, -0.0197,  ...,  0.0153,  0.0281,  0.0217]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.lora_A.weight': tensor([[-0.0262,  0.0155, -0.0151,  ..., -0.0110,  0.0104,  0.0178],\n",
       "         [-0.0096,  0.0061, -0.0277,  ...,  0.0013,  0.0106,  0.0200],\n",
       "         [-0.0181, -0.0029,  0.0035,  ..., -0.0019, -0.0051,  0.0115],\n",
       "         ...,\n",
       "         [ 0.0232, -0.0189,  0.0005,  ..., -0.0141,  0.0181, -0.0150],\n",
       "         [ 0.0264,  0.0182, -0.0198,  ...,  0.0097,  0.0245, -0.0051],\n",
       "         [-0.0134, -0.0251,  0.0306,  ..., -0.0293,  0.0226,  0.0295]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.lora_A.weight': tensor([[ 0.0282,  0.0177,  0.0071,  ...,  0.0255, -0.0267,  0.0310],\n",
       "         [ 0.0006, -0.0195,  0.0171,  ...,  0.0237, -0.0113, -0.0119],\n",
       "         [ 0.0098, -0.0120, -0.0063,  ..., -0.0231,  0.0071, -0.0250],\n",
       "         ...,\n",
       "         [-0.0142,  0.0112, -0.0036,  ...,  0.0003,  0.0135,  0.0058],\n",
       "         [ 0.0265, -0.0206, -0.0189,  ...,  0.0123,  0.0137,  0.0200],\n",
       "         [-0.0027, -0.0161, -0.0043,  ..., -0.0247,  0.0297,  0.0090]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.lora_A.weight': tensor([[ 0.0037,  0.0127,  0.0025,  ..., -0.0025, -0.0018,  0.0150],\n",
       "         [ 0.0048,  0.0150, -0.0014,  ..., -0.0089, -0.0076, -0.0124],\n",
       "         [ 0.0090,  0.0106, -0.0145,  ..., -0.0063, -0.0028,  0.0053],\n",
       "         ...,\n",
       "         [-0.0082, -0.0026, -0.0066,  ..., -0.0083,  0.0059, -0.0148],\n",
       "         [ 0.0151,  0.0087, -0.0081,  ..., -0.0014,  0.0109, -0.0038],\n",
       "         [ 0.0023, -0.0020,  0.0067,  ...,  0.0104, -0.0142,  0.0026]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.lora_A.weight': tensor([[-0.0128, -0.0302, -0.0139,  ...,  0.0156,  0.0015, -0.0251],\n",
       "         [ 0.0160, -0.0146, -0.0190,  ...,  0.0045,  0.0198,  0.0129],\n",
       "         [-0.0128, -0.0195, -0.0044,  ..., -0.0190, -0.0270,  0.0089],\n",
       "         ...,\n",
       "         [-0.0200, -0.0298,  0.0070,  ...,  0.0269,  0.0098,  0.0142],\n",
       "         [-0.0057,  0.0289,  0.0255,  ..., -0.0104,  0.0080, -0.0190],\n",
       "         [ 0.0078,  0.0008,  0.0284,  ...,  0.0280,  0.0254, -0.0118]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.lora_A.weight': tensor([[-0.0166,  0.0179,  0.0007,  ..., -0.0249,  0.0123,  0.0155],\n",
       "         [ 0.0029, -0.0259,  0.0195,  ..., -0.0249,  0.0135, -0.0035],\n",
       "         [ 0.0225,  0.0275,  0.0262,  ...,  0.0106,  0.0270, -0.0240],\n",
       "         ...,\n",
       "         [-0.0193, -0.0256,  0.0272,  ..., -0.0115,  0.0222, -0.0080],\n",
       "         [-0.0145, -0.0052, -0.0136,  ...,  0.0161, -0.0113, -0.0110],\n",
       "         [ 0.0027, -0.0265,  0.0094,  ...,  0.0291, -0.0003,  0.0147]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.lora_A.weight': tensor([[-0.0143,  0.0123, -0.0305,  ..., -0.0063,  0.0172,  0.0071],\n",
       "         [ 0.0092, -0.0172,  0.0304,  ...,  0.0299, -0.0200, -0.0117],\n",
       "         [-0.0114,  0.0298,  0.0305,  ..., -0.0117, -0.0031,  0.0244],\n",
       "         ...,\n",
       "         [-0.0157, -0.0251, -0.0074,  ..., -0.0184, -0.0226, -0.0271],\n",
       "         [ 0.0092, -0.0022,  0.0106,  ...,  0.0266,  0.0024, -0.0030],\n",
       "         [ 0.0199,  0.0309,  0.0055,  ...,  0.0291, -0.0247, -0.0259]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.lora_A.weight': tensor([[ 0.0024,  0.0038,  0.0004,  ...,  0.0107,  0.0194, -0.0078],\n",
       "         [ 0.0121, -0.0161,  0.0105,  ..., -0.0065, -0.0054,  0.0024],\n",
       "         [-0.0072, -0.0136, -0.0088,  ...,  0.0194,  0.0278,  0.0299],\n",
       "         ...,\n",
       "         [ 0.0216,  0.0007, -0.0186,  ..., -0.0270,  0.0205,  0.0189],\n",
       "         [-0.0062, -0.0193,  0.0113,  ...,  0.0300, -0.0205,  0.0067],\n",
       "         [-0.0095,  0.0030, -0.0063,  ...,  0.0310, -0.0277,  0.0025]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.lora_A.weight': tensor([[-0.0007,  0.0150,  0.0291,  ..., -0.0186,  0.0193,  0.0109],\n",
       "         [-0.0211,  0.0212, -0.0129,  ...,  0.0130, -0.0009, -0.0076],\n",
       "         [-0.0164,  0.0282, -0.0298,  ...,  0.0032, -0.0051,  0.0248],\n",
       "         ...,\n",
       "         [-0.0195, -0.0004,  0.0081,  ..., -0.0073, -0.0038, -0.0282],\n",
       "         [ 0.0042,  0.0238, -0.0094,  ..., -0.0292,  0.0112,  0.0008],\n",
       "         [-0.0043,  0.0286, -0.0306,  ..., -0.0181, -0.0023, -0.0199]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.lora_A.weight': tensor([[ 0.0027, -0.0103, -0.0089,  ...,  0.0091,  0.0011,  0.0066],\n",
       "         [ 0.0103, -0.0014, -0.0146,  ..., -0.0133, -0.0074, -0.0067],\n",
       "         [-0.0035,  0.0020,  0.0128,  ..., -0.0088,  0.0005,  0.0115],\n",
       "         ...,\n",
       "         [ 0.0009, -0.0014, -0.0105,  ..., -0.0043, -0.0030, -0.0021],\n",
       "         [ 0.0070,  0.0027, -0.0110,  ...,  0.0024, -0.0019, -0.0130],\n",
       "         [ 0.0064, -0.0016,  0.0058,  ...,  0.0113, -0.0058, -0.0061]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.lora_A.weight': tensor([[-0.0061,  0.0220, -0.0156,  ..., -0.0132,  0.0052,  0.0165],\n",
       "         [ 0.0137,  0.0037,  0.0304,  ...,  0.0282, -0.0262,  0.0278],\n",
       "         [ 0.0155,  0.0287, -0.0114,  ..., -0.0271,  0.0181,  0.0074],\n",
       "         ...,\n",
       "         [ 0.0264,  0.0099, -0.0038,  ...,  0.0168, -0.0176,  0.0151],\n",
       "         [ 0.0284,  0.0186,  0.0135,  ...,  0.0261,  0.0210, -0.0197],\n",
       "         [ 0.0272,  0.0201, -0.0038,  ...,  0.0231, -0.0123,  0.0302]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.lora_A.weight': tensor([[-0.0090,  0.0165, -0.0183,  ..., -0.0020, -0.0253, -0.0247],\n",
       "         [-0.0063, -0.0021,  0.0276,  ...,  0.0287,  0.0085,  0.0115],\n",
       "         [ 0.0128, -0.0004, -0.0288,  ...,  0.0212, -0.0214, -0.0101],\n",
       "         ...,\n",
       "         [ 0.0103, -0.0124, -0.0063,  ..., -0.0293,  0.0012, -0.0293],\n",
       "         [ 0.0086, -0.0310,  0.0058,  ...,  0.0129, -0.0156,  0.0062],\n",
       "         [-0.0231,  0.0226,  0.0057,  ...,  0.0137,  0.0105,  0.0014]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.lora_A.weight': tensor([[-0.0004,  0.0249, -0.0295,  ...,  0.0253, -0.0096, -0.0088],\n",
       "         [-0.0101, -0.0112,  0.0054,  ..., -0.0144,  0.0300,  0.0275],\n",
       "         [ 0.0217, -0.0261, -0.0114,  ...,  0.0293,  0.0292,  0.0123],\n",
       "         ...,\n",
       "         [ 0.0135,  0.0002,  0.0261,  ..., -0.0303,  0.0171, -0.0161],\n",
       "         [-0.0123, -0.0248, -0.0267,  ..., -0.0278,  0.0082, -0.0005],\n",
       "         [-0.0251, -0.0005,  0.0248,  ..., -0.0092, -0.0292, -0.0139]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.lora_A.weight': tensor([[-0.0277,  0.0211,  0.0192,  ..., -0.0112,  0.0186, -0.0292],\n",
       "         [-0.0309, -0.0029, -0.0045,  ...,  0.0029,  0.0013,  0.0051],\n",
       "         [-0.0120, -0.0295,  0.0105,  ...,  0.0181,  0.0020, -0.0072],\n",
       "         ...,\n",
       "         [ 0.0192, -0.0300,  0.0031,  ..., -0.0019, -0.0281,  0.0051],\n",
       "         [ 0.0250, -0.0264, -0.0208,  ...,  0.0282, -0.0294, -0.0245],\n",
       "         [ 0.0106,  0.0118, -0.0186,  ...,  0.0065,  0.0210, -0.0216]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.lora_A.weight': tensor([[ 0.0181,  0.0048, -0.0028,  ...,  0.0020, -0.0162, -0.0278],\n",
       "         [ 0.0177, -0.0066, -0.0042,  ...,  0.0270,  0.0095, -0.0064],\n",
       "         [-0.0096, -0.0293,  0.0172,  ...,  0.0233,  0.0053, -0.0007],\n",
       "         ...,\n",
       "         [-0.0021, -0.0074, -0.0291,  ...,  0.0292,  0.0155,  0.0214],\n",
       "         [ 0.0276, -0.0190, -0.0036,  ..., -0.0228, -0.0095, -0.0042],\n",
       "         [-0.0299, -0.0160,  0.0027,  ...,  0.0284, -0.0295,  0.0103]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.lora_A.weight': tensor([[-0.0090,  0.0087, -0.0077,  ...,  0.0074, -0.0078,  0.0022],\n",
       "         [-0.0139,  0.0096, -0.0109,  ...,  0.0117, -0.0115, -0.0023],\n",
       "         [ 0.0046, -0.0020, -0.0128,  ...,  0.0087,  0.0039,  0.0028],\n",
       "         ...,\n",
       "         [-0.0019,  0.0112,  0.0110,  ...,  0.0148, -0.0024, -0.0132],\n",
       "         [-0.0145, -0.0017, -0.0139,  ...,  0.0046, -0.0134,  0.0103],\n",
       "         [ 0.0128, -0.0029,  0.0040,  ..., -0.0082, -0.0087,  0.0117]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.lora_A.weight': tensor([[-0.0209, -0.0108,  0.0236,  ..., -0.0137, -0.0002, -0.0120],\n",
       "         [-0.0071,  0.0250, -0.0041,  ...,  0.0251, -0.0281, -0.0194],\n",
       "         [ 0.0238,  0.0127,  0.0093,  ..., -0.0118,  0.0205,  0.0148],\n",
       "         ...,\n",
       "         [ 0.0089,  0.0135,  0.0056,  ...,  0.0014,  0.0075, -0.0283],\n",
       "         [ 0.0043, -0.0153,  0.0269,  ...,  0.0051, -0.0232,  0.0140],\n",
       "         [ 0.0261, -0.0113, -0.0151,  ..., -0.0260,  0.0114,  0.0062]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.lora_A.weight': tensor([[-0.0278, -0.0240,  0.0275,  ...,  0.0007,  0.0082, -0.0107],\n",
       "         [-0.0089,  0.0286,  0.0288,  ...,  0.0075, -0.0282,  0.0310],\n",
       "         [-0.0131,  0.0045, -0.0269,  ...,  0.0282,  0.0309, -0.0150],\n",
       "         ...,\n",
       "         [ 0.0248, -0.0283,  0.0262,  ..., -0.0082,  0.0139,  0.0058],\n",
       "         [ 0.0176,  0.0226,  0.0256,  ...,  0.0127,  0.0261, -0.0244],\n",
       "         [-0.0264, -0.0256,  0.0068,  ..., -0.0019,  0.0130, -0.0031]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.lora_A.weight': tensor([[-0.0294,  0.0035,  0.0171,  ...,  0.0184, -0.0003, -0.0162],\n",
       "         [ 0.0310, -0.0303,  0.0280,  ...,  0.0020,  0.0052, -0.0231],\n",
       "         [ 0.0043,  0.0244,  0.0034,  ..., -0.0276,  0.0209, -0.0133],\n",
       "         ...,\n",
       "         [ 0.0183,  0.0134, -0.0020,  ..., -0.0141, -0.0193, -0.0267],\n",
       "         [ 0.0004,  0.0074,  0.0075,  ...,  0.0044,  0.0181, -0.0029],\n",
       "         [ 0.0099, -0.0041, -0.0287,  ...,  0.0084,  0.0299, -0.0266]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.lora_A.weight': tensor([[ 0.0176,  0.0092,  0.0272,  ...,  0.0171, -0.0284, -0.0273],\n",
       "         [ 0.0024,  0.0128,  0.0253,  ...,  0.0289, -0.0172,  0.0106],\n",
       "         [ 0.0295,  0.0265,  0.0134,  ..., -0.0266, -0.0034,  0.0208],\n",
       "         ...,\n",
       "         [ 0.0092,  0.0166, -0.0201,  ...,  0.0022, -0.0216, -0.0029],\n",
       "         [-0.0247, -0.0277, -0.0294,  ...,  0.0253,  0.0032, -0.0300],\n",
       "         [-0.0298, -0.0011,  0.0079,  ..., -0.0033, -0.0170, -0.0139]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.lora_A.weight': tensor([[-0.0035,  0.0201, -0.0258,  ..., -0.0254,  0.0045, -0.0103],\n",
       "         [ 0.0024,  0.0234,  0.0023,  ...,  0.0220,  0.0238, -0.0089],\n",
       "         [ 0.0242, -0.0175,  0.0217,  ..., -0.0155,  0.0147, -0.0156],\n",
       "         ...,\n",
       "         [ 0.0060,  0.0075,  0.0056,  ..., -0.0132,  0.0183, -0.0066],\n",
       "         [-0.0077,  0.0217, -0.0082,  ..., -0.0281, -0.0093,  0.0206],\n",
       "         [-0.0128, -0.0184,  0.0227,  ...,  0.0165, -0.0204, -0.0013]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.lora_A.weight': tensor([[ 0.0024, -0.0045, -0.0078,  ...,  0.0002, -0.0044,  0.0065],\n",
       "         [ 0.0025,  0.0154, -0.0149,  ..., -0.0144,  0.0030, -0.0121],\n",
       "         [-0.0096,  0.0118,  0.0009,  ..., -0.0150,  0.0068,  0.0011],\n",
       "         ...,\n",
       "         [-0.0146, -0.0038,  0.0125,  ...,  0.0078, -0.0097,  0.0013],\n",
       "         [-0.0034, -0.0100,  0.0020,  ...,  0.0120, -0.0119, -0.0147],\n",
       "         [ 0.0059, -0.0126, -0.0010,  ...,  0.0003, -0.0121, -0.0089]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.lora_A.weight': tensor([[ 0.0309, -0.0155, -0.0201,  ..., -0.0178, -0.0116, -0.0138],\n",
       "         [ 0.0231, -0.0283,  0.0098,  ...,  0.0038,  0.0170, -0.0081],\n",
       "         [ 0.0184, -0.0221, -0.0280,  ...,  0.0275,  0.0284, -0.0311],\n",
       "         ...,\n",
       "         [ 0.0298, -0.0183,  0.0020,  ...,  0.0272, -0.0276, -0.0223],\n",
       "         [-0.0242,  0.0041,  0.0117,  ...,  0.0002, -0.0284, -0.0123],\n",
       "         [-0.0173,  0.0039, -0.0090,  ...,  0.0093, -0.0144, -0.0022]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.lora_A.weight': tensor([[-1.5106e-03,  5.8289e-03, -2.3926e-02,  ...,  1.1780e-02,\n",
       "          -7.4768e-03,  1.9165e-02],\n",
       "         [-9.7656e-03, -2.4902e-02,  2.2339e-02,  ..., -2.6855e-03,\n",
       "          -3.2806e-03,  2.3193e-02],\n",
       "         [-2.6733e-02, -2.6733e-02,  2.1606e-02,  ..., -8.9111e-03,\n",
       "          -1.9287e-02, -2.9785e-02],\n",
       "         ...,\n",
       "         [-2.5513e-02,  2.8809e-02, -2.9785e-02,  ...,  1.2146e-02,\n",
       "           8.3618e-03,  2.7588e-02],\n",
       "         [-1.1902e-02, -1.4709e-02, -8.6060e-03,  ..., -1.3916e-02,\n",
       "          -2.0447e-03, -8.2970e-05],\n",
       "         [ 8.3008e-03,  2.0630e-02, -1.2329e-02,  ..., -7.3547e-03,\n",
       "           4.9438e-03, -1.6724e-02]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.lora_A.weight': tensor([[-0.0077,  0.0008,  0.0137,  ..., -0.0111,  0.0117, -0.0217],\n",
       "         [-0.0198,  0.0294, -0.0162,  ..., -0.0178,  0.0294,  0.0204],\n",
       "         [ 0.0200,  0.0222, -0.0119,  ..., -0.0049,  0.0103,  0.0067],\n",
       "         ...,\n",
       "         [-0.0269,  0.0006,  0.0030,  ..., -0.0206, -0.0051,  0.0292],\n",
       "         [ 0.0167,  0.0006,  0.0047,  ...,  0.0242, -0.0262, -0.0165],\n",
       "         [-0.0014,  0.0033, -0.0150,  ...,  0.0222,  0.0179,  0.0002]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.lora_A.weight': tensor([[-1.2451e-02,  1.2939e-02, -2.7771e-03,  ..., -2.0752e-02,\n",
       "           3.7003e-04,  1.0742e-02],\n",
       "         [ 2.7954e-02, -1.2634e-02, -1.9165e-02,  ..., -1.3062e-02,\n",
       "          -1.6327e-03, -7.6294e-05],\n",
       "         [-2.6733e-02, -2.1118e-02,  2.8809e-02,  ..., -3.0762e-02,\n",
       "           1.2634e-02,  1.1169e-02],\n",
       "         ...,\n",
       "         [-2.7466e-02,  2.7832e-02, -1.3000e-02,  ..., -1.4587e-02,\n",
       "           1.6113e-02, -4.2114e-03],\n",
       "         [ 1.6235e-02,  6.9580e-03,  3.0396e-02,  ..., -2.9663e-02,\n",
       "           1.5137e-02,  2.5757e-02],\n",
       "         [ 2.2217e-02,  6.9885e-03,  4.3945e-03,  ...,  1.8677e-02,\n",
       "          -2.8320e-02, -1.3245e-02]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.lora_A.weight': tensor([[ 0.0304,  0.0139, -0.0171,  ...,  0.0300, -0.0104, -0.0276],\n",
       "         [ 0.0146, -0.0016,  0.0298,  ...,  0.0027, -0.0308,  0.0254],\n",
       "         [-0.0255,  0.0148,  0.0118,  ..., -0.0193,  0.0244,  0.0267],\n",
       "         ...,\n",
       "         [ 0.0217,  0.0056,  0.0217,  ..., -0.0305, -0.0173, -0.0273],\n",
       "         [ 0.0214, -0.0095,  0.0141,  ..., -0.0259, -0.0013, -0.0247],\n",
       "         [ 0.0010, -0.0082, -0.0289,  ..., -0.0248,  0.0261,  0.0024]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.lora_A.weight': tensor([[-0.0005, -0.0030,  0.0064,  ..., -0.0040,  0.0155,  0.0087],\n",
       "         [ 0.0101,  0.0027, -0.0085,  ..., -0.0012,  0.0093, -0.0078],\n",
       "         [-0.0043, -0.0142, -0.0151,  ...,  0.0052,  0.0118, -0.0086],\n",
       "         ...,\n",
       "         [ 0.0028,  0.0094,  0.0080,  ..., -0.0074, -0.0046, -0.0090],\n",
       "         [ 0.0042,  0.0026,  0.0056,  ...,  0.0092,  0.0019, -0.0077],\n",
       "         [-0.0128,  0.0031,  0.0066,  ...,  0.0137,  0.0030, -0.0104]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.lora_A.weight': tensor([[ 0.0132, -0.0203, -0.0004,  ...,  0.0149,  0.0107, -0.0162],\n",
       "         [ 0.0067,  0.0118,  0.0148,  ..., -0.0139, -0.0129, -0.0086],\n",
       "         [-0.0294,  0.0069,  0.0135,  ...,  0.0118,  0.0222,  0.0144],\n",
       "         ...,\n",
       "         [-0.0129,  0.0277,  0.0152,  ...,  0.0244, -0.0142,  0.0023],\n",
       "         [-0.0217, -0.0112, -0.0148,  ..., -0.0040, -0.0282,  0.0172],\n",
       "         [ 0.0029,  0.0293, -0.0210,  ..., -0.0212,  0.0244, -0.0082]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.lora_A.weight': tensor([[ 0.0170, -0.0308, -0.0157,  ..., -0.0284,  0.0283, -0.0002],\n",
       "         [-0.0261, -0.0148,  0.0239,  ...,  0.0063,  0.0045,  0.0229],\n",
       "         [-0.0254,  0.0134, -0.0093,  ...,  0.0083, -0.0189,  0.0098],\n",
       "         ...,\n",
       "         [-0.0281,  0.0249, -0.0206,  ..., -0.0281,  0.0134,  0.0098],\n",
       "         [-0.0280, -0.0077,  0.0131,  ..., -0.0168, -0.0183, -0.0238],\n",
       "         [-0.0190, -0.0267,  0.0188,  ...,  0.0039, -0.0157, -0.0050]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.lora_A.weight': tensor([[-0.0250, -0.0082, -0.0295,  ..., -0.0164, -0.0091, -0.0132],\n",
       "         [-0.0036,  0.0168,  0.0166,  ..., -0.0177,  0.0306, -0.0195],\n",
       "         [ 0.0216, -0.0011, -0.0184,  ...,  0.0302,  0.0297,  0.0086],\n",
       "         ...,\n",
       "         [-0.0109,  0.0221, -0.0225,  ..., -0.0111, -0.0044, -0.0041],\n",
       "         [-0.0032, -0.0112,  0.0244,  ...,  0.0133, -0.0106,  0.0019],\n",
       "         [-0.0074, -0.0018,  0.0108,  ..., -0.0171,  0.0121,  0.0266]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.lora_A.weight': tensor([[-0.0173, -0.0255,  0.0190,  ...,  0.0073, -0.0253, -0.0305],\n",
       "         [-0.0098,  0.0038, -0.0179,  ..., -0.0231,  0.0258,  0.0229],\n",
       "         [-0.0005,  0.0156, -0.0048,  ..., -0.0098, -0.0231,  0.0061],\n",
       "         ...,\n",
       "         [ 0.0092,  0.0270,  0.0066,  ...,  0.0302,  0.0236, -0.0103],\n",
       "         [ 0.0119, -0.0171, -0.0229,  ..., -0.0132, -0.0099, -0.0081],\n",
       "         [ 0.0227, -0.0282,  0.0311,  ...,  0.0079, -0.0124, -0.0245]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.lora_A.weight': tensor([[-0.0148,  0.0017,  0.0258,  ..., -0.0151,  0.0168, -0.0236],\n",
       "         [ 0.0273,  0.0118,  0.0260,  ...,  0.0141, -0.0026, -0.0141],\n",
       "         [ 0.0247,  0.0004, -0.0240,  ..., -0.0135,  0.0259, -0.0239],\n",
       "         ...,\n",
       "         [-0.0117, -0.0167, -0.0243,  ..., -0.0217,  0.0162,  0.0123],\n",
       "         [ 0.0042, -0.0087, -0.0146,  ...,  0.0111, -0.0200,  0.0079],\n",
       "         [-0.0014, -0.0143,  0.0089,  ...,  0.0087,  0.0288, -0.0108]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.lora_A.weight': tensor([[ 0.0037, -0.0054,  0.0061,  ...,  0.0108, -0.0110, -0.0033],\n",
       "         [ 0.0078,  0.0097,  0.0048,  ...,  0.0117, -0.0002, -0.0065],\n",
       "         [ 0.0060, -0.0098, -0.0039,  ..., -0.0019,  0.0115,  0.0104],\n",
       "         ...,\n",
       "         [-0.0105, -0.0078,  0.0052,  ..., -0.0001, -0.0134, -0.0021],\n",
       "         [ 0.0117,  0.0135,  0.0068,  ..., -0.0008, -0.0074,  0.0151],\n",
       "         [ 0.0115,  0.0084, -0.0018,  ...,  0.0010,  0.0078, -0.0036]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.lora_A.weight': tensor([[ 0.0168, -0.0178, -0.0053,  ..., -0.0173, -0.0121,  0.0242],\n",
       "         [ 0.0304,  0.0092, -0.0289,  ..., -0.0265, -0.0072, -0.0200],\n",
       "         [ 0.0077,  0.0184,  0.0271,  ..., -0.0199,  0.0121,  0.0209],\n",
       "         ...,\n",
       "         [ 0.0082,  0.0248, -0.0092,  ..., -0.0277, -0.0186, -0.0165],\n",
       "         [-0.0201, -0.0168, -0.0145,  ..., -0.0048, -0.0072,  0.0227],\n",
       "         [-0.0037,  0.0070, -0.0294,  ..., -0.0190, -0.0150, -0.0063]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.lora_A.weight': tensor([[-0.0183, -0.0193,  0.0070,  ...,  0.0273, -0.0037, -0.0025],\n",
       "         [ 0.0064,  0.0299,  0.0304,  ...,  0.0059,  0.0009,  0.0228],\n",
       "         [-0.0232, -0.0134,  0.0048,  ...,  0.0037,  0.0112, -0.0035],\n",
       "         ...,\n",
       "         [-0.0243,  0.0057,  0.0187,  ..., -0.0089,  0.0036, -0.0039],\n",
       "         [ 0.0112,  0.0295, -0.0106,  ..., -0.0277, -0.0291, -0.0050],\n",
       "         [-0.0275,  0.0066,  0.0253,  ...,  0.0167, -0.0282,  0.0201]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.lora_A.weight': tensor([[-0.0251,  0.0265,  0.0231,  ..., -0.0177,  0.0242, -0.0123],\n",
       "         [-0.0024, -0.0027, -0.0182,  ...,  0.0254, -0.0126, -0.0231],\n",
       "         [ 0.0294, -0.0099, -0.0036,  ..., -0.0304,  0.0284, -0.0118],\n",
       "         ...,\n",
       "         [-0.0082, -0.0287,  0.0042,  ...,  0.0037, -0.0170, -0.0310],\n",
       "         [-0.0061,  0.0168,  0.0086,  ..., -0.0203,  0.0105,  0.0047],\n",
       "         [-0.0175,  0.0288,  0.0291,  ..., -0.0154,  0.0089,  0.0091]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.lora_A.weight': tensor([[-0.0057,  0.0247, -0.0037,  ..., -0.0120,  0.0286, -0.0047],\n",
       "         [ 0.0286,  0.0058,  0.0142,  ..., -0.0166,  0.0232,  0.0121],\n",
       "         [-0.0298,  0.0193, -0.0079,  ...,  0.0270,  0.0100, -0.0156],\n",
       "         ...,\n",
       "         [-0.0027, -0.0109,  0.0228,  ..., -0.0201,  0.0021, -0.0143],\n",
       "         [ 0.0261,  0.0312,  0.0024,  ...,  0.0287,  0.0256, -0.0209],\n",
       "         [-0.0143,  0.0092, -0.0298,  ...,  0.0148, -0.0225, -0.0166]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.lora_A.weight': tensor([[ 0.0085,  0.0240, -0.0247,  ...,  0.0162,  0.0075, -0.0020],\n",
       "         [ 0.0267,  0.0214, -0.0017,  ..., -0.0271,  0.0197,  0.0129],\n",
       "         [ 0.0276,  0.0117,  0.0154,  ..., -0.0248,  0.0020,  0.0120],\n",
       "         ...,\n",
       "         [ 0.0289,  0.0110, -0.0173,  ..., -0.0229, -0.0231, -0.0166],\n",
       "         [-0.0262, -0.0231, -0.0184,  ..., -0.0049,  0.0215,  0.0151],\n",
       "         [ 0.0303,  0.0247, -0.0073,  ..., -0.0093, -0.0245, -0.0068]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.lora_A.weight': tensor([[-0.0107,  0.0010,  0.0055,  ...,  0.0045,  0.0063,  0.0098],\n",
       "         [-0.0131, -0.0052,  0.0021,  ...,  0.0043,  0.0083, -0.0002],\n",
       "         [-0.0115,  0.0078, -0.0154,  ...,  0.0096, -0.0137,  0.0135],\n",
       "         ...,\n",
       "         [-0.0039, -0.0041,  0.0114,  ...,  0.0046, -0.0034, -0.0113],\n",
       "         [ 0.0010, -0.0123,  0.0113,  ...,  0.0056, -0.0096,  0.0017],\n",
       "         [ 0.0125, -0.0058, -0.0134,  ...,  0.0116,  0.0055,  0.0075]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.lora_A.weight': tensor([[ 0.0167,  0.0131,  0.0228,  ...,  0.0079, -0.0005,  0.0085],\n",
       "         [-0.0176,  0.0117,  0.0242,  ...,  0.0017, -0.0228,  0.0203],\n",
       "         [ 0.0054, -0.0258, -0.0096,  ..., -0.0016,  0.0048, -0.0190],\n",
       "         ...,\n",
       "         [ 0.0023,  0.0236,  0.0212,  ...,  0.0012,  0.0065,  0.0038],\n",
       "         [ 0.0123,  0.0059, -0.0019,  ...,  0.0058, -0.0135, -0.0063],\n",
       "         [-0.0311, -0.0242, -0.0273,  ..., -0.0043,  0.0020,  0.0186]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.lora_A.weight': tensor([[ 0.0260,  0.0039, -0.0214,  ..., -0.0236,  0.0142, -0.0212],\n",
       "         [ 0.0035, -0.0120, -0.0084,  ..., -0.0095,  0.0244, -0.0042],\n",
       "         [-0.0168,  0.0282,  0.0175,  ...,  0.0217,  0.0259, -0.0107],\n",
       "         ...,\n",
       "         [-0.0113,  0.0242, -0.0273,  ..., -0.0099, -0.0140, -0.0203],\n",
       "         [-0.0168, -0.0175,  0.0310,  ...,  0.0194,  0.0044, -0.0208],\n",
       "         [ 0.0209, -0.0056, -0.0110,  ..., -0.0229, -0.0101, -0.0278]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.lora_A.weight': tensor([[ 0.0089,  0.0222,  0.0266,  ...,  0.0016,  0.0096, -0.0242],\n",
       "         [-0.0078, -0.0153, -0.0226,  ...,  0.0297, -0.0201,  0.0214],\n",
       "         [-0.0266,  0.0294, -0.0181,  ..., -0.0064,  0.0150,  0.0050],\n",
       "         ...,\n",
       "         [ 0.0264, -0.0222,  0.0022,  ..., -0.0055, -0.0210, -0.0308],\n",
       "         [ 0.0126,  0.0062,  0.0175,  ...,  0.0297, -0.0168, -0.0007],\n",
       "         [-0.0019,  0.0186,  0.0164,  ..., -0.0270,  0.0283,  0.0019]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.lora_A.weight': tensor([[-0.0050, -0.0198, -0.0017,  ..., -0.0024,  0.0133,  0.0073],\n",
       "         [ 0.0143, -0.0081,  0.0117,  ...,  0.0183, -0.0200,  0.0117],\n",
       "         [-0.0022,  0.0151,  0.0159,  ..., -0.0068,  0.0248, -0.0138],\n",
       "         ...,\n",
       "         [ 0.0130,  0.0162,  0.0209,  ...,  0.0038, -0.0135, -0.0194],\n",
       "         [ 0.0120, -0.0294,  0.0042,  ..., -0.0172,  0.0229,  0.0019],\n",
       "         [-0.0295, -0.0085, -0.0135,  ..., -0.0049,  0.0164,  0.0209]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.lora_A.weight': tensor([[-0.0171,  0.0243, -0.0084,  ...,  0.0077, -0.0214,  0.0080],\n",
       "         [ 0.0067,  0.0288,  0.0016,  ..., -0.0142, -0.0060,  0.0118],\n",
       "         [-0.0102,  0.0228, -0.0242,  ..., -0.0121, -0.0125, -0.0084],\n",
       "         ...,\n",
       "         [-0.0289, -0.0042, -0.0254,  ...,  0.0244,  0.0125,  0.0052],\n",
       "         [ 0.0068,  0.0203, -0.0302,  ...,  0.0126,  0.0287, -0.0183],\n",
       "         [-0.0240, -0.0283, -0.0162,  ..., -0.0123, -0.0293, -0.0288]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.lora_A.weight': tensor([[-1.4160e-02, -1.0010e-02, -1.8768e-03,  ..., -9.3994e-03,\n",
       "          -1.7700e-03,  1.4038e-02],\n",
       "         [-1.1780e-02,  8.9722e-03,  2.2736e-03,  ..., -1.2451e-02,\n",
       "           3.1891e-03,  4.5776e-05],\n",
       "         [ 5.5313e-04,  6.2256e-03, -5.4932e-03,  ..., -6.6833e-03,\n",
       "          -9.6436e-03, -7.4005e-04],\n",
       "         ...,\n",
       "         [ 1.0742e-02, -1.0132e-02,  8.2397e-03,  ...,  1.3184e-02,\n",
       "          -1.2695e-02,  3.4027e-03],\n",
       "         [-8.7280e-03,  6.8665e-04,  1.0925e-02,  ...,  1.0986e-02,\n",
       "          -9.0332e-03, -1.2146e-02],\n",
       "         [-1.1683e-04,  6.3171e-03,  1.5198e-02,  ...,  1.4954e-02,\n",
       "           1.4709e-02, -5.3711e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.lora_A.weight': tensor([[ 0.0042,  0.0138, -0.0003,  ...,  0.0276,  0.0029,  0.0117],\n",
       "         [-0.0115,  0.0061, -0.0041,  ..., -0.0123,  0.0225,  0.0110],\n",
       "         [-0.0253,  0.0117,  0.0027,  ..., -0.0220,  0.0131,  0.0273],\n",
       "         ...,\n",
       "         [ 0.0142,  0.0130,  0.0018,  ...,  0.0032, -0.0141, -0.0280],\n",
       "         [-0.0032, -0.0270,  0.0118,  ..., -0.0282, -0.0217, -0.0101],\n",
       "         [ 0.0044,  0.0231, -0.0170,  ...,  0.0198,  0.0063, -0.0046]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.lora_A.weight': tensor([[ 0.0049,  0.0056, -0.0237,  ...,  0.0067,  0.0023, -0.0298],\n",
       "         [ 0.0056, -0.0060, -0.0278,  ..., -0.0128, -0.0242, -0.0039],\n",
       "         [ 0.0200, -0.0013,  0.0107,  ..., -0.0090,  0.0283, -0.0006],\n",
       "         ...,\n",
       "         [-0.0278,  0.0095, -0.0194,  ..., -0.0273, -0.0187,  0.0070],\n",
       "         [ 0.0273,  0.0225, -0.0219,  ..., -0.0182,  0.0231, -0.0065],\n",
       "         [ 0.0195, -0.0232,  0.0005,  ..., -0.0011,  0.0205,  0.0251]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.lora_A.weight': tensor([[-0.0052, -0.0205,  0.0214,  ...,  0.0134,  0.0038, -0.0198],\n",
       "         [-0.0161, -0.0208,  0.0128,  ...,  0.0024,  0.0259,  0.0049],\n",
       "         [-0.0205, -0.0294, -0.0177,  ...,  0.0135,  0.0038,  0.0008],\n",
       "         ...,\n",
       "         [ 0.0154, -0.0149,  0.0083,  ..., -0.0280, -0.0293,  0.0063],\n",
       "         [-0.0181,  0.0084, -0.0238,  ..., -0.0233,  0.0026, -0.0054],\n",
       "         [ 0.0102, -0.0142,  0.0021,  ..., -0.0077,  0.0074,  0.0280]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.lora_A.weight': tensor([[ 0.0100, -0.0058,  0.0265,  ..., -0.0123, -0.0193,  0.0097],\n",
       "         [-0.0189, -0.0242, -0.0089,  ..., -0.0287,  0.0258, -0.0067],\n",
       "         [ 0.0192, -0.0012, -0.0278,  ..., -0.0039,  0.0156, -0.0073],\n",
       "         ...,\n",
       "         [ 0.0035, -0.0187, -0.0083,  ..., -0.0238, -0.0108, -0.0287],\n",
       "         [ 0.0236, -0.0254,  0.0168,  ...,  0.0172, -0.0095,  0.0287],\n",
       "         [-0.0175,  0.0091, -0.0243,  ...,  0.0284,  0.0176, -0.0229]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.lora_A.weight': tensor([[ 2.3560e-02, -1.4591e-04,  2.8076e-02,  ..., -2.6245e-02,\n",
       "          -8.9722e-03, -2.3315e-02],\n",
       "         [ 1.8677e-02,  6.4392e-03, -1.4343e-02,  ..., -8.6060e-03,\n",
       "          -4.0293e-05,  9.2773e-03],\n",
       "         [ 2.8320e-02,  7.4158e-03, -1.9287e-02,  ..., -6.4697e-03,\n",
       "          -2.2278e-03,  5.6458e-03],\n",
       "         ...,\n",
       "         [ 1.8311e-02,  1.0803e-02,  1.6479e-02,  ...,  2.7222e-02,\n",
       "           1.9165e-02, -5.2795e-03],\n",
       "         [ 1.5015e-02,  1.5320e-02,  2.9907e-02,  ..., -1.4954e-02,\n",
       "          -1.7334e-02,  2.7710e-02],\n",
       "         [ 2.3438e-02, -3.0029e-02,  2.1606e-02,  ..., -1.0376e-02,\n",
       "          -2.1484e-02, -7.7209e-03]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.lora_A.weight': tensor([[ 0.0017,  0.0006,  0.0048,  ...,  0.0131, -0.0067, -0.0112],\n",
       "         [ 0.0012, -0.0096, -0.0123,  ..., -0.0049, -0.0109, -0.0054],\n",
       "         [-0.0063, -0.0022, -0.0057,  ..., -0.0072, -0.0079,  0.0114],\n",
       "         ...,\n",
       "         [-0.0138,  0.0151,  0.0042,  ..., -0.0037, -0.0003, -0.0042],\n",
       "         [-0.0001,  0.0045,  0.0025,  ...,  0.0128,  0.0078, -0.0063],\n",
       "         [ 0.0056,  0.0139,  0.0103,  ..., -0.0106, -0.0014, -0.0135]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.lora_A.weight': tensor([[ 0.0097, -0.0272, -0.0297,  ..., -0.0193,  0.0073, -0.0004],\n",
       "         [ 0.0208, -0.0076, -0.0311,  ...,  0.0095,  0.0061,  0.0262],\n",
       "         [ 0.0277,  0.0076,  0.0238,  ..., -0.0166,  0.0135,  0.0190],\n",
       "         ...,\n",
       "         [ 0.0266,  0.0303, -0.0150,  ...,  0.0291, -0.0020,  0.0046],\n",
       "         [ 0.0006, -0.0270,  0.0107,  ..., -0.0267,  0.0179,  0.0007],\n",
       "         [ 0.0115, -0.0284, -0.0020,  ...,  0.0232, -0.0260, -0.0186]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.lora_A.weight': tensor([[-0.0249,  0.0258,  0.0065,  ...,  0.0085,  0.0068, -0.0219],\n",
       "         [-0.0070,  0.0219, -0.0039,  ...,  0.0289, -0.0193, -0.0159],\n",
       "         [ 0.0092, -0.0262,  0.0160,  ..., -0.0220,  0.0068, -0.0217],\n",
       "         ...,\n",
       "         [ 0.0193, -0.0032,  0.0003,  ..., -0.0198,  0.0063, -0.0109],\n",
       "         [ 0.0116, -0.0175, -0.0137,  ..., -0.0204, -0.0166, -0.0110],\n",
       "         [ 0.0009,  0.0030,  0.0006,  ...,  0.0194,  0.0237,  0.0311]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.lora_A.weight': tensor([[ 0.0081, -0.0237, -0.0042,  ..., -0.0237, -0.0204, -0.0161],\n",
       "         [-0.0197, -0.0236, -0.0118,  ...,  0.0237,  0.0013,  0.0033],\n",
       "         [-0.0237,  0.0304, -0.0034,  ...,  0.0215,  0.0109,  0.0141],\n",
       "         ...,\n",
       "         [ 0.0004, -0.0122, -0.0103,  ..., -0.0099,  0.0002, -0.0234],\n",
       "         [ 0.0106,  0.0275, -0.0025,  ..., -0.0052, -0.0030,  0.0057],\n",
       "         [-0.0145, -0.0295,  0.0097,  ..., -0.0278, -0.0259, -0.0065]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.lora_A.weight': tensor([[ 0.0085, -0.0103,  0.0223,  ..., -0.0061,  0.0243,  0.0120],\n",
       "         [-0.0024,  0.0293,  0.0106,  ..., -0.0232,  0.0267, -0.0063],\n",
       "         [-0.0225, -0.0033,  0.0049,  ...,  0.0182, -0.0253,  0.0311],\n",
       "         ...,\n",
       "         [-0.0212, -0.0193,  0.0156,  ...,  0.0129,  0.0178, -0.0139],\n",
       "         [ 0.0069,  0.0306, -0.0297,  ..., -0.0021,  0.0299, -0.0005],\n",
       "         [ 0.0113, -0.0264,  0.0182,  ...,  0.0195,  0.0140, -0.0098]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.lora_A.weight': tensor([[ 0.0093, -0.0105,  0.0227,  ...,  0.0152, -0.0033,  0.0282],\n",
       "         [-0.0242,  0.0084, -0.0217,  ..., -0.0237,  0.0137,  0.0127],\n",
       "         [ 0.0262,  0.0021,  0.0028,  ..., -0.0258, -0.0166,  0.0187],\n",
       "         ...,\n",
       "         [ 0.0070,  0.0173, -0.0093,  ..., -0.0072,  0.0058, -0.0295],\n",
       "         [-0.0276, -0.0154, -0.0251,  ...,  0.0015, -0.0311, -0.0153],\n",
       "         [-0.0282,  0.0048, -0.0032,  ..., -0.0193, -0.0291,  0.0181]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.lora_A.weight': tensor([[-0.0085, -0.0086,  0.0087,  ...,  0.0056, -0.0010,  0.0020],\n",
       "         [ 0.0111, -0.0127, -0.0132,  ...,  0.0098, -0.0036, -0.0066],\n",
       "         [-0.0040,  0.0027, -0.0060,  ...,  0.0149, -0.0022,  0.0093],\n",
       "         ...,\n",
       "         [-0.0030,  0.0070,  0.0048,  ...,  0.0049,  0.0053,  0.0142],\n",
       "         [-0.0143,  0.0051,  0.0019,  ..., -0.0001,  0.0068,  0.0071],\n",
       "         [ 0.0084,  0.0067, -0.0106,  ...,  0.0054,  0.0154,  0.0011]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.lora_A.weight': tensor([[ 0.0137,  0.0001, -0.0132,  ...,  0.0020,  0.0038, -0.0117],\n",
       "         [-0.0003, -0.0042, -0.0184,  ...,  0.0153,  0.0304, -0.0016],\n",
       "         [-0.0247, -0.0131, -0.0032,  ..., -0.0182,  0.0270, -0.0203],\n",
       "         ...,\n",
       "         [-0.0179, -0.0229, -0.0197,  ..., -0.0203,  0.0177, -0.0007],\n",
       "         [-0.0165,  0.0131,  0.0146,  ..., -0.0029,  0.0137,  0.0115],\n",
       "         [ 0.0090, -0.0164,  0.0093,  ..., -0.0275, -0.0061, -0.0098]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.lora_A.weight': tensor([[ 0.0100,  0.0048,  0.0228,  ..., -0.0156, -0.0292,  0.0061],\n",
       "         [-0.0176, -0.0069,  0.0189,  ...,  0.0310, -0.0019,  0.0085],\n",
       "         [-0.0025, -0.0308,  0.0178,  ..., -0.0249,  0.0150,  0.0292],\n",
       "         ...,\n",
       "         [ 0.0027,  0.0223, -0.0099,  ...,  0.0225, -0.0171, -0.0249],\n",
       "         [ 0.0114, -0.0311,  0.0110,  ..., -0.0226,  0.0017,  0.0248],\n",
       "         [ 0.0138,  0.0138,  0.0182,  ...,  0.0198, -0.0071,  0.0018]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.lora_A.weight': tensor([[-0.0120, -0.0155,  0.0266,  ...,  0.0173,  0.0154, -0.0220],\n",
       "         [-0.0113,  0.0251, -0.0156,  ..., -0.0064, -0.0254, -0.0295],\n",
       "         [ 0.0220, -0.0275,  0.0231,  ..., -0.0088, -0.0100, -0.0171],\n",
       "         ...,\n",
       "         [ 0.0221,  0.0021,  0.0038,  ..., -0.0310, -0.0050, -0.0091],\n",
       "         [-0.0010, -0.0002,  0.0308,  ...,  0.0225, -0.0126,  0.0049],\n",
       "         [ 0.0002,  0.0019, -0.0197,  ...,  0.0012, -0.0137,  0.0197]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.lora_A.weight': tensor([[ 0.0134,  0.0070,  0.0023,  ...,  0.0286,  0.0233, -0.0221],\n",
       "         [ 0.0015,  0.0272,  0.0116,  ...,  0.0003, -0.0110, -0.0306],\n",
       "         [ 0.0261, -0.0262, -0.0199,  ..., -0.0147,  0.0184, -0.0144],\n",
       "         ...,\n",
       "         [-0.0200, -0.0045, -0.0033,  ..., -0.0031, -0.0310,  0.0177],\n",
       "         [ 0.0271, -0.0232, -0.0249,  ...,  0.0160, -0.0211, -0.0197],\n",
       "         [ 0.0117,  0.0229,  0.0297,  ...,  0.0275,  0.0108,  0.0261]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.lora_A.weight': tensor([[-0.0238, -0.0203, -0.0015,  ..., -0.0105,  0.0076,  0.0250],\n",
       "         [ 0.0071, -0.0205, -0.0308,  ..., -0.0205,  0.0089,  0.0112],\n",
       "         [-0.0031,  0.0308, -0.0023,  ..., -0.0250,  0.0161,  0.0184],\n",
       "         ...,\n",
       "         [-0.0072,  0.0164, -0.0277,  ..., -0.0287, -0.0079, -0.0227],\n",
       "         [ 0.0312,  0.0217,  0.0177,  ..., -0.0124,  0.0098, -0.0133],\n",
       "         [-0.0208,  0.0040,  0.0062,  ...,  0.0166,  0.0151, -0.0107]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.lora_A.weight': tensor([[ 0.0023,  0.0096,  0.0117,  ...,  0.0118, -0.0023, -0.0120],\n",
       "         [ 0.0106, -0.0073, -0.0027,  ...,  0.0037, -0.0068, -0.0050],\n",
       "         [ 0.0106,  0.0129, -0.0108,  ...,  0.0153, -0.0071,  0.0006],\n",
       "         ...,\n",
       "         [-0.0030,  0.0114, -0.0091,  ...,  0.0021,  0.0120,  0.0098],\n",
       "         [ 0.0070,  0.0029,  0.0031,  ...,  0.0130, -0.0058,  0.0087],\n",
       "         [-0.0114, -0.0115,  0.0049,  ..., -0.0150, -0.0100, -0.0026]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.lora_A.weight': tensor([[ 0.0068, -0.0176, -0.0298,  ..., -0.0014,  0.0035, -0.0298],\n",
       "         [-0.0025,  0.0199,  0.0077,  ..., -0.0184, -0.0156, -0.0247],\n",
       "         [-0.0102, -0.0275, -0.0141,  ..., -0.0085, -0.0005,  0.0255],\n",
       "         ...,\n",
       "         [-0.0312,  0.0042, -0.0178,  ...,  0.0137,  0.0063,  0.0021],\n",
       "         [ 0.0118, -0.0126,  0.0239,  ..., -0.0049, -0.0303, -0.0088],\n",
       "         [-0.0303,  0.0052, -0.0148,  ..., -0.0289,  0.0205,  0.0072]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.lora_A.weight': tensor([[-0.0260,  0.0250,  0.0068,  ...,  0.0281, -0.0112,  0.0039],\n",
       "         [ 0.0306, -0.0156, -0.0297,  ..., -0.0031, -0.0272, -0.0079],\n",
       "         [ 0.0046, -0.0112,  0.0173,  ..., -0.0039,  0.0256, -0.0067],\n",
       "         ...,\n",
       "         [ 0.0038, -0.0050,  0.0305,  ...,  0.0156, -0.0135, -0.0232],\n",
       "         [-0.0156, -0.0282, -0.0212,  ...,  0.0139, -0.0110, -0.0270],\n",
       "         [-0.0042,  0.0121,  0.0137,  ..., -0.0120,  0.0233,  0.0047]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.lora_A.weight': tensor([[ 0.0108, -0.0033, -0.0183,  ...,  0.0227, -0.0037,  0.0197],\n",
       "         [ 0.0311,  0.0269,  0.0061,  ..., -0.0010, -0.0029, -0.0243],\n",
       "         [-0.0173, -0.0192,  0.0302,  ...,  0.0306, -0.0278, -0.0110],\n",
       "         ...,\n",
       "         [ 0.0135,  0.0186,  0.0212,  ..., -0.0142,  0.0258,  0.0071],\n",
       "         [-0.0135, -0.0008,  0.0022,  ...,  0.0067,  0.0022,  0.0222],\n",
       "         [ 0.0017, -0.0186, -0.0149,  ..., -0.0033, -0.0017,  0.0309]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.lora_A.weight': tensor([[ 0.0034,  0.0232, -0.0200,  ..., -0.0132, -0.0029, -0.0232],\n",
       "         [ 0.0167, -0.0305, -0.0064,  ..., -0.0179, -0.0159, -0.0146],\n",
       "         [-0.0048,  0.0149, -0.0194,  ..., -0.0031,  0.0077, -0.0186],\n",
       "         ...,\n",
       "         [-0.0098,  0.0027,  0.0150,  ...,  0.0295, -0.0283,  0.0168],\n",
       "         [ 0.0269,  0.0272,  0.0040,  ..., -0.0053, -0.0118,  0.0203],\n",
       "         [ 0.0035, -0.0188, -0.0209,  ..., -0.0145, -0.0142,  0.0209]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.lora_B.weight': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yesindeed/anaconda3/envs/qwen2/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "FlashAttention2 has been toggled on, but it cannot be used due to the following error: the package flash_attn seems to be not installed. Please refer to the documentation of https://huggingface.co/docs/transformers/perf_infer_gpu_one#flashattention-2 to install Flash Attention 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/home/yesindeed/Documents/Research/codes/ours/MedVLMBench/eval/test.ipynb Cell 12\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/yesindeed/Documents/Research/codes/ours/MedVLMBench/eval/test.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m Qwen2VLForConditionalGeneration, AutoTokenizer, AutoProcessor\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/yesindeed/Documents/Research/codes/ours/MedVLMBench/eval/test.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/yesindeed/Documents/Research/codes/ours/MedVLMBench/eval/test.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m model \u001b[39m=\u001b[39m Qwen2VLForConditionalGeneration\u001b[39m.\u001b[39mfrom_pretrained(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/yesindeed/Documents/Research/codes/ours/MedVLMBench/eval/test.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m/mnt/hdd/weights/Qwen2-VL-7B-Instruct\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/yesindeed/Documents/Research/codes/ours/MedVLMBench/eval/test.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     torch_dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mbfloat16,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/yesindeed/Documents/Research/codes/ours/MedVLMBench/eval/test.ipynb#X14sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     attn_implementation\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mflash_attention_2\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/yesindeed/Documents/Research/codes/ours/MedVLMBench/eval/test.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     device_map\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/yesindeed/Documents/Research/codes/ours/MedVLMBench/eval/test.ipynb#X14sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/qwen2/lib/python3.11/site-packages/transformers/modeling_utils.py:311\u001b[0m, in \u001b[0;36mrestore_default_torch_dtype.<locals>._wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m old_dtype \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mget_default_dtype()\n\u001b[1;32m    310\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 311\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    312\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    313\u001b[0m     torch\u001b[39m.\u001b[39mset_default_dtype(old_dtype)\n",
      "File \u001b[0;32m~/anaconda3/envs/qwen2/lib/python3.11/site-packages/transformers/modeling_utils.py:4805\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4803\u001b[0m config \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(config)  \u001b[39m# We do not want to modify the config inplace in from_pretrained.\u001b[39;00m\n\u001b[1;32m   4804\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mgetattr\u001b[39m(config, \u001b[39m\"\u001b[39m\u001b[39m_attn_implementation_autoset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m-> 4805\u001b[0m     config \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_autoset_attn_implementation(\n\u001b[1;32m   4806\u001b[0m         config,\n\u001b[1;32m   4807\u001b[0m         torch_dtype\u001b[39m=\u001b[39mtorch_dtype,\n\u001b[1;32m   4808\u001b[0m         device_map\u001b[39m=\u001b[39mdevice_map,\n\u001b[1;32m   4809\u001b[0m     )\n\u001b[1;32m   4811\u001b[0m \u001b[39mwith\u001b[39;00m ContextManagers(model_init_context):\n\u001b[1;32m   4812\u001b[0m     \u001b[39m# Let's make sure we don't run the init function of buffer modules\u001b[39;00m\n\u001b[1;32m   4813\u001b[0m     model \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(config, \u001b[39m*\u001b[39mmodel_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/qwen2/lib/python3.11/site-packages/transformers/modeling_utils.py:2360\u001b[0m, in \u001b[0;36mPreTrainedModel._autoset_attn_implementation\u001b[0;34m(cls, config, torch_dtype, device_map, check_device_map)\u001b[0m\n\u001b[1;32m   2352\u001b[0m     \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_check_and_enable_flash_attn_3(\n\u001b[1;32m   2353\u001b[0m         config,\n\u001b[1;32m   2354\u001b[0m         torch_dtype\u001b[39m=\u001b[39mtorch_dtype,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2357\u001b[0m         check_device_map\u001b[39m=\u001b[39mcheck_device_map,\n\u001b[1;32m   2358\u001b[0m     )\n\u001b[1;32m   2359\u001b[0m \u001b[39melif\u001b[39;00m config\u001b[39m.\u001b[39m_attn_implementation \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mflash_attention_2\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m-> 2360\u001b[0m     \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_check_and_enable_flash_attn_2(\n\u001b[1;32m   2361\u001b[0m         config,\n\u001b[1;32m   2362\u001b[0m         torch_dtype\u001b[39m=\u001b[39mtorch_dtype,\n\u001b[1;32m   2363\u001b[0m         device_map\u001b[39m=\u001b[39mdevice_map,\n\u001b[1;32m   2364\u001b[0m         hard_check_only\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m   2365\u001b[0m         check_device_map\u001b[39m=\u001b[39mcheck_device_map,\n\u001b[1;32m   2366\u001b[0m     )\n\u001b[1;32m   2367\u001b[0m \u001b[39melif\u001b[39;00m requested_attn_implementation \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mflex_attention\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   2368\u001b[0m     config \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_check_and_enable_flex_attn(config, hard_check_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/qwen2/lib/python3.11/site-packages/transformers/modeling_utils.py:2502\u001b[0m, in \u001b[0;36mPreTrainedModel._check_and_enable_flash_attn_2\u001b[0;34m(cls, config, torch_dtype, device_map, check_device_map, hard_check_only)\u001b[0m\n\u001b[1;32m   2500\u001b[0m         \u001b[39mreturn\u001b[39;00m config\n\u001b[1;32m   2501\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2502\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpreface\u001b[39m}\u001b[39;00m\u001b[39m the package flash_attn seems to be not installed. \u001b[39m\u001b[39m{\u001b[39;00minstall_message\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   2504\u001b[0m flash_attention_version \u001b[39m=\u001b[39m version\u001b[39m.\u001b[39mparse(importlib\u001b[39m.\u001b[39mmetadata\u001b[39m.\u001b[39mversion(\u001b[39m\"\u001b[39m\u001b[39mflash_attn\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m   2505\u001b[0m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mversion\u001b[39m.\u001b[39mcuda:\n",
      "\u001b[0;31mImportError\u001b[0m: FlashAttention2 has been toggled on, but it cannot be used due to the following error: the package flash_attn seems to be not installed. Please refer to the documentation of https://huggingface.co/docs/transformers/perf_infer_gpu_one#flashattention-2 to install Flash Attention 2."
     ]
    }
   ],
   "source": [
    "from transformers import Qwen2VLForConditionalGeneration, AutoTokenizer, AutoProcessor\n",
    "import torch\n",
    "\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "    \"/mnt/hdd/weights/Qwen2-VL-7B-Instruct\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2VLForConditionalGeneration(\n",
       "  (visual): Qwen2VisionTransformerPretrainedModel(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv3d(3, 1280, kernel_size=(2, 14, 14), stride=(2, 14, 14), bias=False)\n",
       "    )\n",
       "    (rotary_pos_emb): VisionRotaryEmbedding()\n",
       "    (blocks): ModuleList(\n",
       "      (0-31): 32 x Qwen2VLVisionBlock(\n",
       "        (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): VisionSdpaAttention(\n",
       "          (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "          (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (mlp): VisionMlp(\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (act): QuickGELUActivation()\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (merger): PatchMerger(\n",
       "      (ln_q): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=5120, out_features=5120, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=5120, out_features=3584, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (model): Qwen2VLModel(\n",
       "    (embed_tokens): Embedding(152064, 3584)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x Qwen2VLDecoderLayer(\n",
       "        (self_attn): Qwen2VLSdpaAttention(\n",
       "          (q_proj): Linear(in_features=3584, out_features=3584, bias=True)\n",
       "          (k_proj): Linear(in_features=3584, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=3584, out_features=512, bias=True)\n",
       "          (o_proj): Linear(in_features=3584, out_features=3584, bias=False)\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=3584, out_features=18944, bias=False)\n",
       "          (up_proj): Linear(in_features=3584, out_features=18944, bias=False)\n",
       "          (down_proj): Linear(in_features=18944, out_features=3584, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=3584, out_features=152064, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2VLProcessor:\n",
       "- image_processor: Qwen2VLImageProcessor {\n",
       "  \"do_convert_rgb\": true,\n",
       "  \"do_normalize\": true,\n",
       "  \"do_rescale\": true,\n",
       "  \"do_resize\": true,\n",
       "  \"image_mean\": [\n",
       "    0.48145466,\n",
       "    0.4578275,\n",
       "    0.40821073\n",
       "  ],\n",
       "  \"image_processor_type\": \"Qwen2VLImageProcessor\",\n",
       "  \"image_std\": [\n",
       "    0.26862954,\n",
       "    0.26130258,\n",
       "    0.27577711\n",
       "  ],\n",
       "  \"max_pixels\": 12845056,\n",
       "  \"merge_size\": 2,\n",
       "  \"min_pixels\": 3136,\n",
       "  \"patch_size\": 14,\n",
       "  \"processor_class\": \"Qwen2VLProcessor\",\n",
       "  \"resample\": 3,\n",
       "  \"rescale_factor\": 0.00392156862745098,\n",
       "  \"size\": {\n",
       "    \"max_pixels\": 12845056,\n",
       "    \"min_pixels\": 3136\n",
       "  },\n",
       "  \"temporal_patch_size\": 2\n",
       "}\n",
       "\n",
       "- tokenizer: Qwen2TokenizerFast(name_or_path='/mnt/hdd/weights/Qwen2-VL-7B-Instruct', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t151643: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151644: AddedToken(\"<|im_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151645: AddedToken(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151646: AddedToken(\"<|object_ref_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151647: AddedToken(\"<|object_ref_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151648: AddedToken(\"<|box_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151649: AddedToken(\"<|box_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151650: AddedToken(\"<|quad_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151651: AddedToken(\"<|quad_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151652: AddedToken(\"<|vision_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151653: AddedToken(\"<|vision_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151654: AddedToken(\"<|vision_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151655: AddedToken(\"<|image_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151656: AddedToken(\"<|video_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}\n",
       "\n",
       "{\n",
       "  \"processor_class\": \"Qwen2VLProcessor\"\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor = AutoProcessor.from_pretrained(\"/mnt/hdd/weights/Qwen2-VL-7B-Instruct\")\n",
    "processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 6.10 GiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m/home/yesindeed/Documents/Research/codes/ours/MedVLMBench/eval/test.ipynb Cell 15\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yesindeed/Documents/Research/codes/ours/MedVLMBench/eval/test.ipynb#X16sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m inputs \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yesindeed/Documents/Research/codes/ours/MedVLMBench/eval/test.ipynb#X16sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# Inference: Generation of the output\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/yesindeed/Documents/Research/codes/ours/MedVLMBench/eval/test.ipynb#X16sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m generated_ids \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mgenerate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39minputs, max_new_tokens\u001b[39m=\u001b[39m\u001b[39m128\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yesindeed/Documents/Research/codes/ours/MedVLMBench/eval/test.ipynb#X16sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m generated_ids_trimmed \u001b[39m=\u001b[39m [out_ids[\u001b[39mlen\u001b[39m(in_ids) :] \u001b[39mfor\u001b[39;00m in_ids, out_ids \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(inputs\u001b[39m.\u001b[39minput_ids, generated_ids)]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yesindeed/Documents/Research/codes/ours/MedVLMBench/eval/test.ipynb#X16sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m output_text \u001b[39m=\u001b[39m processor\u001b[39m.\u001b[39mbatch_decode(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yesindeed/Documents/Research/codes/ours/MedVLMBench/eval/test.ipynb#X16sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     generated_ids_trimmed, skip_special_tokens\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, clean_up_tokenization_spaces\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yesindeed/Documents/Research/codes/ours/MedVLMBench/eval/test.ipynb#X16sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/qwen2/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/qwen2/lib/python3.11/site-packages/transformers/generation/utils.py:2015\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2007\u001b[0m     input_ids, model_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2008\u001b[0m         input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[1;32m   2009\u001b[0m         expand_size\u001b[39m=\u001b[39mgeneration_config\u001b[39m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2010\u001b[0m         is_encoder_decoder\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2011\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2012\u001b[0m     )\n\u001b[1;32m   2014\u001b[0m     \u001b[39m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2015\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sample(\n\u001b[1;32m   2016\u001b[0m         input_ids,\n\u001b[1;32m   2017\u001b[0m         logits_processor\u001b[39m=\u001b[39mprepared_logits_processor,\n\u001b[1;32m   2018\u001b[0m         stopping_criteria\u001b[39m=\u001b[39mprepared_stopping_criteria,\n\u001b[1;32m   2019\u001b[0m         generation_config\u001b[39m=\u001b[39mgeneration_config,\n\u001b[1;32m   2020\u001b[0m         synced_gpus\u001b[39m=\u001b[39msynced_gpus,\n\u001b[1;32m   2021\u001b[0m         streamer\u001b[39m=\u001b[39mstreamer,\n\u001b[1;32m   2022\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2023\u001b[0m     )\n\u001b[1;32m   2025\u001b[0m \u001b[39melif\u001b[39;00m generation_mode \u001b[39min\u001b[39;00m (GenerationMode\u001b[39m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[39m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2026\u001b[0m     \u001b[39m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   2027\u001b[0m     beam_scorer \u001b[39m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   2028\u001b[0m         batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   2029\u001b[0m         num_beams\u001b[39m=\u001b[39mgeneration_config\u001b[39m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2034\u001b[0m         max_length\u001b[39m=\u001b[39mgeneration_config\u001b[39m.\u001b[39mmax_length,\n\u001b[1;32m   2035\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/qwen2/lib/python3.11/site-packages/transformers/generation/utils.py:2965\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2962\u001b[0m model_inputs\u001b[39m.\u001b[39mupdate({\u001b[39m\"\u001b[39m\u001b[39moutput_hidden_states\u001b[39m\u001b[39m\"\u001b[39m: output_hidden_states} \u001b[39mif\u001b[39;00m output_hidden_states \u001b[39melse\u001b[39;00m {})\n\u001b[1;32m   2964\u001b[0m \u001b[39m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2965\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_inputs, return_dict\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   2967\u001b[0m \u001b[39mif\u001b[39;00m synced_gpus \u001b[39mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2968\u001b[0m     \u001b[39mcontinue\u001b[39;00m  \u001b[39m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/qwen2/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/qwen2/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/qwen2/lib/python3.11/site-packages/transformers/models/qwen2_vl/modeling_qwen2_vl.py:1594\u001b[0m, in \u001b[0;36mQwen2VLForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, pixel_values, pixel_values_videos, image_grid_thw, video_grid_thw, rope_deltas)\u001b[0m\n\u001b[1;32m   1592\u001b[0m \u001b[39mif\u001b[39;00m pixel_values \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1593\u001b[0m     pixel_values \u001b[39m=\u001b[39m pixel_values\u001b[39m.\u001b[39mtype(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisual\u001b[39m.\u001b[39mget_dtype())\n\u001b[0;32m-> 1594\u001b[0m     image_embeds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisual(pixel_values, grid_thw\u001b[39m=\u001b[39mimage_grid_thw)\u001b[39m.\u001b[39mto(inputs_embeds\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m   1595\u001b[0m     image_mask \u001b[39m=\u001b[39m input_ids \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mimage_token_id\n\u001b[1;32m   1596\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining:\n",
      "File \u001b[0;32m~/anaconda3/envs/qwen2/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/qwen2/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/qwen2/lib/python3.11/site-packages/transformers/models/qwen2_vl/modeling_qwen2_vl.py:1040\u001b[0m, in \u001b[0;36mQwen2VisionTransformerPretrainedModel.forward\u001b[0;34m(self, hidden_states, grid_thw)\u001b[0m\n\u001b[1;32m   1037\u001b[0m cu_seqlens \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mpad(cu_seqlens, (\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m), value\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m   1039\u001b[0m \u001b[39mfor\u001b[39;00m blk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks:\n\u001b[0;32m-> 1040\u001b[0m     hidden_states \u001b[39m=\u001b[39m blk(hidden_states, cu_seqlens\u001b[39m=\u001b[39mcu_seqlens, rotary_pos_emb\u001b[39m=\u001b[39mrotary_pos_emb)\n\u001b[1;32m   1042\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmerger(hidden_states)\n",
      "File \u001b[0;32m~/anaconda3/envs/qwen2/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/qwen2/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/qwen2/lib/python3.11/site-packages/transformers/models/qwen2_vl/modeling_qwen2_vl.py:377\u001b[0m, in \u001b[0;36mQwen2VLVisionBlock.forward\u001b[0;34m(self, hidden_states, cu_seqlens, rotary_pos_emb)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states, cu_seqlens, rotary_pos_emb) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m--> 377\u001b[0m     hidden_states \u001b[39m=\u001b[39m hidden_states \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattn(\n\u001b[1;32m    378\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm1(hidden_states), cu_seqlens\u001b[39m=\u001b[39mcu_seqlens, rotary_pos_emb\u001b[39m=\u001b[39mrotary_pos_emb\n\u001b[1;32m    379\u001b[0m     )\n\u001b[1;32m    380\u001b[0m     hidden_states \u001b[39m=\u001b[39m hidden_states \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmlp(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(hidden_states))\n\u001b[1;32m    381\u001b[0m     \u001b[39mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/anaconda3/envs/qwen2/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/qwen2/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/qwen2/lib/python3.11/site-packages/transformers/models/qwen2_vl/modeling_qwen2_vl.py:350\u001b[0m, in \u001b[0;36mVisionSdpaAttention.forward\u001b[0;34m(self, hidden_states, cu_seqlens, rotary_pos_emb)\u001b[0m\n\u001b[1;32m    348\u001b[0m k \u001b[39m=\u001b[39m k\u001b[39m.\u001b[39mtranspose(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m    349\u001b[0m v \u001b[39m=\u001b[39m v\u001b[39m.\u001b[39mtranspose(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m--> 350\u001b[0m attn_output \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mscaled_dot_product_attention(q, k, v, attention_mask, dropout_p\u001b[39m=\u001b[39m\u001b[39m0.0\u001b[39m)\n\u001b[1;32m    351\u001b[0m attn_output \u001b[39m=\u001b[39m attn_output\u001b[39m.\u001b[39mtranspose(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m    352\u001b[0m attn_output \u001b[39m=\u001b[39m attn_output\u001b[39m.\u001b[39mreshape(seq_length, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 6.10 GiB. GPU "
     ]
    }
   ],
   "source": [
    "from qwen_vl_utils import process_vision_info\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"image\",\n",
    "                \"image\": \"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-VL/assets/demo.jpeg\",\n",
    "            },\n",
    "            {\"type\": \"text\", \"text\": \"Describe this image.\"},\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "# Preparation for inference\n",
    "text = processor.apply_chat_template(\n",
    "    messages, tokenize=False, add_generation_prompt=True)\n",
    "image_inputs, video_inputs = process_vision_info(messages)\n",
    "inputs = processor(\n",
    "    text=[text],\n",
    "    images=image_inputs,\n",
    "    videos=video_inputs,\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "inputs = inputs.to(\"cuda\")\n",
    "\n",
    "# Inference: Generation of the output\n",
    "generated_ids = model.generate(**inputs, max_new_tokens=128)\n",
    "generated_ids_trimmed = [out_ids[len(in_ids):] for in_ids, out_ids in zip(\n",
    "    inputs.input_ids, generated_ids)]\n",
    "output_text = processor.batch_decode(\n",
    "    generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlmbenchmark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
